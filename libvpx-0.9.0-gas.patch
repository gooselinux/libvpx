diff --git a/.gitattributes b/.gitattributes
index ffc6912..bcd3151 100644
--- a/.gitattributes
+++ b/.gitattributes
@@ -2,6 +2,7 @@
 *.[ch]pp     filter=fixtabswsp
 *.[ch]xx     filter=fixtabswsp
 *.asm        filter=fixtabswsp
+*.S          filter=fixtabswsp
 *.php        filter=fixtabswsp
 *.pl         filter=fixtabswsp
 *.sh         filter=fixtabswsp
diff --git a/build/make/Makefile b/build/make/Makefile
index 412629e..19e049a 100755
--- a/build/make/Makefile
+++ b/build/make/Makefile
@@ -108,13 +108,13 @@ $(BUILD_PFX)%.c.o: %.c
 	$(if $(quiet),@echo "    [CC] $@")
 	$(qexec)$(CC) $(CFLAGS) -c -o $@ $<
 
-$(BUILD_PFX)%.asm.d: %.asm
+$(BUILD_PFX)%.S.d: %.S
 	$(if $(quiet),@echo "    [DEP] $@")
 	$(qexec)mkdir -p $(dir $@)
 	$(qexec)$(SRC_PATH_BARE)/build/make/gen_asm_deps.sh \
             --build-pfx=$(BUILD_PFX) --depfile=$@ $(ASFLAGS) $< > $@
 
-$(BUILD_PFX)%.asm.o: %.asm
+$(BUILD_PFX)%.S.o: %.S
 	$(if $(quiet),@echo "    [AS] $@")
 	$(qexec)$(AS) $(ASFLAGS) -o $@ $<
 
diff --git a/build/make/configure.sh b/build/make/configure.sh
index ed3a34f..5caaf5d 100755
--- a/build/make/configure.sh
+++ b/build/make/configure.sh
@@ -472,7 +472,7 @@ setup_gnu_toolchain() {
         CC=${CC:-${CROSS}gcc}
         AR=${AR:-${CROSS}ar}
         LD=${LD:-${CROSS}${link_with_cc:-ld}}
-        AS=${AS:-${CROSS}as}
+        AS=${AS:-${CROSS}gcc -c}
     STRIP=${STRIP:-${CROSS}strip}
     NM=${NM:-${CROSS}nm}
         AS_SFX=.s
@@ -753,19 +753,12 @@ process_common_toolchain() {
                 ;;
         esac
 
-        AS=yasm
-        AS_SFX=.asm
+        AS="gcc -c"
+        AS_SFX=.S
+        add_asflags -Wa,-msyntax=intel,-mnaked-reg -m${bits}
+        enabled debug && add_asflags -g
         case  ${tgt_os} in
-            win*)
-                add_asflags -f win${bits}
-                enabled debug && add_asflags -g dwarf2
-            ;;
-            linux*|solaris*)
-                add_asflags -f elf${bits}
-                enabled debug && add_asflags -g dwarf2
-            ;;
             darwin*)
-                add_asflags -f macho${bits}
                 enabled x86 && darwin_arch="-arch i386" || darwin_arch="-arch x86_64"
                 add_cflags  ${darwin_arch}
                 add_ldflags ${darwin_arch}
diff --git a/libs.mk b/libs.mk
index f741dba..c3ef539 100644
--- a/libs.mk
+++ b/libs.mk
@@ -8,7 +8,7 @@
 ##
 
 
-ASM:=$(if $(filter yes,$(CONFIG_GCC)),.asm.s,.asm)
+ASM:=.S
 
 include $(SRC_PATH_BARE)/vpx_codec/vpx_codec.mk
 CODEC_SRCS-yes += $(addprefix vpx_codec/,$(call enabled,API_SRCS))
@@ -87,9 +87,9 @@ CODEC_SRCS-$(BUILD_LIBVPX) += vpx_ports/mem.h
 CODEC_SRCS-$(BUILD_LIBVPX) += $(BUILD_PFX)vpx_config.c
 INSTALL-SRCS-no += $(BUILD_PFX)vpx_config.c
 ifeq ($(ARCH_X86)$(ARCH_X86_64),yes)
-CODEC_SRCS-$(BUILD_LIBVPX) += vpx_ports/emms.asm
+CODEC_SRCS-$(BUILD_LIBVPX) += vpx_ports/emms.S
 CODEC_SRCS-$(BUILD_LIBVPX) += vpx_ports/x86.h
-CODEC_SRCS-$(BUILD_LIBVPX) += vpx_ports/x86_abi_support.asm
+CODEC_SRCS-$(BUILD_LIBVPX) += vpx_ports/x86_abi_support.S
 endif
 CODEC_SRCS-$(ARCH_ARM) += $(BUILD_PFX)vpx_config.asm
 CODEC_EXPORTS-$(BUILD_LIBVPX) += vpx_codec/exports
@@ -184,11 +184,10 @@ $(eval $(if $(LIPO_LIBVPX),$(call lipo_lib_template,libvpx.a)))
 # Rule to make assembler configuration file from C configuration file
 #
 ifeq ($(ARCH_X86)$(ARCH_X86_64),yes)
-# YASM
-$(BUILD_PFX)vpx_config.asm: $(BUILD_PFX)vpx_config.h
+# GCC (gas)
+$(BUILD_PFX)vpx_config.S: $(BUILD_PFX)vpx_config.h
 	@echo "    [CREATE] $@"
-	@egrep "#define [A-Z0-9_]+ [01]" $< \
-	    | awk '{print $$2 " equ " $$3}' > $@
+	@egrep "#define [A-Z0-9_]+ [01]" $< > $@
 else
 ADS2GAS=$(if $(filter yes,$(CONFIG_GCC)),| $(ASM_CONVERSION))
 $(BUILD_PFX)vpx_config.asm: $(BUILD_PFX)vpx_config.h
@@ -205,6 +204,7 @@ endif
 #$(filter %$(ASM).o,$(OBJS-yes)): $(BUILD_PFX)vpx_config.asm $(BUILD_PFX)vpx_asm_offsets.asm
 $(filter %.s.o,$(OBJS-yes)):   $(BUILD_PFX)vpx_config.asm
 $(filter %.asm.o,$(OBJS-yes)): $(BUILD_PFX)vpx_config.asm
+$(filter %.S.o,$(OBJS-yes)): $(BUILD_PFX)vpx_config.S
 
 $(shell $(SRC_PATH_BARE)/build/make/version.sh "$(SRC_PATH_BARE)" $(BUILD_PFX)vpx_version.h)
 CLEAN-OBJS += $(BUILD_PFX)vpx_version.h
diff --git a/vp8/common/x86/idctllm_mmx.S b/vp8/common/x86/idctllm_mmx.S
new file mode 100644
index 0000000..4b5c07b
--- /dev/null
+++ b/vp8/common/x86/idctllm_mmx.S
@@ -0,0 +1,265 @@
+//
+//  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
+//
+//  Use of this source code is governed by a BSD-style license and patent
+//  grant that can be found in the LICENSE file in the root of the source
+//  tree. All contributing project authors may be found in the AUTHORS
+//  file in the root of the source tree.
+//
+
+
+#include "vpx_ports/x86_abi_support.S"
+
+// /****************************************************************************
+// * Notes:
+// *
+// * This implementation makes use of 16 bit fixed point verio of two multiply
+// * constants:
+// *        1.   sqrt(2) * cos (pi/8)
+// *         2.   sqrt(2) * sin (pi/8)
+// * Becuase the first constant is bigger than 1, to maintain the same 16 bit
+// * fixed point prrcision as the second one, we use a trick of
+// *        x * a = x + x*(a-1)
+// * so
+// *        x * sqrt(2) * cos (pi/8) = x + x * (sqrt(2) *cos(pi/8)-1).
+// *
+// * For     the second constant, becuase of the 16bit version is 35468, which
+// * is bigger than 32768, in signed 16 bit multiply, it become a negative
+// * number.
+// *        (x * (unsigned)35468 >> 16) = x * (signed)35468 >> 16 + x
+// *
+// **************************************************************************/
+
+
+//void short_idct4x4llm_mmx(short *input, short *output, int pitch)
+global sym(vp8_short_idct4x4llm_mmx)
+sym(vp8_short_idct4x4llm_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 3
+    GET_GOT     rbx
+    // end prolog
+
+        mov         rax,            arg(0) //input
+        mov         rdx,            arg(1) //output
+
+        movq        mm0,            [rax   ]
+        movq        mm1,            [rax+ 8]
+
+        movq        mm2,            [rax+16]
+        movq        mm3,            [rax+24]
+
+        movsxd      rax,            dword ptr arg(2) //pitch
+
+        psubw       mm0,            mm2             // b1= 0-2
+        paddw       mm2,            mm2             //
+
+        movq        mm5,            mm1
+        paddw       mm2,            mm0             // a1 =0+2
+
+        pmulhw      mm5,            [GLOBAL (x_s1sqr2)]        //
+        paddw       mm5,            mm1             // ip1 * sin(pi/8) * sqrt(2)
+
+        movq        mm7,            mm3             //
+        pmulhw      mm7,            [GLOBAL (x_c1sqr2less1)]    //
+
+        paddw       mm7,            mm3             // ip3 * cos(pi/8) * sqrt(2)
+        psubw       mm7,            mm5             // c1
+
+        movq        mm5,            mm1
+        movq        mm4,            mm3
+
+        pmulhw      mm5,            [GLOBAL (x_c1sqr2less1)]
+        paddw       mm5,            mm1
+
+        pmulhw      mm3,            [GLOBAL (x_s1sqr2)]
+        paddw       mm3,            mm4
+
+        paddw       mm3,            mm5             // d1
+        movq        mm6,            mm2             // a1
+
+        movq        mm4,            mm0             // b1
+        paddw       mm2,            mm3             //0
+
+        paddw       mm4,            mm7             //1
+        psubw       mm0,            mm7             //2
+
+        psubw       mm6,            mm3             //3
+
+        movq        mm1,            mm2             // 03 02 01 00
+        movq        mm3,            mm4             // 23 22 21 20
+
+        punpcklwd   mm1,            mm0             // 11 01 10 00
+        punpckhwd   mm2,            mm0             // 13 03 12 02
+
+        punpcklwd   mm3,            mm6             // 31 21 30 20
+        punpckhwd   mm4,            mm6             // 33 23 32 22
+
+        movq        mm0,            mm1             // 11 01 10 00
+        movq        mm5,            mm2             // 13 03 12 02
+
+        punpckldq   mm0,            mm3             // 30 20 10 00
+        punpckhdq   mm1,            mm3             // 31 21 11 01
+
+        punpckldq   mm2,            mm4             // 32 22 12 02
+        punpckhdq   mm5,            mm4             // 33 23 13 03
+
+        movq        mm3,            mm5             // 33 23 13 03
+
+        psubw       mm0,            mm2             // b1= 0-2
+        paddw       mm2,            mm2             //
+
+        movq        mm5,            mm1
+        paddw       mm2,            mm0             // a1 =0+2
+
+        pmulhw      mm5,            [GLOBAL (x_s1sqr2)]         //
+        paddw       mm5,            mm1             // ip1 * sin(pi/8) * sqrt(2)
+
+        movq        mm7,            mm3             //
+        pmulhw      mm7,            [GLOBAL (x_c1sqr2less1)]    //
+
+        paddw       mm7,            mm3             // ip3 * cos(pi/8) * sqrt(2)
+        psubw       mm7,            mm5             // c1
+
+        movq        mm5,            mm1
+        movq        mm4,            mm3
+
+        pmulhw      mm5,            [GLOBAL (x_c1sqr2less1)]
+        paddw       mm5,            mm1
+
+        pmulhw      mm3,            [GLOBAL (x_s1sqr2)]
+        paddw       mm3,            mm4
+
+        paddw       mm3,            mm5             // d1
+        paddw       mm0,            [GLOBAL (fours)]
+
+        paddw       mm2,            [GLOBAL (fours)]
+        movq        mm6,            mm2             // a1
+
+        movq        mm4,            mm0             // b1
+        paddw       mm2,            mm3             //0
+
+        paddw       mm4,            mm7             //1
+        psubw       mm0,            mm7             //2
+
+        psubw       mm6,            mm3             //3
+        psraw       mm2,            3
+
+        psraw       mm0,            3
+        psraw       mm4,            3
+
+        psraw       mm6,            3
+
+        movq        mm1,            mm2             // 03 02 01 00
+        movq        mm3,            mm4             // 23 22 21 20
+
+        punpcklwd   mm1,            mm0             // 11 01 10 00
+        punpckhwd   mm2,            mm0             // 13 03 12 02
+
+        punpcklwd   mm3,            mm6             // 31 21 30 20
+        punpckhwd   mm4,            mm6             // 33 23 32 22
+
+        movq        mm0,            mm1             // 11 01 10 00
+        movq        mm5,            mm2             // 13 03 12 02
+
+        punpckldq   mm0,            mm3             // 30 20 10 00
+        punpckhdq   mm1,            mm3             // 31 21 11 01
+
+        punpckldq   mm2,            mm4             // 32 22 12 02
+        punpckhdq   mm5,            mm4             // 33 23 13 03
+
+        movq        [rdx],          mm0
+
+        movq        [rdx+rax],      mm1
+        movq        [rdx+rax*2],    mm2
+
+        add         rdx,            rax
+        movq        [rdx+rax*2],    mm5
+
+    // begin epilog
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void short_idct4x4llm_1_mmx(short *input, short *output, int pitch)
+global sym(vp8_short_idct4x4llm_1_mmx)
+sym(vp8_short_idct4x4llm_1_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 3
+    GET_GOT     rbx
+    // end prolog
+
+        mov         rax,            arg(0) //input
+        movd        mm0,            [rax]
+
+        paddw       mm0,            [GLOBAL (fours)]
+        mov         rdx,            arg(1) //output
+
+        psraw       mm0,            3
+        movsxd      rax,            dword ptr arg(2) //pitch
+
+        punpcklwd   mm0,            mm0
+        punpckldq   mm0,            mm0
+
+        movq        [rdx],          mm0
+        movq        [rdx+rax],      mm0
+
+        movq        [rdx+rax*2],    mm0
+        add         rdx,            rax
+
+        movq        [rdx+rax*2],    mm0
+
+
+    // begin epilog
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+//void dc_only_idct_mmx(short input_dc, short *output, int pitch)
+global sym(vp8_dc_only_idct_mmx)
+sym(vp8_dc_only_idct_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 3
+    GET_GOT     rbx
+    // end prolog
+
+        movd        mm0,            arg(0) //input_dc
+
+        paddw       mm0,            [GLOBAL (fours)]
+        mov         rdx,            arg(1) //output
+
+        psraw       mm0,            3
+        movsxd      rax,            dword ptr arg(2) //pitch
+
+        punpcklwd   mm0,            mm0
+        punpckldq   mm0,            mm0
+
+        movq        [rdx],          mm0
+        movq        [rdx+rax],      mm0
+
+        movq        [rdx+rax*2],    mm0
+        add         rdx,            rax
+
+        movq        [rdx+rax*2],    mm0
+
+    // begin epilog
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+SECTION_RODATA
+align 16
+x_s1sqr2:
+    .fill 4, 2, 0x8A8C
+align 16
+x_c1sqr2less1:
+    .fill 4, 2, 0x4E7B
+align 16
+fours:
+    .fill 4, 2, 0x0004
diff --git a/vp8/common/x86/idctllm_mmx.asm b/vp8/common/x86/idctllm_mmx.asm
deleted file mode 100644
index 2751c69..0000000
--- a/vp8/common/x86/idctllm_mmx.asm
+++ /dev/null
@@ -1,265 +0,0 @@
-;
-;  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
-;
-;  Use of this source code is governed by a BSD-style license and patent
-;  grant that can be found in the LICENSE file in the root of the source
-;  tree. All contributing project authors may be found in the AUTHORS
-;  file in the root of the source tree.
-;
-
-
-%include "vpx_ports/x86_abi_support.asm"
-
-; /****************************************************************************
-; * Notes:
-; *
-; * This implementation makes use of 16 bit fixed point verio of two multiply
-; * constants:
-; *        1.   sqrt(2) * cos (pi/8)
-; *         2.   sqrt(2) * sin (pi/8)
-; * Becuase the first constant is bigger than 1, to maintain the same 16 bit
-; * fixed point prrcision as the second one, we use a trick of
-; *        x * a = x + x*(a-1)
-; * so
-; *        x * sqrt(2) * cos (pi/8) = x + x * (sqrt(2) *cos(pi/8)-1).
-; *
-; * For     the second constant, becuase of the 16bit version is 35468, which
-; * is bigger than 32768, in signed 16 bit multiply, it become a negative
-; * number.
-; *        (x * (unsigned)35468 >> 16) = x * (signed)35468 >> 16 + x
-; *
-; **************************************************************************/
-
-
-;void short_idct4x4llm_mmx(short *input, short *output, int pitch)
-global sym(vp8_short_idct4x4llm_mmx)
-sym(vp8_short_idct4x4llm_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 3
-    GET_GOT     rbx
-    ; end prolog
-
-        mov         rax,            arg(0) ;input
-        mov         rdx,            arg(1) ;output
-
-        movq        mm0,            [rax   ]
-        movq        mm1,            [rax+ 8]
-
-        movq        mm2,            [rax+16]
-        movq        mm3,            [rax+24]
-
-        movsxd      rax,            dword ptr arg(2) ;pitch
-
-        psubw       mm0,            mm2             ; b1= 0-2
-        paddw       mm2,            mm2             ;
-
-        movq        mm5,            mm1
-        paddw       mm2,            mm0             ; a1 =0+2
-
-        pmulhw      mm5,            [x_s1sqr2 GLOBAL]        ;
-        paddw       mm5,            mm1             ; ip1 * sin(pi/8) * sqrt(2)
-
-        movq        mm7,            mm3             ;
-        pmulhw      mm7,            [x_c1sqr2less1 GLOBAL]    ;
-
-        paddw       mm7,            mm3             ; ip3 * cos(pi/8) * sqrt(2)
-        psubw       mm7,            mm5             ; c1
-
-        movq        mm5,            mm1
-        movq        mm4,            mm3
-
-        pmulhw      mm5,            [x_c1sqr2less1 GLOBAL]
-        paddw       mm5,            mm1
-
-        pmulhw      mm3,            [x_s1sqr2 GLOBAL]
-        paddw       mm3,            mm4
-
-        paddw       mm3,            mm5             ; d1
-        movq        mm6,            mm2             ; a1
-
-        movq        mm4,            mm0             ; b1
-        paddw       mm2,            mm3             ;0
-
-        paddw       mm4,            mm7             ;1
-        psubw       mm0,            mm7             ;2
-
-        psubw       mm6,            mm3             ;3
-
-        movq        mm1,            mm2             ; 03 02 01 00
-        movq        mm3,            mm4             ; 23 22 21 20
-
-        punpcklwd   mm1,            mm0             ; 11 01 10 00
-        punpckhwd   mm2,            mm0             ; 13 03 12 02
-
-        punpcklwd   mm3,            mm6             ; 31 21 30 20
-        punpckhwd   mm4,            mm6             ; 33 23 32 22
-
-        movq        mm0,            mm1             ; 11 01 10 00
-        movq        mm5,            mm2             ; 13 03 12 02
-
-        punpckldq   mm0,            mm3             ; 30 20 10 00
-        punpckhdq   mm1,            mm3             ; 31 21 11 01
-
-        punpckldq   mm2,            mm4             ; 32 22 12 02
-        punpckhdq   mm5,            mm4             ; 33 23 13 03
-
-        movq        mm3,            mm5             ; 33 23 13 03
-
-        psubw       mm0,            mm2             ; b1= 0-2
-        paddw       mm2,            mm2             ;
-
-        movq        mm5,            mm1
-        paddw       mm2,            mm0             ; a1 =0+2
-
-        pmulhw      mm5,            [x_s1sqr2 GLOBAL]         ;
-        paddw       mm5,            mm1             ; ip1 * sin(pi/8) * sqrt(2)
-
-        movq        mm7,            mm3             ;
-        pmulhw      mm7,            [x_c1sqr2less1 GLOBAL]    ;
-
-        paddw       mm7,            mm3             ; ip3 * cos(pi/8) * sqrt(2)
-        psubw       mm7,            mm5             ; c1
-
-        movq        mm5,            mm1
-        movq        mm4,            mm3
-
-        pmulhw      mm5,            [x_c1sqr2less1 GLOBAL]
-        paddw       mm5,            mm1
-
-        pmulhw      mm3,            [x_s1sqr2 GLOBAL]
-        paddw       mm3,            mm4
-
-        paddw       mm3,            mm5             ; d1
-        paddw       mm0,            [fours GLOBAL]
-
-        paddw       mm2,            [fours GLOBAL]
-        movq        mm6,            mm2             ; a1
-
-        movq        mm4,            mm0             ; b1
-        paddw       mm2,            mm3             ;0
-
-        paddw       mm4,            mm7             ;1
-        psubw       mm0,            mm7             ;2
-
-        psubw       mm6,            mm3             ;3
-        psraw       mm2,            3
-
-        psraw       mm0,            3
-        psraw       mm4,            3
-
-        psraw       mm6,            3
-
-        movq        mm1,            mm2             ; 03 02 01 00
-        movq        mm3,            mm4             ; 23 22 21 20
-
-        punpcklwd   mm1,            mm0             ; 11 01 10 00
-        punpckhwd   mm2,            mm0             ; 13 03 12 02
-
-        punpcklwd   mm3,            mm6             ; 31 21 30 20
-        punpckhwd   mm4,            mm6             ; 33 23 32 22
-
-        movq        mm0,            mm1             ; 11 01 10 00
-        movq        mm5,            mm2             ; 13 03 12 02
-
-        punpckldq   mm0,            mm3             ; 30 20 10 00
-        punpckhdq   mm1,            mm3             ; 31 21 11 01
-
-        punpckldq   mm2,            mm4             ; 32 22 12 02
-        punpckhdq   mm5,            mm4             ; 33 23 13 03
-
-        movq        [rdx],          mm0
-
-        movq        [rdx+rax],      mm1
-        movq        [rdx+rax*2],    mm2
-
-        add         rdx,            rax
-        movq        [rdx+rax*2],    mm5
-
-    ; begin epilog
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void short_idct4x4llm_1_mmx(short *input, short *output, int pitch)
-global sym(vp8_short_idct4x4llm_1_mmx)
-sym(vp8_short_idct4x4llm_1_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 3
-    GET_GOT     rbx
-    ; end prolog
-
-        mov         rax,            arg(0) ;input
-        movd        mm0,            [rax]
-
-        paddw       mm0,            [fours GLOBAL]
-        mov         rdx,            arg(1) ;output
-
-        psraw       mm0,            3
-        movsxd      rax,            dword ptr arg(2) ;pitch
-
-        punpcklwd   mm0,            mm0
-        punpckldq   mm0,            mm0
-
-        movq        [rdx],          mm0
-        movq        [rdx+rax],      mm0
-
-        movq        [rdx+rax*2],    mm0
-        add         rdx,            rax
-
-        movq        [rdx+rax*2],    mm0
-
-
-    ; begin epilog
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-;void dc_only_idct_mmx(short input_dc, short *output, int pitch)
-global sym(vp8_dc_only_idct_mmx)
-sym(vp8_dc_only_idct_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 3
-    GET_GOT     rbx
-    ; end prolog
-
-        movd        mm0,            arg(0) ;input_dc
-
-        paddw       mm0,            [fours GLOBAL]
-        mov         rdx,            arg(1) ;output
-
-        psraw       mm0,            3
-        movsxd      rax,            dword ptr arg(2) ;pitch
-
-        punpcklwd   mm0,            mm0
-        punpckldq   mm0,            mm0
-
-        movq        [rdx],          mm0
-        movq        [rdx+rax],      mm0
-
-        movq        [rdx+rax*2],    mm0
-        add         rdx,            rax
-
-        movq        [rdx+rax*2],    mm0
-
-    ; begin epilog
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-SECTION_RODATA
-align 16
-x_s1sqr2:
-    times 4 dw 0x8A8C
-align 16
-x_c1sqr2less1:
-    times 4 dw 0x4E7B
-align 16
-fours:
-    times 4 dw 0x0004
diff --git a/vp8/common/x86/iwalsh_mmx.S b/vp8/common/x86/iwalsh_mmx.S
new file mode 100644
index 0000000..8505bfc
--- /dev/null
+++ b/vp8/common/x86/iwalsh_mmx.S
@@ -0,0 +1,172 @@
+//
+//  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
+//
+//  Use of this source code is governed by a BSD-style license and patent
+//  grant that can be found in the LICENSE file in the root of the source
+//  tree. All contributing project authors may be found in the AUTHORS
+//  file in the root of the source tree.
+//
+
+
+#include "vpx_ports/x86_abi_support.S"
+
+//void vp8_short_inv_walsh4x4_1_mmx(short *input, short *output)
+global sym(vp8_short_inv_walsh4x4_1_mmx)
+sym(vp8_short_inv_walsh4x4_1_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 2
+    push        rsi
+    push        rdi
+    // end prolog
+
+    mov     rsi, arg(0)
+    mov     rax, 3
+
+    mov     rdi, arg(1)
+    add     rax, [rsi]          //input[0] + 3
+
+    movd    mm0, eax
+
+    punpcklwd mm0, mm0          //x x val val
+
+    punpckldq mm0, mm0          //val val val val
+
+    psraw   mm0, 3            //(input[0] + 3) >> 3
+
+    movq  [rdi + 0], mm0
+    movq  [rdi + 8], mm0
+    movq  [rdi + 16], mm0
+    movq  [rdi + 24], mm0
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+//void vp8_short_inv_walsh4x4_mmx(short *input, short *output)
+global sym(vp8_short_inv_walsh4x4_mmx)
+sym(vp8_short_inv_walsh4x4_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 2
+    push        rsi
+    push        rdi
+    // end prolog
+
+    mov     rax, 3
+    mov     rsi, arg(0)
+    mov     rdi, arg(1)
+    shl     rax, 16
+
+    movq    mm0, [rsi + 0]        //ip[0]
+    movq    mm1, [rsi + 8]        //ip[4]
+    or      rax, 3            //00030003h
+
+    movq    mm2, [rsi + 16]       //ip[8]
+    movq    mm3, [rsi + 24]       //ip[12]
+
+    movd    mm7, rax
+    movq    mm4, mm0
+
+    punpcklwd mm7, mm7          //0003000300030003h
+    movq    mm5, mm1
+
+    paddw   mm4, mm3          //ip[0] + ip[12] aka al
+    paddw   mm5, mm2          //ip[4] + ip[8] aka bl
+
+    movq    mm6, mm4          //temp al
+
+    paddw   mm4, mm5          //al + bl
+    psubw   mm6, mm5          //al - bl
+
+    psubw   mm0, mm3          //ip[0] - ip[12] aka d1
+    psubw   mm1, mm2          //ip[4] - ip[8] aka c1
+
+    movq    mm5, mm0          //temp dl
+
+    paddw   mm0, mm1          //dl + cl
+    psubw   mm5, mm1          //dl - cl
+
+    // 03 02 01 00
+    // 13 12 11 10
+    // 23 22 21 20
+    // 33 32 31 30
+
+    movq    mm3, mm4          // 03 02 01 00
+    punpcklwd mm4, mm0          // 11 01 10 00
+    punpckhwd mm3, mm0          // 13 03 12 02
+
+    movq    mm1, mm6          // 23 22 21 20
+    punpcklwd mm6, mm5          // 31 21 30 20
+    punpckhwd mm1, mm5          // 33 23 32 22
+
+    movq    mm0, mm4          // 11 01 10 00
+    movq    mm2, mm3          // 13 03 12 02
+
+    punpckldq mm0, mm6          // 30 20 10 00 aka ip[0]
+    punpckhdq mm4, mm6          // 31 21 11 01 aka ip[4]
+
+    punpckldq mm2, mm1          // 32 22 12 02 aka ip[8]
+    punpckhdq mm3, mm1          // 33 23 13 03 aka ip[12]
+//~~~~~~~~~~~~~~~~~~~~~
+    movq    mm1, mm0
+    movq    mm5, mm4
+
+    paddw   mm1, mm3          //ip[0] + ip[12] aka al
+    paddw   mm5, mm2          //ip[4] + ip[8] aka bl
+
+    movq    mm6, mm1          //temp al
+
+    paddw   mm1, mm5          //al + bl
+    psubw   mm6, mm5          //al - bl
+
+    psubw   mm0, mm3          //ip[0] - ip[12] aka d1
+    psubw   mm4, mm2          //ip[4] - ip[8] aka c1
+
+    movq    mm5, mm0          //temp dl
+
+    paddw   mm0, mm4          //dl + cl
+    psubw   mm5, mm4          //dl - cl
+//~~~~~~~~~~~~~~~~~~~~~
+    movq    mm3, mm1          // 03 02 01 00
+    punpcklwd mm1, mm0          // 11 01 10 00
+    punpckhwd mm3, mm0          // 13 03 12 02
+
+    movq    mm4, mm6          // 23 22 21 20
+    punpcklwd mm6, mm5          // 31 21 30 20
+    punpckhwd mm4, mm5          // 33 23 32 22
+
+    movq    mm0, mm1          // 11 01 10 00
+    movq    mm2, mm3          // 13 03 12 02
+
+    punpckldq mm0, mm6          // 30 20 10 00 aka ip[0]
+    punpckhdq mm1, mm6          // 31 21 11 01 aka ip[4]
+
+    punpckldq mm2, mm4          // 32 22 12 02 aka ip[8]
+    punpckhdq mm3, mm4          // 33 23 13 03 aka ip[12]
+
+    paddw   mm0, mm7
+    paddw   mm1, mm7
+    paddw   mm2, mm7
+    paddw   mm3, mm7
+
+    psraw   mm0, 3
+    psraw   mm1, 3
+    psraw   mm2, 3
+    psraw   mm3, 3
+
+    movq  [rdi + 0], mm0
+    movq  [rdi + 8], mm1
+    movq  [rdi + 16], mm2
+    movq  [rdi + 24], mm3
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
diff --git a/vp8/common/x86/iwalsh_mmx.asm b/vp8/common/x86/iwalsh_mmx.asm
deleted file mode 100644
index 562e590..0000000
--- a/vp8/common/x86/iwalsh_mmx.asm
+++ /dev/null
@@ -1,172 +0,0 @@
-;
-;  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
-;
-;  Use of this source code is governed by a BSD-style license and patent
-;  grant that can be found in the LICENSE file in the root of the source
-;  tree. All contributing project authors may be found in the AUTHORS
-;  file in the root of the source tree.
-;
-
-
-%include "vpx_ports/x86_abi_support.asm"
-
-;void vp8_short_inv_walsh4x4_1_mmx(short *input, short *output)
-global sym(vp8_short_inv_walsh4x4_1_mmx)
-sym(vp8_short_inv_walsh4x4_1_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 2
-    push        rsi
-    push        rdi
-    ; end prolog
-
-    mov     rsi, arg(0)
-    mov     rax, 3
-
-    mov     rdi, arg(1)
-    add     rax, [rsi]          ;input[0] + 3
-
-    movd    mm0, eax
-
-    punpcklwd mm0, mm0          ;x x val val
-
-    punpckldq mm0, mm0          ;val val val val
-
-    psraw   mm0, 3            ;(input[0] + 3) >> 3
-
-    movq  [rdi + 0], mm0
-    movq  [rdi + 8], mm0
-    movq  [rdi + 16], mm0
-    movq  [rdi + 24], mm0
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-;void vp8_short_inv_walsh4x4_mmx(short *input, short *output)
-global sym(vp8_short_inv_walsh4x4_mmx)
-sym(vp8_short_inv_walsh4x4_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 2
-    push        rsi
-    push        rdi
-    ; end prolog
-
-    mov     rax, 3
-    mov     rsi, arg(0)
-    mov     rdi, arg(1)
-    shl     rax, 16
-
-    movq    mm0, [rsi + 0]        ;ip[0]
-    movq    mm1, [rsi + 8]        ;ip[4]
-    or      rax, 3            ;00030003h
-
-    movq    mm2, [rsi + 16]       ;ip[8]
-    movq    mm3, [rsi + 24]       ;ip[12]
-
-    movd    mm7, rax
-    movq    mm4, mm0
-
-    punpcklwd mm7, mm7          ;0003000300030003h
-    movq    mm5, mm1
-
-    paddw   mm4, mm3          ;ip[0] + ip[12] aka al
-    paddw   mm5, mm2          ;ip[4] + ip[8] aka bl
-
-    movq    mm6, mm4          ;temp al
-
-    paddw   mm4, mm5          ;al + bl
-    psubw   mm6, mm5          ;al - bl
-
-    psubw   mm0, mm3          ;ip[0] - ip[12] aka d1
-    psubw   mm1, mm2          ;ip[4] - ip[8] aka c1
-
-    movq    mm5, mm0          ;temp dl
-
-    paddw   mm0, mm1          ;dl + cl
-    psubw   mm5, mm1          ;dl - cl
-
-    ; 03 02 01 00
-    ; 13 12 11 10
-    ; 23 22 21 20
-    ; 33 32 31 30
-
-    movq    mm3, mm4          ; 03 02 01 00
-    punpcklwd mm4, mm0          ; 11 01 10 00
-    punpckhwd mm3, mm0          ; 13 03 12 02
-
-    movq    mm1, mm6          ; 23 22 21 20
-    punpcklwd mm6, mm5          ; 31 21 30 20
-    punpckhwd mm1, mm5          ; 33 23 32 22
-
-    movq    mm0, mm4          ; 11 01 10 00
-    movq    mm2, mm3          ; 13 03 12 02
-
-    punpckldq mm0, mm6          ; 30 20 10 00 aka ip[0]
-    punpckhdq mm4, mm6          ; 31 21 11 01 aka ip[4]
-
-    punpckldq mm2, mm1          ; 32 22 12 02 aka ip[8]
-    punpckhdq mm3, mm1          ; 33 23 13 03 aka ip[12]
-;~~~~~~~~~~~~~~~~~~~~~
-    movq    mm1, mm0
-    movq    mm5, mm4
-
-    paddw   mm1, mm3          ;ip[0] + ip[12] aka al
-    paddw   mm5, mm2          ;ip[4] + ip[8] aka bl
-
-    movq    mm6, mm1          ;temp al
-
-    paddw   mm1, mm5          ;al + bl
-    psubw   mm6, mm5          ;al - bl
-
-    psubw   mm0, mm3          ;ip[0] - ip[12] aka d1
-    psubw   mm4, mm2          ;ip[4] - ip[8] aka c1
-
-    movq    mm5, mm0          ;temp dl
-
-    paddw   mm0, mm4          ;dl + cl
-    psubw   mm5, mm4          ;dl - cl
-;~~~~~~~~~~~~~~~~~~~~~
-    movq    mm3, mm1          ; 03 02 01 00
-    punpcklwd mm1, mm0          ; 11 01 10 00
-    punpckhwd mm3, mm0          ; 13 03 12 02
-
-    movq    mm4, mm6          ; 23 22 21 20
-    punpcklwd mm6, mm5          ; 31 21 30 20
-    punpckhwd mm4, mm5          ; 33 23 32 22
-
-    movq    mm0, mm1          ; 11 01 10 00
-    movq    mm2, mm3          ; 13 03 12 02
-
-    punpckldq mm0, mm6          ; 30 20 10 00 aka ip[0]
-    punpckhdq mm1, mm6          ; 31 21 11 01 aka ip[4]
-
-    punpckldq mm2, mm4          ; 32 22 12 02 aka ip[8]
-    punpckhdq mm3, mm4          ; 33 23 13 03 aka ip[12]
-
-    paddw   mm0, mm7
-    paddw   mm1, mm7
-    paddw   mm2, mm7
-    paddw   mm3, mm7
-
-    psraw   mm0, 3
-    psraw   mm1, 3
-    psraw   mm2, 3
-    psraw   mm3, 3
-
-    movq  [rdi + 0], mm0
-    movq  [rdi + 8], mm1
-    movq  [rdi + 16], mm2
-    movq  [rdi + 24], mm3
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
diff --git a/vp8/common/x86/iwalsh_sse2.S b/vp8/common/x86/iwalsh_sse2.S
new file mode 100644
index 0000000..9a08723
--- /dev/null
+++ b/vp8/common/x86/iwalsh_sse2.S
@@ -0,0 +1,116 @@
+//
+//  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
+//
+//  Use of this source code is governed by a BSD-style license and patent
+//  grant that can be found in the LICENSE file in the root of the source
+//  tree. All contributing project authors may be found in the AUTHORS
+//  file in the root of the source tree.
+//
+
+
+#include "vpx_ports/x86_abi_support.S"
+
+//void vp8_short_inv_walsh4x4_sse2(short *input, short *output)
+global sym(vp8_short_inv_walsh4x4_sse2)
+sym(vp8_short_inv_walsh4x4_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 2
+    push        rsi
+    push        rdi
+    // end prolog
+
+    mov     rsi, arg(0)
+    mov     rdi, arg(1)
+    mov     rax, 3
+
+    movdqa    xmm0, [rsi + 0]       //ip[4] ip[0]
+    movdqa    xmm1, [rsi + 16]      //ip[12] ip[8]
+
+    shl     rax, 16
+    or      rax, 3            //00030003h
+
+    pshufd    xmm2, xmm1, 0x4e       //ip[8] ip[12]
+    movdqa    xmm3, xmm0          //ip[4] ip[0]
+
+    paddw   xmm0, xmm2          //ip[4]+ip[8] ip[0]+ip[12] aka b1 a1
+    psubw   xmm3, xmm2          //ip[4]-ip[8] ip[0]-ip[12] aka c1 d1
+
+    movdqa    xmm4, xmm0
+    punpcklqdq  xmm0, xmm3          //d1 a1
+    punpckhqdq  xmm4, xmm3          //c1 b1
+    movd    xmm7, eax
+
+    movdqa    xmm1, xmm4          //c1 b1
+    paddw   xmm4, xmm0          //dl+cl a1+b1 aka op[4] op[0]
+    psubw   xmm0, xmm1          //d1-c1 a1-b1 aka op[12] op[8]
+
+//;;temp output
+//;  movdqu  [rdi + 0], xmm4
+//;  movdqu  [rdi + 16], xmm3
+
+//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+    // 13 12 11 10 03 02 01 00
+    //
+    // 33 32 31 30 23 22 21 20
+    //
+    movdqa    xmm3, xmm4          // 13 12 11 10 03 02 01 00
+    punpcklwd xmm4, xmm0          // 23 03 22 02 21 01 20 00
+    punpckhwd xmm3, xmm0          // 33 13 32 12 31 11 30 10
+    movdqa    xmm1, xmm4          // 23 03 22 02 21 01 20 00
+    punpcklwd xmm4, xmm3          // 31 21 11 01 30 20 10 00
+    punpckhwd xmm1, xmm3          // 33 23 13 03 32 22 12 02
+    //~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+    pshufd    xmm2, xmm1, 0x4e       //ip[8] ip[12]
+    movdqa    xmm3, xmm4          //ip[4] ip[0]
+
+    pshufd    xmm7, xmm7, 0       //03 03 03 03 03 03 03 03
+
+    paddw   xmm4, xmm2          //ip[4]+ip[8] ip[0]+ip[12] aka b1 a1
+    psubw   xmm3, xmm2          //ip[4]-ip[8] ip[0]-ip[12] aka c1 d1
+
+    movdqa    xmm5, xmm4
+    punpcklqdq  xmm4, xmm3          //d1 a1
+    punpckhqdq  xmm5, xmm3          //c1 b1
+
+    movdqa    xmm1, xmm5          //c1 b1
+    paddw   xmm5, xmm4          //dl+cl a1+b1 aka op[4] op[0]
+    psubw   xmm4, xmm1          //d1-c1 a1-b1 aka op[12] op[8]
+//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+    // 13 12 11 10 03 02 01 00
+    //
+    // 33 32 31 30 23 22 21 20
+    //
+    movdqa    xmm0, xmm5          // 13 12 11 10 03 02 01 00
+    punpcklwd xmm5, xmm4          // 23 03 22 02 21 01 20 00
+    punpckhwd xmm0, xmm4          // 33 13 32 12 31 11 30 10
+    movdqa    xmm1, xmm5          // 23 03 22 02 21 01 20 00
+    punpcklwd xmm5, xmm0          // 31 21 11 01 30 20 10 00
+    punpckhwd xmm1, xmm0          // 33 23 13 03 32 22 12 02
+//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+    paddw   xmm5, xmm7
+    paddw   xmm1, xmm7
+
+    psraw   xmm5, 3
+    psraw   xmm1, 3
+
+    movdqa  [rdi + 0], xmm5
+    movdqa  [rdi + 16], xmm1
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+SECTION_RODATA
+align 16
+x_s1sqr2:
+    .fill 4, 2, 0x8A8C
+align 16
+x_c1sqr2less1:
+    .fill 4, 2, 0x4E7B
+align 16
+fours:
+    .fill 4, 2, 0x0004
diff --git a/vp8/common/x86/iwalsh_sse2.asm b/vp8/common/x86/iwalsh_sse2.asm
deleted file mode 100644
index 96943df..0000000
--- a/vp8/common/x86/iwalsh_sse2.asm
+++ /dev/null
@@ -1,116 +0,0 @@
-;
-;  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
-;
-;  Use of this source code is governed by a BSD-style license and patent
-;  grant that can be found in the LICENSE file in the root of the source
-;  tree. All contributing project authors may be found in the AUTHORS
-;  file in the root of the source tree.
-;
-
-
-%include "vpx_ports/x86_abi_support.asm"
-
-;void vp8_short_inv_walsh4x4_sse2(short *input, short *output)
-global sym(vp8_short_inv_walsh4x4_sse2)
-sym(vp8_short_inv_walsh4x4_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 2
-    push        rsi
-    push        rdi
-    ; end prolog
-
-    mov     rsi, arg(0)
-    mov     rdi, arg(1)
-    mov     rax, 3
-
-    movdqa    xmm0, [rsi + 0]       ;ip[4] ip[0]
-    movdqa    xmm1, [rsi + 16]      ;ip[12] ip[8]
-
-    shl     rax, 16
-    or      rax, 3            ;00030003h
-
-    pshufd    xmm2, xmm1, 4eh       ;ip[8] ip[12]
-    movdqa    xmm3, xmm0          ;ip[4] ip[0]
-
-    paddw   xmm0, xmm2          ;ip[4]+ip[8] ip[0]+ip[12] aka b1 a1
-    psubw   xmm3, xmm2          ;ip[4]-ip[8] ip[0]-ip[12] aka c1 d1
-
-    movdqa    xmm4, xmm0
-    punpcklqdq  xmm0, xmm3          ;d1 a1
-    punpckhqdq  xmm4, xmm3          ;c1 b1
-    movd    xmm7, eax
-
-    movdqa    xmm1, xmm4          ;c1 b1
-    paddw   xmm4, xmm0          ;dl+cl a1+b1 aka op[4] op[0]
-    psubw   xmm0, xmm1          ;d1-c1 a1-b1 aka op[12] op[8]
-
-;;;temp output
-;;  movdqu  [rdi + 0], xmm4
-;;  movdqu  [rdi + 16], xmm3
-
-;~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-    ; 13 12 11 10 03 02 01 00
-    ;
-    ; 33 32 31 30 23 22 21 20
-    ;
-    movdqa    xmm3, xmm4          ; 13 12 11 10 03 02 01 00
-    punpcklwd xmm4, xmm0          ; 23 03 22 02 21 01 20 00
-    punpckhwd xmm3, xmm0          ; 33 13 32 12 31 11 30 10
-    movdqa    xmm1, xmm4          ; 23 03 22 02 21 01 20 00
-    punpcklwd xmm4, xmm3          ; 31 21 11 01 30 20 10 00
-    punpckhwd xmm1, xmm3          ; 33 23 13 03 32 22 12 02
-    ;~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-    pshufd    xmm2, xmm1, 4eh       ;ip[8] ip[12]
-    movdqa    xmm3, xmm4          ;ip[4] ip[0]
-
-    pshufd    xmm7, xmm7, 0       ;03 03 03 03 03 03 03 03
-
-    paddw   xmm4, xmm2          ;ip[4]+ip[8] ip[0]+ip[12] aka b1 a1
-    psubw   xmm3, xmm2          ;ip[4]-ip[8] ip[0]-ip[12] aka c1 d1
-
-    movdqa    xmm5, xmm4
-    punpcklqdq  xmm4, xmm3          ;d1 a1
-    punpckhqdq  xmm5, xmm3          ;c1 b1
-
-    movdqa    xmm1, xmm5          ;c1 b1
-    paddw   xmm5, xmm4          ;dl+cl a1+b1 aka op[4] op[0]
-    psubw   xmm4, xmm1          ;d1-c1 a1-b1 aka op[12] op[8]
-;~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-    ; 13 12 11 10 03 02 01 00
-    ;
-    ; 33 32 31 30 23 22 21 20
-    ;
-    movdqa    xmm0, xmm5          ; 13 12 11 10 03 02 01 00
-    punpcklwd xmm5, xmm4          ; 23 03 22 02 21 01 20 00
-    punpckhwd xmm0, xmm4          ; 33 13 32 12 31 11 30 10
-    movdqa    xmm1, xmm5          ; 23 03 22 02 21 01 20 00
-    punpcklwd xmm5, xmm0          ; 31 21 11 01 30 20 10 00
-    punpckhwd xmm1, xmm0          ; 33 23 13 03 32 22 12 02
-;~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-    paddw   xmm5, xmm7
-    paddw   xmm1, xmm7
-
-    psraw   xmm5, 3
-    psraw   xmm1, 3
-
-    movdqa  [rdi + 0], xmm5
-    movdqa  [rdi + 16], xmm1
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-SECTION_RODATA
-align 16
-x_s1sqr2:
-    times 4 dw 0x8A8C
-align 16
-x_c1sqr2less1:
-    times 4 dw 0x4E7B
-align 16
-fours:
-    times 4 dw 0x0004
diff --git a/vp8/common/x86/loopfilter_mmx.S b/vp8/common/x86/loopfilter_mmx.S
new file mode 100644
index 0000000..3abdba6
--- /dev/null
+++ b/vp8/common/x86/loopfilter_mmx.S
@@ -0,0 +1,1776 @@
+//
+//  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
+//
+//  Use of this source code is governed by a BSD-style license and patent
+//  grant that can be found in the LICENSE file in the root of the source
+//  tree. All contributing project authors may be found in the AUTHORS
+//  file in the root of the source tree.
+//
+
+
+#include "vpx_ports/x86_abi_support.S"
+
+
+//void vp8_loop_filter_horizontal_edge_mmx
+//(
+//    unsigned char *src_ptr,
+//    int src_pixel_step,
+//    const char *flimit,
+//    const char *limit,
+//    const char *thresh,
+//    int  count
+//)
+global sym(vp8_loop_filter_horizontal_edge_mmx)
+sym(vp8_loop_filter_horizontal_edge_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 6
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+    ALIGN_STACK 16, rax
+    sub         rsp, 32                         // reserve 32 bytes
+#   define t0 [rsp + 0]    //__declspec(align(16)) char t0[8];
+#   define t1 [rsp + 16]   //__declspec(align(16)) char t1[8];
+
+        mov         rsi, arg(0) //src_ptr
+        movsxd      rax, dword ptr arg(1) //src_pixel_step     ; destination pitch?
+
+        movsxd      rcx, dword ptr arg(5) //count
+next8_h:
+        mov         rdx, arg(3) //limit
+        movq        mm7, [rdx]
+        mov         rdi, rsi              // rdi points to row +1 for indirect addressing
+        add         rdi, rax
+
+        // calculate breakout conditions
+        movq        mm2, [rdi+2*rax]      // q3
+        movq        mm1, [rsi+2*rax]      // q2
+        movq        mm6, mm1              // q2
+        psubusb     mm1, mm2              // q2-=q3
+        psubusb     mm2, mm6              // q3-=q2
+        por         mm1, mm2              // abs(q3-q2)
+        psubusb     mm1, mm7              //
+
+
+        movq        mm4, [rsi+rax]        // q1
+        movq        mm3, mm4              // q1
+        psubusb     mm4, mm6              // q1-=q2
+        psubusb     mm6, mm3              // q2-=q1
+        por         mm4, mm6              // abs(q2-q1)
+
+        psubusb     mm4, mm7
+        por        mm1, mm4
+
+        movq        mm4, [rsi]            // q0
+        movq        mm0, mm4              // q0
+        psubusb     mm4, mm3              // q0-=q1
+        psubusb     mm3, mm0              // q1-=q0
+        por         mm4, mm3              // abs(q0-q1)
+        movq        t0, mm4               // save to t0
+        psubusb     mm4, mm7
+        por        mm1, mm4
+
+
+        neg         rax                   // negate pitch to deal with above border
+
+        movq        mm2, [rsi+4*rax]      // p3
+        movq        mm4, [rdi+4*rax]      // p2
+        movq        mm5, mm4              // p2
+        psubusb     mm4, mm2              // p2-=p3
+        psubusb     mm2, mm5              // p3-=p2
+        por         mm4, mm2              // abs(p3 - p2)
+        psubusb     mm4, mm7
+        por        mm1, mm4
+
+
+        movq        mm4, [rsi+2*rax]      // p1
+        movq        mm3, mm4              // p1
+        psubusb     mm4, mm5              // p1-=p2
+        psubusb     mm5, mm3              // p2-=p1
+        por         mm4, mm5              // abs(p2 - p1)
+        psubusb     mm4, mm7
+        por        mm1, mm4
+
+        movq        mm2, mm3              // p1
+
+        movq        mm4, [rsi+rax]        // p0
+        movq        mm5, mm4              // p0
+        psubusb     mm4, mm3              // p0-=p1
+        psubusb     mm3, mm5              // p1-=p0
+        por         mm4, mm3              // abs(p1 - p0)
+        movq        t1, mm4               // save to t1
+        psubusb     mm4, mm7
+        por        mm1, mm4
+
+        movq        mm3, [rdi]            // q1
+        movq        mm4, mm3              // q1
+        psubusb     mm3, mm2              // q1-=p1
+        psubusb     mm2, mm4              // p1-=q1
+        por         mm2, mm3              // abs(p1-q1)
+        pand        mm2, [GLOBAL (tfe)]     // set lsb of each byte to zero
+        psrlw       mm2, 1                // abs(p1-q1)/2
+
+        movq        mm6, mm5              // p0
+        movq        mm3, [rsi]            // q0
+        psubusb     mm5, mm3              // p0-=q0
+        psubusb     mm3, mm6              // q0-=p0
+        por         mm5, mm3              // abs(p0 - q0)
+        paddusb     mm5, mm5              // abs(p0-q0)*2
+        paddusb     mm5, mm2              // abs (p0 - q0) *2 + abs(p1-q1)/2
+
+        mov         rdx, arg(2) //flimit           ; get flimit
+        movq        mm2, [rdx]            // flimit mm2
+        paddb       mm2, mm2              // flimit*2 (less than 255)
+        paddb       mm7, mm2              // flimit * 2 + limit (less than 255)
+
+        psubusb     mm5,    mm7           // abs (p0 - q0) *2 + abs(p1-q1)/2  > flimit * 2 + limit
+        por         mm1,    mm5
+        pxor        mm5,    mm5
+        pcmpeqb     mm1,    mm5           // mask mm1
+
+        // calculate high edge variance
+        mov         rdx, arg(4) //thresh           ; get thresh
+        movq        mm7, [rdx]            //
+        movq        mm4, t0               // get abs (q1 - q0)
+        psubusb     mm4, mm7
+        movq        mm3, t1               // get abs (p1 - p0)
+        psubusb     mm3, mm7
+        paddb       mm4, mm3              // abs(q1 - q0) > thresh || abs(p1 - p0) > thresh
+
+        pcmpeqb     mm4,        mm5
+
+        pcmpeqb     mm5,        mm5
+        pxor        mm4,        mm5
+
+
+        // start work on filters
+        movq        mm2, [rsi+2*rax]      // p1
+        movq        mm7, [rdi]            // q1
+        pxor        mm2, [GLOBAL (t80)]     // p1 offset to convert to signed values
+        pxor        mm7, [GLOBAL (t80)]     // q1 offset to convert to signed values
+        psubsb      mm2, mm7              // p1 - q1
+        pand        mm2, mm4              // high var mask (hvm)(p1 - q1)
+        pxor        mm6, [GLOBAL (t80)]     // offset to convert to signed values
+        pxor        mm0, [GLOBAL (t80)]     // offset to convert to signed values
+        movq        mm3, mm0              // q0
+        psubsb      mm0, mm6              // q0 - p0
+        paddsb      mm2, mm0              // 1 * (q0 - p0) + hvm(p1 - q1)
+        paddsb      mm2, mm0              // 2 * (q0 - p0) + hvm(p1 - q1)
+        paddsb      mm2, mm0              // 3 * (q0 - p0) + hvm(p1 - q1)
+        pand        mm1, mm2                  // mask filter values we don't care about
+        movq        mm2, mm1
+        paddsb      mm1, [GLOBAL (t4)]      // 3* (q0 - p0) + hvm(p1 - q1) + 4
+        paddsb      mm2, [GLOBAL (t3)]      // 3* (q0 - p0) + hvm(p1 - q1) + 3
+
+        pxor        mm0, mm0             //
+        pxor        mm5, mm5
+        punpcklbw   mm0, mm2            //
+        punpckhbw   mm5, mm2            //
+        psraw       mm0, 11             //
+        psraw       mm5, 11
+        packsswb    mm0, mm5
+        movq        mm2, mm0            //  (3* (q0 - p0) + hvm(p1 - q1) + 3) >> 3;
+
+        pxor        mm0, mm0              // 0
+        movq        mm5, mm1              // abcdefgh
+        punpcklbw   mm0, mm1              // e0f0g0h0
+        psraw       mm0, 11               // sign extended shift right by 3
+        pxor        mm1, mm1              // 0
+        punpckhbw   mm1, mm5              // a0b0c0d0
+        psraw       mm1, 11               // sign extended shift right by 3
+        movq        mm5, mm0              // save results
+
+        packsswb    mm0, mm1              // (3* (q0 - p0) + hvm(p1 - q1) + 4) >>3
+        paddsw      mm5, [GLOBAL (ones)]
+        paddsw      mm1, [GLOBAL (ones)]
+        psraw       mm5, 1                // partial shifted one more time for 2nd tap
+        psraw       mm1, 1                // partial shifted one more time for 2nd tap
+        packsswb    mm5, mm1              // (3* (q0 - p0) + hvm(p1 - q1) + 4) >>4
+        pandn       mm4, mm5              // high edge variance additive
+
+        paddsb      mm6, mm2              // p0+= p0 add
+        pxor        mm6, [GLOBAL (t80)]     // unoffset
+        movq        [rsi+rax], mm6        // write back
+
+        movq        mm6, [rsi+2*rax]      // p1
+        pxor        mm6, [GLOBAL (t80)]     // reoffset
+        paddsb      mm6, mm4              // p1+= p1 add
+        pxor        mm6, [GLOBAL (t80)]     // unoffset
+        movq        [rsi+2*rax], mm6      // write back
+
+        psubsb      mm3, mm0              // q0-= q0 add
+        pxor        mm3, [GLOBAL (t80)]     // unoffset
+        movq        [rsi], mm3            // write back
+
+        psubsb      mm7, mm4              // q1-= q1 add
+        pxor        mm7, [GLOBAL (t80)]     // unoffset
+        movq        [rdi], mm7            // write back
+
+        add         rsi,8
+        neg         rax
+        dec         rcx
+        jnz         next8_h
+
+    add rsp, 32
+    pop rsp
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void vp8_loop_filter_vertical_edge_mmx
+//(
+//    unsigned char *src_ptr,
+//    int  src_pixel_step,
+//    const char *flimit,
+//    const char *limit,
+//    const char *thresh,
+//    int count
+//)
+global sym(vp8_loop_filter_vertical_edge_mmx)
+sym(vp8_loop_filter_vertical_edge_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 6
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+    ALIGN_STACK 16, rax
+    sub          rsp, 64      // reserve 64 bytes
+#   define t0   [rsp + 0]    //__declspec(align(16)) char t0[8];
+#   define t1   [rsp + 16]   //__declspec(align(16)) char t1[8];
+#   define srct [rsp + 32]   //__declspec(align(16)) char srct[32];
+
+        mov         rsi,        arg(0) //src_ptr
+        movsxd      rax,        dword ptr arg(1) //src_pixel_step     ; destination pitch?
+
+        lea         rsi,        [rsi + rax*4 - 4]
+
+        movsxd      rcx,        dword ptr arg(5) //count
+next8_v:
+        mov         rdi,        rsi           // rdi points to row +1 for indirect addressing
+        add         rdi,        rax
+
+
+        //transpose
+        movq        mm6,        [rsi+2*rax]                 // 67 66 65 64 63 62 61 60
+        movq        mm7,        mm6                         // 77 76 75 74 73 72 71 70
+
+        punpckhbw   mm7,        [rdi+2*rax]                 // 77 67 76 66 75 65 74 64
+        punpcklbw   mm6,        [rdi+2*rax]                 // 73 63 72 62 71 61 70 60
+
+        movq        mm4,        [rsi]                       // 47 46 45 44 43 42 41 40
+        movq        mm5,        mm4                         // 47 46 45 44 43 42 41 40
+
+        punpckhbw   mm5,        [rsi+rax]                   // 57 47 56 46 55 45 54 44
+        punpcklbw   mm4,        [rsi+rax]                   // 53 43 52 42 51 41 50 40
+
+        movq        mm3,        mm5                         // 57 47 56 46 55 45 54 44
+        punpckhwd   mm5,        mm7                         // 77 67 57 47 76 66 56 46
+
+        punpcklwd   mm3,        mm7                         // 75 65 55 45 74 64 54 44
+        movq        mm2,        mm4                         // 53 43 52 42 51 41 50 40
+
+        punpckhwd   mm4,        mm6                         // 73 63 53 43 72 62 52 42
+        punpcklwd   mm2,        mm6                         // 71 61 51 41 70 60 50 40
+
+        neg         rax
+        movq        mm6,        [rsi+rax*2]                 // 27 26 25 24 23 22 21 20
+
+        movq        mm1,        mm6                         // 27 26 25 24 23 22 21 20
+        punpckhbw   mm6,        [rsi+rax]                   // 37 27 36 36 35 25 34 24
+
+        punpcklbw   mm1,        [rsi+rax]                   // 33 23 32 22 31 21 30 20
+        movq        mm7,        [rsi+rax*4];                // 07 06 05 04 03 02 01 00
+
+        punpckhbw   mm7,        [rdi+rax*4]                 // 17 07 16 06 15 05 14 04
+        movq        mm0,        mm7                         // 17 07 16 06 15 05 14 04
+
+        punpckhwd   mm7,        mm6                         // 37 27 17 07 36 26 16 06
+        punpcklwd   mm0,        mm6                         // 35 25 15 05 34 24 14 04
+
+        movq        mm6,        mm7                         // 37 27 17 07 36 26 16 06
+        punpckhdq   mm7,        mm5                         // 77 67 57 47 37 27 17 07  = q3
+
+        punpckldq   mm6,        mm5                         // 76 66 56 46 36 26 16 06  = q2
+
+        movq        mm5,        mm6                         // 76 66 56 46 36 26 16 06
+        psubusb     mm5,        mm7                         // q2-q3
+
+        psubusb     mm7,        mm6                         // q3-q2
+        por         mm7,        mm5;                        // mm7=abs (q3-q2)
+
+        movq        mm5,        mm0                         // 35 25 15 05 34 24 14 04
+        punpckhdq   mm5,        mm3                         // 75 65 55 45 35 25 15 05 = q1
+
+        punpckldq   mm0,        mm3                         // 74 64 54 44 34 24 15 04 = q0
+        movq        mm3,        mm5                         // 75 65 55 45 35 25 15 05 = q1
+
+        psubusb     mm3,        mm6                         // q1-q2
+        psubusb     mm6,        mm5                         // q2-q1
+
+        por         mm6,        mm3                         // mm6=abs(q2-q1)
+        lea         rdx,        srct
+
+        movq        [rdx+24],   mm5                         // save q1
+        movq        [rdx+16],   mm0                         // save q0
+
+        movq        mm3,        [rsi+rax*4]                 // 07 06 05 04 03 02 01 00
+        punpcklbw   mm3,        [rdi+rax*4]                 // 13 03 12 02 11 01 10 00
+
+        movq        mm0,        mm3                         // 13 03 12 02 11 01 10 00
+        punpcklwd   mm0,        mm1                         // 31 21 11 01 30 20 10 00
+
+        punpckhwd   mm3,        mm1                         // 33 23 13 03 32 22 12 02
+        movq        mm1,        mm0                         // 31 21 11 01 30 20 10 00
+
+        punpckldq   mm0,        mm2                         // 70 60 50 40 30 20 10 00  =p3
+        punpckhdq   mm1,        mm2                         // 71 61 51 41 31 21 11 01  =p2
+
+        movq        mm2,        mm1                         // 71 61 51 41 31 21 11 01  =p2
+        psubusb     mm2,        mm0                         // p2-p3
+
+        psubusb     mm0,        mm1                         // p3-p2
+        por         mm0,        mm2                         // mm0=abs(p3-p2)
+
+        movq        mm2,        mm3                         // 33 23 13 03 32 22 12 02
+        punpckldq   mm2,        mm4                         // 72 62 52 42 32 22 12 02 = p1
+
+        punpckhdq   mm3,        mm4                         // 73 63 53 43 33 23 13 03 = p0
+        movq        [rdx+8],    mm3                         // save p0
+
+        movq        [rdx],      mm2                         // save p1
+        movq        mm5,        mm2                         // mm5 = p1
+
+        psubusb     mm2,        mm1                         // p1-p2
+        psubusb     mm1,        mm5                         // p2-p1
+
+        por         mm1,        mm2                         // mm1=abs(p2-p1)
+        mov         rdx,        arg(3) //limit
+
+        movq        mm4,        [rdx]                       // mm4 = limit
+        psubusb     mm7,        mm4
+
+        psubusb     mm0,        mm4
+        psubusb     mm1,        mm4
+
+        psubusb     mm6,        mm4
+        por         mm7,        mm6
+
+        por         mm0,        mm1
+        por         mm0,        mm7                         //   abs(q3-q2) > limit || abs(p3-p2) > limit ||abs(p2-p1) > limit || abs(q2-q1) > limit
+
+        movq        mm1,        mm5                         // p1
+
+        movq        mm7,        mm3                         // mm3=mm7=p0
+        psubusb     mm7,        mm5                         // p0 - p1
+
+        psubusb     mm5,        mm3                         // p1 - p0
+        por         mm5,        mm7                         // abs(p1-p0)
+
+        movq        t0,         mm5                         // save abs(p1-p0)
+        lea         rdx,        srct
+
+        psubusb     mm5,        mm4
+        por         mm0,        mm5                         // mm0=mask
+
+        movq        mm5,        [rdx+16]                    // mm5=q0
+        movq        mm7,        [rdx+24]                    // mm7=q1
+
+        movq        mm6,        mm5                         // mm6=q0
+        movq        mm2,        mm7                         // q1
+        psubusb     mm5,        mm7                         // q0-q1
+
+        psubusb     mm7,        mm6                         // q1-q0
+        por         mm7,        mm5                         // abs(q1-q0)
+
+        movq        t1,         mm7                         // save abs(q1-q0)
+        psubusb     mm7,        mm4
+
+        por         mm0,        mm7                         // mask
+
+        movq        mm5,        mm2                         // q1
+        psubusb     mm5,        mm1                         // q1-=p1
+        psubusb     mm1,        mm2                         // p1-=q1
+        por         mm5,        mm1                         // abs(p1-q1)
+        pand        mm5,        [GLOBAL (tfe)]                // set lsb of each byte to zero
+        psrlw       mm5,        1                           // abs(p1-q1)/2
+
+        mov         rdx,        arg(2) //flimit                      ;
+
+        movq        mm2,        [rdx]                       //flimit  mm2
+        movq        mm1,        mm3                         // mm1=mm3=p0
+
+        movq        mm7,        mm6                         // mm7=mm6=q0
+        psubusb     mm1,        mm7                         // p0-q0
+
+        psubusb     mm7,        mm3                         // q0-p0
+        por         mm1,        mm7                         // abs(q0-p0)
+        paddusb     mm1,        mm1                         // abs(q0-p0)*2
+        paddusb     mm1,        mm5                         // abs (p0 - q0) *2 + abs(p1-q1)/2
+
+        paddb       mm2,        mm2                         // flimit*2 (less than 255)
+        paddb       mm4,        mm2                         // flimit * 2 + limit (less than 255)
+
+        psubusb     mm1,        mm4                         // abs (p0 - q0) *2 + abs(p1-q1)/2  > flimit * 2 + limit
+        por         mm1,        mm0;                        // mask
+
+        pxor        mm0,        mm0
+        pcmpeqb     mm1,        mm0
+
+        // calculate high edge variance
+        mov         rdx,        arg(4) //thresh            ; get thresh
+        movq        mm7,        [rdx]
+        //
+        movq        mm4,        t0              // get abs (q1 - q0)
+        psubusb     mm4,        mm7
+
+        movq        mm3,        t1              // get abs (p1 - p0)
+        psubusb     mm3,        mm7
+
+        por         mm4,        mm3             // abs(q1 - q0) > thresh || abs(p1 - p0) > thresh
+        pcmpeqb     mm4,        mm0
+
+        pcmpeqb     mm0,        mm0
+        pxor        mm4,        mm0
+
+
+
+        // start work on filters
+        lea         rdx,        srct
+
+        movq        mm2,        [rdx]           // p1
+        movq        mm7,        [rdx+24]        // q1
+
+        movq        mm6,        [rdx+8]         // p0
+        movq        mm0,        [rdx+16]        // q0
+
+        pxor        mm2,        [GLOBAL (t80)]    // p1 offset to convert to signed values
+        pxor        mm7,        [GLOBAL (t80)]    // q1 offset to convert to signed values
+
+        psubsb      mm2,        mm7             // p1 - q1
+        pand        mm2,        mm4             // high var mask (hvm)(p1 - q1)
+
+        pxor        mm6,        [GLOBAL (t80)]    // offset to convert to signed values
+        pxor        mm0,        [GLOBAL (t80)]    // offset to convert to signed values
+
+        movq        mm3,        mm0             // q0
+        psubsb      mm0,        mm6             // q0 - p0
+
+        paddsb      mm2,        mm0             // 1 * (q0 - p0) + hvm(p1 - q1)
+        paddsb      mm2,        mm0             // 2 * (q0 - p0) + hvm(p1 - q1)
+
+        paddsb      mm2,        mm0             // 3 * (q0 - p0) + hvm(p1 - q1)
+        pand       mm1,        mm2              // mask filter values we don't care about
+
+        movq        mm2,        mm1
+        paddsb      mm1,        [GLOBAL (t4)]       // 3* (q0 - p0) + hvm(p1 - q1) + 4
+
+        paddsb      mm2,        [GLOBAL (t3)]       // 3* (q0 - p0) + hvm(p1 - q1) + 3
+        pxor        mm0,        mm0          //
+
+        pxor        mm5,        mm5
+        punpcklbw   mm0,        mm2         //
+
+        punpckhbw   mm5,        mm2         //
+        psraw       mm0,        11              //
+
+        psraw       mm5,        11
+        packsswb    mm0,        mm5
+
+        movq        mm2,        mm0         //  (3* (q0 - p0) + hvm(p1 - q1) + 3) >> 3;
+
+        pxor        mm0,        mm0           // 0
+        movq        mm5,        mm1           // abcdefgh
+
+        punpcklbw   mm0,        mm1           // e0f0g0h0
+        psraw       mm0,        11                // sign extended shift right by 3
+
+        pxor        mm1,        mm1           // 0
+        punpckhbw   mm1,        mm5           // a0b0c0d0
+
+        psraw       mm1,        11                // sign extended shift right by 3
+        movq        mm5,        mm0              // save results
+
+        packsswb    mm0,        mm1           // (3* (q0 - p0) + hvm(p1 - q1) + 4) >>3
+        paddsw      mm5,        [GLOBAL (ones)]
+
+        paddsw      mm1,        [GLOBAL (ones)]
+        psraw       mm5,        1                 // partial shifted one more time for 2nd tap
+
+        psraw       mm1,        1                 // partial shifted one more time for 2nd tap
+        packsswb    mm5,        mm1           // (3* (q0 - p0) + hvm(p1 - q1) + 4) >>4
+
+        pandn       mm4,        mm5             // high edge variance additive
+
+        paddsb      mm6,        mm2             // p0+= p0 add
+        pxor        mm6,        [GLOBAL (t80)]    // unoffset
+
+        // mm6=p0                               ;
+        movq        mm1,        [rdx]           // p1
+        pxor        mm1,        [GLOBAL (t80)]    // reoffset
+
+        paddsb      mm1,        mm4                 // p1+= p1 add
+        pxor        mm1,        [GLOBAL (t80)]        // unoffset
+        // mm6 = p0 mm1 = p1
+
+        psubsb      mm3,        mm0                 // q0-= q0 add
+        pxor        mm3,        [GLOBAL (t80)]        // unoffset
+
+        // mm3 = q0
+        psubsb      mm7,        mm4                 // q1-= q1 add
+        pxor        mm7,        [GLOBAL (t80)]        // unoffset
+        // mm7 = q1
+
+        // tranpose and write back
+        // mm1 =    72 62 52 42 32 22 12 02
+        // mm6 =    73 63 53 43 33 23 13 03
+        // mm3 =    74 64 54 44 34 24 14 04
+        // mm7 =    75 65 55 45 35 25 15 05
+
+        movq        mm2,        mm1             // 72 62 52 42 32 22 12 02
+        punpcklbw   mm2,        mm6             // 33 32 23 22 13 12 03 02
+
+        movq        mm4,        mm3             // 74 64 54 44 34 24 14 04
+        punpckhbw   mm1,        mm6             // 73 72 63 62 53 52 43 42
+
+        punpcklbw   mm4,        mm7             // 35 34 25 24 15 14 05 04
+        punpckhbw   mm3,        mm7             // 75 74 65 64 55 54 45 44
+
+        movq        mm6,        mm2             // 33 32 23 22 13 12 03 02
+        punpcklwd   mm2,        mm4             // 15 14 13 12 05 04 03 02
+
+        punpckhwd   mm6,        mm4             // 35 34 33 32 25 24 23 22
+        movq        mm5,        mm1             // 73 72 63 62 53 52 43 42
+
+        punpcklwd   mm1,        mm3             // 55 54 53 52 45 44 43 42
+        punpckhwd   mm5,        mm3             // 75 74 73 72 65 64 63 62
+
+
+        // mm2 = 15 14 13 12 05 04 03 02
+        // mm6 = 35 34 33 32 25 24 23 22
+        // mm5 = 55 54 53 52 45 44 43 42
+        // mm1 = 75 74 73 72 65 64 63 62
+
+
+
+        movd        [rsi+rax*4+2], mm2
+        psrlq       mm2,        32
+
+        movd        [rdi+rax*4+2], mm2
+        movd        [rsi+rax*2+2], mm6
+
+        psrlq       mm6,        32
+        movd        [rsi+rax+2],mm6
+
+        movd        [rsi+2],    mm1
+        psrlq       mm1,        32
+
+        movd        [rdi+2],    mm1
+        neg         rax
+
+        movd        [rdi+rax+2],mm5
+        psrlq       mm5,        32
+
+        movd        [rdi+rax*2+2], mm5
+
+        lea         rsi,        [rsi+rax*8]
+        dec         rcx
+        jnz         next8_v
+
+    add rsp, 64
+    pop rsp
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void vp8_mbloop_filter_horizontal_edge_mmx
+//(
+//    unsigned char *src_ptr,
+//    int  src_pixel_step,
+//    const char *flimit,
+//    const char *limit,
+//    const char *thresh,
+//    int count
+//)
+global sym(vp8_mbloop_filter_horizontal_edge_mmx)
+sym(vp8_mbloop_filter_horizontal_edge_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 6
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+    ALIGN_STACK 16, rax
+    sub          rsp, 32      // reserve 32 bytes
+#   define t0   [rsp + 0]    //__declspec(align(16)) char t0[8];
+#   define t1   [rsp + 16]   //__declspec(align(16)) char t1[8];
+
+        mov         rsi, arg(0) //src_ptr
+        movsxd      rax, dword ptr arg(1) //src_pixel_step     ; destination pitch?
+
+        movsxd      rcx, dword ptr arg(5) //count
+next8_mbh:
+        mov         rdx, arg(3) //limit
+        movq        mm7, [rdx]
+        mov         rdi, rsi              // rdi points to row +1 for indirect addressing
+        add         rdi, rax
+
+        // calculate breakout conditions
+        movq        mm2, [rdi+2*rax]      // q3
+
+        movq        mm1, [rsi+2*rax]      // q2
+        movq        mm6, mm1              // q2
+        psubusb     mm1, mm2              // q2-=q3
+        psubusb     mm2, mm6              // q3-=q2
+        por         mm1, mm2              // abs(q3-q2)
+        psubusb     mm1, mm7
+
+
+        // mm1 = abs(q3-q2), mm6 =q2, mm7 = limit
+        movq        mm4, [rsi+rax]        // q1
+        movq        mm3, mm4              // q1
+        psubusb     mm4, mm6              // q1-=q2
+        psubusb     mm6, mm3              // q2-=q1
+        por         mm4, mm6              // abs(q2-q1)
+        psubusb     mm4, mm7
+        por        mm1, mm4
+
+
+        // mm1 = mask,      mm3=q1, mm7 = limit
+
+        movq        mm4, [rsi]            // q0
+        movq        mm0, mm4              // q0
+        psubusb     mm4, mm3              // q0-=q1
+        psubusb     mm3, mm0              // q1-=q0
+        por         mm4, mm3              // abs(q0-q1)
+        movq        t0, mm4               // save to t0
+        psubusb     mm4, mm7
+        por        mm1, mm4
+
+
+        // mm1 = mask, mm0=q0,  mm7 = limit, t0 = abs(q0-q1)
+
+        neg         rax                   // negate pitch to deal with above border
+
+        movq        mm2, [rsi+4*rax]      // p3
+        movq        mm4, [rdi+4*rax]      // p2
+        movq        mm5, mm4              // p2
+        psubusb     mm4, mm2              // p2-=p3
+        psubusb     mm2, mm5              // p3-=p2
+        por         mm4, mm2              // abs(p3 - p2)
+        psubusb     mm4, mm7
+        por        mm1, mm4
+        // mm1 = mask, mm0=q0,  mm7 = limit, t0 = abs(q0-q1)
+
+        movq        mm4, [rsi+2*rax]      // p1
+        movq        mm3, mm4              // p1
+        psubusb     mm4, mm5              // p1-=p2
+        psubusb     mm5, mm3              // p2-=p1
+        por         mm4, mm5              // abs(p2 - p1)
+        psubusb     mm4, mm7
+        por        mm1, mm4
+
+        movq        mm2, mm3              // p1
+
+
+        // mm1 = mask, mm0=q0,  mm7 = limit, t0 = abs(q0-q1)
+
+        movq        mm4, [rsi+rax]        // p0
+        movq        mm5, mm4              // p0
+        psubusb     mm4, mm3              // p0-=p1
+        psubusb     mm3, mm5              // p1-=p0
+        por         mm4, mm3              // abs(p1 - p0)
+        movq        t1, mm4               // save to t1
+        psubusb     mm4, mm7
+        por        mm1, mm4
+        // mm1 = mask, mm0=q0,  mm7 = limit, t0 = abs(q0-q1) t1 = abs(p1-p0)
+        // mm5 = p0
+        movq        mm3, [rdi]            // q1
+        movq        mm4, mm3              // q1
+        psubusb     mm3, mm2              // q1-=p1
+        psubusb     mm2, mm4              // p1-=q1
+        por         mm2, mm3              // abs(p1-q1)
+        pand        mm2, [GLOBAL (tfe)]     // set lsb of each byte to zero
+        psrlw       mm2, 1                // abs(p1-q1)/2
+
+        movq        mm6, mm5              // p0
+        movq        mm3, mm0              // q0
+        psubusb     mm5, mm3              // p0-=q0
+        psubusb     mm3, mm6              // q0-=p0
+        por         mm5, mm3              // abs(p0 - q0)
+        paddusb     mm5, mm5              // abs(p0-q0)*2
+        paddusb     mm5, mm2              // abs (p0 - q0) *2 + abs(p1-q1)/2
+
+        mov         rdx, arg(2) //flimit           ; get flimit
+        movq        mm2, [rdx]            // flimit mm2
+        paddb       mm2, mm2              // flimit*2 (less than 255)
+        paddb       mm7, mm2              // flimit * 2 + limit (less than 255)
+
+        psubusb     mm5,    mm7           // abs (p0 - q0) *2 + abs(p1-q1)/2  > flimit * 2 + limit
+        por         mm1,    mm5
+        pxor        mm5,    mm5
+        pcmpeqb     mm1,    mm5           // mask mm1
+
+        // mm1 = mask, mm0=q0,  mm7 = flimit, t0 = abs(q0-q1) t1 = abs(p1-p0)
+        // mm6 = p0,
+
+        // calculate high edge variance
+        mov         rdx, arg(4) //thresh           ; get thresh
+        movq        mm7, [rdx]            //
+        movq        mm4, t0               // get abs (q1 - q0)
+        psubusb     mm4, mm7
+        movq        mm3, t1               // get abs (p1 - p0)
+        psubusb     mm3, mm7
+        paddb       mm4, mm3              // abs(q1 - q0) > thresh || abs(p1 - p0) > thresh
+
+        pcmpeqb     mm4,        mm5
+
+        pcmpeqb     mm5,        mm5
+        pxor        mm4,        mm5
+
+
+
+        // mm1 = mask, mm0=q0,  mm7 = thresh, t0 = abs(q0-q1) t1 = abs(p1-p0)
+        // mm6 = p0, mm4=hev
+        // start work on filters
+        movq        mm2, [rsi+2*rax]      // p1
+        movq        mm7, [rdi]            // q1
+        pxor        mm2, [GLOBAL (t80)]     // p1 offset to convert to signed values
+        pxor        mm7, [GLOBAL (t80)]     // q1 offset to convert to signed values
+        psubsb      mm2, mm7              // p1 - q1
+
+        pxor        mm6, [GLOBAL (t80)]     // offset to convert to signed values
+        pxor        mm0, [GLOBAL (t80)]     // offset to convert to signed values
+        movq        mm3, mm0              // q0
+        psubsb      mm0, mm6              // q0 - p0
+        paddsb      mm2, mm0              // 1 * (q0 - p0) + (p1 - q1)
+        paddsb      mm2, mm0              // 2 * (q0 - p0)
+        paddsb      mm2, mm0              // 3 * (q0 - p0) + (p1 - q1)
+        pand        mm1, mm2              // mask filter values we don't care about
+
+
+        // mm1 = vp8_filter, mm4=hev, mm6=ps0, mm3=qs0
+        movq        mm2, mm1              // vp8_filter
+        pand        mm2, mm4;             // Filter2 = vp8_filter & hev
+
+        movq        mm5,        mm2       //
+        paddsb      mm5,        [GLOBAL (t3)];
+
+        pxor        mm0, mm0              // 0
+        pxor        mm7, mm7              // 0
+
+        punpcklbw   mm0, mm5              // e0f0g0h0
+        psraw       mm0, 11               // sign extended shift right by 3
+        punpckhbw   mm7, mm5              // a0b0c0d0
+        psraw       mm7, 11               // sign extended shift right by 3
+        packsswb    mm0, mm7              // Filter2 >>=3;
+
+        movq        mm5, mm0              // Filter2
+
+        paddsb      mm2, [GLOBAL (t4)]      // vp8_signed_char_clamp(Filter2 + 4)
+        pxor        mm0, mm0              // 0
+        pxor        mm7, mm7              // 0
+
+        punpcklbw   mm0, mm2              // e0f0g0h0
+        psraw       mm0, 11               // sign extended shift right by 3
+        punpckhbw   mm7, mm2              // a0b0c0d0
+        psraw       mm7, 11               // sign extended shift right by 3
+        packsswb    mm0, mm7              // Filter2 >>=3;
+
+        // mm0= filter2 mm1 = vp8_filter,  mm3 =qs0 mm5=s mm4 =hev mm6=ps0
+        psubsb      mm3, mm0              // qs0 =qs0 - filter1
+        paddsb      mm6, mm5              // ps0 =ps0 + Fitler2
+
+        // mm1=vp8_filter, mm3=qs0, mm4 =hev mm6=ps0
+        // vp8_filter &= ~hev;
+        // Filter2 = vp8_filter;
+        pandn       mm4, mm1              // vp8_filter&=~hev
+
+
+        // mm3=qs0, mm4=filter2, mm6=ps0
+
+        // u = vp8_signed_char_clamp((63 + Filter2 * 27)>>7);
+        // s = vp8_signed_char_clamp(qs0 - u);
+        // *oq0 = s^0x80;
+        // s = vp8_signed_char_clamp(ps0 + u);
+        // *op0 = s^0x80;
+        pxor        mm0, mm0
+
+        pxor        mm1, mm1
+        pxor        mm2, mm2
+        punpcklbw   mm1, mm4
+        punpckhbw   mm2, mm4
+        pmulhw      mm1, [GLOBAL (s27)]
+        pmulhw      mm2, [GLOBAL (s27)]
+        paddw       mm1, [GLOBAL (s63)]
+        paddw       mm2, [GLOBAL (s63)]
+        psraw       mm1, 7
+        psraw       mm2, 7
+        packsswb    mm1, mm2
+
+        psubsb      mm3, mm1
+        paddsb      mm6, mm1
+
+        pxor        mm3, [GLOBAL (t80)]
+        pxor        mm6, [GLOBAL (t80)]
+        movq        [rsi+rax], mm6
+        movq        [rsi],     mm3
+
+        // roughly 2/7th difference across boundary
+        // u = vp8_signed_char_clamp((63 + Filter2 * 18)>>7);
+        // s = vp8_signed_char_clamp(qs1 - u);
+        // *oq1 = s^0x80;
+        // s = vp8_signed_char_clamp(ps1 + u);
+        // *op1 = s^0x80;
+        pxor        mm1, mm1
+        pxor        mm2, mm2
+        punpcklbw   mm1, mm4
+        punpckhbw   mm2, mm4
+        pmulhw      mm1, [GLOBAL (s18)]
+        pmulhw      mm2, [GLOBAL (s18)]
+        paddw       mm1, [GLOBAL (s63)]
+        paddw       mm2, [GLOBAL (s63)]
+        psraw       mm1, 7
+        psraw       mm2, 7
+        packsswb    mm1, mm2
+
+        movq        mm3, [rdi]
+        movq        mm6, [rsi+rax*2]       // p1
+
+        pxor        mm3, [GLOBAL (t80)]
+        pxor        mm6, [GLOBAL (t80)]
+
+        paddsb      mm6, mm1
+        psubsb      mm3, mm1
+
+        pxor        mm6, [GLOBAL (t80)]
+        pxor        mm3, [GLOBAL (t80)]
+        movq        [rdi], mm3
+        movq        [rsi+rax*2], mm6
+
+        // roughly 1/7th difference across boundary
+        // u = vp8_signed_char_clamp((63 + Filter2 * 9)>>7);
+        // s = vp8_signed_char_clamp(qs2 - u);
+        // *oq2 = s^0x80;
+        // s = vp8_signed_char_clamp(ps2 + u);
+        // *op2 = s^0x80;
+        pxor        mm1, mm1
+        pxor        mm2, mm2
+        punpcklbw   mm1, mm4
+        punpckhbw   mm2, mm4
+        pmulhw      mm1, [GLOBAL (s9)]
+        pmulhw      mm2, [GLOBAL (s9)]
+        paddw       mm1, [GLOBAL (s63)]
+        paddw       mm2, [GLOBAL (s63)]
+        psraw       mm1, 7
+        psraw       mm2, 7
+        packsswb    mm1, mm2
+
+
+        movq        mm6, [rdi+rax*4]
+        neg         rax
+        movq        mm3, [rdi+rax  ]
+
+        pxor        mm6, [GLOBAL (t80)]
+        pxor        mm3, [GLOBAL (t80)]
+
+        paddsb      mm6, mm1
+        psubsb      mm3, mm1
+
+        pxor        mm6, [GLOBAL (t80)]
+        pxor        mm3, [GLOBAL (t80)]
+        movq        [rdi+rax  ], mm3
+        neg         rax
+        movq        [rdi+rax*4], mm6
+
+//EARLY_BREAK_OUT:
+        neg         rax
+        add         rsi,8
+        dec         rcx
+        jnz         next8_mbh
+
+    add rsp, 32
+    pop rsp
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void vp8_mbloop_filter_vertical_edge_mmx
+//(
+//    unsigned char *src_ptr,
+//    int  src_pixel_step,
+//    const char *flimit,
+//    const char *limit,
+//    const char *thresh,
+//    int count
+//)
+global sym(vp8_mbloop_filter_vertical_edge_mmx)
+sym(vp8_mbloop_filter_vertical_edge_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 6
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+    ALIGN_STACK 16, rax
+    sub          rsp, 96      // reserve 96 bytes
+#   define t0   [rsp + 0]    //__declspec(align(16)) char t0[8];
+#   define t1   [rsp + 16]   //__declspec(align(16)) char t1[8];
+#   define srct [rsp + 32]   //__declspec(align(16)) char srct[64];
+
+        mov         rsi,        arg(0) //src_ptr
+        movsxd      rax,        dword ptr arg(1) //src_pixel_step     ; destination pitch?
+
+        lea         rsi,        [rsi + rax*4 - 4]
+
+        movsxd      rcx,        dword ptr arg(5) //count
+next8_mbv:
+        lea         rdi,        [rsi + rax]  // rdi points to row +1 for indirect addressing
+
+        //transpose
+        movq        mm0,        [rdi+2*rax]                 // 77 76 75 74 73 72 71 70
+        movq        mm6,        [rsi+2*rax]                 // 67 66 65 64 63 62 61 60
+
+        movq        mm7,        mm6                         // 77 76 75 74 73 72 71 70
+        punpckhbw   mm7,        mm0                         // 77 67 76 66 75 65 74 64
+
+        punpcklbw   mm6,        mm0                         // 73 63 72 62 71 61 70 60
+        movq        mm0,        [rsi+rax]                   // 57 56 55 54 53 52 51 50
+
+        movq        mm4,        [rsi]                       // 47 46 45 44 43 42 41 40
+        movq        mm5,        mm4                         // 47 46 45 44 43 42 41 40
+
+        punpckhbw   mm5,        mm0                         // 57 47 56 46 55 45 54 44
+        punpcklbw   mm4,        mm0                         // 53 43 52 42 51 41 50 40
+
+        movq        mm3,        mm5                         // 57 47 56 46 55 45 54 44
+        punpckhwd   mm5,        mm7                         // 77 67 57 47 76 66 56 46
+
+        punpcklwd   mm3,        mm7                         // 75 65 55 45 74 64 54 44
+        movq        mm2,        mm4                         // 53 43 52 42 51 41 50 40
+
+        punpckhwd   mm4,        mm6                         // 73 63 53 43 72 62 52 42
+        punpcklwd   mm2,        mm6                         // 71 61 51 41 70 60 50 40
+
+        neg         rax
+
+        movq        mm7,        [rsi+rax]                   // 37 36 35 34 33 32 31 30
+        movq        mm6,        [rsi+rax*2]                 // 27 26 25 24 23 22 21 20
+
+        movq        mm1,        mm6                         // 27 26 25 24 23 22 21 20
+        punpckhbw   mm6,        mm7                         // 37 27 36 36 35 25 34 24
+
+        punpcklbw   mm1,        mm7                         // 33 23 32 22 31 21 30 20
+
+        movq        mm7,        [rsi+rax*4];                // 07 06 05 04 03 02 01 00
+        punpckhbw   mm7,        [rdi+rax*4]                 // 17 07 16 06 15 05 14 04
+
+        movq        mm0,        mm7                         // 17 07 16 06 15 05 14 04
+        punpckhwd   mm7,        mm6                         // 37 27 17 07 36 26 16 06
+
+        punpcklwd   mm0,        mm6                         // 35 25 15 05 34 24 14 04
+        movq        mm6,        mm7                         // 37 27 17 07 36 26 16 06
+
+        punpckhdq   mm7,        mm5                         // 77 67 57 47 37 27 17 07  = q3
+        punpckldq   mm6,        mm5                         // 76 66 56 46 36 26 16 06  = q2
+
+        lea         rdx,        srct
+        movq        mm5,        mm6                         // 76 66 56 46 36 26 16 06
+
+        movq        [rdx+56],   mm7
+        psubusb     mm5,        mm7                         // q2-q3
+
+
+        movq        [rdx+48],   mm6
+        psubusb     mm7,        mm6                         // q3-q2
+
+        por         mm7,        mm5;                        // mm7=abs (q3-q2)
+        movq        mm5,        mm0                         // 35 25 15 05 34 24 14 04
+
+        punpckhdq   mm5,        mm3                         // 75 65 55 45 35 25 15 05 = q1
+        punpckldq   mm0,        mm3                         // 74 64 54 44 34 24 15 04 = q0
+
+        movq        mm3,        mm5                         // 75 65 55 45 35 25 15 05 = q1
+        psubusb     mm3,        mm6                         // q1-q2
+
+        psubusb     mm6,        mm5                         // q2-q1
+        por         mm6,        mm3                         // mm6=abs(q2-q1)
+
+        movq        [rdx+40],   mm5                         // save q1
+        movq        [rdx+32],   mm0                         // save q0
+
+        movq        mm3,        [rsi+rax*4]                 // 07 06 05 04 03 02 01 00
+        punpcklbw   mm3,        [rdi+rax*4]                 // 13 03 12 02 11 01 10 00
+
+        movq        mm0,        mm3                         // 13 03 12 02 11 01 10 00
+        punpcklwd   mm0,        mm1                         // 31 21 11 01 30 20 10 00
+
+        punpckhwd   mm3,        mm1                         // 33 23 13 03 32 22 12 02
+        movq        mm1,        mm0                         // 31 21 11 01 30 20 10 00
+
+        punpckldq   mm0,        mm2                         // 70 60 50 40 30 20 10 00  =p3
+        punpckhdq   mm1,        mm2                         // 71 61 51 41 31 21 11 01  =p2
+
+        movq        [rdx],      mm0                         // save p3
+        movq        [rdx+8],    mm1                         // save p2
+
+        movq        mm2,        mm1                         // 71 61 51 41 31 21 11 01  =p2
+        psubusb     mm2,        mm0                         // p2-p3
+
+        psubusb     mm0,        mm1                         // p3-p2
+        por         mm0,        mm2                         // mm0=abs(p3-p2)
+
+        movq        mm2,        mm3                         // 33 23 13 03 32 22 12 02
+        punpckldq   mm2,        mm4                         // 72 62 52 42 32 22 12 02 = p1
+
+        punpckhdq   mm3,        mm4                         // 73 63 53 43 33 23 13 03 = p0
+        movq        [rdx+24],   mm3                         // save p0
+
+        movq        [rdx+16],   mm2                         // save p1
+        movq        mm5,        mm2                         // mm5 = p1
+
+        psubusb     mm2,        mm1                         // p1-p2
+        psubusb     mm1,        mm5                         // p2-p1
+
+        por         mm1,        mm2                         // mm1=abs(p2-p1)
+        mov         rdx,        arg(3) //limit
+
+        movq        mm4,        [rdx]                       // mm4 = limit
+        psubusb     mm7,        mm4                         // abs(q3-q2) > limit
+
+        psubusb     mm0,        mm4                         // abs(p3-p2) > limit
+        psubusb     mm1,        mm4                         // abs(p2-p1) > limit
+
+        psubusb     mm6,        mm4                         // abs(q2-q1) > limit
+        por         mm7,        mm6                         // or
+
+        por         mm0,        mm1                         //
+        por         mm0,        mm7                         // abs(q3-q2) > limit || abs(p3-p2) > limit ||abs(p2-p1) > limit || abs(q2-q1) > limit
+
+        movq        mm1,        mm5                         // p1
+
+        movq        mm7,        mm3                         // mm3=mm7=p0
+        psubusb     mm7,        mm5                         // p0 - p1
+
+        psubusb     mm5,        mm3                         // p1 - p0
+        por         mm5,        mm7                         // abs(p1-p0)
+
+        movq        t0,         mm5                         // save abs(p1-p0)
+        lea         rdx,        srct
+
+        psubusb     mm5,        mm4                         // mm5 = abs(p1-p0) > limit
+        por         mm0,        mm5                         // mm0=mask
+
+        movq        mm5,        [rdx+32]                    // mm5=q0
+        movq        mm7,        [rdx+40]                    // mm7=q1
+
+        movq        mm6,        mm5                         // mm6=q0
+        movq        mm2,        mm7                         // q1
+        psubusb     mm5,        mm7                         // q0-q1
+
+        psubusb     mm7,        mm6                         // q1-q0
+        por         mm7,        mm5                         // abs(q1-q0)
+
+        movq        t1,         mm7                         // save abs(q1-q0)
+        psubusb     mm7,        mm4                         // mm7=abs(q1-q0)> limit
+
+        por         mm0,        mm7                         // mask
+
+        movq        mm5,        mm2                         // q1
+        psubusb     mm5,        mm1                         // q1-=p1
+        psubusb     mm1,        mm2                         // p1-=q1
+        por         mm5,        mm1                         // abs(p1-q1)
+        pand        mm5,        [GLOBAL (tfe)]                // set lsb of each byte to zero
+        psrlw       mm5,        1                           // abs(p1-q1)/2
+
+        mov         rdx,        arg(2) //flimit                      ;
+
+        movq        mm2,        [rdx]                       //flimit  mm2
+        movq        mm1,        mm3                         // mm1=mm3=p0
+
+        movq        mm7,        mm6                         // mm7=mm6=q0
+        psubusb     mm1,        mm7                         // p0-q0
+
+        psubusb     mm7,        mm3                         // q0-p0
+        por         mm1,        mm7                         // abs(q0-p0)
+        paddusb     mm1,        mm1                         // abs(q0-p0)*2
+        paddusb     mm1,        mm5                         // abs (p0 - q0) *2 + abs(p1-q1)/2
+
+        paddb       mm2,        mm2                         // flimit*2 (less than 255)
+        paddb       mm4,        mm2                         // flimit * 2 + limit (less than 255)
+
+        psubusb     mm1,        mm4                         // abs (p0 - q0) *2 + abs(p1-q1)/2  > flimit * 2 + limit
+        por         mm1,        mm0;                        // mask
+
+        pxor        mm0,        mm0
+        pcmpeqb     mm1,        mm0
+
+        // calculate high edge variance
+        mov         rdx,        arg(4) //thresh            ; get thresh
+        movq        mm7,        [rdx]
+        //
+        movq        mm4,        t0              // get abs (q1 - q0)
+        psubusb     mm4,        mm7             // abs(q1 - q0) > thresh
+
+        movq        mm3,        t1              // get abs (p1 - p0)
+        psubusb     mm3,        mm7             // abs(p1 - p0)> thresh
+
+        por         mm4,        mm3             // abs(q1 - q0) > thresh || abs(p1 - p0) > thresh
+        pcmpeqb     mm4,        mm0
+
+        pcmpeqb     mm0,        mm0
+        pxor        mm4,        mm0
+
+
+
+
+        // start work on filters
+        lea         rdx,        srct
+
+        // start work on filters
+        movq        mm2, [rdx+16]         // p1
+        movq        mm7, [rdx+40]         // q1
+        pxor        mm2, [GLOBAL (t80)]     // p1 offset to convert to signed values
+        pxor        mm7, [GLOBAL (t80)]     // q1 offset to convert to signed values
+        psubsb      mm2, mm7              // p1 - q1
+
+        movq        mm6, [rdx+24]         // p0
+        movq        mm0, [rdx+32]         // q0
+        pxor        mm6, [GLOBAL (t80)]     // offset to convert to signed values
+        pxor        mm0, [GLOBAL (t80)]     // offset to convert to signed values
+
+        movq        mm3, mm0              // q0
+        psubsb      mm0, mm6              // q0 - p0
+        paddsb      mm2, mm0              // 1 * (q0 - p0) + (p1 - q1)
+        paddsb      mm2, mm0              // 2 * (q0 - p0)
+        paddsb      mm2, mm0              // 3 * (q0 - p0) + (p1 - q1)
+        pand       mm1, mm2           // mask filter values we don't care about
+
+        // mm1 = vp8_filter, mm4=hev, mm6=ps0, mm3=qs0
+        movq        mm2, mm1              // vp8_filter
+        pand        mm2, mm4;             // Filter2 = vp8_filter & hev
+
+        movq        mm5,        mm2       //
+        paddsb      mm5,        [GLOBAL (t3)];
+
+        pxor        mm0, mm0              // 0
+        pxor        mm7, mm7              // 0
+
+        punpcklbw   mm0, mm5              // e0f0g0h0
+        psraw       mm0, 11               // sign extended shift right by 3
+        punpckhbw   mm7, mm5              // a0b0c0d0
+        psraw       mm7, 11               // sign extended shift right by 3
+        packsswb    mm0, mm7              // Filter2 >>=3;
+
+        movq        mm5, mm0              // Filter2
+
+        paddsb      mm2, [GLOBAL (t4)]      // vp8_signed_char_clamp(Filter2 + 4)
+        pxor        mm0, mm0              // 0
+        pxor        mm7, mm7              // 0
+
+        punpcklbw   mm0, mm2              // e0f0g0h0
+        psraw       mm0, 11               // sign extended shift right by 3
+        punpckhbw   mm7, mm2              // a0b0c0d0
+        psraw       mm7, 11               // sign extended shift right by 3
+        packsswb    mm0, mm7              // Filter2 >>=3;
+
+        // mm0= filter2 mm1 = vp8_filter,  mm3 =qs0 mm5=s mm4 =hev mm6=ps0
+        psubsb      mm3, mm0              // qs0 =qs0 - filter1
+        paddsb      mm6, mm5              // ps0 =ps0 + Fitler2
+
+        // mm1=vp8_filter, mm3=qs0, mm4 =hev mm6=ps0
+        // vp8_filter &= ~hev;
+        // Filter2 = vp8_filter;
+        pandn       mm4, mm1              // vp8_filter&=~hev
+
+
+        // mm3=qs0, mm4=filter2, mm6=ps0
+
+        // u = vp8_signed_char_clamp((63 + Filter2 * 27)>>7);
+        // s = vp8_signed_char_clamp(qs0 - u);
+        // *oq0 = s^0x80;
+        // s = vp8_signed_char_clamp(ps0 + u);
+        // *op0 = s^0x80;
+        pxor        mm0, mm0
+
+        pxor        mm1, mm1
+        pxor        mm2, mm2
+        punpcklbw   mm1, mm4
+        punpckhbw   mm2, mm4
+        pmulhw      mm1, [GLOBAL (s27)]
+        pmulhw      mm2, [GLOBAL (s27)]
+        paddw       mm1, [GLOBAL (s63)]
+        paddw       mm2, [GLOBAL (s63)]
+        psraw       mm1, 7
+        psraw       mm2, 7
+        packsswb    mm1, mm2
+
+        psubsb      mm3, mm1
+        paddsb      mm6, mm1
+
+        pxor        mm3, [GLOBAL (t80)]
+        pxor        mm6, [GLOBAL (t80)]
+        movq        [rdx+24], mm6
+        movq        [rdx+32], mm3
+
+        // roughly 2/7th difference across boundary
+        // u = vp8_signed_char_clamp((63 + Filter2 * 18)>>7);
+        // s = vp8_signed_char_clamp(qs1 - u);
+        // *oq1 = s^0x80;
+        // s = vp8_signed_char_clamp(ps1 + u);
+        // *op1 = s^0x80;
+        pxor        mm1, mm1
+        pxor        mm2, mm2
+        punpcklbw   mm1, mm4
+        punpckhbw   mm2, mm4
+        pmulhw      mm1, [GLOBAL (s18)]
+        pmulhw      mm2, [GLOBAL (s18)]
+        paddw       mm1, [GLOBAL (s63)]
+        paddw       mm2, [GLOBAL (s63)]
+        psraw       mm1, 7
+        psraw       mm2, 7
+        packsswb    mm1, mm2
+
+        movq        mm3, [rdx + 40]
+        movq        mm6, [rdx + 16]       // p1
+        pxor        mm3, [GLOBAL (t80)]
+        pxor        mm6, [GLOBAL (t80)]
+
+        paddsb      mm6, mm1
+        psubsb      mm3, mm1
+
+        pxor        mm6, [GLOBAL (t80)]
+        pxor        mm3, [GLOBAL (t80)]
+        movq        [rdx + 40], mm3
+        movq        [rdx + 16], mm6
+
+        // roughly 1/7th difference across boundary
+        // u = vp8_signed_char_clamp((63 + Filter2 * 9)>>7);
+        // s = vp8_signed_char_clamp(qs2 - u);
+        // *oq2 = s^0x80;
+        // s = vp8_signed_char_clamp(ps2 + u);
+        // *op2 = s^0x80;
+        pxor        mm1, mm1
+        pxor        mm2, mm2
+        punpcklbw   mm1, mm4
+        punpckhbw   mm2, mm4
+        pmulhw      mm1, [GLOBAL (s9)]
+        pmulhw      mm2, [GLOBAL (s9)]
+        paddw       mm1, [GLOBAL (s63)]
+        paddw       mm2, [GLOBAL (s63)]
+        psraw       mm1, 7
+        psraw       mm2, 7
+        packsswb    mm1, mm2
+
+        movq        mm6, [rdx+ 8]
+        movq        mm3, [rdx+48]
+
+        pxor        mm6, [GLOBAL (t80)]
+        pxor        mm3, [GLOBAL (t80)]
+
+        paddsb      mm6, mm1
+        psubsb      mm3, mm1
+
+        pxor        mm6, [GLOBAL (t80)]           // mm6 = 71 61 51 41 31 21 11 01
+        pxor        mm3, [GLOBAL (t80)]           // mm3 = 76 66 56 46 36 26 15 06
+
+        // tranpose and write back
+        movq        mm0,    [rdx]               // mm0 = 70 60 50 40 30 20 10 00
+        movq        mm1,    mm0                 // mm0 = 70 60 50 40 30 20 10 00
+
+        punpcklbw   mm0,    mm6                 // mm0 = 31 30 21 20 11 10 01 00
+        punpckhbw   mm1,    mm6                 // mm3 = 71 70 61 60 51 50 41 40
+
+        movq        mm2,    [rdx+16]            // mm2 = 72 62 52 42 32 22 12 02
+        movq        mm6,    mm2                 // mm3 = 72 62 52 42 32 22 12 02
+
+        punpcklbw   mm2,    [rdx+24]            // mm2 = 33 32 23 22 13 12 03 02
+        punpckhbw   mm6,    [rdx+24]            // mm3 = 73 72 63 62 53 52 43 42
+
+        movq        mm5,    mm0                 // mm5 = 31 30 21 20 11 10 01 00
+        punpcklwd   mm0,    mm2                 // mm0 = 13 12 11 10 03 02 01 00
+
+        punpckhwd   mm5,    mm2                 // mm5 = 33 32 31 30 23 22 21 20
+        movq        mm4,    mm1                 // mm4 = 71 70 61 60 51 50 41 40
+
+        punpcklwd   mm1,    mm6                 // mm1 = 53 52 51 50 43 42 41 40
+        punpckhwd   mm4,    mm6                 // mm4 = 73 72 71 70 63 62 61 60
+
+        movq        mm2,    [rdx+32]            // mm2 = 74 64 54 44 34 24 14 04
+        punpcklbw   mm2,    [rdx+40]            // mm2 = 35 34 25 24 15 14 05 04
+
+        movq        mm6,    mm3                 // mm6 = 76 66 56 46 36 26 15 06
+        punpcklbw   mm6,    [rdx+56]            // mm6 = 37 36 27 26 17 16 07 06
+
+        movq        mm7,    mm2                 // mm7 = 35 34 25 24 15 14 05 04
+        punpcklwd   mm2,    mm6                 // mm2 = 17 16 15 14 07 06 05 04
+
+        punpckhwd   mm7,    mm6                 // mm7 = 37 36 35 34 27 26 25 24
+        movq        mm6,    mm0                 // mm6 = 13 12 11 10 03 02 01 00
+
+        punpckldq   mm0,    mm2                 // mm0 = 07 06 05 04 03 02 01 00
+        punpckhdq   mm6,    mm2                 // mm6 = 17 16 15 14 13 12 11 10
+
+        movq        [rsi+rax*4], mm0            // write out
+        movq        [rdi+rax*4], mm6            // write out
+
+        movq        mm0,    mm5                 // mm0 = 33 32 31 30 23 22 21 20
+        punpckldq   mm0,    mm7                 // mm0 = 27 26 25 24 23 22 20 20
+
+        punpckhdq   mm5,    mm7                 // mm5 = 37 36 35 34 33 32 31 30
+        movq        [rsi+rax*2], mm0            // write out
+
+        movq        [rdi+rax*2], mm5            // write out
+        movq        mm2,    [rdx+32]            // mm2 = 74 64 54 44 34 24 14 04
+
+        punpckhbw   mm2,    [rdx+40]            // mm2 = 75 74 65 64 54 54 45 44
+        punpckhbw   mm3,    [rdx+56]            // mm3 = 77 76 67 66 57 56 47 46
+
+        movq        mm5,    mm2                 // mm5 = 75 74 65 64 54 54 45 44
+        punpcklwd   mm2,    mm3                 // mm2 = 57 56 55 54 47 46 45 44
+
+        punpckhwd   mm5,    mm3                 // mm5 = 77 76 75 74 67 66 65 64
+        movq        mm0,    mm1                 // mm0=  53 52 51 50 43 42 41 40
+
+        movq        mm3,    mm4                 // mm4 = 73 72 71 70 63 62 61 60
+        punpckldq   mm0,    mm2                 // mm0 = 47 46 45 44 43 42 41 40
+
+        punpckhdq   mm1,    mm2                 // mm1 = 57 56 55 54 53 52 51 50
+        movq        [rsi],  mm0                 // write out
+
+        movq        [rdi],  mm1                 // write out
+        neg         rax
+
+        punpckldq   mm3,    mm5                 // mm3 = 67 66 65 64 63 62 61 60
+        punpckhdq   mm4,    mm5                 // mm4 = 77 76 75 74 73 72 71 60
+
+        movq        [rsi+rax*2], mm3
+        movq        [rdi+rax*2], mm4
+
+        lea         rsi,        [rsi+rax*8]
+        dec         rcx
+
+        jnz         next8_mbv
+
+    add rsp, 96
+    pop rsp
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void vp8_loop_filter_simple_horizontal_edge_mmx
+//(
+//    unsigned char *src_ptr,
+//    int  src_pixel_step,
+//    const char *flimit,
+//    const char *limit,
+//    const char *thresh,
+//    int count
+//)
+global sym(vp8_loop_filter_simple_horizontal_edge_mmx)
+sym(vp8_loop_filter_simple_horizontal_edge_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 6
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov         rsi, arg(0) //src_ptr
+        movsxd      rax, dword ptr arg(1) //src_pixel_step     ; destination pitch?
+
+        movsxd      rcx, dword ptr arg(5) //count
+nexts8_h:
+        mov         rdx, arg(3) //limit
+        movq        mm7, [rdx]
+        mov         rdx, arg(2) //flimit           ; get flimit
+        movq        mm3, [rdx]            //
+        paddb       mm3, mm3              // flimit*2 (less than 255)
+        paddb       mm3, mm7              // flimit * 2 + limit (less than 255)
+
+        mov         rdi, rsi              // rdi points to row +1 for indirect addressing
+        add         rdi, rax
+        neg         rax
+
+        // calculate mask
+        movq        mm1, [rsi+2*rax]      // p1
+        movq        mm0, [rdi]            // q1
+        movq        mm2, mm1
+        movq        mm7, mm0
+        movq        mm4, mm0
+        psubusb     mm0, mm1              // q1-=p1
+        psubusb     mm1, mm4              // p1-=q1
+        por         mm1, mm0              // abs(p1-q1)
+        pand        mm1, [GLOBAL (tfe)]     // set lsb of each byte to zero
+        psrlw       mm1, 1                // abs(p1-q1)/2
+
+        movq        mm5, [rsi+rax]        // p0
+        movq        mm4, [rsi]            // q0
+        movq        mm0, mm4              // q0
+        movq        mm6, mm5              // p0
+        psubusb     mm5, mm4              // p0-=q0
+        psubusb     mm4, mm6              // q0-=p0
+        por         mm5, mm4              // abs(p0 - q0)
+        paddusb     mm5, mm5              // abs(p0-q0)*2
+        paddusb     mm5, mm1              // abs (p0 - q0) *2 + abs(p1-q1)/2
+
+        psubusb     mm5, mm3              // abs(p0 - q0) *2 + abs(p1-q1)/2  > flimit * 2 + limit
+        pxor        mm3, mm3
+        pcmpeqb     mm5, mm3
+
+        // start work on filters
+        pxor        mm2, [GLOBAL (t80)]     // p1 offset to convert to signed values
+        pxor        mm7, [GLOBAL (t80)]     // q1 offset to convert to signed values
+        psubsb      mm2, mm7              // p1 - q1
+
+        pxor        mm6, [GLOBAL (t80)]     // offset to convert to signed values
+        pxor        mm0, [GLOBAL (t80)]     // offset to convert to signed values
+        movq        mm3, mm0              // q0
+        psubsb      mm0, mm6              // q0 - p0
+        paddsb      mm2, mm0              // p1 - q1 + 1 * (q0 - p0)
+        paddsb      mm2, mm0              // p1 - q1 + 2 * (q0 - p0)
+        paddsb      mm2, mm0              // p1 - q1 + 3 * (q0 - p0)
+        pand        mm5, mm2              // mask filter values we don't care about
+
+        // do + 4 side
+        paddsb      mm5, [GLOBAL (t4)]      // 3* (q0 - p0) + (p1 - q1) + 4
+
+        movq        mm0, mm5              // get a copy of filters
+        psllw       mm0, 8                // shift left 8
+        psraw       mm0, 3                // arithmetic shift right 11
+        psrlw       mm0, 8
+        movq        mm1, mm5              // get a copy of filters
+        psraw       mm1, 11               // arithmetic shift right 11
+        psllw       mm1, 8                // shift left 8 to put it back
+
+        por         mm0, mm1              // put the two together to get result
+
+        psubsb      mm3, mm0              // q0-= q0 add
+        pxor        mm3, [GLOBAL (t80)]     // unoffset
+        movq        [rsi], mm3            // write back
+
+
+        // now do +3 side
+        psubsb      mm5, [GLOBAL (t1s)]      // +3 instead of +4
+
+        movq        mm0, mm5              // get a copy of filters
+        psllw       mm0, 8                // shift left 8
+        psraw       mm0, 3                // arithmetic shift right 11
+        psrlw       mm0, 8
+        psraw       mm5, 11               // arithmetic shift right 11
+        psllw       mm5, 8                // shift left 8 to put it back
+        por         mm0, mm5              // put the two together to get result
+
+
+        paddsb      mm6, mm0              // p0+= p0 add
+        pxor        mm6, [GLOBAL (t80)]     // unoffset
+        movq        [rsi+rax], mm6        // write back
+
+        add         rsi,8
+        neg         rax
+        dec         rcx
+        jnz         nexts8_h
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void vp8_loop_filter_simple_vertical_edge_mmx
+//(
+//    unsigned char *src_ptr,
+//    int  src_pixel_step,
+//    const char *flimit,
+//    const char *limit,
+//    const char *thresh,
+//    int count
+//)
+global sym(vp8_loop_filter_simple_vertical_edge_mmx)
+sym(vp8_loop_filter_simple_vertical_edge_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 6
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+    ALIGN_STACK 16, rax
+    sub          rsp, 32      // reserve 32 bytes
+#   define t0   [rsp + 0]    //__declspec(align(16)) char t0[8];
+#   define t1   [rsp + 16]   //__declspec(align(16)) char t1[8];
+
+        mov         rsi, arg(0) //src_ptr
+        movsxd      rax, dword ptr arg(1) //src_pixel_step     ; destination pitch?
+
+        lea         rsi, [rsi + rax*4- 2];  //
+        movsxd      rcx, dword ptr arg(5) //count
+nexts8_v:
+
+        lea         rdi,        [rsi + rax];
+        movd        mm0,        [rdi + rax * 2]                 // xx xx xx xx 73 72 71 70
+
+        movd        mm6,        [rsi + rax * 2]                 // xx xx xx xx 63 62 61 60
+        punpcklbw   mm6,        mm0                             // 73 63 72 62 71 61 70 60
+
+        movd        mm0,        [rsi + rax]                     // xx xx xx xx 53 52 51 50
+        movd        mm4,        [rsi]                           // xx xx xx xx 43 42 41 40
+
+        punpcklbw   mm4,        mm0                             // 53 43 52 42 51 41 50 40
+        movq        mm5,        mm4                             // 53 43 52 42 51 41 50 40
+
+        punpcklwd   mm4,        mm6                             // 71 61 51 41 70 60 50 40
+        punpckhwd   mm5,        mm6                             // 73 63 53 43 72 62 52 42
+
+        neg         rax
+
+        movd        mm7,        [rsi + rax]                     // xx xx xx xx 33 32 31 30
+        movd        mm6,        [rsi + rax * 2]                 // xx xx xx xx 23 22 21 20
+
+        punpcklbw   mm6,        mm7                             // 33 23 32 22 31 21 30 20
+        movd        mm1,        [rdi + rax * 4]                 // xx xx xx xx 13 12 11 10
+
+        movd        mm0,        [rsi + rax * 4]                 // xx xx xx xx 03 02 01 00
+        punpcklbw   mm0,        mm1                             // 13 03 12 02 11 01 10 00
+
+        movq        mm2,        mm0                             // 13 03 12 02 11 01 10 00
+        punpcklwd   mm0,        mm6                             // 31 21 11 01 30 20 10 00
+
+        punpckhwd   mm2,        mm6                             // 33 23 13 03 32 22 12 02
+        movq        mm1,        mm0                             // 13 03 12 02 11 01 10 00
+
+        punpckldq   mm0,        mm4                             // 70 60 50 40 30 20 10 00       = p1
+        movq        mm3,        mm2                             // 33 23 13 03 32 22 12 02
+
+        punpckhdq   mm1,        mm4                             // 71 61 51 41 31 21 11 01       = p0
+        punpckldq   mm2,        mm5                             // 72 62 52 42 32 22 12 02       = q0
+
+        punpckhdq   mm3,        mm5                             // 73 63 53 43 33 23 13 03       = q1
+
+
+        // calculate mask
+        movq        mm6,        mm0                             // p1
+        movq        mm7,        mm3                             // q1
+        psubusb     mm7,        mm6                             // q1-=p1
+        psubusb     mm6,        mm3                             // p1-=q1
+        por         mm6,        mm7                             // abs(p1-q1)
+        pand        mm6,        [GLOBAL (tfe)]                    // set lsb of each byte to zero
+        psrlw       mm6,        1                               // abs(p1-q1)/2
+
+        movq        mm5,        mm1                             // p0
+        movq        mm4,        mm2                             // q0
+
+        psubusb     mm5,        mm2                             // p0-=q0
+        psubusb     mm4,        mm1                             // q0-=p0
+
+        por         mm5,        mm4                             // abs(p0 - q0)
+        paddusb     mm5,        mm5                             // abs(p0-q0)*2
+        paddusb     mm5,        mm6                             // abs (p0 - q0) *2 + abs(p1-q1)/2
+
+        mov         rdx,        arg(2) //flimit                          ; get flimit
+        movq        mm7,        [rdx]
+        mov         rdx,        arg(3)                          // get limit
+        movq        mm6,        [rdx]
+        paddb       mm7,        mm7                             // flimit*2 (less than 255)
+        paddb       mm7,        mm6                             // flimit * 2 + limit (less than 255)
+
+        psubusb     mm5,        mm7                             // abs(p0 - q0) *2 + abs(p1-q1)/2  > flimit * 2 + limit
+        pxor        mm7,        mm7
+        pcmpeqb     mm5,        mm7                             // mm5 = mask
+
+        // start work on filters
+        movq        t0,         mm0
+        movq        t1,         mm3
+
+        pxor        mm0,        [GLOBAL (t80)]                    // p1 offset to convert to signed values
+        pxor        mm3,        [GLOBAL (t80)]                    // q1 offset to convert to signed values
+
+        psubsb      mm0,        mm3                             // p1 - q1
+        movq        mm6,        mm1                             // p0
+
+        movq        mm7,        mm2                             // q0
+        pxor        mm6,        [GLOBAL (t80)]                    // offset to convert to signed values
+
+        pxor        mm7,        [GLOBAL (t80)]                    // offset to convert to signed values
+        movq        mm3,        mm7                             // offseted ; q0
+
+        psubsb      mm7,        mm6                             // q0 - p0
+        paddsb      mm0,        mm7                             // p1 - q1 + 1 * (q0 - p0)
+
+        paddsb      mm0,        mm7                             // p1 - q1 + 2 * (q0 - p0)
+        paddsb      mm0,        mm7                             // p1 - q1 + 3 * (q0 - p0)
+
+        pand        mm5,        mm0                             // mask filter values we don't care about
+
+        paddsb      mm5,        [GLOBAL (t4)]                     //  3* (q0 - p0) + (p1 - q1) + 4
+
+        movq        mm0,        mm5                             // get a copy of filters
+        psllw       mm0,        8                               // shift left 8
+        psraw       mm0,        3                               // arithmetic shift right 11
+        psrlw       mm0,        8
+
+        movq        mm7,        mm5                             // get a copy of filters
+        psraw       mm7,        11                              // arithmetic shift right 11
+        psllw       mm7,        8                               // shift left 8 to put it back
+
+        por         mm0,        mm7                             // put the two together to get result
+
+        psubsb      mm3,        mm0                             // q0-= q0sz add
+        pxor        mm3,        [GLOBAL (t80)]                    // unoffset
+
+        // now do +3 side
+        psubsb      mm5, [GLOBAL (t1s)]                           // +3 instead of +4
+
+        movq        mm0, mm5                                    // get a copy of filters
+        psllw       mm0, 8                                      // shift left 8
+        psraw       mm0, 3                                      // arithmetic shift right 11
+        psrlw       mm0, 8
+
+        psraw       mm5, 11                                     // arithmetic shift right 11
+        psllw       mm5, 8                                      // shift left 8 to put it back
+        por         mm0, mm5                                    // put the two together to get result
+
+        paddsb      mm6, mm0                                    // p0+= p0 add
+        pxor        mm6, [GLOBAL (t80)]                           // unoffset
+
+
+        movq        mm0,        t0
+        movq        mm4,        t1
+
+        // mm0 = 70 60 50 40 30 20 10 00
+        // mm6 = 71 61 51 41 31 21 11 01
+        // mm3 = 72 62 52 42 32 22 12 02
+        // mm4 = 73 63 53 43 33 23 13 03
+        // transpose back to write out
+
+        movq        mm1,        mm0                         //
+        punpcklbw   mm0,        mm6                         // 31 30 21 20 11 10 01 00
+
+        punpckhbw   mm1,        mm6                         // 71 70 61 60 51 50 41 40
+        movq        mm2,        mm3                         //
+
+        punpcklbw   mm2,        mm4                         // 33 32 23 22 13 12 03 02
+        movq        mm5,        mm1                         // 71 70 61 60 51 50 41 40
+
+        punpckhbw   mm3,        mm4                         // 73 72 63 62 53 52 43 42
+        movq        mm6,        mm0                         // 31 30 21 20 11 10 01 00
+
+        punpcklwd   mm0,        mm2                         // 13 12 11 10 03 02 01 00
+        punpckhwd   mm6,        mm2                         // 33 32 31 30 23 22 21 20
+
+        movd        [rsi+rax*4], mm0                        // write 03 02 01 00
+        punpcklwd   mm1,        mm3                         // 53 52 51 50 43 42 41 40
+
+        psrlq       mm0,        32                          // xx xx xx xx 13 12 11 10
+        punpckhwd   mm5,        mm3                         // 73 72 71 70 63 62 61 60
+
+        movd        [rdi+rax*4], mm0                        // write 13 12 11 10
+        movd        [rsi+rax*2], mm6                        // write 23 22 21 20
+
+        psrlq       mm6,        32                          // 33 32 31 30
+        movd        [rsi],      mm1                         // write 43 42 41 40
+
+        movd        [rsi + rax], mm6                        // write 33 32 31 30
+        neg         rax
+
+        movd        [rsi + rax*2], mm5                      // write 63 62 61 60
+        psrlq       mm1,        32                          // 53 52 51 50
+
+        movd        [rdi],      mm1                         // write out 53 52 51 50
+        psrlq       mm5,        32                          // 73 72 71 70
+
+        movd        [rdi + rax*2], mm5                      // write 73 72 71 70
+
+        lea         rsi,        [rsi+rax*8]                 // next 8
+
+        dec         rcx
+        jnz         nexts8_v
+
+    add rsp, 32
+    pop rsp
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+
+//void fast_loop_filter_vertical_edges_mmx(unsigned char *y_ptr,
+//                  int y_stride,
+//                  loop_filter_info *lfi)
+//{
+//
+//
+//    vp8_loop_filter_simple_vertical_edge_mmx(y_ptr+4, y_stride, lfi->flim,lfi->lim,lfi->thr,2);
+//    vp8_loop_filter_simple_vertical_edge_mmx(y_ptr+8, y_stride, lfi->flim,lfi->lim,lfi->thr,2);
+//    vp8_loop_filter_simple_vertical_edge_mmx(y_ptr+12, y_stride, lfi->flim,lfi->lim,lfi->thr,2);
+//}
+
+SECTION_RODATA
+align 16
+tfe:
+    .fill 8, 1, 0xfe
+align 16
+t80:
+    .fill 8, 1, 0x80
+align 16
+t1s:
+    .fill 8, 1, 0x01
+align 16
+t3:
+    .fill 8, 1, 0x03
+align 16
+t4:
+    .fill 8, 1, 0x04
+align 16
+ones:
+    .fill 4, 2, 0x0001
+align 16
+s27:
+    .fill 4, 2, 0x1b00
+align 16
+s18:
+    .fill 4, 2, 0x1200
+align 16
+s9:
+    .fill 4, 2, 0x0900
+align 16
+s63:
+    .fill 4, 2, 0x003f
diff --git a/vp8/common/x86/loopfilter_mmx.asm b/vp8/common/x86/loopfilter_mmx.asm
deleted file mode 100644
index 6e4d2b6..0000000
--- a/vp8/common/x86/loopfilter_mmx.asm
+++ /dev/null
@@ -1,1776 +0,0 @@
-;
-;  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
-;
-;  Use of this source code is governed by a BSD-style license and patent
-;  grant that can be found in the LICENSE file in the root of the source
-;  tree. All contributing project authors may be found in the AUTHORS
-;  file in the root of the source tree.
-;
-
-
-%include "vpx_ports/x86_abi_support.asm"
-
-
-;void vp8_loop_filter_horizontal_edge_mmx
-;(
-;    unsigned char *src_ptr,
-;    int src_pixel_step,
-;    const char *flimit,
-;    const char *limit,
-;    const char *thresh,
-;    int  count
-;)
-global sym(vp8_loop_filter_horizontal_edge_mmx)
-sym(vp8_loop_filter_horizontal_edge_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 6
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-    ALIGN_STACK 16, rax
-    sub         rsp, 32                         ; reserve 32 bytes
-    %define t0 [rsp + 0]    ;__declspec(align(16)) char t0[8];
-    %define t1 [rsp + 16]   ;__declspec(align(16)) char t1[8];
-
-        mov         rsi, arg(0) ;src_ptr
-        movsxd      rax, dword ptr arg(1) ;src_pixel_step     ; destination pitch?
-
-        movsxd      rcx, dword ptr arg(5) ;count
-next8_h:
-        mov         rdx, arg(3) ;limit
-        movq        mm7, [rdx]
-        mov         rdi, rsi              ; rdi points to row +1 for indirect addressing
-        add         rdi, rax
-
-        ; calculate breakout conditions
-        movq        mm2, [rdi+2*rax]      ; q3
-        movq        mm1, [rsi+2*rax]      ; q2
-        movq        mm6, mm1              ; q2
-        psubusb     mm1, mm2              ; q2-=q3
-        psubusb     mm2, mm6              ; q3-=q2
-        por         mm1, mm2              ; abs(q3-q2)
-        psubusb     mm1, mm7              ;
-
-
-        movq        mm4, [rsi+rax]        ; q1
-        movq        mm3, mm4              ; q1
-        psubusb     mm4, mm6              ; q1-=q2
-        psubusb     mm6, mm3              ; q2-=q1
-        por         mm4, mm6              ; abs(q2-q1)
-
-        psubusb     mm4, mm7
-        por        mm1, mm4
-
-        movq        mm4, [rsi]            ; q0
-        movq        mm0, mm4              ; q0
-        psubusb     mm4, mm3              ; q0-=q1
-        psubusb     mm3, mm0              ; q1-=q0
-        por         mm4, mm3              ; abs(q0-q1)
-        movq        t0, mm4               ; save to t0
-        psubusb     mm4, mm7
-        por        mm1, mm4
-
-
-        neg         rax                   ; negate pitch to deal with above border
-
-        movq        mm2, [rsi+4*rax]      ; p3
-        movq        mm4, [rdi+4*rax]      ; p2
-        movq        mm5, mm4              ; p2
-        psubusb     mm4, mm2              ; p2-=p3
-        psubusb     mm2, mm5              ; p3-=p2
-        por         mm4, mm2              ; abs(p3 - p2)
-        psubusb     mm4, mm7
-        por        mm1, mm4
-
-
-        movq        mm4, [rsi+2*rax]      ; p1
-        movq        mm3, mm4              ; p1
-        psubusb     mm4, mm5              ; p1-=p2
-        psubusb     mm5, mm3              ; p2-=p1
-        por         mm4, mm5              ; abs(p2 - p1)
-        psubusb     mm4, mm7
-        por        mm1, mm4
-
-        movq        mm2, mm3              ; p1
-
-        movq        mm4, [rsi+rax]        ; p0
-        movq        mm5, mm4              ; p0
-        psubusb     mm4, mm3              ; p0-=p1
-        psubusb     mm3, mm5              ; p1-=p0
-        por         mm4, mm3              ; abs(p1 - p0)
-        movq        t1, mm4               ; save to t1
-        psubusb     mm4, mm7
-        por        mm1, mm4
-
-        movq        mm3, [rdi]            ; q1
-        movq        mm4, mm3              ; q1
-        psubusb     mm3, mm2              ; q1-=p1
-        psubusb     mm2, mm4              ; p1-=q1
-        por         mm2, mm3              ; abs(p1-q1)
-        pand        mm2, [tfe GLOBAL]     ; set lsb of each byte to zero
-        psrlw       mm2, 1                ; abs(p1-q1)/2
-
-        movq        mm6, mm5              ; p0
-        movq        mm3, [rsi]            ; q0
-        psubusb     mm5, mm3              ; p0-=q0
-        psubusb     mm3, mm6              ; q0-=p0
-        por         mm5, mm3              ; abs(p0 - q0)
-        paddusb     mm5, mm5              ; abs(p0-q0)*2
-        paddusb     mm5, mm2              ; abs (p0 - q0) *2 + abs(p1-q1)/2
-
-        mov         rdx, arg(2) ;flimit           ; get flimit
-        movq        mm2, [rdx]            ; flimit mm2
-        paddb       mm2, mm2              ; flimit*2 (less than 255)
-        paddb       mm7, mm2              ; flimit * 2 + limit (less than 255)
-
-        psubusb     mm5,    mm7           ; abs (p0 - q0) *2 + abs(p1-q1)/2  > flimit * 2 + limit
-        por         mm1,    mm5
-        pxor        mm5,    mm5
-        pcmpeqb     mm1,    mm5           ; mask mm1
-
-        ; calculate high edge variance
-        mov         rdx, arg(4) ;thresh           ; get thresh
-        movq        mm7, [rdx]            ;
-        movq        mm4, t0               ; get abs (q1 - q0)
-        psubusb     mm4, mm7
-        movq        mm3, t1               ; get abs (p1 - p0)
-        psubusb     mm3, mm7
-        paddb       mm4, mm3              ; abs(q1 - q0) > thresh || abs(p1 - p0) > thresh
-
-        pcmpeqb     mm4,        mm5
-
-        pcmpeqb     mm5,        mm5
-        pxor        mm4,        mm5
-
-
-        ; start work on filters
-        movq        mm2, [rsi+2*rax]      ; p1
-        movq        mm7, [rdi]            ; q1
-        pxor        mm2, [t80 GLOBAL]     ; p1 offset to convert to signed values
-        pxor        mm7, [t80 GLOBAL]     ; q1 offset to convert to signed values
-        psubsb      mm2, mm7              ; p1 - q1
-        pand        mm2, mm4              ; high var mask (hvm)(p1 - q1)
-        pxor        mm6, [t80 GLOBAL]     ; offset to convert to signed values
-        pxor        mm0, [t80 GLOBAL]     ; offset to convert to signed values
-        movq        mm3, mm0              ; q0
-        psubsb      mm0, mm6              ; q0 - p0
-        paddsb      mm2, mm0              ; 1 * (q0 - p0) + hvm(p1 - q1)
-        paddsb      mm2, mm0              ; 2 * (q0 - p0) + hvm(p1 - q1)
-        paddsb      mm2, mm0              ; 3 * (q0 - p0) + hvm(p1 - q1)
-        pand        mm1, mm2                  ; mask filter values we don't care about
-        movq        mm2, mm1
-        paddsb      mm1, [t4 GLOBAL]      ; 3* (q0 - p0) + hvm(p1 - q1) + 4
-        paddsb      mm2, [t3 GLOBAL]      ; 3* (q0 - p0) + hvm(p1 - q1) + 3
-
-        pxor        mm0, mm0             ;
-        pxor        mm5, mm5
-        punpcklbw   mm0, mm2            ;
-        punpckhbw   mm5, mm2            ;
-        psraw       mm0, 11             ;
-        psraw       mm5, 11
-        packsswb    mm0, mm5
-        movq        mm2, mm0            ;  (3* (q0 - p0) + hvm(p1 - q1) + 3) >> 3;
-
-        pxor        mm0, mm0              ; 0
-        movq        mm5, mm1              ; abcdefgh
-        punpcklbw   mm0, mm1              ; e0f0g0h0
-        psraw       mm0, 11               ; sign extended shift right by 3
-        pxor        mm1, mm1              ; 0
-        punpckhbw   mm1, mm5              ; a0b0c0d0
-        psraw       mm1, 11               ; sign extended shift right by 3
-        movq        mm5, mm0              ; save results
-
-        packsswb    mm0, mm1              ; (3* (q0 - p0) + hvm(p1 - q1) + 4) >>3
-        paddsw      mm5, [ones GLOBAL]
-        paddsw      mm1, [ones GLOBAL]
-        psraw       mm5, 1                ; partial shifted one more time for 2nd tap
-        psraw       mm1, 1                ; partial shifted one more time for 2nd tap
-        packsswb    mm5, mm1              ; (3* (q0 - p0) + hvm(p1 - q1) + 4) >>4
-        pandn       mm4, mm5              ; high edge variance additive
-
-        paddsb      mm6, mm2              ; p0+= p0 add
-        pxor        mm6, [t80 GLOBAL]     ; unoffset
-        movq        [rsi+rax], mm6        ; write back
-
-        movq        mm6, [rsi+2*rax]      ; p1
-        pxor        mm6, [t80 GLOBAL]     ; reoffset
-        paddsb      mm6, mm4              ; p1+= p1 add
-        pxor        mm6, [t80 GLOBAL]     ; unoffset
-        movq        [rsi+2*rax], mm6      ; write back
-
-        psubsb      mm3, mm0              ; q0-= q0 add
-        pxor        mm3, [t80 GLOBAL]     ; unoffset
-        movq        [rsi], mm3            ; write back
-
-        psubsb      mm7, mm4              ; q1-= q1 add
-        pxor        mm7, [t80 GLOBAL]     ; unoffset
-        movq        [rdi], mm7            ; write back
-
-        add         rsi,8
-        neg         rax
-        dec         rcx
-        jnz         next8_h
-
-    add rsp, 32
-    pop rsp
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void vp8_loop_filter_vertical_edge_mmx
-;(
-;    unsigned char *src_ptr,
-;    int  src_pixel_step,
-;    const char *flimit,
-;    const char *limit,
-;    const char *thresh,
-;    int count
-;)
-global sym(vp8_loop_filter_vertical_edge_mmx)
-sym(vp8_loop_filter_vertical_edge_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 6
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-    ALIGN_STACK 16, rax
-    sub          rsp, 64      ; reserve 64 bytes
-    %define t0   [rsp + 0]    ;__declspec(align(16)) char t0[8];
-    %define t1   [rsp + 16]   ;__declspec(align(16)) char t1[8];
-    %define srct [rsp + 32]   ;__declspec(align(16)) char srct[32];
-
-        mov         rsi,        arg(0) ;src_ptr
-        movsxd      rax,        dword ptr arg(1) ;src_pixel_step     ; destination pitch?
-
-        lea         rsi,        [rsi + rax*4 - 4]
-
-        movsxd      rcx,        dword ptr arg(5) ;count
-next8_v:
-        mov         rdi,        rsi           ; rdi points to row +1 for indirect addressing
-        add         rdi,        rax
-
-
-        ;transpose
-        movq        mm6,        [rsi+2*rax]                 ; 67 66 65 64 63 62 61 60
-        movq        mm7,        mm6                         ; 77 76 75 74 73 72 71 70
-
-        punpckhbw   mm7,        [rdi+2*rax]                 ; 77 67 76 66 75 65 74 64
-        punpcklbw   mm6,        [rdi+2*rax]                 ; 73 63 72 62 71 61 70 60
-
-        movq        mm4,        [rsi]                       ; 47 46 45 44 43 42 41 40
-        movq        mm5,        mm4                         ; 47 46 45 44 43 42 41 40
-
-        punpckhbw   mm5,        [rsi+rax]                   ; 57 47 56 46 55 45 54 44
-        punpcklbw   mm4,        [rsi+rax]                   ; 53 43 52 42 51 41 50 40
-
-        movq        mm3,        mm5                         ; 57 47 56 46 55 45 54 44
-        punpckhwd   mm5,        mm7                         ; 77 67 57 47 76 66 56 46
-
-        punpcklwd   mm3,        mm7                         ; 75 65 55 45 74 64 54 44
-        movq        mm2,        mm4                         ; 53 43 52 42 51 41 50 40
-
-        punpckhwd   mm4,        mm6                         ; 73 63 53 43 72 62 52 42
-        punpcklwd   mm2,        mm6                         ; 71 61 51 41 70 60 50 40
-
-        neg         rax
-        movq        mm6,        [rsi+rax*2]                 ; 27 26 25 24 23 22 21 20
-
-        movq        mm1,        mm6                         ; 27 26 25 24 23 22 21 20
-        punpckhbw   mm6,        [rsi+rax]                   ; 37 27 36 36 35 25 34 24
-
-        punpcklbw   mm1,        [rsi+rax]                   ; 33 23 32 22 31 21 30 20
-        movq        mm7,        [rsi+rax*4];                ; 07 06 05 04 03 02 01 00
-
-        punpckhbw   mm7,        [rdi+rax*4]                 ; 17 07 16 06 15 05 14 04
-        movq        mm0,        mm7                         ; 17 07 16 06 15 05 14 04
-
-        punpckhwd   mm7,        mm6                         ; 37 27 17 07 36 26 16 06
-        punpcklwd   mm0,        mm6                         ; 35 25 15 05 34 24 14 04
-
-        movq        mm6,        mm7                         ; 37 27 17 07 36 26 16 06
-        punpckhdq   mm7,        mm5                         ; 77 67 57 47 37 27 17 07  = q3
-
-        punpckldq   mm6,        mm5                         ; 76 66 56 46 36 26 16 06  = q2
-
-        movq        mm5,        mm6                         ; 76 66 56 46 36 26 16 06
-        psubusb     mm5,        mm7                         ; q2-q3
-
-        psubusb     mm7,        mm6                         ; q3-q2
-        por         mm7,        mm5;                        ; mm7=abs (q3-q2)
-
-        movq        mm5,        mm0                         ; 35 25 15 05 34 24 14 04
-        punpckhdq   mm5,        mm3                         ; 75 65 55 45 35 25 15 05 = q1
-
-        punpckldq   mm0,        mm3                         ; 74 64 54 44 34 24 15 04 = q0
-        movq        mm3,        mm5                         ; 75 65 55 45 35 25 15 05 = q1
-
-        psubusb     mm3,        mm6                         ; q1-q2
-        psubusb     mm6,        mm5                         ; q2-q1
-
-        por         mm6,        mm3                         ; mm6=abs(q2-q1)
-        lea         rdx,        srct
-
-        movq        [rdx+24],   mm5                         ; save q1
-        movq        [rdx+16],   mm0                         ; save q0
-
-        movq        mm3,        [rsi+rax*4]                 ; 07 06 05 04 03 02 01 00
-        punpcklbw   mm3,        [rdi+rax*4]                 ; 13 03 12 02 11 01 10 00
-
-        movq        mm0,        mm3                         ; 13 03 12 02 11 01 10 00
-        punpcklwd   mm0,        mm1                         ; 31 21 11 01 30 20 10 00
-
-        punpckhwd   mm3,        mm1                         ; 33 23 13 03 32 22 12 02
-        movq        mm1,        mm0                         ; 31 21 11 01 30 20 10 00
-
-        punpckldq   mm0,        mm2                         ; 70 60 50 40 30 20 10 00  =p3
-        punpckhdq   mm1,        mm2                         ; 71 61 51 41 31 21 11 01  =p2
-
-        movq        mm2,        mm1                         ; 71 61 51 41 31 21 11 01  =p2
-        psubusb     mm2,        mm0                         ; p2-p3
-
-        psubusb     mm0,        mm1                         ; p3-p2
-        por         mm0,        mm2                         ; mm0=abs(p3-p2)
-
-        movq        mm2,        mm3                         ; 33 23 13 03 32 22 12 02
-        punpckldq   mm2,        mm4                         ; 72 62 52 42 32 22 12 02 = p1
-
-        punpckhdq   mm3,        mm4                         ; 73 63 53 43 33 23 13 03 = p0
-        movq        [rdx+8],    mm3                         ; save p0
-
-        movq        [rdx],      mm2                         ; save p1
-        movq        mm5,        mm2                         ; mm5 = p1
-
-        psubusb     mm2,        mm1                         ; p1-p2
-        psubusb     mm1,        mm5                         ; p2-p1
-
-        por         mm1,        mm2                         ; mm1=abs(p2-p1)
-        mov         rdx,        arg(3) ;limit
-
-        movq        mm4,        [rdx]                       ; mm4 = limit
-        psubusb     mm7,        mm4
-
-        psubusb     mm0,        mm4
-        psubusb     mm1,        mm4
-
-        psubusb     mm6,        mm4
-        por         mm7,        mm6
-
-        por         mm0,        mm1
-        por         mm0,        mm7                         ;   abs(q3-q2) > limit || abs(p3-p2) > limit ||abs(p2-p1) > limit || abs(q2-q1) > limit
-
-        movq        mm1,        mm5                         ; p1
-
-        movq        mm7,        mm3                         ; mm3=mm7=p0
-        psubusb     mm7,        mm5                         ; p0 - p1
-
-        psubusb     mm5,        mm3                         ; p1 - p0
-        por         mm5,        mm7                         ; abs(p1-p0)
-
-        movq        t0,         mm5                         ; save abs(p1-p0)
-        lea         rdx,        srct
-
-        psubusb     mm5,        mm4
-        por         mm0,        mm5                         ; mm0=mask
-
-        movq        mm5,        [rdx+16]                    ; mm5=q0
-        movq        mm7,        [rdx+24]                    ; mm7=q1
-
-        movq        mm6,        mm5                         ; mm6=q0
-        movq        mm2,        mm7                         ; q1
-        psubusb     mm5,        mm7                         ; q0-q1
-
-        psubusb     mm7,        mm6                         ; q1-q0
-        por         mm7,        mm5                         ; abs(q1-q0)
-
-        movq        t1,         mm7                         ; save abs(q1-q0)
-        psubusb     mm7,        mm4
-
-        por         mm0,        mm7                         ; mask
-
-        movq        mm5,        mm2                         ; q1
-        psubusb     mm5,        mm1                         ; q1-=p1
-        psubusb     mm1,        mm2                         ; p1-=q1
-        por         mm5,        mm1                         ; abs(p1-q1)
-        pand        mm5,        [tfe GLOBAL]                ; set lsb of each byte to zero
-        psrlw       mm5,        1                           ; abs(p1-q1)/2
-
-        mov         rdx,        arg(2) ;flimit                      ;
-
-        movq        mm2,        [rdx]                       ;flimit  mm2
-        movq        mm1,        mm3                         ; mm1=mm3=p0
-
-        movq        mm7,        mm6                         ; mm7=mm6=q0
-        psubusb     mm1,        mm7                         ; p0-q0
-
-        psubusb     mm7,        mm3                         ; q0-p0
-        por         mm1,        mm7                         ; abs(q0-p0)
-        paddusb     mm1,        mm1                         ; abs(q0-p0)*2
-        paddusb     mm1,        mm5                         ; abs (p0 - q0) *2 + abs(p1-q1)/2
-
-        paddb       mm2,        mm2                         ; flimit*2 (less than 255)
-        paddb       mm4,        mm2                         ; flimit * 2 + limit (less than 255)
-
-        psubusb     mm1,        mm4                         ; abs (p0 - q0) *2 + abs(p1-q1)/2  > flimit * 2 + limit
-        por         mm1,        mm0;                        ; mask
-
-        pxor        mm0,        mm0
-        pcmpeqb     mm1,        mm0
-
-        ; calculate high edge variance
-        mov         rdx,        arg(4) ;thresh            ; get thresh
-        movq        mm7,        [rdx]
-        ;
-        movq        mm4,        t0              ; get abs (q1 - q0)
-        psubusb     mm4,        mm7
-
-        movq        mm3,        t1              ; get abs (p1 - p0)
-        psubusb     mm3,        mm7
-
-        por         mm4,        mm3             ; abs(q1 - q0) > thresh || abs(p1 - p0) > thresh
-        pcmpeqb     mm4,        mm0
-
-        pcmpeqb     mm0,        mm0
-        pxor        mm4,        mm0
-
-
-
-        ; start work on filters
-        lea         rdx,        srct
-
-        movq        mm2,        [rdx]           ; p1
-        movq        mm7,        [rdx+24]        ; q1
-
-        movq        mm6,        [rdx+8]         ; p0
-        movq        mm0,        [rdx+16]        ; q0
-
-        pxor        mm2,        [t80 GLOBAL]    ; p1 offset to convert to signed values
-        pxor        mm7,        [t80 GLOBAL]    ; q1 offset to convert to signed values
-
-        psubsb      mm2,        mm7             ; p1 - q1
-        pand        mm2,        mm4             ; high var mask (hvm)(p1 - q1)
-
-        pxor        mm6,        [t80 GLOBAL]    ; offset to convert to signed values
-        pxor        mm0,        [t80 GLOBAL]    ; offset to convert to signed values
-
-        movq        mm3,        mm0             ; q0
-        psubsb      mm0,        mm6             ; q0 - p0
-
-        paddsb      mm2,        mm0             ; 1 * (q0 - p0) + hvm(p1 - q1)
-        paddsb      mm2,        mm0             ; 2 * (q0 - p0) + hvm(p1 - q1)
-
-        paddsb      mm2,        mm0             ; 3 * (q0 - p0) + hvm(p1 - q1)
-        pand       mm1,        mm2              ; mask filter values we don't care about
-
-        movq        mm2,        mm1
-        paddsb      mm1,        [t4 GLOBAL]       ; 3* (q0 - p0) + hvm(p1 - q1) + 4
-
-        paddsb      mm2,        [t3 GLOBAL]       ; 3* (q0 - p0) + hvm(p1 - q1) + 3
-        pxor        mm0,        mm0          ;
-
-        pxor        mm5,        mm5
-        punpcklbw   mm0,        mm2         ;
-
-        punpckhbw   mm5,        mm2         ;
-        psraw       mm0,        11              ;
-
-        psraw       mm5,        11
-        packsswb    mm0,        mm5
-
-        movq        mm2,        mm0         ;  (3* (q0 - p0) + hvm(p1 - q1) + 3) >> 3;
-
-        pxor        mm0,        mm0           ; 0
-        movq        mm5,        mm1           ; abcdefgh
-
-        punpcklbw   mm0,        mm1           ; e0f0g0h0
-        psraw       mm0,        11                ; sign extended shift right by 3
-
-        pxor        mm1,        mm1           ; 0
-        punpckhbw   mm1,        mm5           ; a0b0c0d0
-
-        psraw       mm1,        11                ; sign extended shift right by 3
-        movq        mm5,        mm0              ; save results
-
-        packsswb    mm0,        mm1           ; (3* (q0 - p0) + hvm(p1 - q1) + 4) >>3
-        paddsw      mm5,        [ones GLOBAL]
-
-        paddsw      mm1,        [ones GLOBAL]
-        psraw       mm5,        1                 ; partial shifted one more time for 2nd tap
-
-        psraw       mm1,        1                 ; partial shifted one more time for 2nd tap
-        packsswb    mm5,        mm1           ; (3* (q0 - p0) + hvm(p1 - q1) + 4) >>4
-
-        pandn       mm4,        mm5             ; high edge variance additive
-
-        paddsb      mm6,        mm2             ; p0+= p0 add
-        pxor        mm6,        [t80 GLOBAL]    ; unoffset
-
-        ; mm6=p0                               ;
-        movq        mm1,        [rdx]           ; p1
-        pxor        mm1,        [t80 GLOBAL]    ; reoffset
-
-        paddsb      mm1,        mm4                 ; p1+= p1 add
-        pxor        mm1,        [t80 GLOBAL]        ; unoffset
-        ; mm6 = p0 mm1 = p1
-
-        psubsb      mm3,        mm0                 ; q0-= q0 add
-        pxor        mm3,        [t80 GLOBAL]        ; unoffset
-
-        ; mm3 = q0
-        psubsb      mm7,        mm4                 ; q1-= q1 add
-        pxor        mm7,        [t80 GLOBAL]        ; unoffset
-        ; mm7 = q1
-
-        ; tranpose and write back
-        ; mm1 =    72 62 52 42 32 22 12 02
-        ; mm6 =    73 63 53 43 33 23 13 03
-        ; mm3 =    74 64 54 44 34 24 14 04
-        ; mm7 =    75 65 55 45 35 25 15 05
-
-        movq        mm2,        mm1             ; 72 62 52 42 32 22 12 02
-        punpcklbw   mm2,        mm6             ; 33 32 23 22 13 12 03 02
-
-        movq        mm4,        mm3             ; 74 64 54 44 34 24 14 04
-        punpckhbw   mm1,        mm6             ; 73 72 63 62 53 52 43 42
-
-        punpcklbw   mm4,        mm7             ; 35 34 25 24 15 14 05 04
-        punpckhbw   mm3,        mm7             ; 75 74 65 64 55 54 45 44
-
-        movq        mm6,        mm2             ; 33 32 23 22 13 12 03 02
-        punpcklwd   mm2,        mm4             ; 15 14 13 12 05 04 03 02
-
-        punpckhwd   mm6,        mm4             ; 35 34 33 32 25 24 23 22
-        movq        mm5,        mm1             ; 73 72 63 62 53 52 43 42
-
-        punpcklwd   mm1,        mm3             ; 55 54 53 52 45 44 43 42
-        punpckhwd   mm5,        mm3             ; 75 74 73 72 65 64 63 62
-
-
-        ; mm2 = 15 14 13 12 05 04 03 02
-        ; mm6 = 35 34 33 32 25 24 23 22
-        ; mm5 = 55 54 53 52 45 44 43 42
-        ; mm1 = 75 74 73 72 65 64 63 62
-
-
-
-        movd        [rsi+rax*4+2], mm2
-        psrlq       mm2,        32
-
-        movd        [rdi+rax*4+2], mm2
-        movd        [rsi+rax*2+2], mm6
-
-        psrlq       mm6,        32
-        movd        [rsi+rax+2],mm6
-
-        movd        [rsi+2],    mm1
-        psrlq       mm1,        32
-
-        movd        [rdi+2],    mm1
-        neg         rax
-
-        movd        [rdi+rax+2],mm5
-        psrlq       mm5,        32
-
-        movd        [rdi+rax*2+2], mm5
-
-        lea         rsi,        [rsi+rax*8]
-        dec         rcx
-        jnz         next8_v
-
-    add rsp, 64
-    pop rsp
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void vp8_mbloop_filter_horizontal_edge_mmx
-;(
-;    unsigned char *src_ptr,
-;    int  src_pixel_step,
-;    const char *flimit,
-;    const char *limit,
-;    const char *thresh,
-;    int count
-;)
-global sym(vp8_mbloop_filter_horizontal_edge_mmx)
-sym(vp8_mbloop_filter_horizontal_edge_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 6
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-    ALIGN_STACK 16, rax
-    sub          rsp, 32      ; reserve 32 bytes
-    %define t0   [rsp + 0]    ;__declspec(align(16)) char t0[8];
-    %define t1   [rsp + 16]   ;__declspec(align(16)) char t1[8];
-
-        mov         rsi, arg(0) ;src_ptr
-        movsxd      rax, dword ptr arg(1) ;src_pixel_step     ; destination pitch?
-
-        movsxd      rcx, dword ptr arg(5) ;count
-next8_mbh:
-        mov         rdx, arg(3) ;limit
-        movq        mm7, [rdx]
-        mov         rdi, rsi              ; rdi points to row +1 for indirect addressing
-        add         rdi, rax
-
-        ; calculate breakout conditions
-        movq        mm2, [rdi+2*rax]      ; q3
-
-        movq        mm1, [rsi+2*rax]      ; q2
-        movq        mm6, mm1              ; q2
-        psubusb     mm1, mm2              ; q2-=q3
-        psubusb     mm2, mm6              ; q3-=q2
-        por         mm1, mm2              ; abs(q3-q2)
-        psubusb     mm1, mm7
-
-
-        ; mm1 = abs(q3-q2), mm6 =q2, mm7 = limit
-        movq        mm4, [rsi+rax]        ; q1
-        movq        mm3, mm4              ; q1
-        psubusb     mm4, mm6              ; q1-=q2
-        psubusb     mm6, mm3              ; q2-=q1
-        por         mm4, mm6              ; abs(q2-q1)
-        psubusb     mm4, mm7
-        por        mm1, mm4
-
-
-        ; mm1 = mask,      mm3=q1, mm7 = limit
-
-        movq        mm4, [rsi]            ; q0
-        movq        mm0, mm4              ; q0
-        psubusb     mm4, mm3              ; q0-=q1
-        psubusb     mm3, mm0              ; q1-=q0
-        por         mm4, mm3              ; abs(q0-q1)
-        movq        t0, mm4               ; save to t0
-        psubusb     mm4, mm7
-        por        mm1, mm4
-
-
-        ; mm1 = mask, mm0=q0,  mm7 = limit, t0 = abs(q0-q1)
-
-        neg         rax                   ; negate pitch to deal with above border
-
-        movq        mm2, [rsi+4*rax]      ; p3
-        movq        mm4, [rdi+4*rax]      ; p2
-        movq        mm5, mm4              ; p2
-        psubusb     mm4, mm2              ; p2-=p3
-        psubusb     mm2, mm5              ; p3-=p2
-        por         mm4, mm2              ; abs(p3 - p2)
-        psubusb     mm4, mm7
-        por        mm1, mm4
-        ; mm1 = mask, mm0=q0,  mm7 = limit, t0 = abs(q0-q1)
-
-        movq        mm4, [rsi+2*rax]      ; p1
-        movq        mm3, mm4              ; p1
-        psubusb     mm4, mm5              ; p1-=p2
-        psubusb     mm5, mm3              ; p2-=p1
-        por         mm4, mm5              ; abs(p2 - p1)
-        psubusb     mm4, mm7
-        por        mm1, mm4
-
-        movq        mm2, mm3              ; p1
-
-
-        ; mm1 = mask, mm0=q0,  mm7 = limit, t0 = abs(q0-q1)
-
-        movq        mm4, [rsi+rax]        ; p0
-        movq        mm5, mm4              ; p0
-        psubusb     mm4, mm3              ; p0-=p1
-        psubusb     mm3, mm5              ; p1-=p0
-        por         mm4, mm3              ; abs(p1 - p0)
-        movq        t1, mm4               ; save to t1
-        psubusb     mm4, mm7
-        por        mm1, mm4
-        ; mm1 = mask, mm0=q0,  mm7 = limit, t0 = abs(q0-q1) t1 = abs(p1-p0)
-        ; mm5 = p0
-        movq        mm3, [rdi]            ; q1
-        movq        mm4, mm3              ; q1
-        psubusb     mm3, mm2              ; q1-=p1
-        psubusb     mm2, mm4              ; p1-=q1
-        por         mm2, mm3              ; abs(p1-q1)
-        pand        mm2, [tfe GLOBAL]     ; set lsb of each byte to zero
-        psrlw       mm2, 1                ; abs(p1-q1)/2
-
-        movq        mm6, mm5              ; p0
-        movq        mm3, mm0              ; q0
-        psubusb     mm5, mm3              ; p0-=q0
-        psubusb     mm3, mm6              ; q0-=p0
-        por         mm5, mm3              ; abs(p0 - q0)
-        paddusb     mm5, mm5              ; abs(p0-q0)*2
-        paddusb     mm5, mm2              ; abs (p0 - q0) *2 + abs(p1-q1)/2
-
-        mov         rdx, arg(2) ;flimit           ; get flimit
-        movq        mm2, [rdx]            ; flimit mm2
-        paddb       mm2, mm2              ; flimit*2 (less than 255)
-        paddb       mm7, mm2              ; flimit * 2 + limit (less than 255)
-
-        psubusb     mm5,    mm7           ; abs (p0 - q0) *2 + abs(p1-q1)/2  > flimit * 2 + limit
-        por         mm1,    mm5
-        pxor        mm5,    mm5
-        pcmpeqb     mm1,    mm5           ; mask mm1
-
-        ; mm1 = mask, mm0=q0,  mm7 = flimit, t0 = abs(q0-q1) t1 = abs(p1-p0)
-        ; mm6 = p0,
-
-        ; calculate high edge variance
-        mov         rdx, arg(4) ;thresh           ; get thresh
-        movq        mm7, [rdx]            ;
-        movq        mm4, t0               ; get abs (q1 - q0)
-        psubusb     mm4, mm7
-        movq        mm3, t1               ; get abs (p1 - p0)
-        psubusb     mm3, mm7
-        paddb       mm4, mm3              ; abs(q1 - q0) > thresh || abs(p1 - p0) > thresh
-
-        pcmpeqb     mm4,        mm5
-
-        pcmpeqb     mm5,        mm5
-        pxor        mm4,        mm5
-
-
-
-        ; mm1 = mask, mm0=q0,  mm7 = thresh, t0 = abs(q0-q1) t1 = abs(p1-p0)
-        ; mm6 = p0, mm4=hev
-        ; start work on filters
-        movq        mm2, [rsi+2*rax]      ; p1
-        movq        mm7, [rdi]            ; q1
-        pxor        mm2, [t80 GLOBAL]     ; p1 offset to convert to signed values
-        pxor        mm7, [t80 GLOBAL]     ; q1 offset to convert to signed values
-        psubsb      mm2, mm7              ; p1 - q1
-
-        pxor        mm6, [t80 GLOBAL]     ; offset to convert to signed values
-        pxor        mm0, [t80 GLOBAL]     ; offset to convert to signed values
-        movq        mm3, mm0              ; q0
-        psubsb      mm0, mm6              ; q0 - p0
-        paddsb      mm2, mm0              ; 1 * (q0 - p0) + (p1 - q1)
-        paddsb      mm2, mm0              ; 2 * (q0 - p0)
-        paddsb      mm2, mm0              ; 3 * (q0 - p0) + (p1 - q1)
-        pand        mm1, mm2              ; mask filter values we don't care about
-
-
-        ; mm1 = vp8_filter, mm4=hev, mm6=ps0, mm3=qs0
-        movq        mm2, mm1              ; vp8_filter
-        pand        mm2, mm4;             ; Filter2 = vp8_filter & hev
-
-        movq        mm5,        mm2       ;
-        paddsb      mm5,        [t3 GLOBAL];
-
-        pxor        mm0, mm0              ; 0
-        pxor        mm7, mm7              ; 0
-
-        punpcklbw   mm0, mm5              ; e0f0g0h0
-        psraw       mm0, 11               ; sign extended shift right by 3
-        punpckhbw   mm7, mm5              ; a0b0c0d0
-        psraw       mm7, 11               ; sign extended shift right by 3
-        packsswb    mm0, mm7              ; Filter2 >>=3;
-
-        movq        mm5, mm0              ; Filter2
-
-        paddsb      mm2, [t4 GLOBAL]      ; vp8_signed_char_clamp(Filter2 + 4)
-        pxor        mm0, mm0              ; 0
-        pxor        mm7, mm7              ; 0
-
-        punpcklbw   mm0, mm2              ; e0f0g0h0
-        psraw       mm0, 11               ; sign extended shift right by 3
-        punpckhbw   mm7, mm2              ; a0b0c0d0
-        psraw       mm7, 11               ; sign extended shift right by 3
-        packsswb    mm0, mm7              ; Filter2 >>=3;
-
-        ; mm0= filter2 mm1 = vp8_filter,  mm3 =qs0 mm5=s mm4 =hev mm6=ps0
-        psubsb      mm3, mm0              ; qs0 =qs0 - filter1
-        paddsb      mm6, mm5              ; ps0 =ps0 + Fitler2
-
-        ; mm1=vp8_filter, mm3=qs0, mm4 =hev mm6=ps0
-        ; vp8_filter &= ~hev;
-        ; Filter2 = vp8_filter;
-        pandn       mm4, mm1              ; vp8_filter&=~hev
-
-
-        ; mm3=qs0, mm4=filter2, mm6=ps0
-
-        ; u = vp8_signed_char_clamp((63 + Filter2 * 27)>>7);
-        ; s = vp8_signed_char_clamp(qs0 - u);
-        ; *oq0 = s^0x80;
-        ; s = vp8_signed_char_clamp(ps0 + u);
-        ; *op0 = s^0x80;
-        pxor        mm0, mm0
-
-        pxor        mm1, mm1
-        pxor        mm2, mm2
-        punpcklbw   mm1, mm4
-        punpckhbw   mm2, mm4
-        pmulhw      mm1, [s27 GLOBAL]
-        pmulhw      mm2, [s27 GLOBAL]
-        paddw       mm1, [s63 GLOBAL]
-        paddw       mm2, [s63 GLOBAL]
-        psraw       mm1, 7
-        psraw       mm2, 7
-        packsswb    mm1, mm2
-
-        psubsb      mm3, mm1
-        paddsb      mm6, mm1
-
-        pxor        mm3, [t80 GLOBAL]
-        pxor        mm6, [t80 GLOBAL]
-        movq        [rsi+rax], mm6
-        movq        [rsi],     mm3
-
-        ; roughly 2/7th difference across boundary
-        ; u = vp8_signed_char_clamp((63 + Filter2 * 18)>>7);
-        ; s = vp8_signed_char_clamp(qs1 - u);
-        ; *oq1 = s^0x80;
-        ; s = vp8_signed_char_clamp(ps1 + u);
-        ; *op1 = s^0x80;
-        pxor        mm1, mm1
-        pxor        mm2, mm2
-        punpcklbw   mm1, mm4
-        punpckhbw   mm2, mm4
-        pmulhw      mm1, [s18 GLOBAL]
-        pmulhw      mm2, [s18 GLOBAL]
-        paddw       mm1, [s63 GLOBAL]
-        paddw       mm2, [s63 GLOBAL]
-        psraw       mm1, 7
-        psraw       mm2, 7
-        packsswb    mm1, mm2
-
-        movq        mm3, [rdi]
-        movq        mm6, [rsi+rax*2]       ; p1
-
-        pxor        mm3, [t80 GLOBAL]
-        pxor        mm6, [t80 GLOBAL]
-
-        paddsb      mm6, mm1
-        psubsb      mm3, mm1
-
-        pxor        mm6, [t80 GLOBAL]
-        pxor        mm3, [t80 GLOBAL]
-        movq        [rdi], mm3
-        movq        [rsi+rax*2], mm6
-
-        ; roughly 1/7th difference across boundary
-        ; u = vp8_signed_char_clamp((63 + Filter2 * 9)>>7);
-        ; s = vp8_signed_char_clamp(qs2 - u);
-        ; *oq2 = s^0x80;
-        ; s = vp8_signed_char_clamp(ps2 + u);
-        ; *op2 = s^0x80;
-        pxor        mm1, mm1
-        pxor        mm2, mm2
-        punpcklbw   mm1, mm4
-        punpckhbw   mm2, mm4
-        pmulhw      mm1, [s9 GLOBAL]
-        pmulhw      mm2, [s9 GLOBAL]
-        paddw       mm1, [s63 GLOBAL]
-        paddw       mm2, [s63 GLOBAL]
-        psraw       mm1, 7
-        psraw       mm2, 7
-        packsswb    mm1, mm2
-
-
-        movq        mm6, [rdi+rax*4]
-        neg         rax
-        movq        mm3, [rdi+rax  ]
-
-        pxor        mm6, [t80 GLOBAL]
-        pxor        mm3, [t80 GLOBAL]
-
-        paddsb      mm6, mm1
-        psubsb      mm3, mm1
-
-        pxor        mm6, [t80 GLOBAL]
-        pxor        mm3, [t80 GLOBAL]
-        movq        [rdi+rax  ], mm3
-        neg         rax
-        movq        [rdi+rax*4], mm6
-
-;EARLY_BREAK_OUT:
-        neg         rax
-        add         rsi,8
-        dec         rcx
-        jnz         next8_mbh
-
-    add rsp, 32
-    pop rsp
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void vp8_mbloop_filter_vertical_edge_mmx
-;(
-;    unsigned char *src_ptr,
-;    int  src_pixel_step,
-;    const char *flimit,
-;    const char *limit,
-;    const char *thresh,
-;    int count
-;)
-global sym(vp8_mbloop_filter_vertical_edge_mmx)
-sym(vp8_mbloop_filter_vertical_edge_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 6
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-    ALIGN_STACK 16, rax
-    sub          rsp, 96      ; reserve 96 bytes
-    %define t0   [rsp + 0]    ;__declspec(align(16)) char t0[8];
-    %define t1   [rsp + 16]   ;__declspec(align(16)) char t1[8];
-    %define srct [rsp + 32]   ;__declspec(align(16)) char srct[64];
-
-        mov         rsi,        arg(0) ;src_ptr
-        movsxd      rax,        dword ptr arg(1) ;src_pixel_step     ; destination pitch?
-
-        lea         rsi,        [rsi + rax*4 - 4]
-
-        movsxd      rcx,        dword ptr arg(5) ;count
-next8_mbv:
-        lea         rdi,        [rsi + rax]  ; rdi points to row +1 for indirect addressing
-
-        ;transpose
-        movq        mm0,        [rdi+2*rax]                 ; 77 76 75 74 73 72 71 70
-        movq        mm6,        [rsi+2*rax]                 ; 67 66 65 64 63 62 61 60
-
-        movq        mm7,        mm6                         ; 77 76 75 74 73 72 71 70
-        punpckhbw   mm7,        mm0                         ; 77 67 76 66 75 65 74 64
-
-        punpcklbw   mm6,        mm0                         ; 73 63 72 62 71 61 70 60
-        movq        mm0,        [rsi+rax]                   ; 57 56 55 54 53 52 51 50
-
-        movq        mm4,        [rsi]                       ; 47 46 45 44 43 42 41 40
-        movq        mm5,        mm4                         ; 47 46 45 44 43 42 41 40
-
-        punpckhbw   mm5,        mm0                         ; 57 47 56 46 55 45 54 44
-        punpcklbw   mm4,        mm0                         ; 53 43 52 42 51 41 50 40
-
-        movq        mm3,        mm5                         ; 57 47 56 46 55 45 54 44
-        punpckhwd   mm5,        mm7                         ; 77 67 57 47 76 66 56 46
-
-        punpcklwd   mm3,        mm7                         ; 75 65 55 45 74 64 54 44
-        movq        mm2,        mm4                         ; 53 43 52 42 51 41 50 40
-
-        punpckhwd   mm4,        mm6                         ; 73 63 53 43 72 62 52 42
-        punpcklwd   mm2,        mm6                         ; 71 61 51 41 70 60 50 40
-
-        neg         rax
-
-        movq        mm7,        [rsi+rax]                   ; 37 36 35 34 33 32 31 30
-        movq        mm6,        [rsi+rax*2]                 ; 27 26 25 24 23 22 21 20
-
-        movq        mm1,        mm6                         ; 27 26 25 24 23 22 21 20
-        punpckhbw   mm6,        mm7                         ; 37 27 36 36 35 25 34 24
-
-        punpcklbw   mm1,        mm7                         ; 33 23 32 22 31 21 30 20
-
-        movq        mm7,        [rsi+rax*4];                ; 07 06 05 04 03 02 01 00
-        punpckhbw   mm7,        [rdi+rax*4]                 ; 17 07 16 06 15 05 14 04
-
-        movq        mm0,        mm7                         ; 17 07 16 06 15 05 14 04
-        punpckhwd   mm7,        mm6                         ; 37 27 17 07 36 26 16 06
-
-        punpcklwd   mm0,        mm6                         ; 35 25 15 05 34 24 14 04
-        movq        mm6,        mm7                         ; 37 27 17 07 36 26 16 06
-
-        punpckhdq   mm7,        mm5                         ; 77 67 57 47 37 27 17 07  = q3
-        punpckldq   mm6,        mm5                         ; 76 66 56 46 36 26 16 06  = q2
-
-        lea         rdx,        srct
-        movq        mm5,        mm6                         ; 76 66 56 46 36 26 16 06
-
-        movq        [rdx+56],   mm7
-        psubusb     mm5,        mm7                         ; q2-q3
-
-
-        movq        [rdx+48],   mm6
-        psubusb     mm7,        mm6                         ; q3-q2
-
-        por         mm7,        mm5;                        ; mm7=abs (q3-q2)
-        movq        mm5,        mm0                         ; 35 25 15 05 34 24 14 04
-
-        punpckhdq   mm5,        mm3                         ; 75 65 55 45 35 25 15 05 = q1
-        punpckldq   mm0,        mm3                         ; 74 64 54 44 34 24 15 04 = q0
-
-        movq        mm3,        mm5                         ; 75 65 55 45 35 25 15 05 = q1
-        psubusb     mm3,        mm6                         ; q1-q2
-
-        psubusb     mm6,        mm5                         ; q2-q1
-        por         mm6,        mm3                         ; mm6=abs(q2-q1)
-
-        movq        [rdx+40],   mm5                         ; save q1
-        movq        [rdx+32],   mm0                         ; save q0
-
-        movq        mm3,        [rsi+rax*4]                 ; 07 06 05 04 03 02 01 00
-        punpcklbw   mm3,        [rdi+rax*4]                 ; 13 03 12 02 11 01 10 00
-
-        movq        mm0,        mm3                         ; 13 03 12 02 11 01 10 00
-        punpcklwd   mm0,        mm1                         ; 31 21 11 01 30 20 10 00
-
-        punpckhwd   mm3,        mm1                         ; 33 23 13 03 32 22 12 02
-        movq        mm1,        mm0                         ; 31 21 11 01 30 20 10 00
-
-        punpckldq   mm0,        mm2                         ; 70 60 50 40 30 20 10 00  =p3
-        punpckhdq   mm1,        mm2                         ; 71 61 51 41 31 21 11 01  =p2
-
-        movq        [rdx],      mm0                         ; save p3
-        movq        [rdx+8],    mm1                         ; save p2
-
-        movq        mm2,        mm1                         ; 71 61 51 41 31 21 11 01  =p2
-        psubusb     mm2,        mm0                         ; p2-p3
-
-        psubusb     mm0,        mm1                         ; p3-p2
-        por         mm0,        mm2                         ; mm0=abs(p3-p2)
-
-        movq        mm2,        mm3                         ; 33 23 13 03 32 22 12 02
-        punpckldq   mm2,        mm4                         ; 72 62 52 42 32 22 12 02 = p1
-
-        punpckhdq   mm3,        mm4                         ; 73 63 53 43 33 23 13 03 = p0
-        movq        [rdx+24],   mm3                         ; save p0
-
-        movq        [rdx+16],   mm2                         ; save p1
-        movq        mm5,        mm2                         ; mm5 = p1
-
-        psubusb     mm2,        mm1                         ; p1-p2
-        psubusb     mm1,        mm5                         ; p2-p1
-
-        por         mm1,        mm2                         ; mm1=abs(p2-p1)
-        mov         rdx,        arg(3) ;limit
-
-        movq        mm4,        [rdx]                       ; mm4 = limit
-        psubusb     mm7,        mm4                         ; abs(q3-q2) > limit
-
-        psubusb     mm0,        mm4                         ; abs(p3-p2) > limit
-        psubusb     mm1,        mm4                         ; abs(p2-p1) > limit
-
-        psubusb     mm6,        mm4                         ; abs(q2-q1) > limit
-        por         mm7,        mm6                         ; or
-
-        por         mm0,        mm1                         ;
-        por         mm0,        mm7                         ; abs(q3-q2) > limit || abs(p3-p2) > limit ||abs(p2-p1) > limit || abs(q2-q1) > limit
-
-        movq        mm1,        mm5                         ; p1
-
-        movq        mm7,        mm3                         ; mm3=mm7=p0
-        psubusb     mm7,        mm5                         ; p0 - p1
-
-        psubusb     mm5,        mm3                         ; p1 - p0
-        por         mm5,        mm7                         ; abs(p1-p0)
-
-        movq        t0,         mm5                         ; save abs(p1-p0)
-        lea         rdx,        srct
-
-        psubusb     mm5,        mm4                         ; mm5 = abs(p1-p0) > limit
-        por         mm0,        mm5                         ; mm0=mask
-
-        movq        mm5,        [rdx+32]                    ; mm5=q0
-        movq        mm7,        [rdx+40]                    ; mm7=q1
-
-        movq        mm6,        mm5                         ; mm6=q0
-        movq        mm2,        mm7                         ; q1
-        psubusb     mm5,        mm7                         ; q0-q1
-
-        psubusb     mm7,        mm6                         ; q1-q0
-        por         mm7,        mm5                         ; abs(q1-q0)
-
-        movq        t1,         mm7                         ; save abs(q1-q0)
-        psubusb     mm7,        mm4                         ; mm7=abs(q1-q0)> limit
-
-        por         mm0,        mm7                         ; mask
-
-        movq        mm5,        mm2                         ; q1
-        psubusb     mm5,        mm1                         ; q1-=p1
-        psubusb     mm1,        mm2                         ; p1-=q1
-        por         mm5,        mm1                         ; abs(p1-q1)
-        pand        mm5,        [tfe GLOBAL]                ; set lsb of each byte to zero
-        psrlw       mm5,        1                           ; abs(p1-q1)/2
-
-        mov         rdx,        arg(2) ;flimit                      ;
-
-        movq        mm2,        [rdx]                       ;flimit  mm2
-        movq        mm1,        mm3                         ; mm1=mm3=p0
-
-        movq        mm7,        mm6                         ; mm7=mm6=q0
-        psubusb     mm1,        mm7                         ; p0-q0
-
-        psubusb     mm7,        mm3                         ; q0-p0
-        por         mm1,        mm7                         ; abs(q0-p0)
-        paddusb     mm1,        mm1                         ; abs(q0-p0)*2
-        paddusb     mm1,        mm5                         ; abs (p0 - q0) *2 + abs(p1-q1)/2
-
-        paddb       mm2,        mm2                         ; flimit*2 (less than 255)
-        paddb       mm4,        mm2                         ; flimit * 2 + limit (less than 255)
-
-        psubusb     mm1,        mm4                         ; abs (p0 - q0) *2 + abs(p1-q1)/2  > flimit * 2 + limit
-        por         mm1,        mm0;                        ; mask
-
-        pxor        mm0,        mm0
-        pcmpeqb     mm1,        mm0
-
-        ; calculate high edge variance
-        mov         rdx,        arg(4) ;thresh            ; get thresh
-        movq        mm7,        [rdx]
-        ;
-        movq        mm4,        t0              ; get abs (q1 - q0)
-        psubusb     mm4,        mm7             ; abs(q1 - q0) > thresh
-
-        movq        mm3,        t1              ; get abs (p1 - p0)
-        psubusb     mm3,        mm7             ; abs(p1 - p0)> thresh
-
-        por         mm4,        mm3             ; abs(q1 - q0) > thresh || abs(p1 - p0) > thresh
-        pcmpeqb     mm4,        mm0
-
-        pcmpeqb     mm0,        mm0
-        pxor        mm4,        mm0
-
-
-
-
-        ; start work on filters
-        lea         rdx,        srct
-
-        ; start work on filters
-        movq        mm2, [rdx+16]         ; p1
-        movq        mm7, [rdx+40]         ; q1
-        pxor        mm2, [t80 GLOBAL]     ; p1 offset to convert to signed values
-        pxor        mm7, [t80 GLOBAL]     ; q1 offset to convert to signed values
-        psubsb      mm2, mm7              ; p1 - q1
-
-        movq        mm6, [rdx+24]         ; p0
-        movq        mm0, [rdx+32]         ; q0
-        pxor        mm6, [t80 GLOBAL]     ; offset to convert to signed values
-        pxor        mm0, [t80 GLOBAL]     ; offset to convert to signed values
-
-        movq        mm3, mm0              ; q0
-        psubsb      mm0, mm6              ; q0 - p0
-        paddsb      mm2, mm0              ; 1 * (q0 - p0) + (p1 - q1)
-        paddsb      mm2, mm0              ; 2 * (q0 - p0)
-        paddsb      mm2, mm0              ; 3 * (q0 - p0) + (p1 - q1)
-        pand       mm1, mm2           ; mask filter values we don't care about
-
-        ; mm1 = vp8_filter, mm4=hev, mm6=ps0, mm3=qs0
-        movq        mm2, mm1              ; vp8_filter
-        pand        mm2, mm4;             ; Filter2 = vp8_filter & hev
-
-        movq        mm5,        mm2       ;
-        paddsb      mm5,        [t3 GLOBAL];
-
-        pxor        mm0, mm0              ; 0
-        pxor        mm7, mm7              ; 0
-
-        punpcklbw   mm0, mm5              ; e0f0g0h0
-        psraw       mm0, 11               ; sign extended shift right by 3
-        punpckhbw   mm7, mm5              ; a0b0c0d0
-        psraw       mm7, 11               ; sign extended shift right by 3
-        packsswb    mm0, mm7              ; Filter2 >>=3;
-
-        movq        mm5, mm0              ; Filter2
-
-        paddsb      mm2, [t4 GLOBAL]      ; vp8_signed_char_clamp(Filter2 + 4)
-        pxor        mm0, mm0              ; 0
-        pxor        mm7, mm7              ; 0
-
-        punpcklbw   mm0, mm2              ; e0f0g0h0
-        psraw       mm0, 11               ; sign extended shift right by 3
-        punpckhbw   mm7, mm2              ; a0b0c0d0
-        psraw       mm7, 11               ; sign extended shift right by 3
-        packsswb    mm0, mm7              ; Filter2 >>=3;
-
-        ; mm0= filter2 mm1 = vp8_filter,  mm3 =qs0 mm5=s mm4 =hev mm6=ps0
-        psubsb      mm3, mm0              ; qs0 =qs0 - filter1
-        paddsb      mm6, mm5              ; ps0 =ps0 + Fitler2
-
-        ; mm1=vp8_filter, mm3=qs0, mm4 =hev mm6=ps0
-        ; vp8_filter &= ~hev;
-        ; Filter2 = vp8_filter;
-        pandn       mm4, mm1              ; vp8_filter&=~hev
-
-
-        ; mm3=qs0, mm4=filter2, mm6=ps0
-
-        ; u = vp8_signed_char_clamp((63 + Filter2 * 27)>>7);
-        ; s = vp8_signed_char_clamp(qs0 - u);
-        ; *oq0 = s^0x80;
-        ; s = vp8_signed_char_clamp(ps0 + u);
-        ; *op0 = s^0x80;
-        pxor        mm0, mm0
-
-        pxor        mm1, mm1
-        pxor        mm2, mm2
-        punpcklbw   mm1, mm4
-        punpckhbw   mm2, mm4
-        pmulhw      mm1, [s27 GLOBAL]
-        pmulhw      mm2, [s27 GLOBAL]
-        paddw       mm1, [s63 GLOBAL]
-        paddw       mm2, [s63 GLOBAL]
-        psraw       mm1, 7
-        psraw       mm2, 7
-        packsswb    mm1, mm2
-
-        psubsb      mm3, mm1
-        paddsb      mm6, mm1
-
-        pxor        mm3, [t80 GLOBAL]
-        pxor        mm6, [t80 GLOBAL]
-        movq        [rdx+24], mm6
-        movq        [rdx+32], mm3
-
-        ; roughly 2/7th difference across boundary
-        ; u = vp8_signed_char_clamp((63 + Filter2 * 18)>>7);
-        ; s = vp8_signed_char_clamp(qs1 - u);
-        ; *oq1 = s^0x80;
-        ; s = vp8_signed_char_clamp(ps1 + u);
-        ; *op1 = s^0x80;
-        pxor        mm1, mm1
-        pxor        mm2, mm2
-        punpcklbw   mm1, mm4
-        punpckhbw   mm2, mm4
-        pmulhw      mm1, [s18 GLOBAL]
-        pmulhw      mm2, [s18 GLOBAL]
-        paddw       mm1, [s63 GLOBAL]
-        paddw       mm2, [s63 GLOBAL]
-        psraw       mm1, 7
-        psraw       mm2, 7
-        packsswb    mm1, mm2
-
-        movq        mm3, [rdx + 40]
-        movq        mm6, [rdx + 16]       ; p1
-        pxor        mm3, [t80 GLOBAL]
-        pxor        mm6, [t80 GLOBAL]
-
-        paddsb      mm6, mm1
-        psubsb      mm3, mm1
-
-        pxor        mm6, [t80 GLOBAL]
-        pxor        mm3, [t80 GLOBAL]
-        movq        [rdx + 40], mm3
-        movq        [rdx + 16], mm6
-
-        ; roughly 1/7th difference across boundary
-        ; u = vp8_signed_char_clamp((63 + Filter2 * 9)>>7);
-        ; s = vp8_signed_char_clamp(qs2 - u);
-        ; *oq2 = s^0x80;
-        ; s = vp8_signed_char_clamp(ps2 + u);
-        ; *op2 = s^0x80;
-        pxor        mm1, mm1
-        pxor        mm2, mm2
-        punpcklbw   mm1, mm4
-        punpckhbw   mm2, mm4
-        pmulhw      mm1, [s9 GLOBAL]
-        pmulhw      mm2, [s9 GLOBAL]
-        paddw       mm1, [s63 GLOBAL]
-        paddw       mm2, [s63 GLOBAL]
-        psraw       mm1, 7
-        psraw       mm2, 7
-        packsswb    mm1, mm2
-
-        movq        mm6, [rdx+ 8]
-        movq        mm3, [rdx+48]
-
-        pxor        mm6, [t80 GLOBAL]
-        pxor        mm3, [t80 GLOBAL]
-
-        paddsb      mm6, mm1
-        psubsb      mm3, mm1
-
-        pxor        mm6, [t80 GLOBAL]           ; mm6 = 71 61 51 41 31 21 11 01
-        pxor        mm3, [t80 GLOBAL]           ; mm3 = 76 66 56 46 36 26 15 06
-
-        ; tranpose and write back
-        movq        mm0,    [rdx]               ; mm0 = 70 60 50 40 30 20 10 00
-        movq        mm1,    mm0                 ; mm0 = 70 60 50 40 30 20 10 00
-
-        punpcklbw   mm0,    mm6                 ; mm0 = 31 30 21 20 11 10 01 00
-        punpckhbw   mm1,    mm6                 ; mm3 = 71 70 61 60 51 50 41 40
-
-        movq        mm2,    [rdx+16]            ; mm2 = 72 62 52 42 32 22 12 02
-        movq        mm6,    mm2                 ; mm3 = 72 62 52 42 32 22 12 02
-
-        punpcklbw   mm2,    [rdx+24]            ; mm2 = 33 32 23 22 13 12 03 02
-        punpckhbw   mm6,    [rdx+24]            ; mm3 = 73 72 63 62 53 52 43 42
-
-        movq        mm5,    mm0                 ; mm5 = 31 30 21 20 11 10 01 00
-        punpcklwd   mm0,    mm2                 ; mm0 = 13 12 11 10 03 02 01 00
-
-        punpckhwd   mm5,    mm2                 ; mm5 = 33 32 31 30 23 22 21 20
-        movq        mm4,    mm1                 ; mm4 = 71 70 61 60 51 50 41 40
-
-        punpcklwd   mm1,    mm6                 ; mm1 = 53 52 51 50 43 42 41 40
-        punpckhwd   mm4,    mm6                 ; mm4 = 73 72 71 70 63 62 61 60
-
-        movq        mm2,    [rdx+32]            ; mm2 = 74 64 54 44 34 24 14 04
-        punpcklbw   mm2,    [rdx+40]            ; mm2 = 35 34 25 24 15 14 05 04
-
-        movq        mm6,    mm3                 ; mm6 = 76 66 56 46 36 26 15 06
-        punpcklbw   mm6,    [rdx+56]            ; mm6 = 37 36 27 26 17 16 07 06
-
-        movq        mm7,    mm2                 ; mm7 = 35 34 25 24 15 14 05 04
-        punpcklwd   mm2,    mm6                 ; mm2 = 17 16 15 14 07 06 05 04
-
-        punpckhwd   mm7,    mm6                 ; mm7 = 37 36 35 34 27 26 25 24
-        movq        mm6,    mm0                 ; mm6 = 13 12 11 10 03 02 01 00
-
-        punpckldq   mm0,    mm2                 ; mm0 = 07 06 05 04 03 02 01 00
-        punpckhdq   mm6,    mm2                 ; mm6 = 17 16 15 14 13 12 11 10
-
-        movq        [rsi+rax*4], mm0            ; write out
-        movq        [rdi+rax*4], mm6            ; write out
-
-        movq        mm0,    mm5                 ; mm0 = 33 32 31 30 23 22 21 20
-        punpckldq   mm0,    mm7                 ; mm0 = 27 26 25 24 23 22 20 20
-
-        punpckhdq   mm5,    mm7                 ; mm5 = 37 36 35 34 33 32 31 30
-        movq        [rsi+rax*2], mm0            ; write out
-
-        movq        [rdi+rax*2], mm5            ; write out
-        movq        mm2,    [rdx+32]            ; mm2 = 74 64 54 44 34 24 14 04
-
-        punpckhbw   mm2,    [rdx+40]            ; mm2 = 75 74 65 64 54 54 45 44
-        punpckhbw   mm3,    [rdx+56]            ; mm3 = 77 76 67 66 57 56 47 46
-
-        movq        mm5,    mm2                 ; mm5 = 75 74 65 64 54 54 45 44
-        punpcklwd   mm2,    mm3                 ; mm2 = 57 56 55 54 47 46 45 44
-
-        punpckhwd   mm5,    mm3                 ; mm5 = 77 76 75 74 67 66 65 64
-        movq        mm0,    mm1                 ; mm0=  53 52 51 50 43 42 41 40
-
-        movq        mm3,    mm4                 ; mm4 = 73 72 71 70 63 62 61 60
-        punpckldq   mm0,    mm2                 ; mm0 = 47 46 45 44 43 42 41 40
-
-        punpckhdq   mm1,    mm2                 ; mm1 = 57 56 55 54 53 52 51 50
-        movq        [rsi],  mm0                 ; write out
-
-        movq        [rdi],  mm1                 ; write out
-        neg         rax
-
-        punpckldq   mm3,    mm5                 ; mm3 = 67 66 65 64 63 62 61 60
-        punpckhdq   mm4,    mm5                 ; mm4 = 77 76 75 74 73 72 71 60
-
-        movq        [rsi+rax*2], mm3
-        movq        [rdi+rax*2], mm4
-
-        lea         rsi,        [rsi+rax*8]
-        dec         rcx
-
-        jnz         next8_mbv
-
-    add rsp, 96
-    pop rsp
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void vp8_loop_filter_simple_horizontal_edge_mmx
-;(
-;    unsigned char *src_ptr,
-;    int  src_pixel_step,
-;    const char *flimit,
-;    const char *limit,
-;    const char *thresh,
-;    int count
-;)
-global sym(vp8_loop_filter_simple_horizontal_edge_mmx)
-sym(vp8_loop_filter_simple_horizontal_edge_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 6
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov         rsi, arg(0) ;src_ptr
-        movsxd      rax, dword ptr arg(1) ;src_pixel_step     ; destination pitch?
-
-        movsxd      rcx, dword ptr arg(5) ;count
-nexts8_h:
-        mov         rdx, arg(3) ;limit
-        movq        mm7, [rdx]
-        mov         rdx, arg(2) ;flimit           ; get flimit
-        movq        mm3, [rdx]            ;
-        paddb       mm3, mm3              ; flimit*2 (less than 255)
-        paddb       mm3, mm7              ; flimit * 2 + limit (less than 255)
-
-        mov         rdi, rsi              ; rdi points to row +1 for indirect addressing
-        add         rdi, rax
-        neg         rax
-
-        ; calculate mask
-        movq        mm1, [rsi+2*rax]      ; p1
-        movq        mm0, [rdi]            ; q1
-        movq        mm2, mm1
-        movq        mm7, mm0
-        movq        mm4, mm0
-        psubusb     mm0, mm1              ; q1-=p1
-        psubusb     mm1, mm4              ; p1-=q1
-        por         mm1, mm0              ; abs(p1-q1)
-        pand        mm1, [tfe GLOBAL]     ; set lsb of each byte to zero
-        psrlw       mm1, 1                ; abs(p1-q1)/2
-
-        movq        mm5, [rsi+rax]        ; p0
-        movq        mm4, [rsi]            ; q0
-        movq        mm0, mm4              ; q0
-        movq        mm6, mm5              ; p0
-        psubusb     mm5, mm4              ; p0-=q0
-        psubusb     mm4, mm6              ; q0-=p0
-        por         mm5, mm4              ; abs(p0 - q0)
-        paddusb     mm5, mm5              ; abs(p0-q0)*2
-        paddusb     mm5, mm1              ; abs (p0 - q0) *2 + abs(p1-q1)/2
-
-        psubusb     mm5, mm3              ; abs(p0 - q0) *2 + abs(p1-q1)/2  > flimit * 2 + limit
-        pxor        mm3, mm3
-        pcmpeqb     mm5, mm3
-
-        ; start work on filters
-        pxor        mm2, [t80 GLOBAL]     ; p1 offset to convert to signed values
-        pxor        mm7, [t80 GLOBAL]     ; q1 offset to convert to signed values
-        psubsb      mm2, mm7              ; p1 - q1
-
-        pxor        mm6, [t80 GLOBAL]     ; offset to convert to signed values
-        pxor        mm0, [t80 GLOBAL]     ; offset to convert to signed values
-        movq        mm3, mm0              ; q0
-        psubsb      mm0, mm6              ; q0 - p0
-        paddsb      mm2, mm0              ; p1 - q1 + 1 * (q0 - p0)
-        paddsb      mm2, mm0              ; p1 - q1 + 2 * (q0 - p0)
-        paddsb      mm2, mm0              ; p1 - q1 + 3 * (q0 - p0)
-        pand        mm5, mm2              ; mask filter values we don't care about
-
-        ; do + 4 side
-        paddsb      mm5, [t4 GLOBAL]      ; 3* (q0 - p0) + (p1 - q1) + 4
-
-        movq        mm0, mm5              ; get a copy of filters
-        psllw       mm0, 8                ; shift left 8
-        psraw       mm0, 3                ; arithmetic shift right 11
-        psrlw       mm0, 8
-        movq        mm1, mm5              ; get a copy of filters
-        psraw       mm1, 11               ; arithmetic shift right 11
-        psllw       mm1, 8                ; shift left 8 to put it back
-
-        por         mm0, mm1              ; put the two together to get result
-
-        psubsb      mm3, mm0              ; q0-= q0 add
-        pxor        mm3, [t80 GLOBAL]     ; unoffset
-        movq        [rsi], mm3            ; write back
-
-
-        ; now do +3 side
-        psubsb      mm5, [t1s GLOBAL]      ; +3 instead of +4
-
-        movq        mm0, mm5              ; get a copy of filters
-        psllw       mm0, 8                ; shift left 8
-        psraw       mm0, 3                ; arithmetic shift right 11
-        psrlw       mm0, 8
-        psraw       mm5, 11               ; arithmetic shift right 11
-        psllw       mm5, 8                ; shift left 8 to put it back
-        por         mm0, mm5              ; put the two together to get result
-
-
-        paddsb      mm6, mm0              ; p0+= p0 add
-        pxor        mm6, [t80 GLOBAL]     ; unoffset
-        movq        [rsi+rax], mm6        ; write back
-
-        add         rsi,8
-        neg         rax
-        dec         rcx
-        jnz         nexts8_h
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void vp8_loop_filter_simple_vertical_edge_mmx
-;(
-;    unsigned char *src_ptr,
-;    int  src_pixel_step,
-;    const char *flimit,
-;    const char *limit,
-;    const char *thresh,
-;    int count
-;)
-global sym(vp8_loop_filter_simple_vertical_edge_mmx)
-sym(vp8_loop_filter_simple_vertical_edge_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 6
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-    ALIGN_STACK 16, rax
-    sub          rsp, 32      ; reserve 32 bytes
-    %define t0   [rsp + 0]    ;__declspec(align(16)) char t0[8];
-    %define t1   [rsp + 16]   ;__declspec(align(16)) char t1[8];
-
-        mov         rsi, arg(0) ;src_ptr
-        movsxd      rax, dword ptr arg(1) ;src_pixel_step     ; destination pitch?
-
-        lea         rsi, [rsi + rax*4- 2];  ;
-        movsxd      rcx, dword ptr arg(5) ;count
-nexts8_v:
-
-        lea         rdi,        [rsi + rax];
-        movd        mm0,        [rdi + rax * 2]                 ; xx xx xx xx 73 72 71 70
-
-        movd        mm6,        [rsi + rax * 2]                 ; xx xx xx xx 63 62 61 60
-        punpcklbw   mm6,        mm0                             ; 73 63 72 62 71 61 70 60
-
-        movd        mm0,        [rsi + rax]                     ; xx xx xx xx 53 52 51 50
-        movd        mm4,        [rsi]                           ; xx xx xx xx 43 42 41 40
-
-        punpcklbw   mm4,        mm0                             ; 53 43 52 42 51 41 50 40
-        movq        mm5,        mm4                             ; 53 43 52 42 51 41 50 40
-
-        punpcklwd   mm4,        mm6                             ; 71 61 51 41 70 60 50 40
-        punpckhwd   mm5,        mm6                             ; 73 63 53 43 72 62 52 42
-
-        neg         rax
-
-        movd        mm7,        [rsi + rax]                     ; xx xx xx xx 33 32 31 30
-        movd        mm6,        [rsi + rax * 2]                 ; xx xx xx xx 23 22 21 20
-
-        punpcklbw   mm6,        mm7                             ; 33 23 32 22 31 21 30 20
-        movd        mm1,        [rdi + rax * 4]                 ; xx xx xx xx 13 12 11 10
-
-        movd        mm0,        [rsi + rax * 4]                 ; xx xx xx xx 03 02 01 00
-        punpcklbw   mm0,        mm1                             ; 13 03 12 02 11 01 10 00
-
-        movq        mm2,        mm0                             ; 13 03 12 02 11 01 10 00
-        punpcklwd   mm0,        mm6                             ; 31 21 11 01 30 20 10 00
-
-        punpckhwd   mm2,        mm6                             ; 33 23 13 03 32 22 12 02
-        movq        mm1,        mm0                             ; 13 03 12 02 11 01 10 00
-
-        punpckldq   mm0,        mm4                             ; 70 60 50 40 30 20 10 00       = p1
-        movq        mm3,        mm2                             ; 33 23 13 03 32 22 12 02
-
-        punpckhdq   mm1,        mm4                             ; 71 61 51 41 31 21 11 01       = p0
-        punpckldq   mm2,        mm5                             ; 72 62 52 42 32 22 12 02       = q0
-
-        punpckhdq   mm3,        mm5                             ; 73 63 53 43 33 23 13 03       = q1
-
-
-        ; calculate mask
-        movq        mm6,        mm0                             ; p1
-        movq        mm7,        mm3                             ; q1
-        psubusb     mm7,        mm6                             ; q1-=p1
-        psubusb     mm6,        mm3                             ; p1-=q1
-        por         mm6,        mm7                             ; abs(p1-q1)
-        pand        mm6,        [tfe GLOBAL]                    ; set lsb of each byte to zero
-        psrlw       mm6,        1                               ; abs(p1-q1)/2
-
-        movq        mm5,        mm1                             ; p0
-        movq        mm4,        mm2                             ; q0
-
-        psubusb     mm5,        mm2                             ; p0-=q0
-        psubusb     mm4,        mm1                             ; q0-=p0
-
-        por         mm5,        mm4                             ; abs(p0 - q0)
-        paddusb     mm5,        mm5                             ; abs(p0-q0)*2
-        paddusb     mm5,        mm6                             ; abs (p0 - q0) *2 + abs(p1-q1)/2
-
-        mov         rdx,        arg(2) ;flimit                          ; get flimit
-        movq        mm7,        [rdx]
-        mov         rdx,        arg(3)                          ; get limit
-        movq        mm6,        [rdx]
-        paddb       mm7,        mm7                             ; flimit*2 (less than 255)
-        paddb       mm7,        mm6                             ; flimit * 2 + limit (less than 255)
-
-        psubusb     mm5,        mm7                             ; abs(p0 - q0) *2 + abs(p1-q1)/2  > flimit * 2 + limit
-        pxor        mm7,        mm7
-        pcmpeqb     mm5,        mm7                             ; mm5 = mask
-
-        ; start work on filters
-        movq        t0,         mm0
-        movq        t1,         mm3
-
-        pxor        mm0,        [t80 GLOBAL]                    ; p1 offset to convert to signed values
-        pxor        mm3,        [t80 GLOBAL]                    ; q1 offset to convert to signed values
-
-        psubsb      mm0,        mm3                             ; p1 - q1
-        movq        mm6,        mm1                             ; p0
-
-        movq        mm7,        mm2                             ; q0
-        pxor        mm6,        [t80 GLOBAL]                    ; offset to convert to signed values
-
-        pxor        mm7,        [t80 GLOBAL]                    ; offset to convert to signed values
-        movq        mm3,        mm7                             ; offseted ; q0
-
-        psubsb      mm7,        mm6                             ; q0 - p0
-        paddsb      mm0,        mm7                             ; p1 - q1 + 1 * (q0 - p0)
-
-        paddsb      mm0,        mm7                             ; p1 - q1 + 2 * (q0 - p0)
-        paddsb      mm0,        mm7                             ; p1 - q1 + 3 * (q0 - p0)
-
-        pand        mm5,        mm0                             ; mask filter values we don't care about
-
-        paddsb      mm5,        [t4 GLOBAL]                     ;  3* (q0 - p0) + (p1 - q1) + 4
-
-        movq        mm0,        mm5                             ; get a copy of filters
-        psllw       mm0,        8                               ; shift left 8
-        psraw       mm0,        3                               ; arithmetic shift right 11
-        psrlw       mm0,        8
-
-        movq        mm7,        mm5                             ; get a copy of filters
-        psraw       mm7,        11                              ; arithmetic shift right 11
-        psllw       mm7,        8                               ; shift left 8 to put it back
-
-        por         mm0,        mm7                             ; put the two together to get result
-
-        psubsb      mm3,        mm0                             ; q0-= q0sz add
-        pxor        mm3,        [t80 GLOBAL]                    ; unoffset
-
-        ; now do +3 side
-        psubsb      mm5, [t1s GLOBAL]                           ; +3 instead of +4
-
-        movq        mm0, mm5                                    ; get a copy of filters
-        psllw       mm0, 8                                      ; shift left 8
-        psraw       mm0, 3                                      ; arithmetic shift right 11
-        psrlw       mm0, 8
-
-        psraw       mm5, 11                                     ; arithmetic shift right 11
-        psllw       mm5, 8                                      ; shift left 8 to put it back
-        por         mm0, mm5                                    ; put the two together to get result
-
-        paddsb      mm6, mm0                                    ; p0+= p0 add
-        pxor        mm6, [t80 GLOBAL]                           ; unoffset
-
-
-        movq        mm0,        t0
-        movq        mm4,        t1
-
-        ; mm0 = 70 60 50 40 30 20 10 00
-        ; mm6 = 71 61 51 41 31 21 11 01
-        ; mm3 = 72 62 52 42 32 22 12 02
-        ; mm4 = 73 63 53 43 33 23 13 03
-        ; transpose back to write out
-
-        movq        mm1,        mm0                         ;
-        punpcklbw   mm0,        mm6                         ; 31 30 21 20 11 10 01 00
-
-        punpckhbw   mm1,        mm6                         ; 71 70 61 60 51 50 41 40
-        movq        mm2,        mm3                         ;
-
-        punpcklbw   mm2,        mm4                         ; 33 32 23 22 13 12 03 02
-        movq        mm5,        mm1                         ; 71 70 61 60 51 50 41 40
-
-        punpckhbw   mm3,        mm4                         ; 73 72 63 62 53 52 43 42
-        movq        mm6,        mm0                         ; 31 30 21 20 11 10 01 00
-
-        punpcklwd   mm0,        mm2                         ; 13 12 11 10 03 02 01 00
-        punpckhwd   mm6,        mm2                         ; 33 32 31 30 23 22 21 20
-
-        movd        [rsi+rax*4], mm0                        ; write 03 02 01 00
-        punpcklwd   mm1,        mm3                         ; 53 52 51 50 43 42 41 40
-
-        psrlq       mm0,        32                          ; xx xx xx xx 13 12 11 10
-        punpckhwd   mm5,        mm3                         ; 73 72 71 70 63 62 61 60
-
-        movd        [rdi+rax*4], mm0                        ; write 13 12 11 10
-        movd        [rsi+rax*2], mm6                        ; write 23 22 21 20
-
-        psrlq       mm6,        32                          ; 33 32 31 30
-        movd        [rsi],      mm1                         ; write 43 42 41 40
-
-        movd        [rsi + rax], mm6                        ; write 33 32 31 30
-        neg         rax
-
-        movd        [rsi + rax*2], mm5                      ; write 63 62 61 60
-        psrlq       mm1,        32                          ; 53 52 51 50
-
-        movd        [rdi],      mm1                         ; write out 53 52 51 50
-        psrlq       mm5,        32                          ; 73 72 71 70
-
-        movd        [rdi + rax*2], mm5                      ; write 73 72 71 70
-
-        lea         rsi,        [rsi+rax*8]                 ; next 8
-
-        dec         rcx
-        jnz         nexts8_v
-
-    add rsp, 32
-    pop rsp
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-
-;void fast_loop_filter_vertical_edges_mmx(unsigned char *y_ptr,
-;                  int y_stride,
-;                  loop_filter_info *lfi)
-;{
-;
-;
-;    vp8_loop_filter_simple_vertical_edge_mmx(y_ptr+4, y_stride, lfi->flim,lfi->lim,lfi->thr,2);
-;    vp8_loop_filter_simple_vertical_edge_mmx(y_ptr+8, y_stride, lfi->flim,lfi->lim,lfi->thr,2);
-;    vp8_loop_filter_simple_vertical_edge_mmx(y_ptr+12, y_stride, lfi->flim,lfi->lim,lfi->thr,2);
-;}
-
-SECTION_RODATA
-align 16
-tfe:
-    times 8 db 0xfe
-align 16
-t80:
-    times 8 db 0x80
-align 16
-t1s:
-    times 8 db 0x01
-align 16
-t3:
-    times 8 db 0x03
-align 16
-t4:
-    times 8 db 0x04
-align 16
-ones:
-    times 4 dw 0x0001
-align 16
-s27:
-    times 4 dw 0x1b00
-align 16
-s18:
-    times 4 dw 0x1200
-align 16
-s9:
-    times 4 dw 0x0900
-align 16
-s63:
-    times 4 dw 0x003f
diff --git a/vp8/common/x86/loopfilter_sse2.S b/vp8/common/x86/loopfilter_sse2.S
new file mode 100644
index 0000000..cf49840
--- /dev/null
+++ b/vp8/common/x86/loopfilter_sse2.S
@@ -0,0 +1,1978 @@
+//
+//  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
+//
+//  Use of this source code is governed by a BSD-style license and patent
+//  grant that can be found in the LICENSE file in the root of the source
+//  tree. All contributing project authors may be found in the AUTHORS
+//  file in the root of the source tree.
+//
+
+
+#include "vpx_ports/x86_abi_support.S"
+
+
+//void vp8_loop_filter_horizontal_edge_sse2
+//(
+//    unsigned char *src_ptr,
+//    int            src_pixel_step,
+//    const char    *flimit,
+//    const char    *limit,
+//    const char    *thresh,
+//    int            count
+//)
+global sym(vp8_loop_filter_horizontal_edge_sse2)
+sym(vp8_loop_filter_horizontal_edge_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 6
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+    ALIGN_STACK 16, rax
+    sub         rsp, 32                         // reserve 32 bytes
+#   define t0 [rsp + 0]    //__declspec(align(16)) char t0[16];
+#   define t1 [rsp + 16]   //__declspec(align(16)) char t1[16];
+
+        mov         rsi, arg(0) //src_ptr
+        movsxd      rax, dword ptr arg(1) //src_pixel_step     ; destination pitch?
+
+        mov         rdx,    arg(3) //limit
+        movdqa      xmm7,   XMMWORD PTR [rdx]
+        mov         rdi,    rsi           // rdi points to row +1 for indirect addressing
+        add         rdi,    rax
+
+        // calculate breakout conditions
+        movdqu      xmm2,   [rdi+2*rax]      // q3
+        movdqu      xmm1,   [rsi+2*rax]      // q2
+        movdqa      xmm6,   xmm1              // q2
+        psubusb     xmm1,   xmm2              // q2-=q3
+        psubusb     xmm2,   xmm6              // q3-=q2
+        por         xmm1,   xmm2              // abs(q3-q2)
+        psubusb     xmm1,   xmm7              //
+
+
+        movdqu      xmm4,   [rsi+rax]         // q1
+        movdqa      xmm3,   xmm4              // q1
+        psubusb     xmm4,   xmm6              // q1-=q2
+        psubusb     xmm6,   xmm3              // q2-=q1
+        por         xmm4,   xmm6              // abs(q2-q1)
+
+        psubusb     xmm4,   xmm7
+        por         xmm1,   xmm4
+
+        movdqu      xmm4,   [rsi]             // q0
+        movdqa      xmm0,   xmm4              // q0
+        psubusb     xmm4,   xmm3              // q0-=q1
+        psubusb     xmm3,   xmm0              // q1-=q0
+        por         xmm4,   xmm3              // abs(q0-q1)
+        movdqa        t0,       xmm4                  // save to t0
+        psubusb     xmm4,   xmm7
+        por         xmm1,   xmm4
+
+        neg         rax                   // negate pitch to deal with above border
+        movdqu      xmm2,   [rsi+4*rax]      // p3
+        movdqu      xmm4,   [rdi+4*rax]      // p2
+        movdqa      xmm5,   xmm4              // p2
+        psubusb     xmm4,   xmm2              // p2-=p3
+        psubusb     xmm2,   xmm5              // p3-=p2
+        por         xmm4,   xmm2              // abs(p3 - p2)
+        psubusb     xmm4,   xmm7
+        por         xmm1,   xmm4
+
+
+        movdqu      xmm4,   [rsi+2*rax]      // p1
+        movdqa      xmm3,   xmm4              // p1
+        psubusb     xmm4,   xmm5              // p1-=p2
+        psubusb     xmm5,   xmm3              // p2-=p1
+        por         xmm4,   xmm5              // abs(p2 - p1)
+        psubusb     xmm4,   xmm7
+        por         xmm1,   xmm4
+
+        movdqa      xmm2,   xmm3              // p1
+
+        movdqu      xmm4,   [rsi+rax]         // p0
+        movdqa      xmm5,   xmm4              // p0
+        psubusb     xmm4,   xmm3              // p0-=p1
+        psubusb     xmm3,   xmm5              // p1-=p0
+        por         xmm4,   xmm3              // abs(p1 - p0)
+        movdqa      t1,     xmm4                  // save to t1
+        psubusb     xmm4,   xmm7
+        por         xmm1,    xmm4
+
+        movdqu      xmm3,   [rdi]             // q1
+        movdqa      xmm4,   xmm3              // q1
+        psubusb     xmm3,   xmm2              // q1-=p1
+        psubusb     xmm2,   xmm4              // p1-=q1
+        por         xmm2,   xmm3              // abs(p1-q1)
+        pand        xmm2,   [GLOBAL (tfe)]      // set lsb of each byte to zero
+        psrlw       xmm2,   1                 // abs(p1-q1)/2
+
+        movdqa      xmm6,   xmm5              // p0
+        movdqu      xmm3,   [rsi]             // q0
+        psubusb     xmm5,   xmm3              // p0-=q0
+        psubusb     xmm3,   xmm6              // q0-=p0
+        por         xmm5,   xmm3              // abs(p0 - q0)
+        paddusb     xmm5,   xmm5              // abs(p0-q0)*2
+        paddusb     xmm5,   xmm2              // abs (p0 - q0) *2 + abs(p1-q1)/2
+
+        mov         rdx,    arg(2) //flimit            ; get flimit
+        movdqa      xmm2,   [rdx]             //
+
+        paddb       xmm2,   xmm2              // flimit*2 (less than 255)
+        paddb       xmm7,   xmm2              // flimit * 2 + limit (less than 255)
+
+        psubusb     xmm5,    xmm7             // abs (p0 - q0) *2 + abs(p1-q1)/2  > flimit * 2 + limit
+        por         xmm1,    xmm5
+        pxor        xmm5,    xmm5
+        pcmpeqb     xmm1,    xmm5             // mask mm1
+
+
+        // calculate high edge variance
+        mov         rdx,    arg(4) //thresh            ; get thresh
+        movdqa      xmm7,   [rdx]             //
+        movdqa      xmm4,   t0                // get abs (q1 - q0)
+        psubusb     xmm4,   xmm7
+        movdqa      xmm3,   t1                // get abs (p1 - p0)
+        psubusb     xmm3,   xmm7
+        paddb       xmm4,   xmm3              // abs(q1 - q0) > thresh || abs(p1 - p0) > thresh
+        pcmpeqb     xmm4,        xmm5
+        pcmpeqb     xmm5,        xmm5
+        pxor        xmm4,        xmm5
+
+
+        // start work on filters
+        movdqu      xmm2, [rsi+2*rax]     // p1
+        movdqu      xmm7, [rdi]           // q1
+        pxor        xmm2, [GLOBAL (t80)]    // p1 offset to convert to signed values
+        pxor        xmm7, [GLOBAL (t80)]    // q1 offset to convert to signed values
+        psubsb      xmm2, xmm7            // p1 - q1
+        pand        xmm2, xmm4            // high var mask (hvm)(p1 - q1)
+        pxor        xmm6, [GLOBAL (t80)]    // offset to convert to signed values
+        pxor        xmm0, [GLOBAL (t80)]    // offset to convert to signed values
+        movdqa      xmm3, xmm0            // q0
+        psubsb      xmm0, xmm6            // q0 - p0
+        paddsb      xmm2, xmm0            // 1 * (q0 - p0) + hvm(p1 - q1)
+        paddsb      xmm2, xmm0            // 2 * (q0 - p0) + hvm(p1 - q1)
+        paddsb      xmm2, xmm0            // 3 * (q0 - p0) + hvm(p1 - q1)
+        pand        xmm1, xmm2            // mask filter values we don't care about
+        movdqa      xmm2, xmm1
+        paddsb      xmm1, [GLOBAL (t4)]         // 3* (q0 - p0) + hvm(p1 - q1) + 4
+        paddsb      xmm2, [GLOBAL (t3)]         // 3* (q0 - p0) + hvm(p1 - q1) + 3
+
+        pxor        xmm0, xmm0           //
+        pxor        xmm5, xmm5
+        punpcklbw   xmm0, xmm2          //
+        punpckhbw   xmm5, xmm2          //
+        psraw       xmm0, 11                //
+        psraw       xmm5, 11
+        packsswb    xmm0, xmm5
+        movdqa      xmm2, xmm0          //  (3* (q0 - p0) + hvm(p1 - q1) + 3) >> 3;
+
+        pxor        xmm0, xmm0            // 0
+        movdqa      xmm5, xmm1            // abcdefgh
+        punpcklbw   xmm0, xmm1            // e0f0g0h0
+        psraw       xmm0, 11                  // sign extended shift right by 3
+        pxor        xmm1, xmm1            // 0
+        punpckhbw   xmm1, xmm5            // a0b0c0d0
+        psraw       xmm1, 11                  // sign extended shift right by 3
+        movdqa      xmm5, xmm0              // save results
+
+        packsswb    xmm0, xmm1            // (3* (q0 - p0) + hvm(p1 - q1) + 4) >>3
+        paddsw      xmm5, [GLOBAL (ones)]
+        paddsw      xmm1, [GLOBAL (ones)]
+        psraw       xmm5, 1               // partial shifted one more time for 2nd tap
+        psraw       xmm1, 1               // partial shifted one more time for 2nd tap
+        packsswb    xmm5, xmm1            // (3* (q0 - p0) + hvm(p1 - q1) + 4) >>4
+        pandn       xmm4, xmm5            // high edge variance additive
+
+        paddsb      xmm6, xmm2            // p0+= p0 add
+        pxor        xmm6, [GLOBAL (t80)]    // unoffset
+        movdqu      [rsi+rax], xmm6       // write back
+
+        movdqu      xmm6, [rsi+2*rax]     // p1
+        pxor        xmm6, [GLOBAL (t80)]    // reoffset
+        paddsb      xmm6, xmm4            // p1+= p1 add
+        pxor        xmm6, [GLOBAL (t80)]    // unoffset
+        movdqu      [rsi+2*rax], xmm6     // write back
+
+        psubsb      xmm3, xmm0            // q0-= q0 add
+        pxor        xmm3, [GLOBAL (t80)]    // unoffset
+        movdqu      [rsi], xmm3           // write back
+
+        psubsb      xmm7, xmm4            // q1-= q1 add
+        pxor        xmm7, [GLOBAL (t80)]    // unoffset
+        movdqu      [rdi], xmm7           // write back
+
+    add rsp, 32
+    pop rsp
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void vp8_loop_filter_vertical_edge_sse2
+//(
+//    unsigned char *src_ptr,
+//    int            src_pixel_step,
+//    const char    *flimit,
+//    const char    *limit,
+//    const char    *thresh,
+//    int            count
+//)
+global sym(vp8_loop_filter_vertical_edge_sse2)
+sym(vp8_loop_filter_vertical_edge_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 6
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+    ALIGN_STACK 16, rax
+    sub          rsp, 96      // reserve 96 bytes
+#   define t0   [rsp + 0]    //__declspec(align(16)) char t0[16];
+#   define t1   [rsp + 16]   //__declspec(align(16)) char t1[16];
+#   define srct [rsp + 32]   //__declspec(align(16)) char srct[64];
+
+        mov         rsi,        arg(0) //src_ptr
+        movsxd      rax,        dword ptr arg(1) //src_pixel_step     ; destination pitch?
+
+        lea         rsi,        [rsi + rax*4 - 4]
+        mov         rdi,        rsi           // rdi points to row +1 for indirect addressing
+
+        add         rdi,        rax
+        lea         rcx,        [rdi + rax *8]
+
+        //transpose
+        movq        xmm7,       QWORD PTR [rsi+2*rax]                 // 67 66 65 64 63 62 61 60
+        movq        xmm6,       QWORD PTR [rdi+2*rax]                 // 77 76 75 74 73 72 71 70
+
+        punpcklbw   xmm7,       xmm6                        // 77 67 76 66 75 65 74 64 73 63 72 62 71 61 70 60
+        movq        xmm5,       QWORD PTR [rsi]                       // 47 46 45 44 43 42 41 40
+
+        movq        xmm4,       QWORD PTR [rsi+rax]                   // 57 56 55 54 53 52 51 50
+        punpcklbw   xmm5,       xmm4                        // 57 47 56 46 55 45 54 44 53 43 52 42 51 41 50 40
+
+        movdqa      xmm3,       xmm5                        // 57 47 56 46 55 45 54 44 53 43 52 42 51 41 50 40
+        punpckhwd   xmm5,       xmm7                        // 77 67 57 47 76 66 56 46 75 65 55 45 74 64 54 44
+
+        lea         rsi,        [rsi+ rax*8]
+
+        punpcklwd   xmm3,       xmm7                        // 73 63 53 43 72 62 52 42 71 61 51 41 70 60 50 40
+        movq        xmm6,       QWORD PTR [rsi + 2*rax]               // e7 e6 e5 e4 e3 e2 e1 e0
+
+        movq        xmm7,       QWORD PTR [rcx + 2*rax]               // f7 f6 f5 f4 f3 f2 f1 f0
+        punpcklbw   xmm6,       xmm7                        // f7 e7 f6 e6 f5 e5 f4 e4 f3 e3 f2 e2 f1 e1 f0 e0
+
+        movq        xmm4,       QWORD PTR [rsi]                       // c7 c6 c5 c4 c3 c2 c1 c0
+        movq        xmm7,       QWORD PTR [rsi + rax]                 // d7 d6 d5 d4 d3 d2 d1 d0
+
+        punpcklbw   xmm4,       xmm7                        // d7 c7 d6 c6 d5 c5 d4 c4 d3 c3 d2 c2 d1 c1 d0 c0
+        movdqa      xmm7,       xmm4                        // d7 c7 d6 c6 d5 c5 d4 c4 d3 c3 d2 c2 d1 c1 d0 c0
+
+        punpckhwd   xmm7,       xmm6                        // f7 e7 d7 c7 f6 e6 d6 c6 f5 e5 d5 c5 f4 e4 d4 c4
+        punpcklwd   xmm4,       xmm6                        // f3 e3 d3 c3 f2 e2 d2 c2 f1 e1 d1 c1 f0 e0 d0 c0
+
+        // xmm3 xmm4, xmm5 xmm7   in use
+        neg         rax
+
+        lea         rsi,        [rsi+rax*8]
+        movq        xmm6,       QWORD PTR [rsi+rax*2]                 // 27 26 25 24 23 22 21 20
+
+        movq        xmm1,       QWORD PTR [rsi+rax  ]                 // 37 36 35 34 33 32 31 30
+        punpcklbw   xmm6,       xmm1                        // 37 27 36 26 35 25 34 24 33 23 32 22 31 21 30 20
+
+        movq        xmm2,       QWORD PTR [rsi+rax*4]                 // 07 06 05 04 03 02 01 00
+        movq        xmm1,       QWORD PTR [rdi+rax*4]                 // 17 16 15 14 13 12 11 10
+
+        punpcklbw   xmm2,       xmm1                        // 17 07 16 06 15 05 14 04 13 03 12 02 11 01 10 00
+        movdqa      xmm0,       xmm2
+
+        punpckhwd   xmm2,       xmm6                        // 37 27 17 07 36 26 16 06 35 25 15 05 34 24 14 04
+        punpcklwd   xmm0,       xmm6                        // 33 23 13 03 32 22 12 02 31 21 11 01 30 20 10 00
+
+        movdqa      xmm6,       xmm2
+        punpckldq   xmm2,       xmm5                        // 75 65 55 45 35 25 15 05 74 64 54 44 34 24 14 04
+
+        punpckhdq   xmm6,       xmm5                        // 77 67 57 47 37 27 17 07 76 66 56 46 36 26 16 06
+        //xmm0 xmm2 xmm3 xmm4, xmm6, xmm7
+
+        movdqa      xmm5,       xmm0                        // 33 23 13 03 32 22 12 02 31 21 11 01 30 20 10 00
+        punpckhdq   xmm5,       xmm3                        // 73 63 53 43 33 23 13 03 72 62 52 42 32 22 12 02
+
+        punpckldq   xmm0,       xmm3                        // 71 61 51 41 31 21 11 01 70 60 50 40 30 20 10 00
+        lea         rsi,        [rcx+rax]
+        // xmm1, xmm3 free
+        movq        xmm1,       QWORD PTR [rsi+rax*2]                 // a7 a6 a5 a4 a3 a2 a1 a0
+        movq        xmm3,       QWORD PTR [rsi+rax]                   // b7 b6 b5 b4 b3 b2 b1 b0
+
+        punpcklbw   xmm1,       xmm3                        //
+        lea         rdx,        srct                        //
+
+        movdqa      [rdx+16],   xmm1                        // b7 a7 b6 a6 b5 a5 b4 a4 b3 a3 b2 a2 b1 a1 b0 a0
+        movq        xmm3,       QWORD PTR [rsi+rax*4]                 // 87 86 85 84 83 82 81 80
+
+        movq        xmm1,       QWORD PTR [rcx+rax*4]
+        punpcklbw   xmm3,       xmm1                        // 97 87 96 86 95 85 94 84 93 83 92 82 91 81 90 80
+
+        movdqa      [rdx],      xmm3                        // 97 87 96 86 95 85 94 84 93 83 92 82 91 81 90 80
+
+        punpckhwd   xmm3,       [rdx+16]                    // b7 a7 97 87 b6 a6 96 86 b5 a5 95 85 b4 a4 94 84
+        movdqa      xmm1,       xmm3                        // b7 a7 97 87 b6 a6 96 86 b5 a5 95 85 b4 a4 94 84
+
+        punpckhdq   xmm1,       xmm7                        // f7 e7 d7 c7 b7 a7 97 87 f6 e6 d6 c6 b6 a6 96 86
+        punpckldq   xmm3,       xmm7                        // f5 e5 d5 c5 b5 a5 95 85 f4 e4 d4 c4 b4 a4 94 84
+
+        movdqa      xmm7,       xmm2                        // 75 65 55 45 35 25 15 05 74 64 54 44 34 24 14 04
+        punpcklqdq  xmm7,       xmm3                        // f4 e4 d4 c4 b4 a4 94 84 74 64 54 44 34 24 14 04
+
+        punpckhqdq  xmm2,       xmm3                        // f5 e5 d5 c5 b5 a5 95 85 75 65 55 45 35 25 15 05
+        movdqa      [rdx+32],   xmm7                        // save 4s
+
+        movdqa      [rdx+48],   xmm2                        // save 5s
+        movdqa      xmm7,       xmm6                        // 77 67 57 47 37 27 17 07 76 66 56 46 36 26 16 06
+
+        punpckhqdq  xmm7,       xmm1                        // f7 e7 d7 c7 b7 a7 97 87 77 67 57 47 37 27 17 07 = q3
+        punpcklqdq  xmm6,       xmm1                        // f6 e6 d6 c6 b6 a6 96 86 76 66 56 46 36 26 16 06 = q2
+
+        // free 1, 3   xmm7-7s xmm6-6s, xmm2-5s
+        movq        xmm1,       QWORD PTR [rdx]                       // 93 83 92 82 91 81 90 80
+        movq        xmm3,       QWORD PTR [rdx+16]                    // b3 a3 b2 a2 b1 a1 b0 a0
+
+        punpcklwd   xmm1,       xmm3                        // b3 a3 93 83 b2 a2 92 82 b1 a1 91 81 b0 a0 90 80
+        movdqa      xmm3,       xmm1                        // b3 a3 93 83 b2 a2 92 82 b1 a1 91 81 b0 a0 90 80
+
+        punpckhdq   xmm3,       xmm4                        // f3 e3 d3 c3 b3 a3 93 83 f2 e2 d2 c2 b2 a2 92 82
+        punpckldq   xmm1,       xmm4                        // f1 e1 d1 c1 b1 a1 91 81 f0 e0 d0 c0 b0 a0 90 80
+
+        movdqa      xmm4,       xmm5                        // 73 63 53 43 33 23 13 03 72 62 52 42 32 22 12 02
+        punpcklqdq  xmm5,       xmm3                        // f2 e2 d2 c2 b2 a2 92 82 72 62 52 42 32 22 12 02
+
+        punpckhqdq  xmm4,       xmm3                        // f3 e3 d3 c3 b3 a3 93 83 73 63 53 43 33 23 13 03
+        movdqa      [rdx],      xmm5                        // save 2s
+
+        movdqa      [rdx+16],   xmm4                        // save 3s
+
+        movdqa      xmm3,       xmm6                        //
+        psubusb     xmm3,       xmm7                        // q3 - q2
+
+        psubusb     xmm7,       xmm6                        // q2 - q3
+        por         xmm7,       xmm3                        // abs(q3-q2)
+
+        movdqa      xmm3,       xmm2                        // q1
+        psubusb     xmm3,       xmm6                        // q1 - q2
+
+        psubusb     xmm6,       xmm2                        // q2 - q1
+        por         xmm6,       xmm3                        // abs(q2-q1)
+
+
+        movdqa      xmm3,       xmm0                        // 71 61 51 41 31 21 11 01 70 60 50 40 30 20 10 00
+        punpcklqdq  xmm0,       xmm1                        // f0 e0 d0 c0 b0 a0 90 80 70 60 50 40 30 20 10 00
+
+        punpckhqdq  xmm3,       xmm1                        // f1 e1 d1 c1 b1 a1 91 81 71 61 51 41 31 21 11 01
+        movdqa      xmm1,       xmm3
+
+        psubusb     xmm3,       xmm0                        // p2-p3
+        psubusb     xmm0,       xmm1                        // p3-p2
+
+        por         xmm0,       xmm3                        // abs(p3-p2)
+        movdqa      xmm3,       xmm5                        // f2 e2 d2 c2 b2 a2 92 82 72 62 52 42 32 22 12 02
+
+        psubusb     xmm3,       xmm1                        // p1-p2
+        psubusb     xmm1,       xmm5                        // p2-p1
+
+        por         xmm1,       xmm3                        // abs(p1-p2)
+        mov         rdx,        arg(3) //limit
+
+        movdqa      xmm3,       [rdx]                       // limit
+
+        psubusb     xmm7,       xmm3
+        psubusb     xmm0,       xmm3
+
+        psubusb     xmm1,       xmm3
+        psubusb     xmm6,       xmm3
+
+        por         xmm7,       xmm6
+        por         xmm0,       xmm1
+
+        por         xmm0,       xmm7                         //   abs(q3-q2) > limit || abs(p3-p2) > limit ||abs(p2-p1) > limit || abs(q2-q1) > limit
+
+        movdqa      xmm1,       xmm5                         // p1
+
+        movdqa      xmm7,       xmm4                        // xmm4 xmm7 = p0
+
+        psubusb     xmm7,       xmm5                        // p0 - p1
+        psubusb     xmm5,       xmm4                        // p1 - p0
+
+        por         xmm5,       xmm7                        // abs(p1-p0)
+        movdqa        t0,       xmm5                        // save abs(p1-p0)
+
+        lea         rdx,        srct
+        psubusb     xmm5,       xmm3
+
+        por         xmm0,       xmm5                        // xmm0=mask
+        movdqa      xmm5,       [rdx+32]                    // xmm5=q0
+
+        movdqa      xmm7,       [rdx+48]                    // xmm7=q1
+        movdqa      xmm6,       xmm5                        // mm6=q0
+
+        movdqa      xmm2,       xmm7                        // q1
+
+        psubusb     xmm5,       xmm7                        // q0-q1
+        psubusb     xmm7,       xmm6                        // q1-q0
+
+        por         xmm7,       xmm5                        // abs(q1-q0)
+        movdqa        t1,       xmm7                        // save abs(q1-q0)
+
+        psubusb     xmm7,       xmm3
+        por         xmm0,       xmm7                        // mask
+
+        movdqa      xmm5,       xmm2                        // q1
+        psubusb     xmm5,       xmm1                        // q1-=p1
+        psubusb     xmm1,       xmm2                        // p1-=q1
+        por         xmm5,       xmm1                        // abs(p1-q1)
+        pand        xmm5,       [GLOBAL (tfe)]                // set lsb of each byte to zero
+        psrlw       xmm5,       1                           // abs(p1-q1)/2
+
+        mov         rdx,        arg(2) //flimit                      ;
+        movdqa        xmm2,       [rdx]                       //flimit  xmm2
+
+        movdqa      xmm1,       xmm4                        // xmm1=xmm4=p0
+
+        movdqa      xmm7,       xmm6                        // xmm7=xmm6=q0
+        psubusb     xmm1,       xmm7                        // p0-q0
+
+        psubusb     xmm7,       xmm4                        // q0-p0
+        por         xmm1,       xmm7                        // abs(q0-p0)
+        paddusb     xmm1,       xmm1                        // abs(q0-p0)*2
+        paddusb     xmm1,       xmm5                        // abs (p0 - q0) *2 + abs(p1-q1)/2
+
+        paddb       xmm2,       xmm2                        // flimit*2 (less than 255)
+        paddb       xmm3,       xmm2                        // flimit * 2 + limit (less than 255)
+
+        psubusb     xmm1,       xmm3                         // abs (p0 - q0) *2 + abs(p1-q1)/2  > flimit * 2 + limit
+
+        por         xmm1,       xmm0;                       // mask
+
+        pxor        xmm0,       xmm0
+        pcmpeqb     xmm1,       xmm0
+        // calculate high edge variance
+        mov         rdx,        arg(4) //thresh            ; get thresh
+        movdqa      xmm7,       [rdx]
+
+        //
+        movdqa      xmm4,       t0              // get abs (q1 - q0)
+        psubusb     xmm4,       xmm7
+
+        movdqa      xmm3,       t1              // get abs (p1 - p0)
+        psubusb     xmm3,       xmm7
+
+        por         xmm4,       xmm3            // abs(q1 - q0) > thresh || abs(p1 - p0) > thresh
+        pcmpeqb     xmm4,       xmm0
+
+        pcmpeqb     xmm0,       xmm0
+        pxor        xmm4,       xmm0
+
+        // start work on filters
+        lea         rdx,        srct
+
+        movdqa      xmm2,       [rdx]           // p1
+        movdqa      xmm7,       [rdx+48]        // q1
+
+        movdqa      xmm6,       [rdx+16]        // p0
+        movdqa      xmm0,       [rdx+32]        // q0
+
+        pxor        xmm2,       [GLOBAL (t80)]    // p1 offset to convert to signed values
+        pxor        xmm7,       [GLOBAL (t80)]    // q1 offset to convert to signed values
+
+        psubsb      xmm2,       xmm7            // p1 - q1
+        pand        xmm2,       xmm4            // high var mask (hvm)(p1 - q1)
+
+        pxor        xmm6,       [GLOBAL (t80)]    // offset to convert to signed values
+        pxor        xmm0,       [GLOBAL (t80)]    // offset to convert to signed values
+
+        movdqa      xmm3,       xmm0            // q0
+        psubsb      xmm0,       xmm6            // q0 - p0
+
+        paddsb      xmm2,       xmm0            // 1 * (q0 - p0) + hvm(p1 - q1)
+        paddsb      xmm2,       xmm0            // 2 * (q0 - p0) + hvm(p1 - q1)
+
+        paddsb      xmm2,       xmm0            // 3 * (q0 - p0) + hvm(p1 - q1)
+        pand        xmm1,       xmm2            // mask filter values we don't care about
+
+        movdqa      xmm2,       xmm1
+        paddsb      xmm1,       [GLOBAL (t4)]       // 3* (q0 - p0) + hvm(p1 - q1) + 4
+
+        paddsb      xmm2,       [GLOBAL (t3)]       // 3* (q0 - p0) + hvm(p1 - q1) + 3
+        pxor        xmm0,       xmm0             //
+
+        pxor        xmm5,       xmm5
+        punpcklbw   xmm0,       xmm2            //
+
+        punpckhbw   xmm5,       xmm2            //
+        psraw       xmm0,       11              //
+
+        psraw       xmm5,       11
+        packsswb    xmm0,       xmm5
+
+        movdqa      xmm2,       xmm0            //  (3* (q0 - p0) + hvm(p1 - q1) + 3) >> 3;
+
+        pxor        xmm0,       xmm0              // 0
+        movdqa      xmm5,       xmm1              // abcdefgh
+
+        punpcklbw   xmm0,       xmm1              // e0f0g0h0
+        psraw       xmm0,       11                // sign extended shift right by 3
+
+        pxor        xmm1,       xmm1              // 0
+        punpckhbw   xmm1,       xmm5              // a0b0c0d0
+
+        psraw       xmm1,       11                // sign extended shift right by 3
+        movdqa      xmm5,       xmm0              // save results
+
+        packsswb    xmm0,       xmm1              // (3* (q0 - p0) + hvm(p1 - q1) + 4) >>3
+        paddsw      xmm5,       [GLOBAL (ones)]
+
+        paddsw      xmm1,       [GLOBAL (ones)]
+        psraw       xmm5,       1                 // partial shifted one more time for 2nd tap
+
+        psraw       xmm1,       1                 // partial shifted one more time for 2nd tap
+        packsswb    xmm5,       xmm1              // (3* (q0 - p0) + hvm(p1 - q1) + 4) >>4
+
+        pandn       xmm4,       xmm5            // high edge variance additive
+
+        paddsb      xmm6,       xmm2            // p0+= p0 add
+        pxor        xmm6,       [GLOBAL (t80)]    // unoffset
+
+        // mm6=p0                               ;
+        movdqa      xmm1,       [rdx]           // p1
+        pxor        xmm1,       [GLOBAL (t80)]    // reoffset
+
+        paddsb      xmm1,       xmm4            // p1+= p1 add
+        pxor        xmm1,       [GLOBAL (t80)]    // unoffset
+        // mm6 = p0 mm1 = p1
+
+        psubsb      xmm3,       xmm0            // q0-= q0 add
+        pxor        xmm3,       [GLOBAL (t80)]    // unoffset
+
+        // mm3 = q0
+        psubsb      xmm7,       xmm4            // q1-= q1 add
+        pxor        xmm7,       [GLOBAL (t80)]    // unoffset
+        // mm7 = q1
+
+        // tranpose and write back
+        // xmm1 =    f2 e2 d2 c2 b2 a2 92 82 72 62 52 42 32 22 12 02
+        // xmm6 =    f3 e3 d3 c3 b3 a3 93 83 73 63 53 43 33 23 13 03
+        // xmm3 =    f4 e4 d4 c4 b4 a4 94 84 74 64 54 44 34 24 14 04
+        // xmm7 =    f5 e5 d5 c5 b5 a5 95 85 75 65 55 45 35 25 15 05
+        movdqa      xmm2,       xmm1            // f2 e2 d2 c2 b2 a2 92 82 72 62 52 42 32 22 12 02
+        punpcklbw   xmm2,       xmm6            // 73 72 63 62 53 52 43 42 33 32 23 22 13 12 03 02
+
+        movdqa      xmm4,       xmm3            // f4 e4 d4 c4 b4 a4 94 84 74 64 54 44 34 24 14 04
+        punpckhbw   xmm1,       xmm6            // f3 f2 e3 e2 d3 d2 c3 c2 b3 b2 a3 a2 93 92 83 82
+
+        punpcklbw   xmm4,       xmm7            // 75 74 65 64 55 54 45 44 35 34 25 24 15 14 05 04
+        punpckhbw   xmm3,       xmm7            // f5 f4 e5 e4 d5 d4 c5 c4 b5 b4 a5 a4 95 94 85 84
+
+        movdqa      xmm6,       xmm2            // 73 72 63 62 53 52 43 42 33 32 23 22 13 12 03 02
+        punpcklwd   xmm2,       xmm4            // 35 34 33 32 25 24 23 22 15 14 13 12 05 04 03 02
+
+        punpckhwd   xmm6,       xmm4            // 75 74 73 72 65 64 63 62 55 54 53 52 45 44 43 42
+        movdqa      xmm5,       xmm1            // f3 f2 e3 e2 d3 d2 c3 c2 b3 b2 a3 a2 93 92 83 82
+
+        punpcklwd   xmm1,       xmm3            // f5 f4 f3 f2 e5 e4 e3 e2 d5 d4 d3 d2 c5 c4 c3 c2
+        punpckhwd   xmm5,       xmm3            // b5 b4 b3 b2 a5 a4 a3 a2 95 94 93 92 85 84 83 82
+
+        // xmm2 = 35 34 33 32 25 24 23 22 15 14 13 12 05 04 03 02
+        // xmm6 = 75 74 73 72 65 64 63 62 55 54 53 52 45 44 43 42
+        // xmm5 = f3 f2 e3 e2 d3 d2 c3 c2 b3 b2 a3 a2 93 92 83 82
+        // xmm1 = b5 b4 b3 b2 a5 a4 a3 a2 95 94 93 92 85 84 83 82
+        lea         rsi,           [rsi+rax*8]
+
+        movd        [rsi+rax*4+2], xmm2
+        psrldq      xmm2,   4
+
+        movd        [rdi+rax*4+2], xmm2
+        psrldq      xmm2,   4
+
+        movd        [rsi+rax*2+2], xmm2
+        psrldq      xmm2,   4
+
+        movd        [rdi+rax*2+2], xmm2
+        movd        [rsi+2],       xmm6
+
+        psrldq      xmm6,   4
+        movd        [rdi+2],       xmm6
+
+        psrldq      xmm6,   4
+        neg         rax
+
+        movd        [rdi+rax+2],    xmm6
+        psrldq      xmm6,   4
+
+        movd        [rdi+rax*2+2],  xmm6
+        lea         rsi,       [rsi+rax*8]
+
+        neg         rax
+        //;;;;;;;;;;;;;;;;;;;/
+        movd        [rsi+rax*4+2], xmm1
+        psrldq      xmm1,   4
+
+        movd        [rcx+rax*4+2], xmm1
+        psrldq      xmm1,   4
+
+        movd        [rsi+rax*2+2], xmm1
+        psrldq      xmm1,   4
+
+        movd        [rcx+rax*2+2], xmm1
+        psrldq      xmm1,   4
+
+        movd        [rsi+2],       xmm5
+        psrldq      xmm5,   4
+
+        movd        [rcx+2],        xmm5
+        psrldq      xmm5,   4
+
+        neg         rax
+        movd        [rcx+rax+2],    xmm5
+
+        psrldq      xmm5,   4
+        movd        [rcx+rax*2+2],  xmm5
+
+    add rsp, 96
+    pop rsp
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void vp8_mbloop_filter_horizontal_edge_sse2
+//(
+//    unsigned char *src_ptr,
+//    int            src_pixel_step,
+//    const char    *flimit,
+//    const char    *limit,
+//    const char    *thresh,
+//    int            count
+//)
+global sym(vp8_mbloop_filter_horizontal_edge_sse2)
+sym(vp8_mbloop_filter_horizontal_edge_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 6
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+    ALIGN_STACK 16, rax
+    sub         rsp, 32                         // reserve 32 bytes
+#   define t0  [rsp + 0]    //__declspec(align(16)) char t0[8];
+#   define t1  [rsp + 16]   //__declspec(align(16)) char t1[8];
+
+        mov         rsi,                    arg(0) //src_ptr
+        movsxd      rax,                    dword ptr arg(1) //src_pixel_step     ; destination pitch?
+
+        mov         rdx,                    arg(3) //limit
+        movdqa      xmm7,                   XMMWORD PTR [rdx]
+
+        mov         rdi,                    rsi           // rdi points to row +1 for indirect addressing
+        add         rdi,                    rax
+
+        // calculate breakout conditions
+        movdqa      xmm2,                   XMMWORD PTR [rdi+2*rax]      // q3
+        movdqa      xmm1,                   XMMWORD PTR [rsi+2*rax]      // q2
+
+        movdqa      xmm6,                   xmm1              // q2
+        psubusb     xmm1,                   xmm2              // q2-=q3
+
+
+        psubusb     xmm2,                   xmm6              // q3-=q2
+        por         xmm1,                   xmm2              // abs(q3-q2)
+
+        psubusb     xmm1,                   xmm7
+
+        // mm1 = abs(q3-q2), mm6 =q2, mm7 = limit
+        movdqa      xmm4,                   XMMWORD PTR [rsi+rax]         // q1
+        movdqa      xmm3,                   xmm4              // q1
+
+        psubusb     xmm4,                   xmm6              // q1-=q2
+        psubusb     xmm6,                   xmm3              // q2-=q1
+
+        por         xmm4,                   xmm6              // abs(q2-q1)
+        psubusb     xmm4,                   xmm7
+
+        por         xmm1,                   xmm4
+        // mm1 = mask,      mm3=q1, mm7 = limit
+
+        movdqa      xmm4,                   XMMWORD PTR [rsi]             // q0
+        movdqa      xmm0,                   xmm4              // q0
+
+        psubusb     xmm4,                   xmm3              // q0-=q1
+        psubusb     xmm3,                   xmm0              // q1-=q0
+
+        por         xmm4,                   xmm3              // abs(q0-q1)
+        movdqa      t0,                     xmm4                  // save to t0
+
+        psubusb     xmm4,                   xmm7
+        por         xmm1,                   xmm4
+
+        // mm1 = mask, mm0=q0,  mm7 = limit, t0 = abs(q0-q1)
+        neg         rax                   // negate pitch to deal with above border
+
+        movdqa      xmm2,                   XMMWORD PTR [rsi+4*rax]      // p3
+        movdqa      xmm4,                   XMMWORD PTR [rdi+4*rax]      // p2
+
+        movdqa      xmm5,                   xmm4              // p2
+        psubusb     xmm4,                   xmm2              // p2-=p3
+
+        psubusb     xmm2,                   xmm5              // p3-=p2
+        por         xmm4,                   xmm2              // abs(p3 - p2)
+
+        psubusb     xmm4,                   xmm7
+        por         xmm1,                   xmm4
+
+        // mm1 = mask, mm0=q0,  mm7 = limit, t0 = abs(q0-q1)
+        movdqa      xmm4,                   XMMWORD PTR [rsi+2*rax]      // p1
+        movdqa      xmm3,                   xmm4              // p1
+
+        psubusb     xmm4,                   xmm5              // p1-=p2
+        psubusb     xmm5,                   xmm3              // p2-=p1
+
+        por         xmm4,                   xmm5              // abs(p2 - p1)
+        psubusb     xmm4,                   xmm7
+
+        por         xmm1,                   xmm4
+
+        movdqa      xmm2,                   xmm3              // p1
+
+        // mm1 = mask, mm0=q0,  mm7 = limit, t0 = abs(q0-q1)
+        movdqa      xmm4,                   XMMWORD PTR [rsi+rax]         // p0
+        movdqa      xmm5,                   xmm4              // p0
+
+        psubusb     xmm4,                   xmm3              // p0-=p1
+        psubusb     xmm3,                   xmm5              // p1-=p0
+
+        por         xmm4,                   xmm3              // abs(p1 - p0)
+        movdqa        t1,                   xmm4                  // save to t1
+
+        psubusb     xmm4,                   xmm7
+        por         xmm1,                   xmm4
+
+        // mm1 = mask, mm0=q0,  mm7 = limit, t0 = abs(q0-q1) t1 = abs(p1-p0)
+        // mm5 = p0
+        movdqa      xmm3,                   XMMWORD PTR [rdi] // q1
+        movdqa      xmm4,                   xmm3              // q1
+        psubusb     xmm3,                   xmm2              // q1-=p1
+        psubusb     xmm2,                   xmm4              // p1-=q1
+        por         xmm2,                   xmm3              // abs(p1-q1)
+        pand        xmm2,                   [GLOBAL (tfe)]      // set lsb of each byte to zero
+        psrlw       xmm2,                   1                 // abs(p1-q1)/2
+
+        movdqa      xmm6,                   xmm5              // p0
+        movdqa      xmm3,                   xmm0              // q0
+
+        psubusb     xmm5,                   xmm3              // p0-=q0
+        psubusb     xmm3,                   xmm6              // q0-=p0
+
+        por         xmm5,                   xmm3              // abs(p0 - q0)
+        paddusb     xmm5,                   xmm5              // abs(p0-q0)*2
+        paddusb     xmm5,                   xmm2              // abs (p0 - q0) *2 + abs(p1-q1)/2
+
+        mov         rdx,                    arg(2) //flimit            ; get flimit
+        movdqa      xmm2,                   XMMWORD PTR [rdx]             //
+        paddb       xmm2,                   xmm2              // flimit*2 (less than 255)
+        paddb       xmm7,                   xmm2              // flimit * 2 + limit (less than 255)
+
+        psubusb     xmm5,                   xmm7              // abs (p0 - q0) *2 + abs(p1-q1)/2  > flimit * 2 + limit
+        por         xmm1,                   xmm5
+        pxor        xmm5,                   xmm5
+        pcmpeqb     xmm1,                   xmm5               // mask mm1
+        // mm1 = mask, mm0=q0,  mm7 = flimit, t0 = abs(q0-q1) t1 = abs(p1-p0)
+        // mm6 = p0,
+
+        // calculate high edge variance
+        mov         rdx,                    arg(4) //thresh            ; get thresh
+        movdqa      xmm7,                   XMMWORD PTR [rdx]             //
+
+        movdqa      xmm4,                   t0                // get abs (q1 - q0)
+        psubusb     xmm4,                   xmm7
+
+        movdqa      xmm3,                   t1                // get abs (p1 - p0)
+        psubusb     xmm3,                   xmm7
+
+        paddb       xmm4,                   xmm3              // abs(q1 - q0) > thresh || abs(p1 - p0) > thresh
+        pcmpeqb     xmm4,                   xmm5
+
+        pcmpeqb     xmm5,                   xmm5
+        pxor        xmm4,                   xmm5
+        // mm1 = mask, mm0=q0,  mm7 = thresh, t0 = abs(q0-q1) t1 = abs(p1-p0)
+        // mm6 = p0, mm4=hev
+        // start work on filters
+        movdqa      xmm2,                   XMMWORD PTR [rsi+2*rax]   // p1
+        movdqa      xmm7,                   XMMWORD PTR [rdi]             // q1
+
+        pxor        xmm2,                   [GLOBAL (t80)]  // p1 offset to convert to signed values
+        pxor        xmm7,                   [GLOBAL (t80)]  // q1 offset to convert to signed values
+
+        psubsb      xmm2,                   xmm7              // p1 - q1
+        pxor        xmm6,                   [GLOBAL (t80)]  // offset to convert to signed values
+
+        pxor        xmm0,                   [GLOBAL (t80)]  // offset to convert to signed values
+        movdqa      xmm3,                   xmm0              // q0
+
+        psubsb      xmm0,                   xmm6              // q0 - p0
+        paddsb      xmm2,                   xmm0              // 1 * (q0 - p0) + (p1 - q1)
+
+        paddsb      xmm2,                   xmm0              // 2 * (q0 - p0)
+        paddsb      xmm2,                   xmm0              // 3 * (q0 - p0) + (p1 - q1)
+
+        pand        xmm1,                   xmm2              // mask filter values we don't care about
+        // mm1 = vp8_filter, mm4=hev, mm6=ps0, mm3=qs0
+        movdqa      xmm2,                   xmm1              // vp8_filter
+        pand        xmm2,                   xmm4;             // Filter2 = vp8_filter & hev
+
+
+        movdqa      xmm5,                   xmm2          //
+        paddsb      xmm5,                   [GLOBAL (t3)];
+
+        pxor        xmm0,                   xmm0              // 0
+        pxor        xmm7,                   xmm7              // 0
+
+        punpcklbw   xmm0,                   xmm5              // e0f0g0h0
+        psraw       xmm0,                   11                // sign extended shift right by 3
+
+        punpckhbw   xmm7,                   xmm5              // a0b0c0d0
+        psraw       xmm7,                   11                // sign extended shift right by 3
+
+        packsswb    xmm0,                   xmm7              // Filter2 >>=3;
+        movdqa      xmm5,                   xmm0              // Filter2
+
+        paddsb      xmm2,                   [GLOBAL (t4)]      // vp8_signed_char_clamp(Filter2 + 4)
+        pxor        xmm0,                   xmm0              // 0
+
+        pxor        xmm7,                   xmm7              // 0
+        punpcklbw   xmm0,                   xmm2              // e0f0g0h0
+
+        psraw       xmm0,                   11                // sign extended shift right by 3
+        punpckhbw   xmm7,                   xmm2              // a0b0c0d0
+
+        psraw       xmm7,                   11                // sign extended shift right by 3
+        packsswb    xmm0,                   xmm7              // Filter2 >>=3;
+
+        // mm0= filter2 mm1 = vp8_filter,  mm3 =qs0 mm5=s mm4 =hev mm6=ps0
+        psubsb      xmm3,                   xmm0              // qs0 =qs0 - filter1
+        paddsb      xmm6,                   xmm5              // ps0 =ps0 + Fitler2
+
+        // mm1=vp8_filter, mm3=qs0, mm4 =hev mm6=ps0
+        // vp8_filter &= ~hev;
+        // Filter2 = vp8_filter;
+        pandn       xmm4,                   xmm1              // vp8_filter&=~hev
+
+
+        // mm3=qs0, mm4=filter2, mm6=ps0
+
+        // u = vp8_signed_char_clamp((63 + Filter2 * 27)>>7);
+        // s = vp8_signed_char_clamp(qs0 - u);
+        // *oq0 = s^0x80;
+        // s = vp8_signed_char_clamp(ps0 + u);
+        // *op0 = s^0x80;
+        pxor        xmm0,                   xmm0
+        pxor        xmm1,                   xmm1
+
+        pxor        xmm2,                   xmm2
+        punpcklbw   xmm1,                   xmm4
+
+        punpckhbw   xmm2,                   xmm4
+        pmulhw      xmm1,                   [GLOBAL (s27)]
+
+        pmulhw      xmm2,                   [GLOBAL (s27)]
+        paddw       xmm1,                   [GLOBAL (s63)]
+
+        paddw       xmm2,                   [GLOBAL (s63)]
+        psraw       xmm1,                   7
+
+        psraw       xmm2,                   7
+        packsswb    xmm1,                   xmm2
+
+        psubsb      xmm3,                   xmm1
+        paddsb      xmm6,                   xmm1
+
+        pxor        xmm3,                   [GLOBAL (t80)]
+        pxor        xmm6,                   [GLOBAL (t80)]
+
+        movdqa      XMMWORD PTR [rsi+rax],  xmm6
+        movdqa      XMMWORD PTR [rsi],      xmm3
+
+        // roughly 2/7th difference across boundary
+        // u = vp8_signed_char_clamp((63 + Filter2 * 18)>>7);
+        // s = vp8_signed_char_clamp(qs1 - u);
+        // *oq1 = s^0x80;
+        // s = vp8_signed_char_clamp(ps1 + u);
+        // *op1 = s^0x80;
+        pxor        xmm1,                   xmm1
+        pxor        xmm2,                   xmm2
+
+        punpcklbw   xmm1,                   xmm4
+        punpckhbw   xmm2,                   xmm4
+
+        pmulhw      xmm1,                   [GLOBAL (s18)]
+        pmulhw      xmm2,                   [GLOBAL (s18)]
+
+        paddw       xmm1,                   [GLOBAL (s63)]
+        paddw       xmm2,                   [GLOBAL (s63)]
+
+        psraw       xmm1,                   7
+        psraw       xmm2,                   7
+
+        packsswb    xmm1,                   xmm2
+
+        movdqa      xmm3,                   XMMWORD PTR [rdi]
+        movdqa      xmm6,                   XMMWORD PTR [rsi+rax*2]       // p1
+
+        pxor        xmm3,                   [GLOBAL (t80)]
+        pxor        xmm6,                   [GLOBAL (t80)]
+
+        paddsb      xmm6,                   xmm1
+        psubsb      xmm3,                   xmm1
+
+        pxor        xmm6,                   [GLOBAL (t80)]
+        pxor        xmm3,                   [GLOBAL (t80)]
+
+        movdqa      XMMWORD PTR [rdi],      xmm3
+        movdqa      XMMWORD PTR [rsi+rax*2],xmm6
+
+        // roughly 1/7th difference across boundary
+        // u = vp8_signed_char_clamp((63 + Filter2 * 9)>>7);
+        // s = vp8_signed_char_clamp(qs2 - u);
+        // *oq2 = s^0x80;
+        // s = vp8_signed_char_clamp(ps2 + u);
+        // *op2 = s^0x80;
+        pxor        xmm1,                   xmm1
+        pxor        xmm2,                   xmm2
+
+        punpcklbw   xmm1,                   xmm4
+        punpckhbw   xmm2,                   xmm4
+
+        pmulhw      xmm1,                   [GLOBAL (s9)]
+        pmulhw      xmm2,                   [GLOBAL (s9)]
+
+        paddw       xmm1,                   [GLOBAL (s63)]
+        paddw       xmm2,                   [GLOBAL (s63)]
+
+        psraw       xmm1,                   7
+        psraw       xmm2,                   7
+
+        packsswb    xmm1,                   xmm2
+
+
+        movdqa      xmm6,                   XMMWORD PTR [rdi+rax*4]
+        neg         rax
+
+        movdqa      xmm3,                   XMMWORD PTR [rdi+rax  ]
+
+        pxor        xmm6,                   [GLOBAL (t80)]
+        pxor        xmm3,                   [GLOBAL (t80)]
+
+        paddsb      xmm6,                   xmm1
+        psubsb      xmm3,                   xmm1
+
+        pxor        xmm6,                   [GLOBAL (t80)]
+        pxor        xmm3,                   [GLOBAL (t80)]
+
+        movdqa      XMMWORD PTR [rdi+rax  ], xmm3
+        neg         rax
+
+        movdqa      XMMWORD PTR [rdi+rax*4], xmm6
+
+    add rsp, 32
+    pop rsp
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void vp8_mbloop_filter_vertical_edge_sse2
+//(
+//    unsigned char *src_ptr,
+//    int            src_pixel_step,
+//    const char    *flimit,
+//    const char    *limit,
+//    const char    *thresh,
+//    int            count
+//)
+global sym(vp8_mbloop_filter_vertical_edge_sse2)
+sym(vp8_mbloop_filter_vertical_edge_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 6
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+    ALIGN_STACK 16, rax
+    sub          rsp, 160     // reserve 160 bytes
+#   define t0   [rsp + 0]    //__declspec(align(16)) char t0[16];
+#   define t1   [rsp + 16]   //__declspec(align(16)) char t1[16];
+#   define srct [rsp + 32]   //__declspec(align(16)) char srct[128];
+
+
+        mov         rsi,                arg(0) //src_ptr
+        movsxd      rax,                dword ptr arg(1) //src_pixel_step                    ; destination pitch?
+
+        lea         rsi,                [rsi + rax*4 - 4]
+        lea         rdi,                [rsi + rax]                     // rdi points to row +1 for indirect addressing
+
+        mov         rcx,                rax
+        neg         rcx
+
+        // Transpose
+        movq        xmm0,               QWORD PTR [rdi+rax*2]           // xx xx xx xx xx xx xx xx 77 76 75 74 73 72 71 70
+        movq        xmm7,               QWORD PTR [rsi+rax*2]           // xx xx xx xx xx xx xx xx 67 66 65 64 63 62 61 60
+
+        punpcklbw   xmm7,               xmm0                            // 77 67 76 66 75 65 74 64 73 63 72 62 71 61 70 60
+        movq        xmm0,               QWORD PTR [rsi+rax]             //
+
+        movq        xmm5,               QWORD PTR [rsi]                 //
+        punpcklbw   xmm5,               xmm0                            // 57 47 56 46 55 45 54 44 53 43 52 42 51 41 50 40
+
+        movdqa      xmm6,               xmm5                            // 57 47 56 46 55 45 54 44 53 43 52 42 51 41 50 40
+        punpcklwd   xmm5,               xmm7                            // 73 63 53 43 72 62 52 42 71 61 51 41 70 60 50 40
+
+        punpckhwd   xmm6,               xmm7                            // 77 67 57 47 76 66 56 46 75 65 55 45 74 64 54 44
+        movq        xmm7,               QWORD PTR [rsi + rcx]           // xx xx xx xx xx xx xx xx 37 36 35 34 33 32 31 30
+
+        movq        xmm0,               QWORD PTR [rsi + rcx*2]         // xx xx xx xx xx xx xx xx 27 26 25 24 23 22 21 20
+        punpcklbw   xmm0,               xmm7                            // 37 27 36 36 35 25 34 24 33 23 32 22 31 21 30 20
+
+        movq        xmm4,               QWORD PTR [rsi + rcx*4]         // xx xx xx xx xx xx xx xx 07 06 05 04 03 02 01 00
+        movq        xmm7,               QWORD PTR [rdi + rcx*4]         // xx xx xx xx xx xx xx xx 17 16 15 14 13 12 11 10
+
+        punpcklbw   xmm4,               xmm7                            // 17 07 16 06 15 05 14 04 13 03 12 02 11 01 10 00
+        movdqa      xmm3,               xmm4                            // 17 07 16 06 15 05 14 04 13 03 12 02 11 01 10 00
+
+        punpcklwd   xmm3,               xmm0                            // 33 23 13 03 32 22 12 02 31 21 11 01 30 20 10 00
+        punpckhwd   xmm4,               xmm0                            // 37 27 17 07 36 26 16 06 35 25 15 05 34 24 14 04
+
+        movdqa      xmm7,               xmm4                            // 37 27 17 07 36 26 16 06 35 25 15 05 34 24 14 04
+        movdqa      xmm2,               xmm3                            // 33 23 13 03 32 22 12 02 31 21 11 01 30 20 10 00
+
+        punpckhdq   xmm7,               xmm6                            // 77 67 57 47 37 27 17 07 76 66 56 46 36 26 16 06
+        punpckldq   xmm4,               xmm6                            // 75 65 55 45 35 25 15 05 74 64 54 44 34 24 14 04
+
+        punpckhdq   xmm3,               xmm5                            // 73 63 53 43 33 23 13 03 72 62 52 42 32 22 12 02
+        punpckldq   xmm2,               xmm5                            // 71 61 51 41 31 21 11 01 70 60 50 40 30 20 10 00
+
+        movdqa      t0,                 xmm2                            // save to free XMM2
+        //movdqa        t1,                 xmm3
+
+        // XMM3 XMM4 XMM7 in use
+        lea         rsi,                [rsi+rax*8]
+        lea         rdi,                [rdi+rax*8]
+
+        movq        xmm6,               QWORD PTR [rdi+rax*2]           // xx xx xx xx xx xx xx xx f7 f6 f5 f4 f3 f2 f1 f0
+        movq        xmm5,               QWORD PTR [rsi+rax*2]           // xx xx xx xx xx xx xx xx e7 e6 e5 e4 e3 e2 e1 e0
+
+        punpcklbw   xmm5,               xmm6                            // f7 e7 f6 e6 f5 e5 f4 e4 f3 e3 f2 e2 f1 e1 f0 e0
+        movq        xmm6,               QWORD PTR [rsi+rax]             // xx xx xx xx xx xx xx xx d7 d6 d5 d4 d3 d2 d1 d0
+
+        movq        xmm1,               QWORD PTR [rsi]                 // xx xx xx xx xx xx xx xx c7 c6 c5 c4 c3 c2 c1 c0
+        punpcklbw   xmm1,               xmm6                            // d7 c7 d6 c6 d5 c5 d4 c4 d3 c3 d2 c2 d1 e1 d0 c0
+
+        movdqa      xmm6,               xmm1                            //
+        punpckhwd   xmm6,               xmm5                            // f7 e7 d7 c7 f6 e6 d6 c6 f5 e5 d5 c5 f4 e4 d4 c4
+
+        punpcklwd   xmm1,               xmm5                            // f3 e3 d3 c3 f2 e2 d2 c2 f1 e1 d1 c1 f0 e0 d0 c0
+        movq        xmm5,               QWORD PTR [rsi+rcx]             // xx xx xx xx xx xx xx xx b7 b6 b5 b4 b3 b2 b1 b0
+
+        movq        xmm0,               QWORD PTR [rsi+rcx*2]           // xx xx xx xx xx xx xx xx a7 a6 a5 a4 a3 a2 a1 a0
+        punpcklbw   xmm0,               xmm5                            // b7 a7 b6 a6 b5 a5 b4 a4 b3 a3 b2 a2 b1 a1 b0 a0
+
+        movq        xmm2,               QWORD PTR [rsi+rcx*4]           // xx xx xx xx xx xx xx xx 87 86 85 84 83 82 81 80
+        movq        xmm5,               QWORD PTR [rdi+rcx*4]           // xx xx xx xx xx xx xx xx 97 96 95 94 93 92 91 90
+
+        punpcklbw   xmm2,               xmm5                            // 97 87 96 86 95 85 94 84 93 83 92 82 91 81 90 80
+        movdqa      xmm5,               xmm2                            // 97 87 96 86 95 85 94 84 93 83 92 82 91 81 90 80
+
+        punpcklwd   xmm5,               xmm0                            // b3 a3 93 83 b2 a2 92 82 b1 a1 91 81 b0 a0 90 80
+        punpckhwd   xmm2,               xmm0                            // b7 a7 97 87 b6 a6 96 86 b5 a5 95 85 b4 a4 94 84
+
+        movdqa      xmm0,               xmm5
+        punpckldq   xmm0,               xmm1                            // f1 e1 d1 c1 b1 a1 91 81 f0 e0 d0 c0 b0 a0 90 80
+
+
+        punpckhdq   xmm5,               xmm1                            // f3 e3 d3 c3 b3 a3 93 83 f2 e2 d2 c2 b2 a2 92 82
+        movdqa      xmm1,               xmm2                            // b7 a7 97 87 b6 a6 96 86 b5 a5 95 85 b4 a4 94 84
+
+        punpckldq   xmm1,               xmm6                            // f5 e5 d5 c5 b5 a5 95 85 f4 e4 d4 c4 b4 a4 94 84
+        punpckhdq   xmm2,               xmm6                            // f7 e7 d7 c7 b7 a7 97 87 f6 e6 d6 c6 b6 a6 96 86
+
+        movdqa      xmm6,               xmm7                            // 77 67 57 47 37 27 17 07 76 66 56 46 36 26 16 06
+        punpcklqdq  xmm6,               xmm2                            // f6 e6 d6 c6 b6 a6 96 86 76 66 56 46 36 26 16 06
+
+
+        lea         rdx,                srct
+        punpckhqdq  xmm7,               xmm2                            // f7 e7 d7 c7 b7 a7 97 87 77 67 57 47 37 27 17 07
+
+        movdqa      [rdx+112],          xmm7                            // save 7
+        movdqa      xmm2,               xmm3                            // 73 63 53 43 33 23 13 03 72 62 52 42 32 22 12 02
+
+        movdqa      [rdx+96],           xmm6                            // save 6
+        punpcklqdq  xmm2,               xmm5                            // f2 e2 d2 c2 b2 a2 92 82 72 62 52 42 32 22 12 02
+
+        punpckhqdq  xmm3,               xmm5                            // f3 e3 d3 c3 b3 a3 93 83 73 63 53 43 33 23 13 03
+        movdqa      [rdx+32],           xmm2                            // save 2
+
+        movdqa      xmm5,               xmm4                            // 75 65 55 45 35 25 15 05 74 64 54 44 34 24 14 04
+        punpcklqdq  xmm4,               xmm1                            // f4 e4 d4 c4 b4 a4 94 84 74 64 54 44 34 24 14 04
+
+        movdqa      [rdx+48],           xmm3                            // save 3
+        punpckhqdq  xmm5,               xmm1                            // f5 e5 d5 c5 b5 a5 95 85 75 65 55 45 35 25 15 05
+
+        movdqa      [rdx+64],           xmm4                            // save 4
+        movdqa      [rdx+80],           xmm5                            // save 5
+
+        movdqa      xmm1,               t0                              // get
+        movdqa      xmm2,               xmm1                            //
+
+        punpckhqdq  xmm1,               xmm0                            // f1 e1 d1 c1 b1 a1 91 81 71 61 51 41 31 21 11 01
+        punpcklqdq  xmm2,               xmm0                            // f0 e0 d0 c0 b0 a0 90 80 70 60 50 40 30 20 10 00
+
+        movdqa      [rdx+16],           xmm1
+        movdqa      [rdx],              xmm2
+
+        movdqa      xmm0,               xmm6                            // q2
+        psubusb     xmm0,               xmm7                            // q2-q3
+
+        psubusb     xmm7,               xmm6                            // q3-q2
+        por         xmm7,               xmm0                            // abs (q3-q2)
+
+        movdqa      xmm1,               xmm5                            // q1
+        psubusb     xmm1,               xmm6                            // q1-q2
+
+        psubusb     xmm6,               xmm5                            // q2-q1
+        por         xmm6,               xmm1                            // abs (q2-q1)
+
+        ///*
+        //movdqa      xmm0,               xmm4                            ; q0
+        //psubusb     xmm0                xmm5                            ; q0-q1
+        //
+        //pusbusb     xmm5,               xmm4                            ; q1-q0
+        //por         xmm5,               xmm0                            ; abs (q1-q0)
+        //*/
+
+        movdqa      xmm1,               [rdx+16]                        // p2
+        movdqa      xmm0,               xmm1
+
+        psubusb     xmm0,               xmm2                            // p2 - p3;
+        psubusb     xmm2,               xmm1                            // p3 - p2;
+
+        por         xmm0,               xmm2                            // abs(p2-p3)
+
+        movdqa      xmm2,               [rdx+32]                        // p1
+        movdqa      xmm5,               xmm2                            // p1
+
+        psubusb     xmm5,               xmm1                            // p1-p2
+        psubusb     xmm1,               xmm2                            // p2-p1
+
+        por         xmm1,               xmm5                            // abs(p2-p1)
+        mov         rdx,                arg(3) //limit
+
+        movdqa      xmm4,               [rdx]                           // limit
+        psubusb     xmm7,               xmm4                            //
+
+
+        psubusb     xmm0,               xmm4                            // abs(p3-p2) > limit
+        psubusb     xmm1,               xmm4                            // abs(p2-p1) > limit
+
+        psubusb     xmm6,               xmm4                            // abs(q2-q1) > limit
+        por         xmm7,               xmm6                            // or
+
+        por         xmm0,               xmm1                            //
+        por         xmm0,               xmm7                            // abs(q3-q2) > limit || abs(p3-p2) > limit ||abs(p2-p1) > limit || abs(q2-q1) > limit
+
+        movdqa      xmm1,               xmm2                            // p1
+
+        movdqa      xmm7,               xmm3                            // p0
+        psubusb     xmm7,               xmm2                            // p0-p1
+
+        psubusb     xmm2,               xmm3                            // p1-p0
+        por         xmm2,               xmm7                            // abs(p1-p0)
+
+        movdqa      t0,                 xmm2                            // save abs(p1-p0)
+        lea         rdx,                srct
+
+        psubusb     xmm2,               xmm4                            // abs(p1-p0)>limit
+        por         xmm0,               xmm2                            // mask
+
+        movdqa      xmm5,               [rdx+64]                        // q0
+        movdqa      xmm7,               [rdx+80]                        // q1
+
+        movdqa      xmm6,               xmm5                            // q0
+        movdqa      xmm2,               xmm7                            // q1
+        psubusb     xmm5,               xmm7                            // q0-q1
+
+        psubusb     xmm7,               xmm6                            // q1-q0
+        por         xmm7,               xmm5                            // abs(q1-q0)
+
+        movdqa      t1,                 xmm7                            // save abs(q1-q0)
+        psubusb     xmm7,               xmm4                            // abs(q1-q0)> limit
+
+        por         xmm0,               xmm7                            // mask
+
+        movdqa      xmm5,                xmm2                           // q1
+        psubusb     xmm5,                xmm1                           // q1-=p1
+        psubusb     xmm1,                xmm2                           // p1-=q1
+        por         xmm5,                xmm1                           // abs(p1-q1)
+        pand        xmm5,                [GLOBAL (tfe)]                   // set lsb of each byte to zero
+        psrlw       xmm5,                1                              // abs(p1-q1)/2
+
+        mov         rdx,                arg(2) //flimit                          ;
+        movdqa      xmm2,               [rdx]                           // flimit
+
+        movdqa      xmm1,               xmm3                            // p0
+        movdqa      xmm7,               xmm6                            // q0
+        psubusb     xmm1,               xmm7                            // p0-q0
+        psubusb     xmm7,               xmm3                            // q0-p0
+        por         xmm1,               xmm7                            // abs(q0-p0)
+        paddusb     xmm1,               xmm1                            // abs(q0-p0)*2
+        paddusb     xmm1,               xmm5                            // abs (p0 - q0) *2 + abs(p1-q1)/2
+
+        paddb       xmm2,               xmm2                            // flimit*2 (less than 255)
+        paddb       xmm4,               xmm2                            // flimit * 2 + limit (less than 255)
+
+        psubusb     xmm1,               xmm4                            // abs (p0 - q0) *2 + abs(p1-q1)/2  > flimit * 2 + limit
+        por         xmm1,               xmm0;                           // mask
+        pxor        xmm0,               xmm0
+        pcmpeqb     xmm1,               xmm0
+
+        // calculate high edge variance
+        mov         rdx,                arg(4) //thresh                          ; get thresh
+        movdqa      xmm7,               [rdx]
+
+        movdqa      xmm4,               t0                              // get abs (q1 - q0)
+        psubusb     xmm4,               xmm7                            // abs(q1 - q0) > thresh
+
+        movdqa      xmm3,               t1                              // get abs (p1 - p0)
+        psubusb     xmm3,               xmm7                            // abs(p1 - p0)> thresh
+
+        por         xmm4,               xmm3                            // abs(q1 - q0) > thresh || abs(p1 - p0) > thresh
+        pcmpeqb     xmm4,               xmm0
+
+        pcmpeqb     xmm0,               xmm0
+        pxor        xmm4,               xmm0
+
+
+        // start work on filters
+        lea         rdx,                srct
+
+        // start work on filters
+        movdqa      xmm2,               [rdx+32]                        // p1
+        movdqa      xmm7,               [rdx+80]                        // q1
+
+        pxor        xmm2,               [GLOBAL (t80)]                    // p1 offset to convert to signed values
+        pxor        xmm7,               [GLOBAL (t80)]                    // q1 offset to convert to signed values
+
+        psubsb      xmm2,               xmm7                            // p1 - q1
+        movdqa      xmm6,               [rdx+48]                        // p0
+
+        movdqa      xmm0,               [rdx+64]                        // q0
+        pxor        xmm6,               [GLOBAL (t80)]                    // offset to convert to signed values
+
+        pxor        xmm0,               [GLOBAL (t80)]                    // offset to convert to signed values
+        movdqa      xmm3,               xmm0                            // q0
+
+        psubsb      xmm0,               xmm6                            // q0 - p0
+        paddsb      xmm2,               xmm0                            // 1 * (q0 - p0) + (p1 - q1)
+
+        paddsb      xmm2,               xmm0                            // 2 * (q0 - p0)
+        paddsb      xmm2,               xmm0                            // 3 * (q0 - p0)+ (p1 - q1)
+
+        pand        xmm1,               xmm2                            // mask filter values we don't care about
+
+        // xmm1 = vp8_filter, xmm4=hev, xmm6=ps0, xmm3=qs0
+        movdqa      xmm2,               xmm1                            // vp8_filter
+        pand        xmm2,               xmm4;                           // Filter2 = vp8_filter & hev
+
+        movdqa      xmm5,               xmm2
+        paddsb      xmm5,               [GLOBAL (t3)]
+
+        pxor        xmm0,               xmm0                            // 0
+        pxor        xmm7,               xmm7                            // 0
+
+        punpcklbw   xmm0,               xmm5                            // e0f0g0h0
+        psraw       xmm0,               11                              // sign extended shift right by 3
+
+        punpckhbw   xmm7,               xmm5                            // a0b0c0d0
+        psraw       xmm7,               11                              // sign extended shift right by 3
+
+        packsswb    xmm0,               xmm7                            // Filter2 >>=3;
+        movdqa      xmm5,               xmm0                            // Filter2
+
+        paddsb      xmm2,               [GLOBAL (t4)]                     // vp8_signed_char_clamp(Filter2 + 4)
+        pxor        xmm0,               xmm0                            // 0
+
+        pxor        xmm7,               xmm7                            // 0
+        punpcklbw   xmm0,               xmm2                            // e0f0g0h0
+
+        psraw       xmm0,               11                              // sign extended shift right by 3
+        punpckhbw   xmm7,               xmm2                            // a0b0c0d0
+
+        psraw       xmm7,               11                              // sign extended shift right by 3
+        packsswb    xmm0,               xmm7                            // Filter2 >>=3;
+
+        // xmm0= filter2 xmm1 = vp8_filter,  xmm3 =qs0 xmm5=s xmm4 =hev xmm6=ps0
+        psubsb      xmm3,               xmm0                            // qs0 =qs0 - filter1
+        paddsb      xmm6,               xmm5                            // ps0 =ps0 + Fitler2
+
+
+        // xmm1=vp8_filter, xmm3=qs0, xmm4 =hev xmm6=ps0
+        // vp8_filter &= ~hev;
+        // Filter2 = vp8_filter;
+        pandn       xmm4,                   xmm1                        // vp8_filter&=~hev
+
+        // xmm3=qs0, xmm4=filter2, xmm6=ps0
+        // u = vp8_signed_char_clamp((63 + Filter2 * 27)>>7);
+        // s = vp8_signed_char_clamp(qs0 - u);
+        // *oq0 = s^0x80;
+        // s = vp8_signed_char_clamp(ps0 + u);
+        // *op0 = s^0x80;
+        pxor        xmm0,                   xmm0
+        pxor        xmm1,                   xmm1
+
+        pxor        xmm2,                   xmm2
+        punpcklbw   xmm1,                   xmm4
+
+        punpckhbw   xmm2,                   xmm4
+        pmulhw      xmm1,                   [GLOBAL (s27)]
+
+        pmulhw      xmm2,                   [GLOBAL (s27)]
+        paddw       xmm1,                   [GLOBAL (s63)]
+
+        paddw       xmm2,                   [GLOBAL (s63)]
+        psraw       xmm1,                   7
+
+        psraw       xmm2,                   7
+        packsswb    xmm1,                   xmm2
+
+        psubsb      xmm3,                   xmm1
+        paddsb      xmm6,                   xmm1
+
+        pxor        xmm3,                   [GLOBAL (t80)]
+        pxor        xmm6,                   [GLOBAL (t80)]
+
+        movdqa      [rdx+48],               xmm6
+        movdqa      [rdx+64],               xmm3
+
+        // roughly 2/7th difference across boundary
+        // u = vp8_signed_char_clamp((63 + Filter2 * 18)>>7);
+        // s = vp8_signed_char_clamp(qs1 - u);
+        // *oq1 = s^0x80;
+        // s = vp8_signed_char_clamp(ps1 + u);
+        // *op1 = s^0x80;
+        pxor        xmm1,                       xmm1
+        pxor        xmm2,                       xmm2
+
+        punpcklbw   xmm1,                       xmm4
+        punpckhbw   xmm2,                       xmm4
+
+        pmulhw      xmm1,                       [GLOBAL (s18)]
+        pmulhw      xmm2,                       [GLOBAL (s18)]
+
+        paddw       xmm1,                       [GLOBAL (s63)]
+        paddw       xmm2,                       [GLOBAL (s63)]
+
+        psraw       xmm1,                       7
+        psraw       xmm2,                       7
+
+        packsswb    xmm1,                       xmm2
+
+        movdqa      xmm3,                       [rdx + 80]              ///q1
+        movdqa      xmm6,                       [rdx + 32]              // p1
+
+        pxor        xmm3,                       [GLOBAL (t80)]
+        pxor        xmm6,                       [GLOBAL (t80)]
+
+        paddsb      xmm6,                       xmm1
+        psubsb      xmm3,                       xmm1
+
+        pxor        xmm6,                       [GLOBAL (t80)]
+        pxor        xmm3,                       [GLOBAL (t80)]
+
+        movdqa      [rdx + 80],                 xmm3
+        movdqa      [rdx + 32],                 xmm6
+
+
+        // roughly 1/7th difference across boundary
+        // u = vp8_signed_char_clamp((63 + Filter2 * 9)>>7);
+        // s = vp8_signed_char_clamp(qs2 - u);
+        // *oq2 = s^0x80;
+        // s = vp8_signed_char_clamp(ps2 + u);
+        // *op2 = s^0x80;
+        pxor        xmm1,                       xmm1
+        pxor        xmm2,                       xmm2
+
+        punpcklbw   xmm1,                       xmm4
+        punpckhbw   xmm2,                       xmm4
+
+        pmulhw      xmm1,                       [GLOBAL (s9)]
+        pmulhw      xmm2,                       [GLOBAL (s9)]
+
+        paddw       xmm1,                       [GLOBAL (s63)]
+        paddw       xmm2,                       [GLOBAL (s63)]
+
+        psraw       xmm1,                       7
+        psraw       xmm2,                       7
+
+        packsswb    xmm1,                       xmm2
+
+        movdqa      xmm6,                       [rdx+16]
+        movdqa      xmm3,                       [rdx+96]
+
+        pxor        xmm6,                       [GLOBAL (t80)]
+        pxor        xmm3,                       [GLOBAL (t80)]
+
+        paddsb      xmm6,                       xmm1
+        psubsb      xmm3,                       xmm1
+
+        pxor        xmm6,                       [GLOBAL (t80)]        // xmm6 = f1 e1 d1 c1 b1 a1 91 81 71 61 51 41 31 21 11 01
+        pxor        xmm3,                       [GLOBAL (t80)]        // xmm3 = f6 e6 d6 c6 b6 a6 96 86 76 66 56 46 36 26 15 06
+
+
+        // transpose and write back
+        movdqa      xmm0,                       [rdx]               // f0 e0 d0 c0 b0 a0 90 80 70 60 50 40 30 20 10 00
+        movdqa      xmm1,                       xmm0                // f0 e0 d0 c0 b0 a0 90 80 70 60 50 40 30 20 10 00
+
+        punpcklbw   xmm0,                       xmm6                // 71 70 61 60 51 50 41 40 31 30 21 20 11 10 01 00
+        punpckhbw   xmm1,                       xmm6                // f1 f0 e1 e0 d1 d0 c1 c0 b1 b0 a1 a0 91 90 81 80
+
+        movdqa      xmm2,                       [rdx+32]            // f2 e2 d2 c2 b2 a2 92 82 72 62 52 42 32 22 12 02
+        movdqa      xmm6,                       xmm2                // f2 e2 d2 c2 b2 a2 92 82 72 62 52 42 32 22 12 02
+
+        punpcklbw   xmm2,                       [rdx+48]            // 73 72 63 62 53 52 43 42 33 32 23 22 13 12 03 02
+        punpckhbw   xmm6,                       [rdx+48]            // f3 f2 e3 e2 d3 d2 c3 c2 b3 b2 a3 a2 93 92 83 82
+
+        movdqa      xmm5,                       xmm0                // 71 70 61 60 51 50 41 40 31 30 21 20 11 10 01 00
+        punpcklwd   xmm0,                       xmm2                // 33 32 31 30 23 22 21 20 13 12 11 10 03 02 01 00
+
+        punpckhwd   xmm5,                       xmm2                // 73 72 71 70 63 62 61 60 53 52 51 50 43 42 41 40
+        movdqa      xmm4,                       xmm1                // f1 f0 e1 e0 d1 d0 c1 c0 b1 b0 a1 a0 91 90 81 80
+
+        punpcklwd   xmm1,                       xmm6                // b3 b2 b1 b0 a3 a2 a1 a0 93 92 91 90 83 82 81 80
+        punpckhwd   xmm4,                       xmm6                // f3 f2 f1 f0 e3 e2 e1 e0 d3 d2 d1 d0 c3 c2 c1 c0
+
+        movdqa      xmm2,                       [rdx+64]            // f4 e4 d4 c4 b4 a4 94 84 74 64 54 44 34 24 14 04
+        punpcklbw   xmm2,                       [rdx+80]            // 75 74 65 64 55 54 45 44 35 34 25 24 15 14 05 04
+
+        movdqa      xmm6,                       xmm3                // f6 e6 d6 c6 b6 a6 96 86 76 66 56 46 36 26 16 06
+        punpcklbw   xmm6,                       [rdx+112]           // 77 76 67 66 57 56 47 46 37 36 27 26 17 16 07 06
+
+        movdqa      xmm7,                       xmm2                // 75 74 65 64 55 54 45 44 35 34 25 24 15 14 05 04
+        punpcklwd   xmm2,                       xmm6                // 37 36 35 34 27 26 25 24 17 16 15 14 07 06 05 04
+
+        punpckhwd   xmm7,                       xmm6                // 77 76 75 74 67 66 65 64 57 56 55 54 47 46 45 44
+        movdqa      xmm6,                       xmm0                // 33 32 31 30 23 22 21 20 13 12 11 10 03 02 01 00
+
+        punpckldq   xmm0,                       xmm2                // 17 16 15 14 13 12 11 10 07 06 05 04 03 02 01 00
+        punpckhdq   xmm6,                       xmm2                // 37 36 35 34 33 32 31 30 27 26 25 24 23 22 21 20
+
+        lea         rsi,                        [rsi+rcx*8]
+        lea         rdi,                        [rdi+rcx*8]
+
+        movq        QWORD PTR [rsi+rcx*4],      xmm0
+        psrldq      xmm0,                       8
+
+        movq        QWORD PTR [rsi+rcx*2],      xmm6
+        psrldq      xmm6,                       8
+
+        movq        QWORD PTR [rdi+rcx*4],      xmm0
+        movq        QWORD PTR [rsi+rcx],        xmm6
+
+        movdqa      xmm0,                       xmm5                // 73 72 71 70 63 62 61 60 53 52 51 50 43 42 41 40
+        punpckldq   xmm0,                       xmm7                // 57 56 55 54 53 52 51 50 47 46 45 44 43 42 41 40
+
+        punpckhdq   xmm5,                       xmm7                // 77 76 75 74 73 72 71 70 67 66 65 64 63 62 61 60
+
+        movq        QWORD PTR [rsi],            xmm0
+        psrldq      xmm0,                       8
+
+        movq        QWORD PTR [rsi+rax*2],      xmm5
+        psrldq      xmm5,                       8
+
+        movq        QWORD PTR [rsi+rax],        xmm0
+        movq        QWORD PTR [rdi+rax*2],      xmm5
+
+        movdqa      xmm2,                       [rdx+64]            // f4 e4 d4 c4 b4 a4 94 84 74 64 54 44 34 24 14 04
+        punpckhbw   xmm2,                       [rdx+80]            // f5 f4 e5 e4 d5 d4 c5 c4 b5 b4 a5 a4 95 94 85 84
+
+        punpckhbw   xmm3,                       [rdx+112]           // f7 f6 e7 e6 d7 d6 c7 c6 b7 b6 a7 a6 97 96 87 86
+        movdqa      xmm0,                       xmm2
+
+        punpcklwd   xmm0,                       xmm3                // b7 b6 b4 b4 a7 a6 a5 a4 97 96 95 94 87 86 85 84
+        punpckhwd   xmm2,                       xmm3                // f7 f6 f5 f4 e7 e6 e5 e4 d7 d6 d5 d4 c7 c6 c5 c4
+
+        movdqa      xmm3,                       xmm1                // b3 b2 b1 b0 a3 a2 a1 a0 93 92 91 90 83 82 81 80
+        punpckldq   xmm1,                       xmm0                // 97 96 95 94 93 92 91 90 87 86 85 83 84 82 81 80
+
+        punpckhdq   xmm3,                       xmm0                // b7 b6 b5 b4 b3 b2 b1 b0 a7 a6 a5 a4 a3 a2 a1 a0
+
+        lea         rsi,                        [rsi+rax*8]
+        lea         rdi,                        [rdi+rax*8]
+
+        movq        QWORD PTR [rsi+rcx*4],      xmm1
+        psrldq      xmm1,                       8
+
+        movq        QWORD PTR [rsi+rcx*2],      xmm3
+        psrldq      xmm3,                       8
+
+        movq        QWORD PTR [rdi+rcx*4],      xmm1
+        movq        QWORD PTR [rsi+rcx],        xmm3
+
+        movdqa      xmm1,                       xmm4                // f3 f2 f1 f0 e3 e2 e1 e0 d3 d2 d1 d0 c3 c2 c1 c0
+        punpckldq   xmm1,                       xmm2                // d7 d6 d5 d4 d3 d2 d1 d0 c7 c6 c5 c4 c3 c2 c1 c0
+
+        punpckhdq   xmm4,                       xmm2                // f7 f6 f4 f4 f3 f2 f1 f0 e7 e6 e5 e4 e3 e2 e1 e0
+        movq        QWORD PTR [rsi],            xmm1
+
+        psrldq      xmm1,                       8
+
+        movq        QWORD PTR [rsi+rax*2],      xmm4
+        psrldq      xmm4,                       8
+
+        movq        QWORD PTR [rsi+rax],        xmm1
+        movq        QWORD PTR [rdi+rax*2],      xmm4
+
+    add rsp, 160
+    pop rsp
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void vp8_loop_filter_simple_horizontal_edge_sse2
+//(
+//    unsigned char *src_ptr,
+//    int  src_pixel_step,
+//    const char *flimit,
+//    const char *limit,
+//    const char *thresh,
+//    int count
+//)
+global sym(vp8_loop_filter_simple_horizontal_edge_sse2)
+sym(vp8_loop_filter_simple_horizontal_edge_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 6
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov         rsi, arg(0)             //src_ptr
+        movsxd      rax, dword ptr arg(1)   //src_pixel_step     ; destination pitch?
+        mov         rdx, arg(2) //flimit     ; get flimit
+        movdqa      xmm3, XMMWORD PTR [rdx]
+        mov         rdx, arg(3) //limit
+        movdqa      xmm7, XMMWORD PTR [rdx]
+
+        paddb       xmm3, xmm3              // flimit*2 (less than 255)
+        paddb       xmm3, xmm7              // flimit * 2 + limit (less than 255)
+
+        mov         rdi, rsi                // rdi points to row +1 for indirect addressing
+        add         rdi, rax
+        neg         rax
+
+        // calculate mask
+        movdqu      xmm1, [rsi+2*rax]       // p1
+        movdqu      xmm0, [rdi]             // q1
+        movdqa      xmm2, xmm1
+        movdqa      xmm7, xmm0
+        movdqa      xmm4, xmm0
+        psubusb     xmm0, xmm1              // q1-=p1
+        psubusb     xmm1, xmm4              // p1-=q1
+        por         xmm1, xmm0              // abs(p1-q1)
+        pand        xmm1, [GLOBAL (tfe)]      // set lsb of each byte to zero
+        psrlw       xmm1, 1                 // abs(p1-q1)/2
+
+        movdqu      xmm5, [rsi+rax]         // p0
+        movdqu      xmm4, [rsi]             // q0
+        movdqa      xmm0, xmm4              // q0
+        movdqa      xmm6, xmm5              // p0
+        psubusb     xmm5, xmm4              // p0-=q0
+        psubusb     xmm4, xmm6              // q0-=p0
+        por         xmm5, xmm4              // abs(p0 - q0)
+        paddusb     xmm5, xmm5              // abs(p0-q0)*2
+        paddusb     xmm5, xmm1              // abs (p0 - q0) *2 + abs(p1-q1)/2
+
+        psubusb     xmm5, xmm3              // abs(p0 - q0) *2 + abs(p1-q1)/2  > flimit * 2 + limit
+        pxor        xmm3, xmm3
+        pcmpeqb     xmm5, xmm3
+
+        // start work on filters
+        pxor        xmm2, [GLOBAL (t80)]      // p1 offset to convert to signed values
+        pxor        xmm7, [GLOBAL (t80)]      // q1 offset to convert to signed values
+        psubsb      xmm2, xmm7              // p1 - q1
+
+        pxor        xmm6, [GLOBAL (t80)]      // offset to convert to signed values
+        pxor        xmm0, [GLOBAL (t80)]      // offset to convert to signed values
+        movdqa      xmm3, xmm0              // q0
+        psubsb      xmm0, xmm6              // q0 - p0
+        paddsb      xmm2, xmm0              // p1 - q1 + 1 * (q0 - p0)
+        paddsb      xmm2, xmm0              // p1 - q1 + 2 * (q0 - p0)
+        paddsb      xmm2, xmm0              // p1 - q1 + 3 * (q0 - p0)
+        pand        xmm5, xmm2              // mask filter values we don't care about
+
+        // do + 4 side
+        paddsb      xmm5, [GLOBAL (t4)]       // 3* (q0 - p0) + (p1 - q1) + 4
+
+        movdqa      xmm0, xmm5              // get a copy of filters
+        psllw       xmm0, 8                 // shift left 8
+        psraw       xmm0, 3                 // arithmetic shift right 11
+        psrlw       xmm0, 8
+        movdqa      xmm1, xmm5              // get a copy of filters
+        psraw       xmm1, 11                // arithmetic shift right 11
+        psllw       xmm1, 8                 // shift left 8 to put it back
+
+        por         xmm0, xmm1              // put the two together to get result
+
+        psubsb      xmm3, xmm0              // q0-= q0 add
+        pxor        xmm3, [GLOBAL (t80)]      // unoffset
+        movdqu      [rsi], xmm3             // write back
+
+        // now do +3 side
+        psubsb      xmm5, [GLOBAL (t1s)]      // +3 instead of +4
+
+        movdqa      xmm0, xmm5              // get a copy of filters
+        psllw       xmm0, 8                 // shift left 8
+        psraw       xmm0, 3                 // arithmetic shift right 11
+        psrlw       xmm0, 8
+        psraw       xmm5, 11                // arithmetic shift right 11
+        psllw       xmm5, 8                 // shift left 8 to put it back
+        por         xmm0, xmm5              // put the two together to get result
+
+
+        paddsb      xmm6, xmm0              // p0+= p0 add
+        pxor        xmm6, [GLOBAL (t80)]      // unoffset
+        movdqu      [rsi+rax], xmm6         // write back
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void vp8_loop_filter_simple_vertical_edge_sse2
+//(
+//    unsigned char *src_ptr,
+//    int  src_pixel_step,
+//    const char *flimit,
+//    const char *limit,
+//    const char *thresh,
+//    int count
+//)
+global sym(vp8_loop_filter_simple_vertical_edge_sse2)
+sym(vp8_loop_filter_simple_vertical_edge_sse2):
+    push        rbp         // save old base pointer value.
+    mov         rbp, rsp    // set new base pointer value.
+    SHADOW_ARGS_TO_STACK 6
+    GET_GOT     rbx         // save callee-saved reg
+    push        rsi
+    push        rdi
+    // end prolog
+
+    ALIGN_STACK 16, rax
+    sub         rsp, 32                         // reserve 32 bytes
+#   define t0  [rsp + 0]    //__declspec(align(16)) char t0[16];
+#   define t1  [rsp + 16]   //__declspec(align(16)) char t1[16];
+
+        mov         rsi, arg(0) //src_ptr
+        movsxd      rax, dword ptr arg(1) //src_pixel_step     ; destination pitch?
+
+        lea         rsi,        [rsi - 2 ]
+        lea         rdi,        [rsi + rax]
+        lea         rdx,        [rsi + rax*4]
+        lea         rcx,        [rdx + rax]
+
+        movdqu      xmm0,       [rsi]                   // (high 96 bits unused) 03 02 01 00
+        movdqu      xmm1,       [rdx]                   // (high 96 bits unused) 43 42 41 40
+        movdqu      xmm2,       [rdi]                   // 13 12 11 10
+        movdqu      xmm3,       [rcx]                   // 53 52 51 50
+        punpckldq   xmm0,       xmm1                    // (high 64 bits unused) 43 42 41 40 03 02 01 00
+        punpckldq   xmm2,       xmm3                    // 53 52 51 50 13 12 11 10
+
+        movdqu      xmm4,       [rsi + rax*2]           // 23 22 21 20
+        movdqu      xmm5,       [rdx + rax*2]           // 63 62 61 60
+        movdqu      xmm6,       [rdi + rax*2]           // 33 32 31 30
+        movdqu      xmm7,       [rcx + rax*2]           // 73 72 71 70
+        punpckldq   xmm4,       xmm5                    // 63 62 61 60 23 22 21 20
+        punpckldq   xmm6,       xmm7                    // 73 72 71 70 33 32 31 30
+
+        punpcklbw   xmm0,       xmm2                    // 53 43 52 42 51 41 50 40 13 03 12 02 11 01 10 00
+        punpcklbw   xmm4,       xmm6                    // 73 63 72 62 71 61 70 60 33 23 32 22 31 21 30 20
+
+        movdqa      xmm1,       xmm0
+        punpcklwd   xmm0,       xmm4                    // 33 23 13 03 32 22 12 02 31 21 11 01 30 20 10 00
+        punpckhwd   xmm1,       xmm4                    // 73 63 53 43 72 62 52 42 71 61 51 41 70 60 50 40
+
+        movdqa      xmm2,       xmm0
+        punpckldq   xmm0,       xmm1                    // 71 61 51 41 31 21 11 01 70 60 50 40 30 20 10 00
+        punpckhdq   xmm2,       xmm1                    // 73 63 53 43 33 23 13 03 72 62 52 42 32 22 12 02
+
+        movdqa      t0,         xmm0                    // save to t0
+        movdqa      t1,         xmm2                    // save to t1
+
+        lea         rsi,        [rsi + rax*8]
+        lea         rdi,        [rsi + rax]
+        lea         rdx,        [rsi + rax*4]
+        lea         rcx,        [rdx + rax]
+
+        movdqu      xmm4,       [rsi]                   // 83 82 81 80
+        movdqu      xmm1,       [rdx]                   // c3 c2 c1 c0
+        movdqu      xmm6,       [rdi]                   // 93 92 91 90
+        movdqu      xmm3,       [rcx]                   // d3 d2 d1 d0
+        punpckldq   xmm4,       xmm1                    // c3 c2 c1 c0 83 82 81 80
+        punpckldq   xmm6,       xmm3                    // d3 d2 d1 d0 93 92 91 90
+
+        movdqu      xmm0,       [rsi + rax*2]           // a3 a2 a1 a0
+        movdqu      xmm5,       [rdx + rax*2]           // e3 e2 e1 e0
+        movdqu      xmm2,       [rdi + rax*2]           // b3 b2 b1 b0
+        movdqu      xmm7,       [rcx + rax*2]           // f3 f2 f1 f0
+        punpckldq   xmm0,       xmm5                    // e3 e2 e1 e0 a3 a2 a1 a0
+        punpckldq   xmm2,       xmm7                    // f3 f2 f1 f0 b3 b2 b1 b0
+
+        punpcklbw   xmm4,       xmm6                    // d3 c3 d2 c2 d1 c1 d0 c0 93 83 92 82 91 81 90 80
+        punpcklbw   xmm0,       xmm2                    // f3 e3 f2 e2 f1 e1 f0 e0 b3 a3 b2 a2 b1 a1 b0 a0
+
+        movdqa      xmm1,       xmm4
+        punpcklwd   xmm4,       xmm0                    // b3 a3 93 83 b2 a2 92 82 b1 a1 91 81 b0 a0 90 80
+        punpckhwd   xmm1,       xmm0                    // f3 e3 d3 c3 f2 e2 d2 c2 f1 e1 d1 c1 f0 e0 d0 c0
+
+        movdqa      xmm6,       xmm4
+        punpckldq   xmm4,       xmm1                    // f1 e1 d1 c1 b1 a1 91 81 f0 e0 d0 c0 b0 a0 90 80
+        punpckhdq   xmm6,       xmm1                    // f3 e3 d3 c3 b3 a3 93 83 f2 e2 d2 c2 b2 a2 92 82
+
+        movdqa      xmm0,       t0                      // 71 61 51 41 31 21 11 01 70 60 50 40 30 20 10 00
+        movdqa      xmm2,       t1                      // 73 63 53 43 33 23 13 03 72 62 52 42 32 22 12 02
+        movdqa      xmm1,       xmm0
+        movdqa      xmm3,       xmm2
+
+        punpcklqdq  xmm0,       xmm4                    // p1  f0 e0 d0 c0 b0 a0 90 80 70 60 50 40 30 20 10 00
+        punpckhqdq  xmm1,       xmm4                    // p0  f1 e1 d1 c1 b1 a1 91 81 71 61 51 41 31 21 11 01
+        punpcklqdq  xmm2,       xmm6                    // q0  f2 e2 d2 c2 b2 a2 92 82 72 62 52 42 32 22 12 02
+        punpckhqdq  xmm3,       xmm6                    // q1  f3 e3 d3 c3 b3 a3 93 83 73 63 53 43 33 23 13 03
+
+        // calculate mask
+        movdqa      xmm6,       xmm0                            // p1
+        movdqa      xmm7,       xmm3                            // q1
+        psubusb     xmm7,       xmm0                            // q1-=p1
+        psubusb     xmm6,       xmm3                            // p1-=q1
+        por         xmm6,       xmm7                            // abs(p1-q1)
+        pand        xmm6,       [GLOBAL (tfe)]                    // set lsb of each byte to zero
+        psrlw       xmm6,       1                               // abs(p1-q1)/2
+
+        movdqa      xmm5,       xmm1                            // p0
+        movdqa      xmm4,       xmm2                            // q0
+        psubusb     xmm5,       xmm2                            // p0-=q0
+        psubusb     xmm4,       xmm1                            // q0-=p0
+        por         xmm5,       xmm4                            // abs(p0 - q0)
+        paddusb     xmm5,       xmm5                            // abs(p0-q0)*2
+        paddusb     xmm5,       xmm6                            // abs (p0 - q0) *2 + abs(p1-q1)/2
+
+        mov         rdx,        arg(2)                          //flimit
+        movdqa      xmm7, XMMWORD PTR [rdx]
+        mov         rdx,        arg(3)                          // get limit
+        movdqa      xmm6, XMMWORD PTR [rdx]
+        paddb       xmm7,        xmm7                           // flimit*2 (less than 255)
+        paddb       xmm7,        xmm6                           // flimit * 2 + limit (less than 255)
+
+        psubusb     xmm5,        xmm7                           // abs(p0 - q0) *2 + abs(p1-q1)/2  > flimit * 2 + limit
+        pxor        xmm7,        xmm7
+        pcmpeqb     xmm5,        xmm7                           // mm5 = mask
+
+        // start work on filters
+        movdqa        t0,        xmm0
+        movdqa        t1,        xmm3
+
+        pxor        xmm0,        [GLOBAL (t80)]                   // p1 offset to convert to signed values
+        pxor        xmm3,        [GLOBAL (t80)]                   // q1 offset to convert to signed values
+
+        psubsb      xmm0,        xmm3                           // p1 - q1
+        movdqa      xmm6,        xmm1                           // p0
+
+        movdqa      xmm7,        xmm2                           // q0
+        pxor        xmm6,        [GLOBAL (t80)]                   // offset to convert to signed values
+
+        pxor        xmm7,        [GLOBAL (t80)]                   // offset to convert to signed values
+        movdqa      xmm3,        xmm7                           // offseted ; q0
+
+        psubsb      xmm7,        xmm6                           // q0 - p0
+        paddsb      xmm0,        xmm7                           // p1 - q1 + 1 * (q0 - p0)
+
+        paddsb      xmm0,        xmm7                           // p1 - q1 + 2 * (q0 - p0)
+        paddsb      xmm0,        xmm7                           // p1 - q1 + 3 * (q0 - p0)
+
+        pand        xmm5,        xmm0                           // mask filter values we don't care about
+
+
+        paddsb      xmm5,        [GLOBAL (t4)]                    //  3* (q0 - p0) + (p1 - q1) + 4
+
+        movdqa      xmm0,        xmm5                           // get a copy of filters
+        psllw       xmm0,        8                              // shift left 8
+
+        psraw       xmm0,        3                              // arithmetic shift right 11
+        psrlw       xmm0,        8
+
+        movdqa      xmm7,        xmm5                           // get a copy of filters
+        psraw       xmm7,        11                             // arithmetic shift right 11
+
+        psllw       xmm7,        8                              // shift left 8 to put it back
+        por         xmm0,        xmm7                           // put the two together to get result
+
+        psubsb      xmm3,        xmm0                           // q0-= q0sz add
+        pxor        xmm3,        [GLOBAL (t80)]                   // unoffset   q0
+
+        // now do +3 side
+        psubsb      xmm5,        [GLOBAL (t1s)]                   // +3 instead of +4
+        movdqa      xmm0,        xmm5                           // get a copy of filters
+
+        psllw       xmm0,        8                              // shift left 8
+        psraw       xmm0,        3                              // arithmetic shift right 11
+
+        psrlw       xmm0,        8
+        psraw       xmm5,        11                             // arithmetic shift right 11
+
+        psllw       xmm5,        8                              // shift left 8 to put it back
+        por         xmm0,        xmm5                           // put the two together to get result
+
+        paddsb      xmm6,        xmm0                           // p0+= p0 add
+        pxor        xmm6,        [GLOBAL (t80)]                   // unoffset   p0
+
+        movdqa      xmm0,        t0                             // p1
+        movdqa      xmm4,        t1                             // q1
+
+        // transpose back to write out
+        // p1  f0 e0 d0 c0 b0 a0 90 80 70 60 50 40 30 20 10 00
+        // p0  f1 e1 d1 c1 b1 a1 91 81 71 61 51 41 31 21 11 01
+        // q0  f2 e2 d2 c2 b2 a2 92 82 72 62 52 42 32 22 12 02
+        // q1  f3 e3 d3 c3 b3 a3 93 83 73 63 53 43 33 23 13 03
+        movdqa      xmm1,       xmm0
+        punpcklbw   xmm0,       xmm6                               // 71 70 61 60 51 50 41 40 31 30 21 20 11 10 01 00
+        punpckhbw   xmm1,       xmm6                               // f1 f0 e1 e0 d1 d0 c1 c0 b1 b0 a1 a0 91 90 81 80
+
+        movdqa      xmm5,       xmm3
+        punpcklbw   xmm3,       xmm4                               // 73 72 63 62 53 52 43 42 33 32 23 22 13 12 03 02
+        punpckhbw   xmm5,       xmm4                               // f3 f2 e3 e2 d3 d2 c3 c2 b3 b2 a3 a2 93 92 83 82
+
+        movdqa      xmm2,       xmm0
+        punpcklwd   xmm0,       xmm3                               // 33 32 31 30 23 22 21 20 13 12 11 10 03 02 01 00
+        punpckhwd   xmm2,       xmm3                               // 73 72 71 70 63 62 61 60 53 52 51 50 43 42 41 40
+
+        movdqa      xmm3,       xmm1
+        punpcklwd   xmm1,       xmm5                               // b3 b2 b1 b0 a3 a2 a1 a0 93 92 91 90 83 82 81 80
+        punpckhwd   xmm3,       xmm5                               // f3 f2 f1 f0 e3 e2 e1 e0 d3 d2 d1 d0 c3 c2 c1 c0
+
+        // write out order: xmm0 xmm2 xmm1 xmm3
+        lea         rdx,        [rsi + rax*4]
+
+        movd        [rsi],      xmm1                               // write the second 8-line result
+        psrldq      xmm1,       4
+        movd        [rdi],      xmm1
+        psrldq      xmm1,       4
+        movd        [rsi + rax*2], xmm1
+        psrldq      xmm1,       4
+        movd        [rdi + rax*2], xmm1
+
+        movd        [rdx],      xmm3
+        psrldq      xmm3,       4
+        movd        [rcx],      xmm3
+        psrldq      xmm3,       4
+        movd        [rdx + rax*2], xmm3
+        psrldq      xmm3,       4
+        movd        [rcx + rax*2], xmm3
+
+        neg         rax
+        lea         rsi,        [rsi + rax*8]
+        neg         rax
+        lea         rdi,        [rsi + rax]
+        lea         rdx,        [rsi + rax*4]
+        lea         rcx,        [rdx + rax]
+
+        movd        [rsi],      xmm0                                // write the first 8-line result
+        psrldq      xmm0,       4
+        movd        [rdi],      xmm0
+        psrldq      xmm0,       4
+        movd        [rsi + rax*2], xmm0
+        psrldq      xmm0,       4
+        movd        [rdi + rax*2], xmm0
+
+        movd        [rdx],      xmm2
+        psrldq      xmm2,       4
+        movd        [rcx],      xmm2
+        psrldq      xmm2,       4
+        movd        [rdx + rax*2], xmm2
+        psrldq      xmm2,       4
+        movd        [rcx + rax*2], xmm2
+
+    add rsp, 32
+    pop rsp
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+SECTION_RODATA
+align 16
+tfe:
+    .fill 16, 1, 0xfe
+align 16
+t80:
+    .fill 16, 1, 0x80
+align 16
+t1s:
+    .fill 16, 1, 0x01
+align 16
+t3:
+    .fill 16, 1, 0x03
+align 16
+t4:
+    .fill 16, 1, 0x04
+align 16
+ones:
+    .fill 8, 2, 0x0001
+align 16
+s27:
+    .fill 8, 2, 0x1b00
+align 16
+s18:
+    .fill 8, 2, 0x1200
+align 16
+s9:
+    .fill 8, 2, 0x0900
+align 16
+s63:
+    .fill 8, 2, 0x003f
diff --git a/vp8/common/x86/loopfilter_sse2.asm b/vp8/common/x86/loopfilter_sse2.asm
deleted file mode 100644
index 5275dfa..0000000
--- a/vp8/common/x86/loopfilter_sse2.asm
+++ /dev/null
@@ -1,1978 +0,0 @@
-;
-;  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
-;
-;  Use of this source code is governed by a BSD-style license and patent
-;  grant that can be found in the LICENSE file in the root of the source
-;  tree. All contributing project authors may be found in the AUTHORS
-;  file in the root of the source tree.
-;
-
-
-%include "vpx_ports/x86_abi_support.asm"
-
-
-;void vp8_loop_filter_horizontal_edge_sse2
-;(
-;    unsigned char *src_ptr,
-;    int            src_pixel_step,
-;    const char    *flimit,
-;    const char    *limit,
-;    const char    *thresh,
-;    int            count
-;)
-global sym(vp8_loop_filter_horizontal_edge_sse2)
-sym(vp8_loop_filter_horizontal_edge_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 6
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-    ALIGN_STACK 16, rax
-    sub         rsp, 32                         ; reserve 32 bytes
-    %define t0 [rsp + 0]    ;__declspec(align(16)) char t0[16];
-    %define t1 [rsp + 16]   ;__declspec(align(16)) char t1[16];
-
-        mov         rsi, arg(0) ;src_ptr
-        movsxd      rax, dword ptr arg(1) ;src_pixel_step     ; destination pitch?
-
-        mov         rdx,    arg(3) ;limit
-        movdqa      xmm7,   XMMWORD PTR [rdx]
-        mov         rdi,    rsi           ; rdi points to row +1 for indirect addressing
-        add         rdi,    rax
-
-        ; calculate breakout conditions
-        movdqu      xmm2,   [rdi+2*rax]      ; q3
-        movdqu      xmm1,   [rsi+2*rax]      ; q2
-        movdqa      xmm6,   xmm1              ; q2
-        psubusb     xmm1,   xmm2              ; q2-=q3
-        psubusb     xmm2,   xmm6              ; q3-=q2
-        por         xmm1,   xmm2              ; abs(q3-q2)
-        psubusb     xmm1,   xmm7              ;
-
-
-        movdqu      xmm4,   [rsi+rax]         ; q1
-        movdqa      xmm3,   xmm4              ; q1
-        psubusb     xmm4,   xmm6              ; q1-=q2
-        psubusb     xmm6,   xmm3              ; q2-=q1
-        por         xmm4,   xmm6              ; abs(q2-q1)
-
-        psubusb     xmm4,   xmm7
-        por         xmm1,   xmm4
-
-        movdqu      xmm4,   [rsi]             ; q0
-        movdqa      xmm0,   xmm4              ; q0
-        psubusb     xmm4,   xmm3              ; q0-=q1
-        psubusb     xmm3,   xmm0              ; q1-=q0
-        por         xmm4,   xmm3              ; abs(q0-q1)
-        movdqa        t0,       xmm4                  ; save to t0
-        psubusb     xmm4,   xmm7
-        por         xmm1,   xmm4
-
-        neg         rax                   ; negate pitch to deal with above border
-        movdqu      xmm2,   [rsi+4*rax]      ; p3
-        movdqu      xmm4,   [rdi+4*rax]      ; p2
-        movdqa      xmm5,   xmm4              ; p2
-        psubusb     xmm4,   xmm2              ; p2-=p3
-        psubusb     xmm2,   xmm5              ; p3-=p2
-        por         xmm4,   xmm2              ; abs(p3 - p2)
-        psubusb     xmm4,   xmm7
-        por         xmm1,   xmm4
-
-
-        movdqu      xmm4,   [rsi+2*rax]      ; p1
-        movdqa      xmm3,   xmm4              ; p1
-        psubusb     xmm4,   xmm5              ; p1-=p2
-        psubusb     xmm5,   xmm3              ; p2-=p1
-        por         xmm4,   xmm5              ; abs(p2 - p1)
-        psubusb     xmm4,   xmm7
-        por         xmm1,   xmm4
-
-        movdqa      xmm2,   xmm3              ; p1
-
-        movdqu      xmm4,   [rsi+rax]         ; p0
-        movdqa      xmm5,   xmm4              ; p0
-        psubusb     xmm4,   xmm3              ; p0-=p1
-        psubusb     xmm3,   xmm5              ; p1-=p0
-        por         xmm4,   xmm3              ; abs(p1 - p0)
-        movdqa      t1,     xmm4                  ; save to t1
-        psubusb     xmm4,   xmm7
-        por         xmm1,    xmm4
-
-        movdqu      xmm3,   [rdi]             ; q1
-        movdqa      xmm4,   xmm3              ; q1
-        psubusb     xmm3,   xmm2              ; q1-=p1
-        psubusb     xmm2,   xmm4              ; p1-=q1
-        por         xmm2,   xmm3              ; abs(p1-q1)
-        pand        xmm2,   [tfe GLOBAL]      ; set lsb of each byte to zero
-        psrlw       xmm2,   1                 ; abs(p1-q1)/2
-
-        movdqa      xmm6,   xmm5              ; p0
-        movdqu      xmm3,   [rsi]             ; q0
-        psubusb     xmm5,   xmm3              ; p0-=q0
-        psubusb     xmm3,   xmm6              ; q0-=p0
-        por         xmm5,   xmm3              ; abs(p0 - q0)
-        paddusb     xmm5,   xmm5              ; abs(p0-q0)*2
-        paddusb     xmm5,   xmm2              ; abs (p0 - q0) *2 + abs(p1-q1)/2
-
-        mov         rdx,    arg(2) ;flimit            ; get flimit
-        movdqa      xmm2,   [rdx]             ;
-
-        paddb       xmm2,   xmm2              ; flimit*2 (less than 255)
-        paddb       xmm7,   xmm2              ; flimit * 2 + limit (less than 255)
-
-        psubusb     xmm5,    xmm7             ; abs (p0 - q0) *2 + abs(p1-q1)/2  > flimit * 2 + limit
-        por         xmm1,    xmm5
-        pxor        xmm5,    xmm5
-        pcmpeqb     xmm1,    xmm5             ; mask mm1
-
-
-        ; calculate high edge variance
-        mov         rdx,    arg(4) ;thresh            ; get thresh
-        movdqa      xmm7,   [rdx]             ;
-        movdqa      xmm4,   t0                ; get abs (q1 - q0)
-        psubusb     xmm4,   xmm7
-        movdqa      xmm3,   t1                ; get abs (p1 - p0)
-        psubusb     xmm3,   xmm7
-        paddb       xmm4,   xmm3              ; abs(q1 - q0) > thresh || abs(p1 - p0) > thresh
-        pcmpeqb     xmm4,        xmm5
-        pcmpeqb     xmm5,        xmm5
-        pxor        xmm4,        xmm5
-
-
-        ; start work on filters
-        movdqu      xmm2, [rsi+2*rax]     ; p1
-        movdqu      xmm7, [rdi]           ; q1
-        pxor        xmm2, [t80 GLOBAL]    ; p1 offset to convert to signed values
-        pxor        xmm7, [t80 GLOBAL]    ; q1 offset to convert to signed values
-        psubsb      xmm2, xmm7            ; p1 - q1
-        pand        xmm2, xmm4            ; high var mask (hvm)(p1 - q1)
-        pxor        xmm6, [t80 GLOBAL]    ; offset to convert to signed values
-        pxor        xmm0, [t80 GLOBAL]    ; offset to convert to signed values
-        movdqa      xmm3, xmm0            ; q0
-        psubsb      xmm0, xmm6            ; q0 - p0
-        paddsb      xmm2, xmm0            ; 1 * (q0 - p0) + hvm(p1 - q1)
-        paddsb      xmm2, xmm0            ; 2 * (q0 - p0) + hvm(p1 - q1)
-        paddsb      xmm2, xmm0            ; 3 * (q0 - p0) + hvm(p1 - q1)
-        pand        xmm1, xmm2            ; mask filter values we don't care about
-        movdqa      xmm2, xmm1
-        paddsb      xmm1, [t4 GLOBAL]         ; 3* (q0 - p0) + hvm(p1 - q1) + 4
-        paddsb      xmm2, [t3 GLOBAL]         ; 3* (q0 - p0) + hvm(p1 - q1) + 3
-
-        pxor        xmm0, xmm0           ;
-        pxor        xmm5, xmm5
-        punpcklbw   xmm0, xmm2          ;
-        punpckhbw   xmm5, xmm2          ;
-        psraw       xmm0, 11                ;
-        psraw       xmm5, 11
-        packsswb    xmm0, xmm5
-        movdqa      xmm2, xmm0          ;  (3* (q0 - p0) + hvm(p1 - q1) + 3) >> 3;
-
-        pxor        xmm0, xmm0            ; 0
-        movdqa      xmm5, xmm1            ; abcdefgh
-        punpcklbw   xmm0, xmm1            ; e0f0g0h0
-        psraw       xmm0, 11                  ; sign extended shift right by 3
-        pxor        xmm1, xmm1            ; 0
-        punpckhbw   xmm1, xmm5            ; a0b0c0d0
-        psraw       xmm1, 11                  ; sign extended shift right by 3
-        movdqa      xmm5, xmm0              ; save results
-
-        packsswb    xmm0, xmm1            ; (3* (q0 - p0) + hvm(p1 - q1) + 4) >>3
-        paddsw      xmm5, [ones GLOBAL]
-        paddsw      xmm1, [ones GLOBAL]
-        psraw       xmm5, 1               ; partial shifted one more time for 2nd tap
-        psraw       xmm1, 1               ; partial shifted one more time for 2nd tap
-        packsswb    xmm5, xmm1            ; (3* (q0 - p0) + hvm(p1 - q1) + 4) >>4
-        pandn       xmm4, xmm5            ; high edge variance additive
-
-        paddsb      xmm6, xmm2            ; p0+= p0 add
-        pxor        xmm6, [t80 GLOBAL]    ; unoffset
-        movdqu      [rsi+rax], xmm6       ; write back
-
-        movdqu      xmm6, [rsi+2*rax]     ; p1
-        pxor        xmm6, [t80 GLOBAL]    ; reoffset
-        paddsb      xmm6, xmm4            ; p1+= p1 add
-        pxor        xmm6, [t80 GLOBAL]    ; unoffset
-        movdqu      [rsi+2*rax], xmm6     ; write back
-
-        psubsb      xmm3, xmm0            ; q0-= q0 add
-        pxor        xmm3, [t80 GLOBAL]    ; unoffset
-        movdqu      [rsi], xmm3           ; write back
-
-        psubsb      xmm7, xmm4            ; q1-= q1 add
-        pxor        xmm7, [t80 GLOBAL]    ; unoffset
-        movdqu      [rdi], xmm7           ; write back
-
-    add rsp, 32
-    pop rsp
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void vp8_loop_filter_vertical_edge_sse2
-;(
-;    unsigned char *src_ptr,
-;    int            src_pixel_step,
-;    const char    *flimit,
-;    const char    *limit,
-;    const char    *thresh,
-;    int            count
-;)
-global sym(vp8_loop_filter_vertical_edge_sse2)
-sym(vp8_loop_filter_vertical_edge_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 6
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-    ALIGN_STACK 16, rax
-    sub          rsp, 96      ; reserve 96 bytes
-    %define t0   [rsp + 0]    ;__declspec(align(16)) char t0[16];
-    %define t1   [rsp + 16]   ;__declspec(align(16)) char t1[16];
-    %define srct [rsp + 32]   ;__declspec(align(16)) char srct[64];
-
-        mov         rsi,        arg(0) ;src_ptr
-        movsxd      rax,        dword ptr arg(1) ;src_pixel_step     ; destination pitch?
-
-        lea         rsi,        [rsi + rax*4 - 4]
-        mov         rdi,        rsi           ; rdi points to row +1 for indirect addressing
-
-        add         rdi,        rax
-        lea         rcx,        [rdi + rax *8]
-
-        ;transpose
-        movq        xmm7,       QWORD PTR [rsi+2*rax]                 ; 67 66 65 64 63 62 61 60
-        movq        xmm6,       QWORD PTR [rdi+2*rax]                 ; 77 76 75 74 73 72 71 70
-
-        punpcklbw   xmm7,       xmm6                        ; 77 67 76 66 75 65 74 64 73 63 72 62 71 61 70 60
-        movq        xmm5,       QWORD PTR [rsi]                       ; 47 46 45 44 43 42 41 40
-
-        movq        xmm4,       QWORD PTR [rsi+rax]                   ; 57 56 55 54 53 52 51 50
-        punpcklbw   xmm5,       xmm4                        ; 57 47 56 46 55 45 54 44 53 43 52 42 51 41 50 40
-
-        movdqa      xmm3,       xmm5                        ; 57 47 56 46 55 45 54 44 53 43 52 42 51 41 50 40
-        punpckhwd   xmm5,       xmm7                        ; 77 67 57 47 76 66 56 46 75 65 55 45 74 64 54 44
-
-        lea         rsi,        [rsi+ rax*8]
-
-        punpcklwd   xmm3,       xmm7                        ; 73 63 53 43 72 62 52 42 71 61 51 41 70 60 50 40
-        movq        xmm6,       QWORD PTR [rsi + 2*rax]               ; e7 e6 e5 e4 e3 e2 e1 e0
-
-        movq        xmm7,       QWORD PTR [rcx + 2*rax]               ; f7 f6 f5 f4 f3 f2 f1 f0
-        punpcklbw   xmm6,       xmm7                        ; f7 e7 f6 e6 f5 e5 f4 e4 f3 e3 f2 e2 f1 e1 f0 e0
-
-        movq        xmm4,       QWORD PTR [rsi]                       ; c7 c6 c5 c4 c3 c2 c1 c0
-        movq        xmm7,       QWORD PTR [rsi + rax]                 ; d7 d6 d5 d4 d3 d2 d1 d0
-
-        punpcklbw   xmm4,       xmm7                        ; d7 c7 d6 c6 d5 c5 d4 c4 d3 c3 d2 c2 d1 c1 d0 c0
-        movdqa      xmm7,       xmm4                        ; d7 c7 d6 c6 d5 c5 d4 c4 d3 c3 d2 c2 d1 c1 d0 c0
-
-        punpckhwd   xmm7,       xmm6                        ; f7 e7 d7 c7 f6 e6 d6 c6 f5 e5 d5 c5 f4 e4 d4 c4
-        punpcklwd   xmm4,       xmm6                        ; f3 e3 d3 c3 f2 e2 d2 c2 f1 e1 d1 c1 f0 e0 d0 c0
-
-        ; xmm3 xmm4, xmm5 xmm7   in use
-        neg         rax
-
-        lea         rsi,        [rsi+rax*8]
-        movq        xmm6,       QWORD PTR [rsi+rax*2]                 ; 27 26 25 24 23 22 21 20
-
-        movq        xmm1,       QWORD PTR [rsi+rax  ]                 ; 37 36 35 34 33 32 31 30
-        punpcklbw   xmm6,       xmm1                        ; 37 27 36 26 35 25 34 24 33 23 32 22 31 21 30 20
-
-        movq        xmm2,       QWORD PTR [rsi+rax*4]                 ; 07 06 05 04 03 02 01 00
-        movq        xmm1,       QWORD PTR [rdi+rax*4]                 ; 17 16 15 14 13 12 11 10
-
-        punpcklbw   xmm2,       xmm1                        ; 17 07 16 06 15 05 14 04 13 03 12 02 11 01 10 00
-        movdqa      xmm0,       xmm2
-
-        punpckhwd   xmm2,       xmm6                        ; 37 27 17 07 36 26 16 06 35 25 15 05 34 24 14 04
-        punpcklwd   xmm0,       xmm6                        ; 33 23 13 03 32 22 12 02 31 21 11 01 30 20 10 00
-
-        movdqa      xmm6,       xmm2
-        punpckldq   xmm2,       xmm5                        ; 75 65 55 45 35 25 15 05 74 64 54 44 34 24 14 04
-
-        punpckhdq   xmm6,       xmm5                        ; 77 67 57 47 37 27 17 07 76 66 56 46 36 26 16 06
-        ;xmm0 xmm2 xmm3 xmm4, xmm6, xmm7
-
-        movdqa      xmm5,       xmm0                        ; 33 23 13 03 32 22 12 02 31 21 11 01 30 20 10 00
-        punpckhdq   xmm5,       xmm3                        ; 73 63 53 43 33 23 13 03 72 62 52 42 32 22 12 02
-
-        punpckldq   xmm0,       xmm3                        ; 71 61 51 41 31 21 11 01 70 60 50 40 30 20 10 00
-        lea         rsi,        [rcx+rax]
-        ; xmm1, xmm3 free
-        movq        xmm1,       QWORD PTR [rsi+rax*2]                 ; a7 a6 a5 a4 a3 a2 a1 a0
-        movq        xmm3,       QWORD PTR [rsi+rax]                   ; b7 b6 b5 b4 b3 b2 b1 b0
-
-        punpcklbw   xmm1,       xmm3                        ;
-        lea         rdx,        srct                        ;
-
-        movdqa      [rdx+16],   xmm1                        ; b7 a7 b6 a6 b5 a5 b4 a4 b3 a3 b2 a2 b1 a1 b0 a0
-        movq        xmm3,       QWORD PTR [rsi+rax*4]                 ; 87 86 85 84 83 82 81 80
-
-        movq        xmm1,       QWORD PTR [rcx+rax*4]
-        punpcklbw   xmm3,       xmm1                        ; 97 87 96 86 95 85 94 84 93 83 92 82 91 81 90 80
-
-        movdqa      [rdx],      xmm3                        ; 97 87 96 86 95 85 94 84 93 83 92 82 91 81 90 80
-
-        punpckhwd   xmm3,       [rdx+16]                    ; b7 a7 97 87 b6 a6 96 86 b5 a5 95 85 b4 a4 94 84
-        movdqa      xmm1,       xmm3                        ; b7 a7 97 87 b6 a6 96 86 b5 a5 95 85 b4 a4 94 84
-
-        punpckhdq   xmm1,       xmm7                        ; f7 e7 d7 c7 b7 a7 97 87 f6 e6 d6 c6 b6 a6 96 86
-        punpckldq   xmm3,       xmm7                        ; f5 e5 d5 c5 b5 a5 95 85 f4 e4 d4 c4 b4 a4 94 84
-
-        movdqa      xmm7,       xmm2                        ; 75 65 55 45 35 25 15 05 74 64 54 44 34 24 14 04
-        punpcklqdq  xmm7,       xmm3                        ; f4 e4 d4 c4 b4 a4 94 84 74 64 54 44 34 24 14 04
-
-        punpckhqdq  xmm2,       xmm3                        ; f5 e5 d5 c5 b5 a5 95 85 75 65 55 45 35 25 15 05
-        movdqa      [rdx+32],   xmm7                        ; save 4s
-
-        movdqa      [rdx+48],   xmm2                        ; save 5s
-        movdqa      xmm7,       xmm6                        ; 77 67 57 47 37 27 17 07 76 66 56 46 36 26 16 06
-
-        punpckhqdq  xmm7,       xmm1                        ; f7 e7 d7 c7 b7 a7 97 87 77 67 57 47 37 27 17 07 = q3
-        punpcklqdq  xmm6,       xmm1                        ; f6 e6 d6 c6 b6 a6 96 86 76 66 56 46 36 26 16 06 = q2
-
-        ; free 1, 3   xmm7-7s xmm6-6s, xmm2-5s
-        movq        xmm1,       QWORD PTR [rdx]                       ; 93 83 92 82 91 81 90 80
-        movq        xmm3,       QWORD PTR [rdx+16]                    ; b3 a3 b2 a2 b1 a1 b0 a0
-
-        punpcklwd   xmm1,       xmm3                        ; b3 a3 93 83 b2 a2 92 82 b1 a1 91 81 b0 a0 90 80
-        movdqa      xmm3,       xmm1                        ; b3 a3 93 83 b2 a2 92 82 b1 a1 91 81 b0 a0 90 80
-
-        punpckhdq   xmm3,       xmm4                        ; f3 e3 d3 c3 b3 a3 93 83 f2 e2 d2 c2 b2 a2 92 82
-        punpckldq   xmm1,       xmm4                        ; f1 e1 d1 c1 b1 a1 91 81 f0 e0 d0 c0 b0 a0 90 80
-
-        movdqa      xmm4,       xmm5                        ; 73 63 53 43 33 23 13 03 72 62 52 42 32 22 12 02
-        punpcklqdq  xmm5,       xmm3                        ; f2 e2 d2 c2 b2 a2 92 82 72 62 52 42 32 22 12 02
-
-        punpckhqdq  xmm4,       xmm3                        ; f3 e3 d3 c3 b3 a3 93 83 73 63 53 43 33 23 13 03
-        movdqa      [rdx],      xmm5                        ; save 2s
-
-        movdqa      [rdx+16],   xmm4                        ; save 3s
-
-        movdqa      xmm3,       xmm6                        ;
-        psubusb     xmm3,       xmm7                        ; q3 - q2
-
-        psubusb     xmm7,       xmm6                        ; q2 - q3
-        por         xmm7,       xmm3                        ; abs(q3-q2)
-
-        movdqa      xmm3,       xmm2                        ; q1
-        psubusb     xmm3,       xmm6                        ; q1 - q2
-
-        psubusb     xmm6,       xmm2                        ; q2 - q1
-        por         xmm6,       xmm3                        ; abs(q2-q1)
-
-
-        movdqa      xmm3,       xmm0                        ; 71 61 51 41 31 21 11 01 70 60 50 40 30 20 10 00
-        punpcklqdq  xmm0,       xmm1                        ; f0 e0 d0 c0 b0 a0 90 80 70 60 50 40 30 20 10 00
-
-        punpckhqdq  xmm3,       xmm1                        ; f1 e1 d1 c1 b1 a1 91 81 71 61 51 41 31 21 11 01
-        movdqa      xmm1,       xmm3
-
-        psubusb     xmm3,       xmm0                        ; p2-p3
-        psubusb     xmm0,       xmm1                        ; p3-p2
-
-        por         xmm0,       xmm3                        ; abs(p3-p2)
-        movdqa      xmm3,       xmm5                        ; f2 e2 d2 c2 b2 a2 92 82 72 62 52 42 32 22 12 02
-
-        psubusb     xmm3,       xmm1                        ; p1-p2
-        psubusb     xmm1,       xmm5                        ; p2-p1
-
-        por         xmm1,       xmm3                        ; abs(p1-p2)
-        mov         rdx,        arg(3) ;limit
-
-        movdqa      xmm3,       [rdx]                       ; limit
-
-        psubusb     xmm7,       xmm3
-        psubusb     xmm0,       xmm3
-
-        psubusb     xmm1,       xmm3
-        psubusb     xmm6,       xmm3
-
-        por         xmm7,       xmm6
-        por         xmm0,       xmm1
-
-        por         xmm0,       xmm7                         ;   abs(q3-q2) > limit || abs(p3-p2) > limit ||abs(p2-p1) > limit || abs(q2-q1) > limit
-
-        movdqa      xmm1,       xmm5                         ; p1
-
-        movdqa      xmm7,       xmm4                        ; xmm4 xmm7 = p0
-
-        psubusb     xmm7,       xmm5                        ; p0 - p1
-        psubusb     xmm5,       xmm4                        ; p1 - p0
-
-        por         xmm5,       xmm7                        ; abs(p1-p0)
-        movdqa        t0,       xmm5                        ; save abs(p1-p0)
-
-        lea         rdx,        srct
-        psubusb     xmm5,       xmm3
-
-        por         xmm0,       xmm5                        ; xmm0=mask
-        movdqa      xmm5,       [rdx+32]                    ; xmm5=q0
-
-        movdqa      xmm7,       [rdx+48]                    ; xmm7=q1
-        movdqa      xmm6,       xmm5                        ; mm6=q0
-
-        movdqa      xmm2,       xmm7                        ; q1
-
-        psubusb     xmm5,       xmm7                        ; q0-q1
-        psubusb     xmm7,       xmm6                        ; q1-q0
-
-        por         xmm7,       xmm5                        ; abs(q1-q0)
-        movdqa        t1,       xmm7                        ; save abs(q1-q0)
-
-        psubusb     xmm7,       xmm3
-        por         xmm0,       xmm7                        ; mask
-
-        movdqa      xmm5,       xmm2                        ; q1
-        psubusb     xmm5,       xmm1                        ; q1-=p1
-        psubusb     xmm1,       xmm2                        ; p1-=q1
-        por         xmm5,       xmm1                        ; abs(p1-q1)
-        pand        xmm5,       [tfe GLOBAL]                ; set lsb of each byte to zero
-        psrlw       xmm5,       1                           ; abs(p1-q1)/2
-
-        mov         rdx,        arg(2) ;flimit                      ;
-        movdqa        xmm2,       [rdx]                       ;flimit  xmm2
-
-        movdqa      xmm1,       xmm4                        ; xmm1=xmm4=p0
-
-        movdqa      xmm7,       xmm6                        ; xmm7=xmm6=q0
-        psubusb     xmm1,       xmm7                        ; p0-q0
-
-        psubusb     xmm7,       xmm4                        ; q0-p0
-        por         xmm1,       xmm7                        ; abs(q0-p0)
-        paddusb     xmm1,       xmm1                        ; abs(q0-p0)*2
-        paddusb     xmm1,       xmm5                        ; abs (p0 - q0) *2 + abs(p1-q1)/2
-
-        paddb       xmm2,       xmm2                        ; flimit*2 (less than 255)
-        paddb       xmm3,       xmm2                        ; flimit * 2 + limit (less than 255)
-
-        psubusb     xmm1,       xmm3                         ; abs (p0 - q0) *2 + abs(p1-q1)/2  > flimit * 2 + limit
-
-        por         xmm1,       xmm0;                       ; mask
-
-        pxor        xmm0,       xmm0
-        pcmpeqb     xmm1,       xmm0
-        ; calculate high edge variance
-        mov         rdx,        arg(4) ;thresh            ; get thresh
-        movdqa      xmm7,       [rdx]
-
-        ;
-        movdqa      xmm4,       t0              ; get abs (q1 - q0)
-        psubusb     xmm4,       xmm7
-
-        movdqa      xmm3,       t1              ; get abs (p1 - p0)
-        psubusb     xmm3,       xmm7
-
-        por         xmm4,       xmm3            ; abs(q1 - q0) > thresh || abs(p1 - p0) > thresh
-        pcmpeqb     xmm4,       xmm0
-
-        pcmpeqb     xmm0,       xmm0
-        pxor        xmm4,       xmm0
-
-        ; start work on filters
-        lea         rdx,        srct
-
-        movdqa      xmm2,       [rdx]           ; p1
-        movdqa      xmm7,       [rdx+48]        ; q1
-
-        movdqa      xmm6,       [rdx+16]        ; p0
-        movdqa      xmm0,       [rdx+32]        ; q0
-
-        pxor        xmm2,       [t80 GLOBAL]    ; p1 offset to convert to signed values
-        pxor        xmm7,       [t80 GLOBAL]    ; q1 offset to convert to signed values
-
-        psubsb      xmm2,       xmm7            ; p1 - q1
-        pand        xmm2,       xmm4            ; high var mask (hvm)(p1 - q1)
-
-        pxor        xmm6,       [t80 GLOBAL]    ; offset to convert to signed values
-        pxor        xmm0,       [t80 GLOBAL]    ; offset to convert to signed values
-
-        movdqa      xmm3,       xmm0            ; q0
-        psubsb      xmm0,       xmm6            ; q0 - p0
-
-        paddsb      xmm2,       xmm0            ; 1 * (q0 - p0) + hvm(p1 - q1)
-        paddsb      xmm2,       xmm0            ; 2 * (q0 - p0) + hvm(p1 - q1)
-
-        paddsb      xmm2,       xmm0            ; 3 * (q0 - p0) + hvm(p1 - q1)
-        pand        xmm1,       xmm2            ; mask filter values we don't care about
-
-        movdqa      xmm2,       xmm1
-        paddsb      xmm1,       [t4 GLOBAL]       ; 3* (q0 - p0) + hvm(p1 - q1) + 4
-
-        paddsb      xmm2,       [t3 GLOBAL]       ; 3* (q0 - p0) + hvm(p1 - q1) + 3
-        pxor        xmm0,       xmm0             ;
-
-        pxor        xmm5,       xmm5
-        punpcklbw   xmm0,       xmm2            ;
-
-        punpckhbw   xmm5,       xmm2            ;
-        psraw       xmm0,       11              ;
-
-        psraw       xmm5,       11
-        packsswb    xmm0,       xmm5
-
-        movdqa      xmm2,       xmm0            ;  (3* (q0 - p0) + hvm(p1 - q1) + 3) >> 3;
-
-        pxor        xmm0,       xmm0              ; 0
-        movdqa      xmm5,       xmm1              ; abcdefgh
-
-        punpcklbw   xmm0,       xmm1              ; e0f0g0h0
-        psraw       xmm0,       11                ; sign extended shift right by 3
-
-        pxor        xmm1,       xmm1              ; 0
-        punpckhbw   xmm1,       xmm5              ; a0b0c0d0
-
-        psraw       xmm1,       11                ; sign extended shift right by 3
-        movdqa      xmm5,       xmm0              ; save results
-
-        packsswb    xmm0,       xmm1              ; (3* (q0 - p0) + hvm(p1 - q1) + 4) >>3
-        paddsw      xmm5,       [ones GLOBAL]
-
-        paddsw      xmm1,       [ones GLOBAL]
-        psraw       xmm5,       1                 ; partial shifted one more time for 2nd tap
-
-        psraw       xmm1,       1                 ; partial shifted one more time for 2nd tap
-        packsswb    xmm5,       xmm1              ; (3* (q0 - p0) + hvm(p1 - q1) + 4) >>4
-
-        pandn       xmm4,       xmm5            ; high edge variance additive
-
-        paddsb      xmm6,       xmm2            ; p0+= p0 add
-        pxor        xmm6,       [t80 GLOBAL]    ; unoffset
-
-        ; mm6=p0                               ;
-        movdqa      xmm1,       [rdx]           ; p1
-        pxor        xmm1,       [t80 GLOBAL]    ; reoffset
-
-        paddsb      xmm1,       xmm4            ; p1+= p1 add
-        pxor        xmm1,       [t80 GLOBAL]    ; unoffset
-        ; mm6 = p0 mm1 = p1
-
-        psubsb      xmm3,       xmm0            ; q0-= q0 add
-        pxor        xmm3,       [t80 GLOBAL]    ; unoffset
-
-        ; mm3 = q0
-        psubsb      xmm7,       xmm4            ; q1-= q1 add
-        pxor        xmm7,       [t80 GLOBAL]    ; unoffset
-        ; mm7 = q1
-
-        ; tranpose and write back
-        ; xmm1 =    f2 e2 d2 c2 b2 a2 92 82 72 62 52 42 32 22 12 02
-        ; xmm6 =    f3 e3 d3 c3 b3 a3 93 83 73 63 53 43 33 23 13 03
-        ; xmm3 =    f4 e4 d4 c4 b4 a4 94 84 74 64 54 44 34 24 14 04
-        ; xmm7 =    f5 e5 d5 c5 b5 a5 95 85 75 65 55 45 35 25 15 05
-        movdqa      xmm2,       xmm1            ; f2 e2 d2 c2 b2 a2 92 82 72 62 52 42 32 22 12 02
-        punpcklbw   xmm2,       xmm6            ; 73 72 63 62 53 52 43 42 33 32 23 22 13 12 03 02
-
-        movdqa      xmm4,       xmm3            ; f4 e4 d4 c4 b4 a4 94 84 74 64 54 44 34 24 14 04
-        punpckhbw   xmm1,       xmm6            ; f3 f2 e3 e2 d3 d2 c3 c2 b3 b2 a3 a2 93 92 83 82
-
-        punpcklbw   xmm4,       xmm7            ; 75 74 65 64 55 54 45 44 35 34 25 24 15 14 05 04
-        punpckhbw   xmm3,       xmm7            ; f5 f4 e5 e4 d5 d4 c5 c4 b5 b4 a5 a4 95 94 85 84
-
-        movdqa      xmm6,       xmm2            ; 73 72 63 62 53 52 43 42 33 32 23 22 13 12 03 02
-        punpcklwd   xmm2,       xmm4            ; 35 34 33 32 25 24 23 22 15 14 13 12 05 04 03 02
-
-        punpckhwd   xmm6,       xmm4            ; 75 74 73 72 65 64 63 62 55 54 53 52 45 44 43 42
-        movdqa      xmm5,       xmm1            ; f3 f2 e3 e2 d3 d2 c3 c2 b3 b2 a3 a2 93 92 83 82
-
-        punpcklwd   xmm1,       xmm3            ; f5 f4 f3 f2 e5 e4 e3 e2 d5 d4 d3 d2 c5 c4 c3 c2
-        punpckhwd   xmm5,       xmm3            ; b5 b4 b3 b2 a5 a4 a3 a2 95 94 93 92 85 84 83 82
-
-        ; xmm2 = 35 34 33 32 25 24 23 22 15 14 13 12 05 04 03 02
-        ; xmm6 = 75 74 73 72 65 64 63 62 55 54 53 52 45 44 43 42
-        ; xmm5 = f3 f2 e3 e2 d3 d2 c3 c2 b3 b2 a3 a2 93 92 83 82
-        ; xmm1 = b5 b4 b3 b2 a5 a4 a3 a2 95 94 93 92 85 84 83 82
-        lea         rsi,           [rsi+rax*8]
-
-        movd        [rsi+rax*4+2], xmm2
-        psrldq      xmm2,   4
-
-        movd        [rdi+rax*4+2], xmm2
-        psrldq      xmm2,   4
-
-        movd        [rsi+rax*2+2], xmm2
-        psrldq      xmm2,   4
-
-        movd        [rdi+rax*2+2], xmm2
-        movd        [rsi+2],       xmm6
-
-        psrldq      xmm6,   4
-        movd        [rdi+2],       xmm6
-
-        psrldq      xmm6,   4
-        neg         rax
-
-        movd        [rdi+rax+2],    xmm6
-        psrldq      xmm6,   4
-
-        movd        [rdi+rax*2+2],  xmm6
-        lea         rsi,       [rsi+rax*8]
-
-        neg         rax
-        ;;;;;;;;;;;;;;;;;;;;/
-        movd        [rsi+rax*4+2], xmm1
-        psrldq      xmm1,   4
-
-        movd        [rcx+rax*4+2], xmm1
-        psrldq      xmm1,   4
-
-        movd        [rsi+rax*2+2], xmm1
-        psrldq      xmm1,   4
-
-        movd        [rcx+rax*2+2], xmm1
-        psrldq      xmm1,   4
-
-        movd        [rsi+2],       xmm5
-        psrldq      xmm5,   4
-
-        movd        [rcx+2],        xmm5
-        psrldq      xmm5,   4
-
-        neg         rax
-        movd        [rcx+rax+2],    xmm5
-
-        psrldq      xmm5,   4
-        movd        [rcx+rax*2+2],  xmm5
-
-    add rsp, 96
-    pop rsp
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void vp8_mbloop_filter_horizontal_edge_sse2
-;(
-;    unsigned char *src_ptr,
-;    int            src_pixel_step,
-;    const char    *flimit,
-;    const char    *limit,
-;    const char    *thresh,
-;    int            count
-;)
-global sym(vp8_mbloop_filter_horizontal_edge_sse2)
-sym(vp8_mbloop_filter_horizontal_edge_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 6
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-    ALIGN_STACK 16, rax
-    sub         rsp, 32                         ; reserve 32 bytes
-    %define t0  [rsp + 0]    ;__declspec(align(16)) char t0[8];
-    %define t1  [rsp + 16]   ;__declspec(align(16)) char t1[8];
-
-        mov         rsi,                    arg(0) ;src_ptr
-        movsxd      rax,                    dword ptr arg(1) ;src_pixel_step     ; destination pitch?
-
-        mov         rdx,                    arg(3) ;limit
-        movdqa      xmm7,                   XMMWORD PTR [rdx]
-
-        mov         rdi,                    rsi           ; rdi points to row +1 for indirect addressing
-        add         rdi,                    rax
-
-        ; calculate breakout conditions
-        movdqa      xmm2,                   XMMWORD PTR [rdi+2*rax]      ; q3
-        movdqa      xmm1,                   XMMWORD PTR [rsi+2*rax]      ; q2
-
-        movdqa      xmm6,                   xmm1              ; q2
-        psubusb     xmm1,                   xmm2              ; q2-=q3
-
-
-        psubusb     xmm2,                   xmm6              ; q3-=q2
-        por         xmm1,                   xmm2              ; abs(q3-q2)
-
-        psubusb     xmm1,                   xmm7
-
-        ; mm1 = abs(q3-q2), mm6 =q2, mm7 = limit
-        movdqa      xmm4,                   XMMWORD PTR [rsi+rax]         ; q1
-        movdqa      xmm3,                   xmm4              ; q1
-
-        psubusb     xmm4,                   xmm6              ; q1-=q2
-        psubusb     xmm6,                   xmm3              ; q2-=q1
-
-        por         xmm4,                   xmm6              ; abs(q2-q1)
-        psubusb     xmm4,                   xmm7
-
-        por         xmm1,                   xmm4
-        ; mm1 = mask,      mm3=q1, mm7 = limit
-
-        movdqa      xmm4,                   XMMWORD PTR [rsi]             ; q0
-        movdqa      xmm0,                   xmm4              ; q0
-
-        psubusb     xmm4,                   xmm3              ; q0-=q1
-        psubusb     xmm3,                   xmm0              ; q1-=q0
-
-        por         xmm4,                   xmm3              ; abs(q0-q1)
-        movdqa      t0,                     xmm4                  ; save to t0
-
-        psubusb     xmm4,                   xmm7
-        por         xmm1,                   xmm4
-
-        ; mm1 = mask, mm0=q0,  mm7 = limit, t0 = abs(q0-q1)
-        neg         rax                   ; negate pitch to deal with above border
-
-        movdqa      xmm2,                   XMMWORD PTR [rsi+4*rax]      ; p3
-        movdqa      xmm4,                   XMMWORD PTR [rdi+4*rax]      ; p2
-
-        movdqa      xmm5,                   xmm4              ; p2
-        psubusb     xmm4,                   xmm2              ; p2-=p3
-
-        psubusb     xmm2,                   xmm5              ; p3-=p2
-        por         xmm4,                   xmm2              ; abs(p3 - p2)
-
-        psubusb     xmm4,                   xmm7
-        por         xmm1,                   xmm4
-
-        ; mm1 = mask, mm0=q0,  mm7 = limit, t0 = abs(q0-q1)
-        movdqa      xmm4,                   XMMWORD PTR [rsi+2*rax]      ; p1
-        movdqa      xmm3,                   xmm4              ; p1
-
-        psubusb     xmm4,                   xmm5              ; p1-=p2
-        psubusb     xmm5,                   xmm3              ; p2-=p1
-
-        por         xmm4,                   xmm5              ; abs(p2 - p1)
-        psubusb     xmm4,                   xmm7
-
-        por         xmm1,                   xmm4
-
-        movdqa      xmm2,                   xmm3              ; p1
-
-        ; mm1 = mask, mm0=q0,  mm7 = limit, t0 = abs(q0-q1)
-        movdqa      xmm4,                   XMMWORD PTR [rsi+rax]         ; p0
-        movdqa      xmm5,                   xmm4              ; p0
-
-        psubusb     xmm4,                   xmm3              ; p0-=p1
-        psubusb     xmm3,                   xmm5              ; p1-=p0
-
-        por         xmm4,                   xmm3              ; abs(p1 - p0)
-        movdqa        t1,                   xmm4                  ; save to t1
-
-        psubusb     xmm4,                   xmm7
-        por         xmm1,                   xmm4
-
-        ; mm1 = mask, mm0=q0,  mm7 = limit, t0 = abs(q0-q1) t1 = abs(p1-p0)
-        ; mm5 = p0
-        movdqa      xmm3,                   XMMWORD PTR [rdi] ; q1
-        movdqa      xmm4,                   xmm3              ; q1
-        psubusb     xmm3,                   xmm2              ; q1-=p1
-        psubusb     xmm2,                   xmm4              ; p1-=q1
-        por         xmm2,                   xmm3              ; abs(p1-q1)
-        pand        xmm2,                   [tfe GLOBAL]      ; set lsb of each byte to zero
-        psrlw       xmm2,                   1                 ; abs(p1-q1)/2
-
-        movdqa      xmm6,                   xmm5              ; p0
-        movdqa      xmm3,                   xmm0              ; q0
-
-        psubusb     xmm5,                   xmm3              ; p0-=q0
-        psubusb     xmm3,                   xmm6              ; q0-=p0
-
-        por         xmm5,                   xmm3              ; abs(p0 - q0)
-        paddusb     xmm5,                   xmm5              ; abs(p0-q0)*2
-        paddusb     xmm5,                   xmm2              ; abs (p0 - q0) *2 + abs(p1-q1)/2
-
-        mov         rdx,                    arg(2) ;flimit            ; get flimit
-        movdqa      xmm2,                   XMMWORD PTR [rdx]             ;
-        paddb       xmm2,                   xmm2              ; flimit*2 (less than 255)
-        paddb       xmm7,                   xmm2              ; flimit * 2 + limit (less than 255)
-
-        psubusb     xmm5,                   xmm7              ; abs (p0 - q0) *2 + abs(p1-q1)/2  > flimit * 2 + limit
-        por         xmm1,                   xmm5
-        pxor        xmm5,                   xmm5
-        pcmpeqb     xmm1,                   xmm5               ; mask mm1
-        ; mm1 = mask, mm0=q0,  mm7 = flimit, t0 = abs(q0-q1) t1 = abs(p1-p0)
-        ; mm6 = p0,
-
-        ; calculate high edge variance
-        mov         rdx,                    arg(4) ;thresh            ; get thresh
-        movdqa      xmm7,                   XMMWORD PTR [rdx]             ;
-
-        movdqa      xmm4,                   t0                ; get abs (q1 - q0)
-        psubusb     xmm4,                   xmm7
-
-        movdqa      xmm3,                   t1                ; get abs (p1 - p0)
-        psubusb     xmm3,                   xmm7
-
-        paddb       xmm4,                   xmm3              ; abs(q1 - q0) > thresh || abs(p1 - p0) > thresh
-        pcmpeqb     xmm4,                   xmm5
-
-        pcmpeqb     xmm5,                   xmm5
-        pxor        xmm4,                   xmm5
-        ; mm1 = mask, mm0=q0,  mm7 = thresh, t0 = abs(q0-q1) t1 = abs(p1-p0)
-        ; mm6 = p0, mm4=hev
-        ; start work on filters
-        movdqa      xmm2,                   XMMWORD PTR [rsi+2*rax]   ; p1
-        movdqa      xmm7,                   XMMWORD PTR [rdi]             ; q1
-
-        pxor        xmm2,                   [t80 GLOBAL]  ; p1 offset to convert to signed values
-        pxor        xmm7,                   [t80 GLOBAL]  ; q1 offset to convert to signed values
-
-        psubsb      xmm2,                   xmm7              ; p1 - q1
-        pxor        xmm6,                   [t80 GLOBAL]  ; offset to convert to signed values
-
-        pxor        xmm0,                   [t80 GLOBAL]  ; offset to convert to signed values
-        movdqa      xmm3,                   xmm0              ; q0
-
-        psubsb      xmm0,                   xmm6              ; q0 - p0
-        paddsb      xmm2,                   xmm0              ; 1 * (q0 - p0) + (p1 - q1)
-
-        paddsb      xmm2,                   xmm0              ; 2 * (q0 - p0)
-        paddsb      xmm2,                   xmm0              ; 3 * (q0 - p0) + (p1 - q1)
-
-        pand        xmm1,                   xmm2              ; mask filter values we don't care about
-        ; mm1 = vp8_filter, mm4=hev, mm6=ps0, mm3=qs0
-        movdqa      xmm2,                   xmm1              ; vp8_filter
-        pand        xmm2,                   xmm4;             ; Filter2 = vp8_filter & hev
-
-
-        movdqa      xmm5,                   xmm2          ;
-        paddsb      xmm5,                   [t3 GLOBAL];
-
-        pxor        xmm0,                   xmm0              ; 0
-        pxor        xmm7,                   xmm7              ; 0
-
-        punpcklbw   xmm0,                   xmm5              ; e0f0g0h0
-        psraw       xmm0,                   11                ; sign extended shift right by 3
-
-        punpckhbw   xmm7,                   xmm5              ; a0b0c0d0
-        psraw       xmm7,                   11                ; sign extended shift right by 3
-
-        packsswb    xmm0,                   xmm7              ; Filter2 >>=3;
-        movdqa      xmm5,                   xmm0              ; Filter2
-
-        paddsb      xmm2,                   [t4 GLOBAL]      ; vp8_signed_char_clamp(Filter2 + 4)
-        pxor        xmm0,                   xmm0              ; 0
-
-        pxor        xmm7,                   xmm7              ; 0
-        punpcklbw   xmm0,                   xmm2              ; e0f0g0h0
-
-        psraw       xmm0,                   11                ; sign extended shift right by 3
-        punpckhbw   xmm7,                   xmm2              ; a0b0c0d0
-
-        psraw       xmm7,                   11                ; sign extended shift right by 3
-        packsswb    xmm0,                   xmm7              ; Filter2 >>=3;
-
-        ; mm0= filter2 mm1 = vp8_filter,  mm3 =qs0 mm5=s mm4 =hev mm6=ps0
-        psubsb      xmm3,                   xmm0              ; qs0 =qs0 - filter1
-        paddsb      xmm6,                   xmm5              ; ps0 =ps0 + Fitler2
-
-        ; mm1=vp8_filter, mm3=qs0, mm4 =hev mm6=ps0
-        ; vp8_filter &= ~hev;
-        ; Filter2 = vp8_filter;
-        pandn       xmm4,                   xmm1              ; vp8_filter&=~hev
-
-
-        ; mm3=qs0, mm4=filter2, mm6=ps0
-
-        ; u = vp8_signed_char_clamp((63 + Filter2 * 27)>>7);
-        ; s = vp8_signed_char_clamp(qs0 - u);
-        ; *oq0 = s^0x80;
-        ; s = vp8_signed_char_clamp(ps0 + u);
-        ; *op0 = s^0x80;
-        pxor        xmm0,                   xmm0
-        pxor        xmm1,                   xmm1
-
-        pxor        xmm2,                   xmm2
-        punpcklbw   xmm1,                   xmm4
-
-        punpckhbw   xmm2,                   xmm4
-        pmulhw      xmm1,                   [s27 GLOBAL]
-
-        pmulhw      xmm2,                   [s27 GLOBAL]
-        paddw       xmm1,                   [s63 GLOBAL]
-
-        paddw       xmm2,                   [s63 GLOBAL]
-        psraw       xmm1,                   7
-
-        psraw       xmm2,                   7
-        packsswb    xmm1,                   xmm2
-
-        psubsb      xmm3,                   xmm1
-        paddsb      xmm6,                   xmm1
-
-        pxor        xmm3,                   [t80 GLOBAL]
-        pxor        xmm6,                   [t80 GLOBAL]
-
-        movdqa      XMMWORD PTR [rsi+rax],  xmm6
-        movdqa      XMMWORD PTR [rsi],      xmm3
-
-        ; roughly 2/7th difference across boundary
-        ; u = vp8_signed_char_clamp((63 + Filter2 * 18)>>7);
-        ; s = vp8_signed_char_clamp(qs1 - u);
-        ; *oq1 = s^0x80;
-        ; s = vp8_signed_char_clamp(ps1 + u);
-        ; *op1 = s^0x80;
-        pxor        xmm1,                   xmm1
-        pxor        xmm2,                   xmm2
-
-        punpcklbw   xmm1,                   xmm4
-        punpckhbw   xmm2,                   xmm4
-
-        pmulhw      xmm1,                   [s18 GLOBAL]
-        pmulhw      xmm2,                   [s18 GLOBAL]
-
-        paddw       xmm1,                   [s63 GLOBAL]
-        paddw       xmm2,                   [s63 GLOBAL]
-
-        psraw       xmm1,                   7
-        psraw       xmm2,                   7
-
-        packsswb    xmm1,                   xmm2
-
-        movdqa      xmm3,                   XMMWORD PTR [rdi]
-        movdqa      xmm6,                   XMMWORD PTR [rsi+rax*2]       ; p1
-
-        pxor        xmm3,                   [t80 GLOBAL]
-        pxor        xmm6,                   [t80 GLOBAL]
-
-        paddsb      xmm6,                   xmm1
-        psubsb      xmm3,                   xmm1
-
-        pxor        xmm6,                   [t80 GLOBAL]
-        pxor        xmm3,                   [t80 GLOBAL]
-
-        movdqa      XMMWORD PTR [rdi],      xmm3
-        movdqa      XMMWORD PTR [rsi+rax*2],xmm6
-
-        ; roughly 1/7th difference across boundary
-        ; u = vp8_signed_char_clamp((63 + Filter2 * 9)>>7);
-        ; s = vp8_signed_char_clamp(qs2 - u);
-        ; *oq2 = s^0x80;
-        ; s = vp8_signed_char_clamp(ps2 + u);
-        ; *op2 = s^0x80;
-        pxor        xmm1,                   xmm1
-        pxor        xmm2,                   xmm2
-
-        punpcklbw   xmm1,                   xmm4
-        punpckhbw   xmm2,                   xmm4
-
-        pmulhw      xmm1,                   [s9 GLOBAL]
-        pmulhw      xmm2,                   [s9 GLOBAL]
-
-        paddw       xmm1,                   [s63 GLOBAL]
-        paddw       xmm2,                   [s63 GLOBAL]
-
-        psraw       xmm1,                   7
-        psraw       xmm2,                   7
-
-        packsswb    xmm1,                   xmm2
-
-
-        movdqa      xmm6,                   XMMWORD PTR [rdi+rax*4]
-        neg         rax
-
-        movdqa      xmm3,                   XMMWORD PTR [rdi+rax  ]
-
-        pxor        xmm6,                   [t80 GLOBAL]
-        pxor        xmm3,                   [t80 GLOBAL]
-
-        paddsb      xmm6,                   xmm1
-        psubsb      xmm3,                   xmm1
-
-        pxor        xmm6,                   [t80 GLOBAL]
-        pxor        xmm3,                   [t80 GLOBAL]
-
-        movdqa      XMMWORD PTR [rdi+rax  ], xmm3
-        neg         rax
-
-        movdqa      XMMWORD PTR [rdi+rax*4], xmm6
-
-    add rsp, 32
-    pop rsp
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void vp8_mbloop_filter_vertical_edge_sse2
-;(
-;    unsigned char *src_ptr,
-;    int            src_pixel_step,
-;    const char    *flimit,
-;    const char    *limit,
-;    const char    *thresh,
-;    int            count
-;)
-global sym(vp8_mbloop_filter_vertical_edge_sse2)
-sym(vp8_mbloop_filter_vertical_edge_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 6
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-    ALIGN_STACK 16, rax
-    sub          rsp, 160     ; reserve 160 bytes
-    %define t0   [rsp + 0]    ;__declspec(align(16)) char t0[16];
-    %define t1   [rsp + 16]   ;__declspec(align(16)) char t1[16];
-    %define srct [rsp + 32]   ;__declspec(align(16)) char srct[128];
-
-
-        mov         rsi,                arg(0) ;src_ptr
-        movsxd      rax,                dword ptr arg(1) ;src_pixel_step                    ; destination pitch?
-
-        lea         rsi,                [rsi + rax*4 - 4]
-        lea         rdi,                [rsi + rax]                     ; rdi points to row +1 for indirect addressing
-
-        mov         rcx,                rax
-        neg         rcx
-
-        ; Transpose
-        movq        xmm0,               QWORD PTR [rdi+rax*2]           ; xx xx xx xx xx xx xx xx 77 76 75 74 73 72 71 70
-        movq        xmm7,               QWORD PTR [rsi+rax*2]           ; xx xx xx xx xx xx xx xx 67 66 65 64 63 62 61 60
-
-        punpcklbw   xmm7,               xmm0                            ; 77 67 76 66 75 65 74 64 73 63 72 62 71 61 70 60
-        movq        xmm0,               QWORD PTR [rsi+rax]             ;
-
-        movq        xmm5,               QWORD PTR [rsi]                 ;
-        punpcklbw   xmm5,               xmm0                            ; 57 47 56 46 55 45 54 44 53 43 52 42 51 41 50 40
-
-        movdqa      xmm6,               xmm5                            ; 57 47 56 46 55 45 54 44 53 43 52 42 51 41 50 40
-        punpcklwd   xmm5,               xmm7                            ; 73 63 53 43 72 62 52 42 71 61 51 41 70 60 50 40
-
-        punpckhwd   xmm6,               xmm7                            ; 77 67 57 47 76 66 56 46 75 65 55 45 74 64 54 44
-        movq        xmm7,               QWORD PTR [rsi + rcx]           ; xx xx xx xx xx xx xx xx 37 36 35 34 33 32 31 30
-
-        movq        xmm0,               QWORD PTR [rsi + rcx*2]         ; xx xx xx xx xx xx xx xx 27 26 25 24 23 22 21 20
-        punpcklbw   xmm0,               xmm7                            ; 37 27 36 36 35 25 34 24 33 23 32 22 31 21 30 20
-
-        movq        xmm4,               QWORD PTR [rsi + rcx*4]         ; xx xx xx xx xx xx xx xx 07 06 05 04 03 02 01 00
-        movq        xmm7,               QWORD PTR [rdi + rcx*4]         ; xx xx xx xx xx xx xx xx 17 16 15 14 13 12 11 10
-
-        punpcklbw   xmm4,               xmm7                            ; 17 07 16 06 15 05 14 04 13 03 12 02 11 01 10 00
-        movdqa      xmm3,               xmm4                            ; 17 07 16 06 15 05 14 04 13 03 12 02 11 01 10 00
-
-        punpcklwd   xmm3,               xmm0                            ; 33 23 13 03 32 22 12 02 31 21 11 01 30 20 10 00
-        punpckhwd   xmm4,               xmm0                            ; 37 27 17 07 36 26 16 06 35 25 15 05 34 24 14 04
-
-        movdqa      xmm7,               xmm4                            ; 37 27 17 07 36 26 16 06 35 25 15 05 34 24 14 04
-        movdqa      xmm2,               xmm3                            ; 33 23 13 03 32 22 12 02 31 21 11 01 30 20 10 00
-
-        punpckhdq   xmm7,               xmm6                            ; 77 67 57 47 37 27 17 07 76 66 56 46 36 26 16 06
-        punpckldq   xmm4,               xmm6                            ; 75 65 55 45 35 25 15 05 74 64 54 44 34 24 14 04
-
-        punpckhdq   xmm3,               xmm5                            ; 73 63 53 43 33 23 13 03 72 62 52 42 32 22 12 02
-        punpckldq   xmm2,               xmm5                            ; 71 61 51 41 31 21 11 01 70 60 50 40 30 20 10 00
-
-        movdqa      t0,                 xmm2                            ; save to free XMM2
-        ;movdqa        t1,                 xmm3
-
-        ; XMM3 XMM4 XMM7 in use
-        lea         rsi,                [rsi+rax*8]
-        lea         rdi,                [rdi+rax*8]
-
-        movq        xmm6,               QWORD PTR [rdi+rax*2]           ; xx xx xx xx xx xx xx xx f7 f6 f5 f4 f3 f2 f1 f0
-        movq        xmm5,               QWORD PTR [rsi+rax*2]           ; xx xx xx xx xx xx xx xx e7 e6 e5 e4 e3 e2 e1 e0
-
-        punpcklbw   xmm5,               xmm6                            ; f7 e7 f6 e6 f5 e5 f4 e4 f3 e3 f2 e2 f1 e1 f0 e0
-        movq        xmm6,               QWORD PTR [rsi+rax]             ; xx xx xx xx xx xx xx xx d7 d6 d5 d4 d3 d2 d1 d0
-
-        movq        xmm1,               QWORD PTR [rsi]                 ; xx xx xx xx xx xx xx xx c7 c6 c5 c4 c3 c2 c1 c0
-        punpcklbw   xmm1,               xmm6                            ; d7 c7 d6 c6 d5 c5 d4 c4 d3 c3 d2 c2 d1 e1 d0 c0
-
-        movdqa      xmm6,               xmm1                            ;
-        punpckhwd   xmm6,               xmm5                            ; f7 e7 d7 c7 f6 e6 d6 c6 f5 e5 d5 c5 f4 e4 d4 c4
-
-        punpcklwd   xmm1,               xmm5                            ; f3 e3 d3 c3 f2 e2 d2 c2 f1 e1 d1 c1 f0 e0 d0 c0
-        movq        xmm5,               QWORD PTR [rsi+rcx]             ; xx xx xx xx xx xx xx xx b7 b6 b5 b4 b3 b2 b1 b0
-
-        movq        xmm0,               QWORD PTR [rsi+rcx*2]           ; xx xx xx xx xx xx xx xx a7 a6 a5 a4 a3 a2 a1 a0
-        punpcklbw   xmm0,               xmm5                            ; b7 a7 b6 a6 b5 a5 b4 a4 b3 a3 b2 a2 b1 a1 b0 a0
-
-        movq        xmm2,               QWORD PTR [rsi+rcx*4]           ; xx xx xx xx xx xx xx xx 87 86 85 84 83 82 81 80
-        movq        xmm5,               QWORD PTR [rdi+rcx*4]           ; xx xx xx xx xx xx xx xx 97 96 95 94 93 92 91 90
-
-        punpcklbw   xmm2,               xmm5                            ; 97 87 96 86 95 85 94 84 93 83 92 82 91 81 90 80
-        movdqa      xmm5,               xmm2                            ; 97 87 96 86 95 85 94 84 93 83 92 82 91 81 90 80
-
-        punpcklwd   xmm5,               xmm0                            ; b3 a3 93 83 b2 a2 92 82 b1 a1 91 81 b0 a0 90 80
-        punpckhwd   xmm2,               xmm0                            ; b7 a7 97 87 b6 a6 96 86 b5 a5 95 85 b4 a4 94 84
-
-        movdqa      xmm0,               xmm5
-        punpckldq   xmm0,               xmm1                            ; f1 e1 d1 c1 b1 a1 91 81 f0 e0 d0 c0 b0 a0 90 80
-
-
-        punpckhdq   xmm5,               xmm1                            ; f3 e3 d3 c3 b3 a3 93 83 f2 e2 d2 c2 b2 a2 92 82
-        movdqa      xmm1,               xmm2                            ; b7 a7 97 87 b6 a6 96 86 b5 a5 95 85 b4 a4 94 84
-
-        punpckldq   xmm1,               xmm6                            ; f5 e5 d5 c5 b5 a5 95 85 f4 e4 d4 c4 b4 a4 94 84
-        punpckhdq   xmm2,               xmm6                            ; f7 e7 d7 c7 b7 a7 97 87 f6 e6 d6 c6 b6 a6 96 86
-
-        movdqa      xmm6,               xmm7                            ; 77 67 57 47 37 27 17 07 76 66 56 46 36 26 16 06
-        punpcklqdq  xmm6,               xmm2                            ; f6 e6 d6 c6 b6 a6 96 86 76 66 56 46 36 26 16 06
-
-
-        lea         rdx,                srct
-        punpckhqdq  xmm7,               xmm2                            ; f7 e7 d7 c7 b7 a7 97 87 77 67 57 47 37 27 17 07
-
-        movdqa      [rdx+112],          xmm7                            ; save 7
-        movdqa      xmm2,               xmm3                            ; 73 63 53 43 33 23 13 03 72 62 52 42 32 22 12 02
-
-        movdqa      [rdx+96],           xmm6                            ; save 6
-        punpcklqdq  xmm2,               xmm5                            ; f2 e2 d2 c2 b2 a2 92 82 72 62 52 42 32 22 12 02
-
-        punpckhqdq  xmm3,               xmm5                            ; f3 e3 d3 c3 b3 a3 93 83 73 63 53 43 33 23 13 03
-        movdqa      [rdx+32],           xmm2                            ; save 2
-
-        movdqa      xmm5,               xmm4                            ; 75 65 55 45 35 25 15 05 74 64 54 44 34 24 14 04
-        punpcklqdq  xmm4,               xmm1                            ; f4 e4 d4 c4 b4 a4 94 84 74 64 54 44 34 24 14 04
-
-        movdqa      [rdx+48],           xmm3                            ; save 3
-        punpckhqdq  xmm5,               xmm1                            ; f5 e5 d5 c5 b5 a5 95 85 75 65 55 45 35 25 15 05
-
-        movdqa      [rdx+64],           xmm4                            ; save 4
-        movdqa      [rdx+80],           xmm5                            ; save 5
-
-        movdqa      xmm1,               t0                              ; get
-        movdqa      xmm2,               xmm1                            ;
-
-        punpckhqdq  xmm1,               xmm0                            ; f1 e1 d1 c1 b1 a1 91 81 71 61 51 41 31 21 11 01
-        punpcklqdq  xmm2,               xmm0                            ; f0 e0 d0 c0 b0 a0 90 80 70 60 50 40 30 20 10 00
-
-        movdqa      [rdx+16],           xmm1
-        movdqa      [rdx],              xmm2
-
-        movdqa      xmm0,               xmm6                            ; q2
-        psubusb     xmm0,               xmm7                            ; q2-q3
-
-        psubusb     xmm7,               xmm6                            ; q3-q2
-        por         xmm7,               xmm0                            ; abs (q3-q2)
-
-        movdqa      xmm1,               xmm5                            ; q1
-        psubusb     xmm1,               xmm6                            ; q1-q2
-
-        psubusb     xmm6,               xmm5                            ; q2-q1
-        por         xmm6,               xmm1                            ; abs (q2-q1)
-
-        ;/*
-        ;movdqa      xmm0,               xmm4                            ; q0
-        ;psubusb     xmm0                xmm5                            ; q0-q1
-        ;
-        ;pusbusb     xmm5,               xmm4                            ; q1-q0
-        ;por         xmm5,               xmm0                            ; abs (q1-q0)
-        ;*/
-
-        movdqa      xmm1,               [rdx+16]                        ; p2
-        movdqa      xmm0,               xmm1
-
-        psubusb     xmm0,               xmm2                            ; p2 - p3;
-        psubusb     xmm2,               xmm1                            ; p3 - p2;
-
-        por         xmm0,               xmm2                            ; abs(p2-p3)
-
-        movdqa      xmm2,               [rdx+32]                        ; p1
-        movdqa      xmm5,               xmm2                            ; p1
-
-        psubusb     xmm5,               xmm1                            ; p1-p2
-        psubusb     xmm1,               xmm2                            ; p2-p1
-
-        por         xmm1,               xmm5                            ; abs(p2-p1)
-        mov         rdx,                arg(3) ;limit
-
-        movdqa      xmm4,               [rdx]                           ; limit
-        psubusb     xmm7,               xmm4                            ;
-
-
-        psubusb     xmm0,               xmm4                            ; abs(p3-p2) > limit
-        psubusb     xmm1,               xmm4                            ; abs(p2-p1) > limit
-
-        psubusb     xmm6,               xmm4                            ; abs(q2-q1) > limit
-        por         xmm7,               xmm6                            ; or
-
-        por         xmm0,               xmm1                            ;
-        por         xmm0,               xmm7                            ; abs(q3-q2) > limit || abs(p3-p2) > limit ||abs(p2-p1) > limit || abs(q2-q1) > limit
-
-        movdqa      xmm1,               xmm2                            ; p1
-
-        movdqa      xmm7,               xmm3                            ; p0
-        psubusb     xmm7,               xmm2                            ; p0-p1
-
-        psubusb     xmm2,               xmm3                            ; p1-p0
-        por         xmm2,               xmm7                            ; abs(p1-p0)
-
-        movdqa      t0,                 xmm2                            ; save abs(p1-p0)
-        lea         rdx,                srct
-
-        psubusb     xmm2,               xmm4                            ; abs(p1-p0)>limit
-        por         xmm0,               xmm2                            ; mask
-
-        movdqa      xmm5,               [rdx+64]                        ; q0
-        movdqa      xmm7,               [rdx+80]                        ; q1
-
-        movdqa      xmm6,               xmm5                            ; q0
-        movdqa      xmm2,               xmm7                            ; q1
-        psubusb     xmm5,               xmm7                            ; q0-q1
-
-        psubusb     xmm7,               xmm6                            ; q1-q0
-        por         xmm7,               xmm5                            ; abs(q1-q0)
-
-        movdqa      t1,                 xmm7                            ; save abs(q1-q0)
-        psubusb     xmm7,               xmm4                            ; abs(q1-q0)> limit
-
-        por         xmm0,               xmm7                            ; mask
-
-        movdqa      xmm5,                xmm2                           ; q1
-        psubusb     xmm5,                xmm1                           ; q1-=p1
-        psubusb     xmm1,                xmm2                           ; p1-=q1
-        por         xmm5,                xmm1                           ; abs(p1-q1)
-        pand        xmm5,                [tfe GLOBAL]                   ; set lsb of each byte to zero
-        psrlw       xmm5,                1                              ; abs(p1-q1)/2
-
-        mov         rdx,                arg(2) ;flimit                          ;
-        movdqa      xmm2,               [rdx]                           ; flimit
-
-        movdqa      xmm1,               xmm3                            ; p0
-        movdqa      xmm7,               xmm6                            ; q0
-        psubusb     xmm1,               xmm7                            ; p0-q0
-        psubusb     xmm7,               xmm3                            ; q0-p0
-        por         xmm1,               xmm7                            ; abs(q0-p0)
-        paddusb     xmm1,               xmm1                            ; abs(q0-p0)*2
-        paddusb     xmm1,               xmm5                            ; abs (p0 - q0) *2 + abs(p1-q1)/2
-
-        paddb       xmm2,               xmm2                            ; flimit*2 (less than 255)
-        paddb       xmm4,               xmm2                            ; flimit * 2 + limit (less than 255)
-
-        psubusb     xmm1,               xmm4                            ; abs (p0 - q0) *2 + abs(p1-q1)/2  > flimit * 2 + limit
-        por         xmm1,               xmm0;                           ; mask
-        pxor        xmm0,               xmm0
-        pcmpeqb     xmm1,               xmm0
-
-        ; calculate high edge variance
-        mov         rdx,                arg(4) ;thresh                          ; get thresh
-        movdqa      xmm7,               [rdx]
-
-        movdqa      xmm4,               t0                              ; get abs (q1 - q0)
-        psubusb     xmm4,               xmm7                            ; abs(q1 - q0) > thresh
-
-        movdqa      xmm3,               t1                              ; get abs (p1 - p0)
-        psubusb     xmm3,               xmm7                            ; abs(p1 - p0)> thresh
-
-        por         xmm4,               xmm3                            ; abs(q1 - q0) > thresh || abs(p1 - p0) > thresh
-        pcmpeqb     xmm4,               xmm0
-
-        pcmpeqb     xmm0,               xmm0
-        pxor        xmm4,               xmm0
-
-
-        ; start work on filters
-        lea         rdx,                srct
-
-        ; start work on filters
-        movdqa      xmm2,               [rdx+32]                        ; p1
-        movdqa      xmm7,               [rdx+80]                        ; q1
-
-        pxor        xmm2,               [t80 GLOBAL]                    ; p1 offset to convert to signed values
-        pxor        xmm7,               [t80 GLOBAL]                    ; q1 offset to convert to signed values
-
-        psubsb      xmm2,               xmm7                            ; p1 - q1
-        movdqa      xmm6,               [rdx+48]                        ; p0
-
-        movdqa      xmm0,               [rdx+64]                        ; q0
-        pxor        xmm6,               [t80 GLOBAL]                    ; offset to convert to signed values
-
-        pxor        xmm0,               [t80 GLOBAL]                    ; offset to convert to signed values
-        movdqa      xmm3,               xmm0                            ; q0
-
-        psubsb      xmm0,               xmm6                            ; q0 - p0
-        paddsb      xmm2,               xmm0                            ; 1 * (q0 - p0) + (p1 - q1)
-
-        paddsb      xmm2,               xmm0                            ; 2 * (q0 - p0)
-        paddsb      xmm2,               xmm0                            ; 3 * (q0 - p0)+ (p1 - q1)
-
-        pand        xmm1,               xmm2                            ; mask filter values we don't care about
-
-        ; xmm1 = vp8_filter, xmm4=hev, xmm6=ps0, xmm3=qs0
-        movdqa      xmm2,               xmm1                            ; vp8_filter
-        pand        xmm2,               xmm4;                           ; Filter2 = vp8_filter & hev
-
-        movdqa      xmm5,               xmm2
-        paddsb      xmm5,               [t3 GLOBAL]
-
-        pxor        xmm0,               xmm0                            ; 0
-        pxor        xmm7,               xmm7                            ; 0
-
-        punpcklbw   xmm0,               xmm5                            ; e0f0g0h0
-        psraw       xmm0,               11                              ; sign extended shift right by 3
-
-        punpckhbw   xmm7,               xmm5                            ; a0b0c0d0
-        psraw       xmm7,               11                              ; sign extended shift right by 3
-
-        packsswb    xmm0,               xmm7                            ; Filter2 >>=3;
-        movdqa      xmm5,               xmm0                            ; Filter2
-
-        paddsb      xmm2,               [t4 GLOBAL]                     ; vp8_signed_char_clamp(Filter2 + 4)
-        pxor        xmm0,               xmm0                            ; 0
-
-        pxor        xmm7,               xmm7                            ; 0
-        punpcklbw   xmm0,               xmm2                            ; e0f0g0h0
-
-        psraw       xmm0,               11                              ; sign extended shift right by 3
-        punpckhbw   xmm7,               xmm2                            ; a0b0c0d0
-
-        psraw       xmm7,               11                              ; sign extended shift right by 3
-        packsswb    xmm0,               xmm7                            ; Filter2 >>=3;
-
-        ; xmm0= filter2 xmm1 = vp8_filter,  xmm3 =qs0 xmm5=s xmm4 =hev xmm6=ps0
-        psubsb      xmm3,               xmm0                            ; qs0 =qs0 - filter1
-        paddsb      xmm6,               xmm5                            ; ps0 =ps0 + Fitler2
-
-
-        ; xmm1=vp8_filter, xmm3=qs0, xmm4 =hev xmm6=ps0
-        ; vp8_filter &= ~hev;
-        ; Filter2 = vp8_filter;
-        pandn       xmm4,                   xmm1                        ; vp8_filter&=~hev
-
-        ; xmm3=qs0, xmm4=filter2, xmm6=ps0
-        ; u = vp8_signed_char_clamp((63 + Filter2 * 27)>>7);
-        ; s = vp8_signed_char_clamp(qs0 - u);
-        ; *oq0 = s^0x80;
-        ; s = vp8_signed_char_clamp(ps0 + u);
-        ; *op0 = s^0x80;
-        pxor        xmm0,                   xmm0
-        pxor        xmm1,                   xmm1
-
-        pxor        xmm2,                   xmm2
-        punpcklbw   xmm1,                   xmm4
-
-        punpckhbw   xmm2,                   xmm4
-        pmulhw      xmm1,                   [s27 GLOBAL]
-
-        pmulhw      xmm2,                   [s27 GLOBAL]
-        paddw       xmm1,                   [s63 GLOBAL]
-
-        paddw       xmm2,                   [s63 GLOBAL]
-        psraw       xmm1,                   7
-
-        psraw       xmm2,                   7
-        packsswb    xmm1,                   xmm2
-
-        psubsb      xmm3,                   xmm1
-        paddsb      xmm6,                   xmm1
-
-        pxor        xmm3,                   [t80 GLOBAL]
-        pxor        xmm6,                   [t80 GLOBAL]
-
-        movdqa      [rdx+48],               xmm6
-        movdqa      [rdx+64],               xmm3
-
-        ; roughly 2/7th difference across boundary
-        ; u = vp8_signed_char_clamp((63 + Filter2 * 18)>>7);
-        ; s = vp8_signed_char_clamp(qs1 - u);
-        ; *oq1 = s^0x80;
-        ; s = vp8_signed_char_clamp(ps1 + u);
-        ; *op1 = s^0x80;
-        pxor        xmm1,                       xmm1
-        pxor        xmm2,                       xmm2
-
-        punpcklbw   xmm1,                       xmm4
-        punpckhbw   xmm2,                       xmm4
-
-        pmulhw      xmm1,                       [s18 GLOBAL]
-        pmulhw      xmm2,                       [s18 GLOBAL]
-
-        paddw       xmm1,                       [s63 GLOBAL]
-        paddw       xmm2,                       [s63 GLOBAL]
-
-        psraw       xmm1,                       7
-        psraw       xmm2,                       7
-
-        packsswb    xmm1,                       xmm2
-
-        movdqa      xmm3,                       [rdx + 80]              ;/q1
-        movdqa      xmm6,                       [rdx + 32]              ; p1
-
-        pxor        xmm3,                       [t80 GLOBAL]
-        pxor        xmm6,                       [t80 GLOBAL]
-
-        paddsb      xmm6,                       xmm1
-        psubsb      xmm3,                       xmm1
-
-        pxor        xmm6,                       [t80 GLOBAL]
-        pxor        xmm3,                       [t80 GLOBAL]
-
-        movdqa      [rdx + 80],                 xmm3
-        movdqa      [rdx + 32],                 xmm6
-
-
-        ; roughly 1/7th difference across boundary
-        ; u = vp8_signed_char_clamp((63 + Filter2 * 9)>>7);
-        ; s = vp8_signed_char_clamp(qs2 - u);
-        ; *oq2 = s^0x80;
-        ; s = vp8_signed_char_clamp(ps2 + u);
-        ; *op2 = s^0x80;
-        pxor        xmm1,                       xmm1
-        pxor        xmm2,                       xmm2
-
-        punpcklbw   xmm1,                       xmm4
-        punpckhbw   xmm2,                       xmm4
-
-        pmulhw      xmm1,                       [s9 GLOBAL]
-        pmulhw      xmm2,                       [s9 GLOBAL]
-
-        paddw       xmm1,                       [s63 GLOBAL]
-        paddw       xmm2,                       [s63 GLOBAL]
-
-        psraw       xmm1,                       7
-        psraw       xmm2,                       7
-
-        packsswb    xmm1,                       xmm2
-
-        movdqa      xmm6,                       [rdx+16]
-        movdqa      xmm3,                       [rdx+96]
-
-        pxor        xmm6,                       [t80 GLOBAL]
-        pxor        xmm3,                       [t80 GLOBAL]
-
-        paddsb      xmm6,                       xmm1
-        psubsb      xmm3,                       xmm1
-
-        pxor        xmm6,                       [t80 GLOBAL]        ; xmm6 = f1 e1 d1 c1 b1 a1 91 81 71 61 51 41 31 21 11 01
-        pxor        xmm3,                       [t80 GLOBAL]        ; xmm3 = f6 e6 d6 c6 b6 a6 96 86 76 66 56 46 36 26 15 06
-
-
-        ; transpose and write back
-        movdqa      xmm0,                       [rdx]               ; f0 e0 d0 c0 b0 a0 90 80 70 60 50 40 30 20 10 00
-        movdqa      xmm1,                       xmm0                ; f0 e0 d0 c0 b0 a0 90 80 70 60 50 40 30 20 10 00
-
-        punpcklbw   xmm0,                       xmm6                ; 71 70 61 60 51 50 41 40 31 30 21 20 11 10 01 00
-        punpckhbw   xmm1,                       xmm6                ; f1 f0 e1 e0 d1 d0 c1 c0 b1 b0 a1 a0 91 90 81 80
-
-        movdqa      xmm2,                       [rdx+32]            ; f2 e2 d2 c2 b2 a2 92 82 72 62 52 42 32 22 12 02
-        movdqa      xmm6,                       xmm2                ; f2 e2 d2 c2 b2 a2 92 82 72 62 52 42 32 22 12 02
-
-        punpcklbw   xmm2,                       [rdx+48]            ; 73 72 63 62 53 52 43 42 33 32 23 22 13 12 03 02
-        punpckhbw   xmm6,                       [rdx+48]            ; f3 f2 e3 e2 d3 d2 c3 c2 b3 b2 a3 a2 93 92 83 82
-
-        movdqa      xmm5,                       xmm0                ; 71 70 61 60 51 50 41 40 31 30 21 20 11 10 01 00
-        punpcklwd   xmm0,                       xmm2                ; 33 32 31 30 23 22 21 20 13 12 11 10 03 02 01 00
-
-        punpckhwd   xmm5,                       xmm2                ; 73 72 71 70 63 62 61 60 53 52 51 50 43 42 41 40
-        movdqa      xmm4,                       xmm1                ; f1 f0 e1 e0 d1 d0 c1 c0 b1 b0 a1 a0 91 90 81 80
-
-        punpcklwd   xmm1,                       xmm6                ; b3 b2 b1 b0 a3 a2 a1 a0 93 92 91 90 83 82 81 80
-        punpckhwd   xmm4,                       xmm6                ; f3 f2 f1 f0 e3 e2 e1 e0 d3 d2 d1 d0 c3 c2 c1 c0
-
-        movdqa      xmm2,                       [rdx+64]            ; f4 e4 d4 c4 b4 a4 94 84 74 64 54 44 34 24 14 04
-        punpcklbw   xmm2,                       [rdx+80]            ; 75 74 65 64 55 54 45 44 35 34 25 24 15 14 05 04
-
-        movdqa      xmm6,                       xmm3                ; f6 e6 d6 c6 b6 a6 96 86 76 66 56 46 36 26 16 06
-        punpcklbw   xmm6,                       [rdx+112]           ; 77 76 67 66 57 56 47 46 37 36 27 26 17 16 07 06
-
-        movdqa      xmm7,                       xmm2                ; 75 74 65 64 55 54 45 44 35 34 25 24 15 14 05 04
-        punpcklwd   xmm2,                       xmm6                ; 37 36 35 34 27 26 25 24 17 16 15 14 07 06 05 04
-
-        punpckhwd   xmm7,                       xmm6                ; 77 76 75 74 67 66 65 64 57 56 55 54 47 46 45 44
-        movdqa      xmm6,                       xmm0                ; 33 32 31 30 23 22 21 20 13 12 11 10 03 02 01 00
-
-        punpckldq   xmm0,                       xmm2                ; 17 16 15 14 13 12 11 10 07 06 05 04 03 02 01 00
-        punpckhdq   xmm6,                       xmm2                ; 37 36 35 34 33 32 31 30 27 26 25 24 23 22 21 20
-
-        lea         rsi,                        [rsi+rcx*8]
-        lea         rdi,                        [rdi+rcx*8]
-
-        movq        QWORD PTR [rsi+rcx*4],      xmm0
-        psrldq      xmm0,                       8
-
-        movq        QWORD PTR [rsi+rcx*2],      xmm6
-        psrldq      xmm6,                       8
-
-        movq        QWORD PTR [rdi+rcx*4],      xmm0
-        movq        QWORD PTR [rsi+rcx],        xmm6
-
-        movdqa      xmm0,                       xmm5                ; 73 72 71 70 63 62 61 60 53 52 51 50 43 42 41 40
-        punpckldq   xmm0,                       xmm7                ; 57 56 55 54 53 52 51 50 47 46 45 44 43 42 41 40
-
-        punpckhdq   xmm5,                       xmm7                ; 77 76 75 74 73 72 71 70 67 66 65 64 63 62 61 60
-
-        movq        QWORD PTR [rsi],            xmm0
-        psrldq      xmm0,                       8
-
-        movq        QWORD PTR [rsi+rax*2],      xmm5
-        psrldq      xmm5,                       8
-
-        movq        QWORD PTR [rsi+rax],        xmm0
-        movq        QWORD PTR [rdi+rax*2],      xmm5
-
-        movdqa      xmm2,                       [rdx+64]            ; f4 e4 d4 c4 b4 a4 94 84 74 64 54 44 34 24 14 04
-        punpckhbw   xmm2,                       [rdx+80]            ; f5 f4 e5 e4 d5 d4 c5 c4 b5 b4 a5 a4 95 94 85 84
-
-        punpckhbw   xmm3,                       [rdx+112]           ; f7 f6 e7 e6 d7 d6 c7 c6 b7 b6 a7 a6 97 96 87 86
-        movdqa      xmm0,                       xmm2
-
-        punpcklwd   xmm0,                       xmm3                ; b7 b6 b4 b4 a7 a6 a5 a4 97 96 95 94 87 86 85 84
-        punpckhwd   xmm2,                       xmm3                ; f7 f6 f5 f4 e7 e6 e5 e4 d7 d6 d5 d4 c7 c6 c5 c4
-
-        movdqa      xmm3,                       xmm1                ; b3 b2 b1 b0 a3 a2 a1 a0 93 92 91 90 83 82 81 80
-        punpckldq   xmm1,                       xmm0                ; 97 96 95 94 93 92 91 90 87 86 85 83 84 82 81 80
-
-        punpckhdq   xmm3,                       xmm0                ; b7 b6 b5 b4 b3 b2 b1 b0 a7 a6 a5 a4 a3 a2 a1 a0
-
-        lea         rsi,                        [rsi+rax*8]
-        lea         rdi,                        [rdi+rax*8]
-
-        movq        QWORD PTR [rsi+rcx*4],      xmm1
-        psrldq      xmm1,                       8
-
-        movq        QWORD PTR [rsi+rcx*2],      xmm3
-        psrldq      xmm3,                       8
-
-        movq        QWORD PTR [rdi+rcx*4],      xmm1
-        movq        QWORD PTR [rsi+rcx],        xmm3
-
-        movdqa      xmm1,                       xmm4                ; f3 f2 f1 f0 e3 e2 e1 e0 d3 d2 d1 d0 c3 c2 c1 c0
-        punpckldq   xmm1,                       xmm2                ; d7 d6 d5 d4 d3 d2 d1 d0 c7 c6 c5 c4 c3 c2 c1 c0
-
-        punpckhdq   xmm4,                       xmm2                ; f7 f6 f4 f4 f3 f2 f1 f0 e7 e6 e5 e4 e3 e2 e1 e0
-        movq        QWORD PTR [rsi],            xmm1
-
-        psrldq      xmm1,                       8
-
-        movq        QWORD PTR [rsi+rax*2],      xmm4
-        psrldq      xmm4,                       8
-
-        movq        QWORD PTR [rsi+rax],        xmm1
-        movq        QWORD PTR [rdi+rax*2],      xmm4
-
-    add rsp, 160
-    pop rsp
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void vp8_loop_filter_simple_horizontal_edge_sse2
-;(
-;    unsigned char *src_ptr,
-;    int  src_pixel_step,
-;    const char *flimit,
-;    const char *limit,
-;    const char *thresh,
-;    int count
-;)
-global sym(vp8_loop_filter_simple_horizontal_edge_sse2)
-sym(vp8_loop_filter_simple_horizontal_edge_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 6
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov         rsi, arg(0)             ;src_ptr
-        movsxd      rax, dword ptr arg(1)   ;src_pixel_step     ; destination pitch?
-        mov         rdx, arg(2) ;flimit     ; get flimit
-        movdqa      xmm3, XMMWORD PTR [rdx]
-        mov         rdx, arg(3) ;limit
-        movdqa      xmm7, XMMWORD PTR [rdx]
-
-        paddb       xmm3, xmm3              ; flimit*2 (less than 255)
-        paddb       xmm3, xmm7              ; flimit * 2 + limit (less than 255)
-
-        mov         rdi, rsi                ; rdi points to row +1 for indirect addressing
-        add         rdi, rax
-        neg         rax
-
-        ; calculate mask
-        movdqu      xmm1, [rsi+2*rax]       ; p1
-        movdqu      xmm0, [rdi]             ; q1
-        movdqa      xmm2, xmm1
-        movdqa      xmm7, xmm0
-        movdqa      xmm4, xmm0
-        psubusb     xmm0, xmm1              ; q1-=p1
-        psubusb     xmm1, xmm4              ; p1-=q1
-        por         xmm1, xmm0              ; abs(p1-q1)
-        pand        xmm1, [tfe GLOBAL]      ; set lsb of each byte to zero
-        psrlw       xmm1, 1                 ; abs(p1-q1)/2
-
-        movdqu      xmm5, [rsi+rax]         ; p0
-        movdqu      xmm4, [rsi]             ; q0
-        movdqa      xmm0, xmm4              ; q0
-        movdqa      xmm6, xmm5              ; p0
-        psubusb     xmm5, xmm4              ; p0-=q0
-        psubusb     xmm4, xmm6              ; q0-=p0
-        por         xmm5, xmm4              ; abs(p0 - q0)
-        paddusb     xmm5, xmm5              ; abs(p0-q0)*2
-        paddusb     xmm5, xmm1              ; abs (p0 - q0) *2 + abs(p1-q1)/2
-
-        psubusb     xmm5, xmm3              ; abs(p0 - q0) *2 + abs(p1-q1)/2  > flimit * 2 + limit
-        pxor        xmm3, xmm3
-        pcmpeqb     xmm5, xmm3
-
-        ; start work on filters
-        pxor        xmm2, [t80 GLOBAL]      ; p1 offset to convert to signed values
-        pxor        xmm7, [t80 GLOBAL]      ; q1 offset to convert to signed values
-        psubsb      xmm2, xmm7              ; p1 - q1
-
-        pxor        xmm6, [t80 GLOBAL]      ; offset to convert to signed values
-        pxor        xmm0, [t80 GLOBAL]      ; offset to convert to signed values
-        movdqa      xmm3, xmm0              ; q0
-        psubsb      xmm0, xmm6              ; q0 - p0
-        paddsb      xmm2, xmm0              ; p1 - q1 + 1 * (q0 - p0)
-        paddsb      xmm2, xmm0              ; p1 - q1 + 2 * (q0 - p0)
-        paddsb      xmm2, xmm0              ; p1 - q1 + 3 * (q0 - p0)
-        pand        xmm5, xmm2              ; mask filter values we don't care about
-
-        ; do + 4 side
-        paddsb      xmm5, [t4 GLOBAL]       ; 3* (q0 - p0) + (p1 - q1) + 4
-
-        movdqa      xmm0, xmm5              ; get a copy of filters
-        psllw       xmm0, 8                 ; shift left 8
-        psraw       xmm0, 3                 ; arithmetic shift right 11
-        psrlw       xmm0, 8
-        movdqa      xmm1, xmm5              ; get a copy of filters
-        psraw       xmm1, 11                ; arithmetic shift right 11
-        psllw       xmm1, 8                 ; shift left 8 to put it back
-
-        por         xmm0, xmm1              ; put the two together to get result
-
-        psubsb      xmm3, xmm0              ; q0-= q0 add
-        pxor        xmm3, [t80 GLOBAL]      ; unoffset
-        movdqu      [rsi], xmm3             ; write back
-
-        ; now do +3 side
-        psubsb      xmm5, [t1s GLOBAL]      ; +3 instead of +4
-
-        movdqa      xmm0, xmm5              ; get a copy of filters
-        psllw       xmm0, 8                 ; shift left 8
-        psraw       xmm0, 3                 ; arithmetic shift right 11
-        psrlw       xmm0, 8
-        psraw       xmm5, 11                ; arithmetic shift right 11
-        psllw       xmm5, 8                 ; shift left 8 to put it back
-        por         xmm0, xmm5              ; put the two together to get result
-
-
-        paddsb      xmm6, xmm0              ; p0+= p0 add
-        pxor        xmm6, [t80 GLOBAL]      ; unoffset
-        movdqu      [rsi+rax], xmm6         ; write back
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void vp8_loop_filter_simple_vertical_edge_sse2
-;(
-;    unsigned char *src_ptr,
-;    int  src_pixel_step,
-;    const char *flimit,
-;    const char *limit,
-;    const char *thresh,
-;    int count
-;)
-global sym(vp8_loop_filter_simple_vertical_edge_sse2)
-sym(vp8_loop_filter_simple_vertical_edge_sse2):
-    push        rbp         ; save old base pointer value.
-    mov         rbp, rsp    ; set new base pointer value.
-    SHADOW_ARGS_TO_STACK 6
-    GET_GOT     rbx         ; save callee-saved reg
-    push        rsi
-    push        rdi
-    ; end prolog
-
-    ALIGN_STACK 16, rax
-    sub         rsp, 32                         ; reserve 32 bytes
-    %define t0  [rsp + 0]    ;__declspec(align(16)) char t0[16];
-    %define t1  [rsp + 16]   ;__declspec(align(16)) char t1[16];
-
-        mov         rsi, arg(0) ;src_ptr
-        movsxd      rax, dword ptr arg(1) ;src_pixel_step     ; destination pitch?
-
-        lea         rsi,        [rsi - 2 ]
-        lea         rdi,        [rsi + rax]
-        lea         rdx,        [rsi + rax*4]
-        lea         rcx,        [rdx + rax]
-
-        movdqu      xmm0,       [rsi]                   ; (high 96 bits unused) 03 02 01 00
-        movdqu      xmm1,       [rdx]                   ; (high 96 bits unused) 43 42 41 40
-        movdqu      xmm2,       [rdi]                   ; 13 12 11 10
-        movdqu      xmm3,       [rcx]                   ; 53 52 51 50
-        punpckldq   xmm0,       xmm1                    ; (high 64 bits unused) 43 42 41 40 03 02 01 00
-        punpckldq   xmm2,       xmm3                    ; 53 52 51 50 13 12 11 10
-
-        movdqu      xmm4,       [rsi + rax*2]           ; 23 22 21 20
-        movdqu      xmm5,       [rdx + rax*2]           ; 63 62 61 60
-        movdqu      xmm6,       [rdi + rax*2]           ; 33 32 31 30
-        movdqu      xmm7,       [rcx + rax*2]           ; 73 72 71 70
-        punpckldq   xmm4,       xmm5                    ; 63 62 61 60 23 22 21 20
-        punpckldq   xmm6,       xmm7                    ; 73 72 71 70 33 32 31 30
-
-        punpcklbw   xmm0,       xmm2                    ; 53 43 52 42 51 41 50 40 13 03 12 02 11 01 10 00
-        punpcklbw   xmm4,       xmm6                    ; 73 63 72 62 71 61 70 60 33 23 32 22 31 21 30 20
-
-        movdqa      xmm1,       xmm0
-        punpcklwd   xmm0,       xmm4                    ; 33 23 13 03 32 22 12 02 31 21 11 01 30 20 10 00
-        punpckhwd   xmm1,       xmm4                    ; 73 63 53 43 72 62 52 42 71 61 51 41 70 60 50 40
-
-        movdqa      xmm2,       xmm0
-        punpckldq   xmm0,       xmm1                    ; 71 61 51 41 31 21 11 01 70 60 50 40 30 20 10 00
-        punpckhdq   xmm2,       xmm1                    ; 73 63 53 43 33 23 13 03 72 62 52 42 32 22 12 02
-
-        movdqa      t0,         xmm0                    ; save to t0
-        movdqa      t1,         xmm2                    ; save to t1
-
-        lea         rsi,        [rsi + rax*8]
-        lea         rdi,        [rsi + rax]
-        lea         rdx,        [rsi + rax*4]
-        lea         rcx,        [rdx + rax]
-
-        movdqu      xmm4,       [rsi]                   ; 83 82 81 80
-        movdqu      xmm1,       [rdx]                   ; c3 c2 c1 c0
-        movdqu      xmm6,       [rdi]                   ; 93 92 91 90
-        movdqu      xmm3,       [rcx]                   ; d3 d2 d1 d0
-        punpckldq   xmm4,       xmm1                    ; c3 c2 c1 c0 83 82 81 80
-        punpckldq   xmm6,       xmm3                    ; d3 d2 d1 d0 93 92 91 90
-
-        movdqu      xmm0,       [rsi + rax*2]           ; a3 a2 a1 a0
-        movdqu      xmm5,       [rdx + rax*2]           ; e3 e2 e1 e0
-        movdqu      xmm2,       [rdi + rax*2]           ; b3 b2 b1 b0
-        movdqu      xmm7,       [rcx + rax*2]           ; f3 f2 f1 f0
-        punpckldq   xmm0,       xmm5                    ; e3 e2 e1 e0 a3 a2 a1 a0
-        punpckldq   xmm2,       xmm7                    ; f3 f2 f1 f0 b3 b2 b1 b0
-
-        punpcklbw   xmm4,       xmm6                    ; d3 c3 d2 c2 d1 c1 d0 c0 93 83 92 82 91 81 90 80
-        punpcklbw   xmm0,       xmm2                    ; f3 e3 f2 e2 f1 e1 f0 e0 b3 a3 b2 a2 b1 a1 b0 a0
-
-        movdqa      xmm1,       xmm4
-        punpcklwd   xmm4,       xmm0                    ; b3 a3 93 83 b2 a2 92 82 b1 a1 91 81 b0 a0 90 80
-        punpckhwd   xmm1,       xmm0                    ; f3 e3 d3 c3 f2 e2 d2 c2 f1 e1 d1 c1 f0 e0 d0 c0
-
-        movdqa      xmm6,       xmm4
-        punpckldq   xmm4,       xmm1                    ; f1 e1 d1 c1 b1 a1 91 81 f0 e0 d0 c0 b0 a0 90 80
-        punpckhdq   xmm6,       xmm1                    ; f3 e3 d3 c3 b3 a3 93 83 f2 e2 d2 c2 b2 a2 92 82
-
-        movdqa      xmm0,       t0                      ; 71 61 51 41 31 21 11 01 70 60 50 40 30 20 10 00
-        movdqa      xmm2,       t1                      ; 73 63 53 43 33 23 13 03 72 62 52 42 32 22 12 02
-        movdqa      xmm1,       xmm0
-        movdqa      xmm3,       xmm2
-
-        punpcklqdq  xmm0,       xmm4                    ; p1  f0 e0 d0 c0 b0 a0 90 80 70 60 50 40 30 20 10 00
-        punpckhqdq  xmm1,       xmm4                    ; p0  f1 e1 d1 c1 b1 a1 91 81 71 61 51 41 31 21 11 01
-        punpcklqdq  xmm2,       xmm6                    ; q0  f2 e2 d2 c2 b2 a2 92 82 72 62 52 42 32 22 12 02
-        punpckhqdq  xmm3,       xmm6                    ; q1  f3 e3 d3 c3 b3 a3 93 83 73 63 53 43 33 23 13 03
-
-        ; calculate mask
-        movdqa      xmm6,       xmm0                            ; p1
-        movdqa      xmm7,       xmm3                            ; q1
-        psubusb     xmm7,       xmm0                            ; q1-=p1
-        psubusb     xmm6,       xmm3                            ; p1-=q1
-        por         xmm6,       xmm7                            ; abs(p1-q1)
-        pand        xmm6,       [tfe GLOBAL]                    ; set lsb of each byte to zero
-        psrlw       xmm6,       1                               ; abs(p1-q1)/2
-
-        movdqa      xmm5,       xmm1                            ; p0
-        movdqa      xmm4,       xmm2                            ; q0
-        psubusb     xmm5,       xmm2                            ; p0-=q0
-        psubusb     xmm4,       xmm1                            ; q0-=p0
-        por         xmm5,       xmm4                            ; abs(p0 - q0)
-        paddusb     xmm5,       xmm5                            ; abs(p0-q0)*2
-        paddusb     xmm5,       xmm6                            ; abs (p0 - q0) *2 + abs(p1-q1)/2
-
-        mov         rdx,        arg(2)                          ;flimit
-        movdqa      xmm7, XMMWORD PTR [rdx]
-        mov         rdx,        arg(3)                          ; get limit
-        movdqa      xmm6, XMMWORD PTR [rdx]
-        paddb       xmm7,        xmm7                           ; flimit*2 (less than 255)
-        paddb       xmm7,        xmm6                           ; flimit * 2 + limit (less than 255)
-
-        psubusb     xmm5,        xmm7                           ; abs(p0 - q0) *2 + abs(p1-q1)/2  > flimit * 2 + limit
-        pxor        xmm7,        xmm7
-        pcmpeqb     xmm5,        xmm7                           ; mm5 = mask
-
-        ; start work on filters
-        movdqa        t0,        xmm0
-        movdqa        t1,        xmm3
-
-        pxor        xmm0,        [t80 GLOBAL]                   ; p1 offset to convert to signed values
-        pxor        xmm3,        [t80 GLOBAL]                   ; q1 offset to convert to signed values
-
-        psubsb      xmm0,        xmm3                           ; p1 - q1
-        movdqa      xmm6,        xmm1                           ; p0
-
-        movdqa      xmm7,        xmm2                           ; q0
-        pxor        xmm6,        [t80 GLOBAL]                   ; offset to convert to signed values
-
-        pxor        xmm7,        [t80 GLOBAL]                   ; offset to convert to signed values
-        movdqa      xmm3,        xmm7                           ; offseted ; q0
-
-        psubsb      xmm7,        xmm6                           ; q0 - p0
-        paddsb      xmm0,        xmm7                           ; p1 - q1 + 1 * (q0 - p0)
-
-        paddsb      xmm0,        xmm7                           ; p1 - q1 + 2 * (q0 - p0)
-        paddsb      xmm0,        xmm7                           ; p1 - q1 + 3 * (q0 - p0)
-
-        pand        xmm5,        xmm0                           ; mask filter values we don't care about
-
-
-        paddsb      xmm5,        [t4 GLOBAL]                    ;  3* (q0 - p0) + (p1 - q1) + 4
-
-        movdqa      xmm0,        xmm5                           ; get a copy of filters
-        psllw       xmm0,        8                              ; shift left 8
-
-        psraw       xmm0,        3                              ; arithmetic shift right 11
-        psrlw       xmm0,        8
-
-        movdqa      xmm7,        xmm5                           ; get a copy of filters
-        psraw       xmm7,        11                             ; arithmetic shift right 11
-
-        psllw       xmm7,        8                              ; shift left 8 to put it back
-        por         xmm0,        xmm7                           ; put the two together to get result
-
-        psubsb      xmm3,        xmm0                           ; q0-= q0sz add
-        pxor        xmm3,        [t80 GLOBAL]                   ; unoffset   q0
-
-        ; now do +3 side
-        psubsb      xmm5,        [t1s GLOBAL]                   ; +3 instead of +4
-        movdqa      xmm0,        xmm5                           ; get a copy of filters
-
-        psllw       xmm0,        8                              ; shift left 8
-        psraw       xmm0,        3                              ; arithmetic shift right 11
-
-        psrlw       xmm0,        8
-        psraw       xmm5,        11                             ; arithmetic shift right 11
-
-        psllw       xmm5,        8                              ; shift left 8 to put it back
-        por         xmm0,        xmm5                           ; put the two together to get result
-
-        paddsb      xmm6,        xmm0                           ; p0+= p0 add
-        pxor        xmm6,        [t80 GLOBAL]                   ; unoffset   p0
-
-        movdqa      xmm0,        t0                             ; p1
-        movdqa      xmm4,        t1                             ; q1
-
-        ; transpose back to write out
-        ; p1  f0 e0 d0 c0 b0 a0 90 80 70 60 50 40 30 20 10 00
-        ; p0  f1 e1 d1 c1 b1 a1 91 81 71 61 51 41 31 21 11 01
-        ; q0  f2 e2 d2 c2 b2 a2 92 82 72 62 52 42 32 22 12 02
-        ; q1  f3 e3 d3 c3 b3 a3 93 83 73 63 53 43 33 23 13 03
-        movdqa      xmm1,       xmm0
-        punpcklbw   xmm0,       xmm6                               ; 71 70 61 60 51 50 41 40 31 30 21 20 11 10 01 00
-        punpckhbw   xmm1,       xmm6                               ; f1 f0 e1 e0 d1 d0 c1 c0 b1 b0 a1 a0 91 90 81 80
-
-        movdqa      xmm5,       xmm3
-        punpcklbw   xmm3,       xmm4                               ; 73 72 63 62 53 52 43 42 33 32 23 22 13 12 03 02
-        punpckhbw   xmm5,       xmm4                               ; f3 f2 e3 e2 d3 d2 c3 c2 b3 b2 a3 a2 93 92 83 82
-
-        movdqa      xmm2,       xmm0
-        punpcklwd   xmm0,       xmm3                               ; 33 32 31 30 23 22 21 20 13 12 11 10 03 02 01 00
-        punpckhwd   xmm2,       xmm3                               ; 73 72 71 70 63 62 61 60 53 52 51 50 43 42 41 40
-
-        movdqa      xmm3,       xmm1
-        punpcklwd   xmm1,       xmm5                               ; b3 b2 b1 b0 a3 a2 a1 a0 93 92 91 90 83 82 81 80
-        punpckhwd   xmm3,       xmm5                               ; f3 f2 f1 f0 e3 e2 e1 e0 d3 d2 d1 d0 c3 c2 c1 c0
-
-        ; write out order: xmm0 xmm2 xmm1 xmm3
-        lea         rdx,        [rsi + rax*4]
-
-        movd        [rsi],      xmm1                               ; write the second 8-line result
-        psrldq      xmm1,       4
-        movd        [rdi],      xmm1
-        psrldq      xmm1,       4
-        movd        [rsi + rax*2], xmm1
-        psrldq      xmm1,       4
-        movd        [rdi + rax*2], xmm1
-
-        movd        [rdx],      xmm3
-        psrldq      xmm3,       4
-        movd        [rcx],      xmm3
-        psrldq      xmm3,       4
-        movd        [rdx + rax*2], xmm3
-        psrldq      xmm3,       4
-        movd        [rcx + rax*2], xmm3
-
-        neg         rax
-        lea         rsi,        [rsi + rax*8]
-        neg         rax
-        lea         rdi,        [rsi + rax]
-        lea         rdx,        [rsi + rax*4]
-        lea         rcx,        [rdx + rax]
-
-        movd        [rsi],      xmm0                                ; write the first 8-line result
-        psrldq      xmm0,       4
-        movd        [rdi],      xmm0
-        psrldq      xmm0,       4
-        movd        [rsi + rax*2], xmm0
-        psrldq      xmm0,       4
-        movd        [rdi + rax*2], xmm0
-
-        movd        [rdx],      xmm2
-        psrldq      xmm2,       4
-        movd        [rcx],      xmm2
-        psrldq      xmm2,       4
-        movd        [rdx + rax*2], xmm2
-        psrldq      xmm2,       4
-        movd        [rcx + rax*2], xmm2
-
-    add rsp, 32
-    pop rsp
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-SECTION_RODATA
-align 16
-tfe:
-    times 16 db 0xfe
-align 16
-t80:
-    times 16 db 0x80
-align 16
-t1s:
-    times 16 db 0x01
-align 16
-t3:
-    times 16 db 0x03
-align 16
-t4:
-    times 16 db 0x04
-align 16
-ones:
-    times 8 dw 0x0001
-align 16
-s27:
-    times 8 dw 0x1b00
-align 16
-s18:
-    times 8 dw 0x1200
-align 16
-s9:
-    times 8 dw 0x0900
-align 16
-s63:
-    times 8 dw 0x003f
diff --git a/vp8/common/x86/postproc_mmx.S b/vp8/common/x86/postproc_mmx.S
new file mode 100644
index 0000000..7ed7782
--- /dev/null
+++ b/vp8/common/x86/postproc_mmx.S
@@ -0,0 +1,533 @@
+//
+//  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
+//
+//  Use of this source code is governed by a BSD-style license and patent
+//  grant that can be found in the LICENSE file in the root of the source
+//  tree. All contributing project authors may be found in the AUTHORS
+//  file in the root of the source tree.
+//
+
+
+#include "vpx_ports/x86_abi_support.S"
+
+#define VP8_FILTER_WEIGHT 128
+#define VP8_FILTER_SHIFT  7
+
+//void vp8_post_proc_down_and_across_mmx
+//(
+//    unsigned char *src_ptr,
+//    unsigned char *dst_ptr,
+//    int src_pixels_per_line,
+//    int dst_pixels_per_line,
+//    int rows,
+//    int cols,
+//    int flimit
+//)
+global sym(vp8_post_proc_down_and_across_mmx)
+sym(vp8_post_proc_down_and_across_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 7
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+#if ABI_IS_32BIT && CONFIG_PIC
+    // move the global rd onto the stack, since we don't have enough registers
+    // to do PIC addressing
+    movq        mm0, [GLOBAL (rd)]
+    sub         rsp, 8
+    movq        [rsp], mm0
+# define RD [rsp]
+#else
+# define RD [GLOBAL (rd)]
+#endif
+
+        push        rbx
+        lea         rbx, [GLOBAL (Blur)]
+        movd        mm2, dword ptr arg(6) //flimit
+        punpcklwd   mm2, mm2
+        punpckldq   mm2, mm2
+
+        mov         rsi,        arg(0) //src_ptr
+        mov         rdi,        arg(1) //dst_ptr
+
+        movsxd      rcx, DWORD PTR arg(4) //rows
+        movsxd      rax, DWORD PTR arg(2) //src_pixels_per_line ; destination pitch?
+        pxor        mm0, mm0              // mm0 = 00000000
+
+nextrow:
+
+        xor         rdx,        rdx       // clear out rdx for use as loop counter
+nextcol:
+
+        pxor        mm7, mm7              // mm7 = 00000000
+        movq        mm6, [rbx + 32 ]      // mm6 = kernel 2 taps
+        movq        mm3, [rsi]            // mm4 = r0 p0..p7
+        punpcklbw   mm3, mm0              // mm3 = p0..p3
+        movq        mm1, mm3              // mm1 = p0..p3
+        pmullw      mm3, mm6              // mm3 *= kernel 2 modifiers
+
+        movq        mm6, [rbx + 48]       // mm6 = kernel 3 taps
+        movq        mm5, [rsi + rax]      // mm4 = r1 p0..p7
+        punpcklbw   mm5, mm0              // mm5 = r1 p0..p3
+        pmullw      mm6, mm5              // mm6 *= p0..p3 * kernel 3 modifiers
+        paddusw     mm3, mm6              // mm3 += mm6
+
+        // thresholding
+        movq        mm7, mm1              // mm7 = r0 p0..p3
+        psubusw     mm7, mm5              // mm7 = r0 p0..p3 - r1 p0..p3
+        psubusw     mm5, mm1              // mm5 = r1 p0..p3 - r0 p0..p3
+        paddusw     mm7, mm5              // mm7 = abs(r0 p0..p3 - r1 p0..p3)
+        pcmpgtw     mm7, mm2
+
+        movq        mm6, [rbx + 64 ]      // mm6 = kernel 4 modifiers
+        movq        mm5, [rsi + 2*rax]    // mm4 = r2 p0..p7
+        punpcklbw   mm5, mm0              // mm5 = r2 p0..p3
+        pmullw      mm6, mm5              // mm5 *= kernel 4 modifiers
+        paddusw     mm3, mm6              // mm3 += mm5
+
+        // thresholding
+        movq        mm6, mm1              // mm6 = r0 p0..p3
+        psubusw     mm6, mm5              // mm6 = r0 p0..p3 - r2 p0..p3
+        psubusw     mm5, mm1              // mm5 = r2 p0..p3 - r2 p0..p3
+        paddusw     mm6, mm5              // mm6 = abs(r0 p0..p3 - r2 p0..p3)
+        pcmpgtw     mm6, mm2
+        por         mm7, mm6              // accumulate thresholds
+
+
+        neg         rax
+        movq        mm6, [rbx ]           // kernel 0 taps
+        movq        mm5, [rsi+2*rax]      // mm4 = r-2 p0..p7
+        punpcklbw   mm5, mm0              // mm5 = r-2 p0..p3
+        pmullw      mm6, mm5              // mm5 *= kernel 0 modifiers
+        paddusw     mm3, mm6              // mm3 += mm5
+
+        // thresholding
+        movq        mm6, mm1              // mm6 = r0 p0..p3
+        psubusw     mm6, mm5              // mm6 = p0..p3 - r-2 p0..p3
+        psubusw     mm5, mm1              // mm5 = r-2 p0..p3 - p0..p3
+        paddusw     mm6, mm5              // mm6 = abs(r0 p0..p3 - r-2 p0..p3)
+        pcmpgtw     mm6, mm2
+        por         mm7, mm6              // accumulate thresholds
+
+        movq        mm6, [rbx + 16]       // kernel 1 taps
+        movq        mm4, [rsi+rax]        // mm4 = r-1 p0..p7
+        punpcklbw   mm4, mm0              // mm4 = r-1 p0..p3
+        pmullw      mm6, mm4              // mm4 *= kernel 1 modifiers.
+        paddusw     mm3, mm6              // mm3 += mm5
+
+        // thresholding
+        movq        mm6, mm1              // mm6 = r0 p0..p3
+        psubusw     mm6, mm4              // mm6 = p0..p3 - r-2 p0..p3
+        psubusw     mm4, mm1              // mm5 = r-1 p0..p3 - p0..p3
+        paddusw     mm6, mm4              // mm6 = abs(r0 p0..p3 - r-1 p0..p3)
+        pcmpgtw     mm6, mm2
+        por         mm7, mm6              // accumulate thresholds
+
+
+        paddusw     mm3, RD               // mm3 += round value
+        psraw       mm3, VP8_FILTER_SHIFT     // mm3 /= 128
+
+        pand        mm1, mm7              // mm1 select vals > thresh from source
+        pandn       mm7, mm3              // mm7 select vals < thresh from blurred result
+        paddusw     mm1, mm7              // combination
+
+        packuswb    mm1, mm0              // pack to bytes
+
+        movd        [rdi], mm1            //
+        neg         rax                   // pitch is positive
+
+
+        add         rsi, 4
+        add         rdi, 4
+        add         rdx, 4
+
+        cmp         edx, dword ptr arg(5) //cols
+        jl          nextcol
+        // done with the all cols, start the across filtering in place
+        sub         rsi, rdx
+        sub         rdi, rdx
+
+
+        push        rax
+        xor         rdx,    rdx
+        mov         rax,    [rdi-4];
+
+acrossnextcol:
+        pxor        mm7, mm7              // mm7 = 00000000
+        movq        mm6, [rbx + 32 ]      //
+        movq        mm4, [rdi+rdx]        // mm4 = p0..p7
+        movq        mm3, mm4              // mm3 = p0..p7
+        punpcklbw   mm3, mm0              // mm3 = p0..p3
+        movq        mm1, mm3              // mm1 = p0..p3
+        pmullw      mm3, mm6              // mm3 *= kernel 2 modifiers
+
+        movq        mm6, [rbx + 48]
+        psrlq       mm4, 8                // mm4 = p1..p7
+        movq        mm5, mm4              // mm5 = p1..p7
+        punpcklbw   mm5, mm0              // mm5 = p1..p4
+        pmullw      mm6, mm5              // mm6 *= p1..p4 * kernel 3 modifiers
+        paddusw     mm3, mm6              // mm3 += mm6
+
+        // thresholding
+        movq        mm7, mm1              // mm7 = p0..p3
+        psubusw     mm7, mm5              // mm7 = p0..p3 - p1..p4
+        psubusw     mm5, mm1              // mm5 = p1..p4 - p0..p3
+        paddusw     mm7, mm5              // mm7 = abs(p0..p3 - p1..p4)
+        pcmpgtw     mm7, mm2
+
+        movq        mm6, [rbx + 64 ]
+        psrlq       mm4, 8                // mm4 = p2..p7
+        movq        mm5, mm4              // mm5 = p2..p7
+        punpcklbw   mm5, mm0              // mm5 = p2..p5
+        pmullw      mm6, mm5              // mm5 *= kernel 4 modifiers
+        paddusw     mm3, mm6              // mm3 += mm5
+
+        // thresholding
+        movq        mm6, mm1              // mm6 = p0..p3
+        psubusw     mm6, mm5              // mm6 = p0..p3 - p1..p4
+        psubusw     mm5, mm1              // mm5 = p1..p4 - p0..p3
+        paddusw     mm6, mm5              // mm6 = abs(p0..p3 - p1..p4)
+        pcmpgtw     mm6, mm2
+        por         mm7, mm6              // accumulate thresholds
+
+
+        movq        mm6, [rbx ]
+        movq        mm4, [rdi+rdx-2]      // mm4 = p-2..p5
+        movq        mm5, mm4              // mm5 = p-2..p5
+        punpcklbw   mm5, mm0              // mm5 = p-2..p1
+        pmullw      mm6, mm5              // mm5 *= kernel 0 modifiers
+        paddusw     mm3, mm6              // mm3 += mm5
+
+        // thresholding
+        movq        mm6, mm1              // mm6 = p0..p3
+        psubusw     mm6, mm5              // mm6 = p0..p3 - p1..p4
+        psubusw     mm5, mm1              // mm5 = p1..p4 - p0..p3
+        paddusw     mm6, mm5              // mm6 = abs(p0..p3 - p1..p4)
+        pcmpgtw     mm6, mm2
+        por         mm7, mm6              // accumulate thresholds
+
+        movq        mm6, [rbx + 16]
+        psrlq       mm4, 8                // mm4 = p-1..p5
+        punpcklbw   mm4, mm0              // mm4 = p-1..p2
+        pmullw      mm6, mm4              // mm4 *= kernel 1 modifiers.
+        paddusw     mm3, mm6              // mm3 += mm5
+
+        // thresholding
+        movq        mm6, mm1              // mm6 = p0..p3
+        psubusw     mm6, mm4              // mm6 = p0..p3 - p1..p4
+        psubusw     mm4, mm1              // mm5 = p1..p4 - p0..p3
+        paddusw     mm6, mm4              // mm6 = abs(p0..p3 - p1..p4)
+        pcmpgtw     mm6, mm2
+        por         mm7, mm6              // accumulate thresholds
+
+        paddusw     mm3, RD               // mm3 += round value
+        psraw       mm3, VP8_FILTER_SHIFT     // mm3 /= 128
+
+        pand        mm1, mm7              // mm1 select vals > thresh from source
+        pandn       mm7, mm3              // mm7 select vals < thresh from blurred result
+        paddusw     mm1, mm7              // combination
+
+        packuswb    mm1, mm0              // pack to bytes
+        mov         DWORD PTR [rdi+rdx-4],  eax   // store previous four bytes
+        movd        eax,    mm1
+
+        add         rdx, 4
+        cmp         edx, dword ptr arg(5) //cols
+        jl          acrossnextcol;
+
+        mov         DWORD PTR [rdi+rdx-4],  eax
+        pop         rax
+
+        // done with this rwo
+        add         rsi,rax               // next line
+        movsxd      rax, dword ptr arg(3) //dst_pixels_per_line ; destination pitch?
+        add         rdi,rax               // next destination
+        movsxd      rax, dword ptr arg(2) //src_pixels_per_line ; destination pitch?
+
+        dec         rcx                   // decrement count
+        jnz         nextrow               // next row
+        pop         rbx
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+#undef RD
+
+
+//void vp8_mbpost_proc_down_mmx(unsigned char *dst,
+//                             int pitch, int rows, int cols,int flimit)
+extern sym(vp8_rv)
+global sym(vp8_mbpost_proc_down_mmx)
+sym(vp8_mbpost_proc_down_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 5
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+    ALIGN_STACK 16, rax
+    sub         rsp, 136
+
+    // unsigned char d[16][8] at [rsp]
+    // create flimit2 at [rsp+128]
+    mov         eax, dword ptr arg(4) //flimit
+    mov         [rsp+128], eax
+    mov         [rsp+128+4], eax
+#define flimit2 [rsp+128]
+
+#if ! ABI_IS_32BIT
+    lea         r8,       [GLOBAL (sym(vp8_rv))]
+#endif
+
+    //rows +=8;
+    add         dword ptr arg(2), 8
+
+    //for(c=0; c<cols; c+=4)
+loop_col:
+            mov         rsi,        arg(0)  //s
+            pxor        mm0,        mm0     //
+
+            movsxd      rax,        dword ptr arg(1) //pitch       ;
+            neg         rax                                     // rax = -pitch
+
+            lea         rsi,        [rsi + rax*8];              // rdi = s[-pitch*8]
+            neg         rax
+
+
+            pxor        mm5,        mm5
+            pxor        mm6,        mm6     //
+
+            pxor        mm7,        mm7     //
+            mov         rdi,        rsi
+
+            mov         rcx,        15          //
+
+loop_initvar:
+            movd        mm1,        DWORD PTR [rdi];
+            punpcklbw   mm1,        mm0     //
+
+            paddw       mm5,        mm1     //
+            pmullw      mm1,        mm1     //
+
+            movq        mm2,        mm1     //
+            punpcklwd   mm1,        mm0     //
+
+            punpckhwd   mm2,        mm0     //
+            paddd       mm6,        mm1     //
+
+            paddd       mm7,        mm2     //
+            lea         rdi,        [rdi+rax]   //
+
+            dec         rcx
+            jne         loop_initvar
+            //save the var and sum
+            xor         rdx,        rdx
+loop_row:
+            movd        mm1,        DWORD PTR [rsi]     // [s-pitch*8]
+            movd        mm2,        DWORD PTR [rdi]     // [s+pitch*7]
+
+            punpcklbw   mm1,        mm0
+            punpcklbw   mm2,        mm0
+
+            paddw       mm5,        mm2
+            psubw       mm5,        mm1
+
+            pmullw      mm2,        mm2
+            movq        mm4,        mm2
+
+            punpcklwd   mm2,        mm0
+            punpckhwd   mm4,        mm0
+
+            paddd       mm6,        mm2
+            paddd       mm7,        mm4
+
+            pmullw      mm1,        mm1
+            movq        mm2,        mm1
+
+            punpcklwd   mm1,        mm0
+            psubd       mm6,        mm1
+
+            punpckhwd   mm2,        mm0
+            psubd       mm7,        mm2
+
+
+            movq        mm3,        mm6
+            pslld       mm3,        4
+
+            psubd       mm3,        mm6
+            movq        mm1,        mm5
+
+            movq        mm4,        mm5
+            pmullw      mm1,        mm1
+
+            pmulhw      mm4,        mm4
+            movq        mm2,        mm1
+
+            punpcklwd   mm1,        mm4
+            punpckhwd   mm2,        mm4
+
+            movq        mm4,        mm7
+            pslld       mm4,        4
+
+            psubd       mm4,        mm7
+
+            psubd       mm3,        mm1
+            psubd       mm4,        mm2
+
+            psubd       mm3,        flimit2
+            psubd       mm4,        flimit2
+
+            psrad       mm3,        31
+            psrad       mm4,        31
+
+            packssdw    mm3,        mm4
+            packsswb    mm3,        mm0
+
+            movd        mm1,        DWORD PTR [rsi+rax*8]
+
+            movq        mm2,        mm1
+            punpcklbw   mm1,        mm0
+
+            paddw       mm1,        mm5
+            mov         rcx,        rdx
+
+            and         rcx,        127
+#if ABI_IS_32BIT && CONFIG_PIC
+            push        rax
+            lea         rax,        [GLOBAL (sym(vp8_rv))]
+            movq        mm4,        [rax + rcx*2] //vp8_rv[rcx*2]
+            pop         rax
+#elif ! ABI_IS_32BIT
+            movq        mm4,        [r8 + rcx*2] //vp8_rv[rcx*2]
+#else
+            movq        mm4,        [sym(vp8_rv) + rcx*2]
+#endif
+            paddw       mm1,        mm4
+            //paddw     xmm1,       eight8s
+            psraw       mm1,        4
+
+            packuswb    mm1,        mm0
+            pand        mm1,        mm3
+
+            pandn       mm3,        mm2
+            por         mm1,        mm3
+
+            and         rcx,        15
+            movd        DWORD PTR   [rsp+rcx*4], mm1 //d[rcx*4]
+
+            mov         rcx,        rdx
+            sub         rcx,        8
+
+            and         rcx,        15
+            movd        mm1,        DWORD PTR [rsp+rcx*4] //d[rcx*4]
+
+            movd        [rsi],      mm1
+            lea         rsi,        [rsi+rax]
+
+            lea         rdi,        [rdi+rax]
+            add         rdx,        1
+
+            cmp         edx,        dword ptr arg(2) //rows
+            jl          loop_row
+
+
+        add         dword ptr arg(0), 4 // s += 4
+        sub         dword ptr arg(3), 4 // cols -= 4
+        cmp         dword ptr arg(3), 0
+        jg          loop_col
+
+    add         rsp, 136
+    pop         rsp
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+#undef flimit2
+
+
+//void vp8_plane_add_noise_mmx (unsigned char *Start, unsigned char *noise,
+//                            unsigned char blackclamp[16],
+//                            unsigned char whiteclamp[16],
+//                            unsigned char bothclamp[16],
+//                            unsigned int Width, unsigned int Height, int Pitch)
+extern sym(rand)
+global sym(vp8_plane_add_noise_mmx)
+sym(vp8_plane_add_noise_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 8
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+addnoise_loop:
+    call WRT_PLT (sym (rand))
+    mov     rcx, arg(1) //noise
+    and     rax, 0xff
+    add     rcx, rax
+
+    // we rely on the fact that the clamping vectors are stored contiguously
+    // in black/white/both order. Note that we have to reload this here because
+    // rdx could be trashed by rand()
+    mov     rdx, arg(2) // blackclamp
+
+
+            mov     rdi, rcx
+            movsxd  rcx, dword ptr arg(5) //[Width]
+            mov     rsi, arg(0) //Pos
+            xor         rax,rax
+
+addnoise_nextset:
+            movq        mm1,[rsi+rax]         // get the source
+
+            psubusb     mm1, [rdx]    //blackclamp        ; clamp both sides so we don't outrange adding noise
+            paddusb     mm1, [rdx+32] //bothclamp
+            psubusb     mm1, [rdx+16] //whiteclamp
+
+            movq        mm2,[rdi+rax]         // get the noise for this line
+            paddb       mm1,mm2              // add it in
+            movq        [rsi+rax],mm1         // store the result
+
+            add         rax,8                 // move to the next line
+
+            cmp         rax, rcx
+            jl          addnoise_nextset
+
+    movsxd  rax, dword ptr arg(7) // Pitch
+    add     arg(0), rax // Start += Pitch
+    sub     dword ptr arg(6), 1   // Height -= 1
+    jg      addnoise_loop
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+SECTION_RODATA
+align 16
+Blur:
+    .fill 16, 2, 16
+    .fill  8, 2, 64
+    .fill 16, 2, 16
+    .fill  8, 2,  0
+
+rd:
+    .fill 4, 2, 0x40
diff --git a/vp8/common/x86/postproc_mmx.asm b/vp8/common/x86/postproc_mmx.asm
deleted file mode 100644
index 721c8d6..0000000
--- a/vp8/common/x86/postproc_mmx.asm
+++ /dev/null
@@ -1,533 +0,0 @@
-;
-;  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
-;
-;  Use of this source code is governed by a BSD-style license and patent
-;  grant that can be found in the LICENSE file in the root of the source
-;  tree. All contributing project authors may be found in the AUTHORS
-;  file in the root of the source tree.
-;
-
-
-%include "vpx_ports/x86_abi_support.asm"
-
-%define VP8_FILTER_WEIGHT 128
-%define VP8_FILTER_SHIFT  7
-
-;void vp8_post_proc_down_and_across_mmx
-;(
-;    unsigned char *src_ptr,
-;    unsigned char *dst_ptr,
-;    int src_pixels_per_line,
-;    int dst_pixels_per_line,
-;    int rows,
-;    int cols,
-;    int flimit
-;)
-global sym(vp8_post_proc_down_and_across_mmx)
-sym(vp8_post_proc_down_and_across_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 7
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-%if ABI_IS_32BIT=1 && CONFIG_PIC=1
-    ; move the global rd onto the stack, since we don't have enough registers
-    ; to do PIC addressing
-    movq        mm0, [rd GLOBAL]
-    sub         rsp, 8
-    movq        [rsp], mm0
-%define RD [rsp]
-%else
-%define RD [rd GLOBAL]
-%endif
-
-        push        rbx
-        lea         rbx, [Blur GLOBAL]
-        movd        mm2, dword ptr arg(6) ;flimit
-        punpcklwd   mm2, mm2
-        punpckldq   mm2, mm2
-
-        mov         rsi,        arg(0) ;src_ptr
-        mov         rdi,        arg(1) ;dst_ptr
-
-        movsxd      rcx, DWORD PTR arg(4) ;rows
-        movsxd      rax, DWORD PTR arg(2) ;src_pixels_per_line ; destination pitch?
-        pxor        mm0, mm0              ; mm0 = 00000000
-
-nextrow:
-
-        xor         rdx,        rdx       ; clear out rdx for use as loop counter
-nextcol:
-
-        pxor        mm7, mm7              ; mm7 = 00000000
-        movq        mm6, [rbx + 32 ]      ; mm6 = kernel 2 taps
-        movq        mm3, [rsi]            ; mm4 = r0 p0..p7
-        punpcklbw   mm3, mm0              ; mm3 = p0..p3
-        movq        mm1, mm3              ; mm1 = p0..p3
-        pmullw      mm3, mm6              ; mm3 *= kernel 2 modifiers
-
-        movq        mm6, [rbx + 48]       ; mm6 = kernel 3 taps
-        movq        mm5, [rsi + rax]      ; mm4 = r1 p0..p7
-        punpcklbw   mm5, mm0              ; mm5 = r1 p0..p3
-        pmullw      mm6, mm5              ; mm6 *= p0..p3 * kernel 3 modifiers
-        paddusw     mm3, mm6              ; mm3 += mm6
-
-        ; thresholding
-        movq        mm7, mm1              ; mm7 = r0 p0..p3
-        psubusw     mm7, mm5              ; mm7 = r0 p0..p3 - r1 p0..p3
-        psubusw     mm5, mm1              ; mm5 = r1 p0..p3 - r0 p0..p3
-        paddusw     mm7, mm5              ; mm7 = abs(r0 p0..p3 - r1 p0..p3)
-        pcmpgtw     mm7, mm2
-
-        movq        mm6, [rbx + 64 ]      ; mm6 = kernel 4 modifiers
-        movq        mm5, [rsi + 2*rax]    ; mm4 = r2 p0..p7
-        punpcklbw   mm5, mm0              ; mm5 = r2 p0..p3
-        pmullw      mm6, mm5              ; mm5 *= kernel 4 modifiers
-        paddusw     mm3, mm6              ; mm3 += mm5
-
-        ; thresholding
-        movq        mm6, mm1              ; mm6 = r0 p0..p3
-        psubusw     mm6, mm5              ; mm6 = r0 p0..p3 - r2 p0..p3
-        psubusw     mm5, mm1              ; mm5 = r2 p0..p3 - r2 p0..p3
-        paddusw     mm6, mm5              ; mm6 = abs(r0 p0..p3 - r2 p0..p3)
-        pcmpgtw     mm6, mm2
-        por         mm7, mm6              ; accumulate thresholds
-
-
-        neg         rax
-        movq        mm6, [rbx ]           ; kernel 0 taps
-        movq        mm5, [rsi+2*rax]      ; mm4 = r-2 p0..p7
-        punpcklbw   mm5, mm0              ; mm5 = r-2 p0..p3
-        pmullw      mm6, mm5              ; mm5 *= kernel 0 modifiers
-        paddusw     mm3, mm6              ; mm3 += mm5
-
-        ; thresholding
-        movq        mm6, mm1              ; mm6 = r0 p0..p3
-        psubusw     mm6, mm5              ; mm6 = p0..p3 - r-2 p0..p3
-        psubusw     mm5, mm1              ; mm5 = r-2 p0..p3 - p0..p3
-        paddusw     mm6, mm5              ; mm6 = abs(r0 p0..p3 - r-2 p0..p3)
-        pcmpgtw     mm6, mm2
-        por         mm7, mm6              ; accumulate thresholds
-
-        movq        mm6, [rbx + 16]       ; kernel 1 taps
-        movq        mm4, [rsi+rax]        ; mm4 = r-1 p0..p7
-        punpcklbw   mm4, mm0              ; mm4 = r-1 p0..p3
-        pmullw      mm6, mm4              ; mm4 *= kernel 1 modifiers.
-        paddusw     mm3, mm6              ; mm3 += mm5
-
-        ; thresholding
-        movq        mm6, mm1              ; mm6 = r0 p0..p3
-        psubusw     mm6, mm4              ; mm6 = p0..p3 - r-2 p0..p3
-        psubusw     mm4, mm1              ; mm5 = r-1 p0..p3 - p0..p3
-        paddusw     mm6, mm4              ; mm6 = abs(r0 p0..p3 - r-1 p0..p3)
-        pcmpgtw     mm6, mm2
-        por         mm7, mm6              ; accumulate thresholds
-
-
-        paddusw     mm3, RD               ; mm3 += round value
-        psraw       mm3, VP8_FILTER_SHIFT     ; mm3 /= 128
-
-        pand        mm1, mm7              ; mm1 select vals > thresh from source
-        pandn       mm7, mm3              ; mm7 select vals < thresh from blurred result
-        paddusw     mm1, mm7              ; combination
-
-        packuswb    mm1, mm0              ; pack to bytes
-
-        movd        [rdi], mm1            ;
-        neg         rax                   ; pitch is positive
-
-
-        add         rsi, 4
-        add         rdi, 4
-        add         rdx, 4
-
-        cmp         edx, dword ptr arg(5) ;cols
-        jl          nextcol
-        ; done with the all cols, start the across filtering in place
-        sub         rsi, rdx
-        sub         rdi, rdx
-
-
-        push        rax
-        xor         rdx,    rdx
-        mov         rax,    [rdi-4];
-
-acrossnextcol:
-        pxor        mm7, mm7              ; mm7 = 00000000
-        movq        mm6, [rbx + 32 ]      ;
-        movq        mm4, [rdi+rdx]        ; mm4 = p0..p7
-        movq        mm3, mm4              ; mm3 = p0..p7
-        punpcklbw   mm3, mm0              ; mm3 = p0..p3
-        movq        mm1, mm3              ; mm1 = p0..p3
-        pmullw      mm3, mm6              ; mm3 *= kernel 2 modifiers
-
-        movq        mm6, [rbx + 48]
-        psrlq       mm4, 8                ; mm4 = p1..p7
-        movq        mm5, mm4              ; mm5 = p1..p7
-        punpcklbw   mm5, mm0              ; mm5 = p1..p4
-        pmullw      mm6, mm5              ; mm6 *= p1..p4 * kernel 3 modifiers
-        paddusw     mm3, mm6              ; mm3 += mm6
-
-        ; thresholding
-        movq        mm7, mm1              ; mm7 = p0..p3
-        psubusw     mm7, mm5              ; mm7 = p0..p3 - p1..p4
-        psubusw     mm5, mm1              ; mm5 = p1..p4 - p0..p3
-        paddusw     mm7, mm5              ; mm7 = abs(p0..p3 - p1..p4)
-        pcmpgtw     mm7, mm2
-
-        movq        mm6, [rbx + 64 ]
-        psrlq       mm4, 8                ; mm4 = p2..p7
-        movq        mm5, mm4              ; mm5 = p2..p7
-        punpcklbw   mm5, mm0              ; mm5 = p2..p5
-        pmullw      mm6, mm5              ; mm5 *= kernel 4 modifiers
-        paddusw     mm3, mm6              ; mm3 += mm5
-
-        ; thresholding
-        movq        mm6, mm1              ; mm6 = p0..p3
-        psubusw     mm6, mm5              ; mm6 = p0..p3 - p1..p4
-        psubusw     mm5, mm1              ; mm5 = p1..p4 - p0..p3
-        paddusw     mm6, mm5              ; mm6 = abs(p0..p3 - p1..p4)
-        pcmpgtw     mm6, mm2
-        por         mm7, mm6              ; accumulate thresholds
-
-
-        movq        mm6, [rbx ]
-        movq        mm4, [rdi+rdx-2]      ; mm4 = p-2..p5
-        movq        mm5, mm4              ; mm5 = p-2..p5
-        punpcklbw   mm5, mm0              ; mm5 = p-2..p1
-        pmullw      mm6, mm5              ; mm5 *= kernel 0 modifiers
-        paddusw     mm3, mm6              ; mm3 += mm5
-
-        ; thresholding
-        movq        mm6, mm1              ; mm6 = p0..p3
-        psubusw     mm6, mm5              ; mm6 = p0..p3 - p1..p4
-        psubusw     mm5, mm1              ; mm5 = p1..p4 - p0..p3
-        paddusw     mm6, mm5              ; mm6 = abs(p0..p3 - p1..p4)
-        pcmpgtw     mm6, mm2
-        por         mm7, mm6              ; accumulate thresholds
-
-        movq        mm6, [rbx + 16]
-        psrlq       mm4, 8                ; mm4 = p-1..p5
-        punpcklbw   mm4, mm0              ; mm4 = p-1..p2
-        pmullw      mm6, mm4              ; mm4 *= kernel 1 modifiers.
-        paddusw     mm3, mm6              ; mm3 += mm5
-
-        ; thresholding
-        movq        mm6, mm1              ; mm6 = p0..p3
-        psubusw     mm6, mm4              ; mm6 = p0..p3 - p1..p4
-        psubusw     mm4, mm1              ; mm5 = p1..p4 - p0..p3
-        paddusw     mm6, mm4              ; mm6 = abs(p0..p3 - p1..p4)
-        pcmpgtw     mm6, mm2
-        por         mm7, mm6              ; accumulate thresholds
-
-        paddusw     mm3, RD               ; mm3 += round value
-        psraw       mm3, VP8_FILTER_SHIFT     ; mm3 /= 128
-
-        pand        mm1, mm7              ; mm1 select vals > thresh from source
-        pandn       mm7, mm3              ; mm7 select vals < thresh from blurred result
-        paddusw     mm1, mm7              ; combination
-
-        packuswb    mm1, mm0              ; pack to bytes
-        mov         DWORD PTR [rdi+rdx-4],  eax   ; store previous four bytes
-        movd        eax,    mm1
-
-        add         rdx, 4
-        cmp         edx, dword ptr arg(5) ;cols
-        jl          acrossnextcol;
-
-        mov         DWORD PTR [rdi+rdx-4],  eax
-        pop         rax
-
-        ; done with this rwo
-        add         rsi,rax               ; next line
-        movsxd      rax, dword ptr arg(3) ;dst_pixels_per_line ; destination pitch?
-        add         rdi,rax               ; next destination
-        movsxd      rax, dword ptr arg(2) ;src_pixels_per_line ; destination pitch?
-
-        dec         rcx                   ; decrement count
-        jnz         nextrow               ; next row
-        pop         rbx
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-%undef RD
-
-
-;void vp8_mbpost_proc_down_mmx(unsigned char *dst,
-;                             int pitch, int rows, int cols,int flimit)
-extern sym(vp8_rv)
-global sym(vp8_mbpost_proc_down_mmx)
-sym(vp8_mbpost_proc_down_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 5
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-    ALIGN_STACK 16, rax
-    sub         rsp, 136
-
-    ; unsigned char d[16][8] at [rsp]
-    ; create flimit2 at [rsp+128]
-    mov         eax, dword ptr arg(4) ;flimit
-    mov         [rsp+128], eax
-    mov         [rsp+128+4], eax
-%define flimit2 [rsp+128]
-
-%if ABI_IS_32BIT=0
-    lea         r8,       [sym(vp8_rv) GLOBAL]
-%endif
-
-    ;rows +=8;
-    add         dword ptr arg(2), 8
-
-    ;for(c=0; c<cols; c+=4)
-loop_col:
-            mov         rsi,        arg(0)  ;s
-            pxor        mm0,        mm0     ;
-
-            movsxd      rax,        dword ptr arg(1) ;pitch       ;
-            neg         rax                                     ; rax = -pitch
-
-            lea         rsi,        [rsi + rax*8];              ; rdi = s[-pitch*8]
-            neg         rax
-
-
-            pxor        mm5,        mm5
-            pxor        mm6,        mm6     ;
-
-            pxor        mm7,        mm7     ;
-            mov         rdi,        rsi
-
-            mov         rcx,        15          ;
-
-loop_initvar:
-            movd        mm1,        DWORD PTR [rdi];
-            punpcklbw   mm1,        mm0     ;
-
-            paddw       mm5,        mm1     ;
-            pmullw      mm1,        mm1     ;
-
-            movq        mm2,        mm1     ;
-            punpcklwd   mm1,        mm0     ;
-
-            punpckhwd   mm2,        mm0     ;
-            paddd       mm6,        mm1     ;
-
-            paddd       mm7,        mm2     ;
-            lea         rdi,        [rdi+rax]   ;
-
-            dec         rcx
-            jne         loop_initvar
-            ;save the var and sum
-            xor         rdx,        rdx
-loop_row:
-            movd        mm1,        DWORD PTR [rsi]     ; [s-pitch*8]
-            movd        mm2,        DWORD PTR [rdi]     ; [s+pitch*7]
-
-            punpcklbw   mm1,        mm0
-            punpcklbw   mm2,        mm0
-
-            paddw       mm5,        mm2
-            psubw       mm5,        mm1
-
-            pmullw      mm2,        mm2
-            movq        mm4,        mm2
-
-            punpcklwd   mm2,        mm0
-            punpckhwd   mm4,        mm0
-
-            paddd       mm6,        mm2
-            paddd       mm7,        mm4
-
-            pmullw      mm1,        mm1
-            movq        mm2,        mm1
-
-            punpcklwd   mm1,        mm0
-            psubd       mm6,        mm1
-
-            punpckhwd   mm2,        mm0
-            psubd       mm7,        mm2
-
-
-            movq        mm3,        mm6
-            pslld       mm3,        4
-
-            psubd       mm3,        mm6
-            movq        mm1,        mm5
-
-            movq        mm4,        mm5
-            pmullw      mm1,        mm1
-
-            pmulhw      mm4,        mm4
-            movq        mm2,        mm1
-
-            punpcklwd   mm1,        mm4
-            punpckhwd   mm2,        mm4
-
-            movq        mm4,        mm7
-            pslld       mm4,        4
-
-            psubd       mm4,        mm7
-
-            psubd       mm3,        mm1
-            psubd       mm4,        mm2
-
-            psubd       mm3,        flimit2
-            psubd       mm4,        flimit2
-
-            psrad       mm3,        31
-            psrad       mm4,        31
-
-            packssdw    mm3,        mm4
-            packsswb    mm3,        mm0
-
-            movd        mm1,        DWORD PTR [rsi+rax*8]
-
-            movq        mm2,        mm1
-            punpcklbw   mm1,        mm0
-
-            paddw       mm1,        mm5
-            mov         rcx,        rdx
-
-            and         rcx,        127
-%if ABI_IS_32BIT=1 && CONFIG_PIC=1
-            push        rax
-            lea         rax,        [sym(vp8_rv) GLOBAL]
-            movq        mm4,        [rax + rcx*2] ;vp8_rv[rcx*2]
-            pop         rax
-%elif ABI_IS_32BIT=0
-            movq        mm4,        [r8 + rcx*2] ;vp8_rv[rcx*2]
-%else
-            movq        mm4,        [sym(vp8_rv) + rcx*2]
-%endif
-            paddw       mm1,        mm4
-            ;paddw     xmm1,       eight8s
-            psraw       mm1,        4
-
-            packuswb    mm1,        mm0
-            pand        mm1,        mm3
-
-            pandn       mm3,        mm2
-            por         mm1,        mm3
-
-            and         rcx,        15
-            movd        DWORD PTR   [rsp+rcx*4], mm1 ;d[rcx*4]
-
-            mov         rcx,        rdx
-            sub         rcx,        8
-
-            and         rcx,        15
-            movd        mm1,        DWORD PTR [rsp+rcx*4] ;d[rcx*4]
-
-            movd        [rsi],      mm1
-            lea         rsi,        [rsi+rax]
-
-            lea         rdi,        [rdi+rax]
-            add         rdx,        1
-
-            cmp         edx,        dword arg(2) ;rows
-            jl          loop_row
-
-
-        add         dword arg(0), 4 ; s += 4
-        sub         dword arg(3), 4 ; cols -= 4
-        cmp         dword arg(3), 0
-        jg          loop_col
-
-    add         rsp, 136
-    pop         rsp
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-%undef flimit2
-
-
-;void vp8_plane_add_noise_mmx (unsigned char *Start, unsigned char *noise,
-;                            unsigned char blackclamp[16],
-;                            unsigned char whiteclamp[16],
-;                            unsigned char bothclamp[16],
-;                            unsigned int Width, unsigned int Height, int Pitch)
-extern sym(rand)
-global sym(vp8_plane_add_noise_mmx)
-sym(vp8_plane_add_noise_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 8
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-addnoise_loop:
-    call sym(rand) WRT_PLT
-    mov     rcx, arg(1) ;noise
-    and     rax, 0xff
-    add     rcx, rax
-
-    ; we rely on the fact that the clamping vectors are stored contiguously
-    ; in black/white/both order. Note that we have to reload this here because
-    ; rdx could be trashed by rand()
-    mov     rdx, arg(2) ; blackclamp
-
-
-            mov     rdi, rcx
-            movsxd  rcx, dword arg(5) ;[Width]
-            mov     rsi, arg(0) ;Pos
-            xor         rax,rax
-
-addnoise_nextset:
-            movq        mm1,[rsi+rax]         ; get the source
-
-            psubusb     mm1, [rdx]    ;blackclamp        ; clamp both sides so we don't outrange adding noise
-            paddusb     mm1, [rdx+32] ;bothclamp
-            psubusb     mm1, [rdx+16] ;whiteclamp
-
-            movq        mm2,[rdi+rax]         ; get the noise for this line
-            paddb       mm1,mm2              ; add it in
-            movq        [rsi+rax],mm1         ; store the result
-
-            add         rax,8                 ; move to the next line
-
-            cmp         rax, rcx
-            jl          addnoise_nextset
-
-    movsxd  rax, dword arg(7) ; Pitch
-    add     arg(0), rax ; Start += Pitch
-    sub     dword arg(6), 1   ; Height -= 1
-    jg      addnoise_loop
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-SECTION_RODATA
-align 16
-Blur:
-    times 16 dw 16
-    times  8 dw 64
-    times 16 dw 16
-    times  8 dw  0
-
-rd:
-    times 4 dw 0x40
diff --git a/vp8/common/x86/postproc_sse2.S b/vp8/common/x86/postproc_sse2.S
new file mode 100644
index 0000000..4e1ce8c
--- /dev/null
+++ b/vp8/common/x86/postproc_sse2.S
@@ -0,0 +1,688 @@
+//
+//  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
+//
+//  Use of this source code is governed by a BSD-style license and patent
+//  grant that can be found in the LICENSE file in the root of the source
+//  tree. All contributing project authors may be found in the AUTHORS
+//  file in the root of the source tree.
+//
+
+
+#include "vpx_ports/x86_abi_support.S"
+
+//void vp8_post_proc_down_and_across_xmm
+//(
+//    unsigned char *src_ptr,
+//    unsigned char *dst_ptr,
+//    int src_pixels_per_line,
+//    int dst_pixels_per_line,
+//    int rows,
+//    int cols,
+//    int flimit
+//)
+global sym(vp8_post_proc_down_and_across_xmm)
+sym(vp8_post_proc_down_and_across_xmm):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 7
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+#if ABI_IS_32BIT && CONFIG_PIC
+    ALIGN_STACK 16, rax
+    // move the global rd onto the stack, since we don't have enough registers
+    // to do PIC addressing
+    movdqa      xmm0, [GLOBAL (rd42)]
+    sub         rsp, 16
+    movdqa      [rsp], xmm0
+# define RD42 [rsp]
+#else
+# define RD42 [GLOBAL (rd42)]
+#endif
+
+
+        movd        xmm2,       dword ptr arg(6) //flimit
+        punpcklwd   xmm2,       xmm2
+        punpckldq   xmm2,       xmm2
+        punpcklqdq  xmm2,       xmm2
+
+        mov         rsi,        arg(0) //src_ptr
+        mov         rdi,        arg(1) //dst_ptr
+
+        movsxd      rcx,        DWORD PTR arg(4) //rows
+        movsxd      rax,        DWORD PTR arg(2) //src_pixels_per_line ; destination pitch?
+        pxor        xmm0,       xmm0              // mm0 = 00000000
+
+nextrow:
+
+        xor         rdx,        rdx       // clear out rdx for use as loop counter
+nextcol:
+        movq        xmm3,       QWORD PTR [rsi]         // mm4 = r0 p0..p7
+        punpcklbw   xmm3,       xmm0                    // mm3 = p0..p3
+        movdqa      xmm1,       xmm3                    // mm1 = p0..p3
+        psllw       xmm3,       2                       //
+
+        movq        xmm5,       QWORD PTR [rsi + rax]   // mm4 = r1 p0..p7
+        punpcklbw   xmm5,       xmm0                    // mm5 = r1 p0..p3
+        paddusw     xmm3,       xmm5                    // mm3 += mm6
+
+        // thresholding
+        movdqa      xmm7,       xmm1                    // mm7 = r0 p0..p3
+        psubusw     xmm7,       xmm5                    // mm7 = r0 p0..p3 - r1 p0..p3
+        psubusw     xmm5,       xmm1                    // mm5 = r1 p0..p3 - r0 p0..p3
+        paddusw     xmm7,       xmm5                    // mm7 = abs(r0 p0..p3 - r1 p0..p3)
+        pcmpgtw     xmm7,       xmm2
+
+        movq        xmm5,       QWORD PTR [rsi + 2*rax] // mm4 = r2 p0..p7
+        punpcklbw   xmm5,       xmm0                    // mm5 = r2 p0..p3
+        paddusw     xmm3,       xmm5                    // mm3 += mm5
+
+        // thresholding
+        movdqa      xmm6,       xmm1                    // mm6 = r0 p0..p3
+        psubusw     xmm6,       xmm5                    // mm6 = r0 p0..p3 - r2 p0..p3
+        psubusw     xmm5,       xmm1                    // mm5 = r2 p0..p3 - r2 p0..p3
+        paddusw     xmm6,       xmm5                    // mm6 = abs(r0 p0..p3 - r2 p0..p3)
+        pcmpgtw     xmm6,       xmm2
+        por         xmm7,       xmm6                    // accumulate thresholds
+
+
+        neg         rax
+        movq        xmm5,       QWORD PTR [rsi+2*rax]   // mm4 = r-2 p0..p7
+        punpcklbw   xmm5,       xmm0                    // mm5 = r-2 p0..p3
+        paddusw     xmm3,       xmm5                    // mm3 += mm5
+
+        // thresholding
+        movdqa      xmm6,       xmm1                    // mm6 = r0 p0..p3
+        psubusw     xmm6,       xmm5                    // mm6 = p0..p3 - r-2 p0..p3
+        psubusw     xmm5,       xmm1                    // mm5 = r-2 p0..p3 - p0..p3
+        paddusw     xmm6,       xmm5                    // mm6 = abs(r0 p0..p3 - r-2 p0..p3)
+        pcmpgtw     xmm6,       xmm2
+        por         xmm7,       xmm6                    // accumulate thresholds
+
+        movq        xmm4,       QWORD PTR [rsi+rax]     // mm4 = r-1 p0..p7
+        punpcklbw   xmm4,       xmm0                    // mm4 = r-1 p0..p3
+        paddusw     xmm3,       xmm4                    // mm3 += mm5
+
+        // thresholding
+        movdqa      xmm6,       xmm1                    // mm6 = r0 p0..p3
+        psubusw     xmm6,       xmm4                    // mm6 = p0..p3 - r-2 p0..p3
+        psubusw     xmm4,       xmm1                    // mm5 = r-1 p0..p3 - p0..p3
+        paddusw     xmm6,       xmm4                    // mm6 = abs(r0 p0..p3 - r-1 p0..p3)
+        pcmpgtw     xmm6,       xmm2
+        por         xmm7,       xmm6                    // accumulate thresholds
+
+
+        paddusw     xmm3,       RD42                    // mm3 += round value
+        psraw       xmm3,       3                       // mm3 /= 8
+
+        pand        xmm1,       xmm7                    // mm1 select vals > thresh from source
+        pandn       xmm7,       xmm3                    // mm7 select vals < thresh from blurred result
+        paddusw     xmm1,       xmm7                    // combination
+
+        packuswb    xmm1,       xmm0                    // pack to bytes
+        movq        QWORD PTR [rdi], xmm1             //
+
+        neg         rax                   // pitch is positive
+        add         rsi,        8
+        add         rdi,        8
+
+        add         rdx,        8
+        cmp         edx,        dword ptr arg(5) //cols
+
+        jl          nextcol
+
+        // done with the all cols, start the across filtering in place
+        sub         rsi,        rdx
+        sub         rdi,        rdx
+
+        xor         rdx,        rdx
+        movq        mm0,        QWORD PTR [rdi-8];
+
+acrossnextcol:
+        movq        xmm7,       QWORD PTR [rdi +rdx -2]
+        movd        xmm4,       DWORD PTR [rdi +rdx +6]
+
+        pslldq      xmm4,       8
+        por         xmm4,       xmm7
+
+        movdqa      xmm3,       xmm4
+        psrldq      xmm3,       2
+        punpcklbw   xmm3,       xmm0              // mm3 = p0..p3
+        movdqa      xmm1,       xmm3              // mm1 = p0..p3
+        psllw       xmm3,       2
+
+
+        movdqa      xmm5,       xmm4
+        psrldq      xmm5,       3
+        punpcklbw   xmm5,       xmm0              // mm5 = p1..p4
+        paddusw     xmm3,       xmm5              // mm3 += mm6
+
+        // thresholding
+        movdqa      xmm7,       xmm1              // mm7 = p0..p3
+        psubusw     xmm7,       xmm5              // mm7 = p0..p3 - p1..p4
+        psubusw     xmm5,       xmm1              // mm5 = p1..p4 - p0..p3
+        paddusw     xmm7,       xmm5              // mm7 = abs(p0..p3 - p1..p4)
+        pcmpgtw     xmm7,       xmm2
+
+        movdqa      xmm5,       xmm4
+        psrldq      xmm5,       4
+        punpcklbw   xmm5,       xmm0              // mm5 = p2..p5
+        paddusw     xmm3,       xmm5              // mm3 += mm5
+
+        // thresholding
+        movdqa      xmm6,       xmm1              // mm6 = p0..p3
+        psubusw     xmm6,       xmm5              // mm6 = p0..p3 - p1..p4
+        psubusw     xmm5,       xmm1              // mm5 = p1..p4 - p0..p3
+        paddusw     xmm6,       xmm5              // mm6 = abs(p0..p3 - p1..p4)
+        pcmpgtw     xmm6,       xmm2
+        por         xmm7,       xmm6              // accumulate thresholds
+
+
+        movdqa      xmm5,       xmm4              // mm5 = p-2..p5
+        punpcklbw   xmm5,       xmm0              // mm5 = p-2..p1
+        paddusw     xmm3,       xmm5              // mm3 += mm5
+
+        // thresholding
+        movdqa      xmm6,       xmm1              // mm6 = p0..p3
+        psubusw     xmm6,       xmm5              // mm6 = p0..p3 - p1..p4
+        psubusw     xmm5,       xmm1              // mm5 = p1..p4 - p0..p3
+        paddusw     xmm6,       xmm5              // mm6 = abs(p0..p3 - p1..p4)
+        pcmpgtw     xmm6,       xmm2
+        por         xmm7,       xmm6              // accumulate thresholds
+
+        psrldq      xmm4,       1                   // mm4 = p-1..p5
+        punpcklbw   xmm4,       xmm0              // mm4 = p-1..p2
+        paddusw     xmm3,       xmm4              // mm3 += mm5
+
+        // thresholding
+        movdqa      xmm6,       xmm1              // mm6 = p0..p3
+        psubusw     xmm6,       xmm4              // mm6 = p0..p3 - p1..p4
+        psubusw     xmm4,       xmm1              // mm5 = p1..p4 - p0..p3
+        paddusw     xmm6,       xmm4              // mm6 = abs(p0..p3 - p1..p4)
+        pcmpgtw     xmm6,       xmm2
+        por         xmm7,       xmm6              // accumulate thresholds
+
+        paddusw     xmm3,       RD42              // mm3 += round value
+        psraw       xmm3,       3                 // mm3 /= 8
+
+        pand        xmm1,       xmm7              // mm1 select vals > thresh from source
+        pandn       xmm7,       xmm3              // mm7 select vals < thresh from blurred result
+        paddusw     xmm1,       xmm7              // combination
+
+        packuswb    xmm1,       xmm0              // pack to bytes
+        movq        QWORD PTR [rdi+rdx-8],  mm0   // store previous four bytes
+        movdq2q     mm0,        xmm1
+
+        add         rdx,        8
+        cmp         edx,        dword ptr arg(5) //cols
+        jl          acrossnextcol;
+
+        // last 8 pixels
+        movq        QWORD PTR [rdi+rdx-8],  mm0
+
+        // done with this rwo
+        add         rsi,rax               // next line
+        mov         eax, dword ptr arg(3) //dst_pixels_per_line ; destination pitch?
+        add         rdi,rax               // next destination
+        mov         eax, dword ptr arg(2) //src_pixels_per_line ; destination pitch?
+
+        dec         rcx                   // decrement count
+        jnz         nextrow               // next row
+
+#if ABI_IS_32BIT && CONFIG_PIC
+    add rsp,16
+    pop rsp
+#endif
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+#undef RD42
+
+
+//void vp8_mbpost_proc_down_xmm(unsigned char *dst,
+//                            int pitch, int rows, int cols,int flimit)
+extern sym(vp8_rv)
+global sym(vp8_mbpost_proc_down_xmm)
+sym(vp8_mbpost_proc_down_xmm):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 5
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+    ALIGN_STACK 16, rax
+    sub         rsp, 128+16
+
+    // unsigned char d[16][8] at [rsp]
+    // create flimit2 at [rsp+128]
+    mov         eax, dword ptr arg(4) //flimit
+    mov         [rsp+128], eax
+    mov         [rsp+128+4], eax
+    mov         [rsp+128+8], eax
+    mov         [rsp+128+12], eax
+#define flimit4 [rsp+128]
+
+#if ! ABI_IS_32BIT
+    lea         r8,       [GLOBAL (sym(vp8_rv))]
+#endif
+
+    //rows +=8;
+    add         dword ptr arg(2), 8
+
+    //for(c=0; c<cols; c+=8)
+loop_col:
+            mov         rsi,        arg(0) // s
+            pxor        xmm0,       xmm0        //
+
+            movsxd      rax,        dword ptr arg(1) //pitch       ;
+            neg         rax                                     // rax = -pitch
+
+            lea         rsi,        [rsi + rax*8];              // rdi = s[-pitch*8]
+            neg         rax
+
+
+            pxor        xmm5,       xmm5
+            pxor        xmm6,       xmm6        //
+
+            pxor        xmm7,       xmm7        //
+            mov         rdi,        rsi
+
+            mov         rcx,        15          //
+
+loop_initvar:
+            movq        xmm1,       QWORD PTR [rdi];
+            punpcklbw   xmm1,       xmm0        //
+
+            paddw       xmm5,       xmm1        //
+            pmullw      xmm1,       xmm1        //
+
+            movdqa      xmm2,       xmm1        //
+            punpcklwd   xmm1,       xmm0        //
+
+            punpckhwd   xmm2,       xmm0        //
+            paddd       xmm6,       xmm1        //
+
+            paddd       xmm7,       xmm2        //
+            lea         rdi,        [rdi+rax]   //
+
+            dec         rcx
+            jne         loop_initvar
+            //save the var and sum
+            xor         rdx,        rdx
+loop_row:
+            movq        xmm1,       QWORD PTR [rsi]     // [s-pitch*8]
+            movq        xmm2,       QWORD PTR [rdi]     // [s+pitch*7]
+
+            punpcklbw   xmm1,       xmm0
+            punpcklbw   xmm2,       xmm0
+
+            paddw       xmm5,       xmm2
+            psubw       xmm5,       xmm1
+
+            pmullw      xmm2,       xmm2
+            movdqa      xmm4,       xmm2
+
+            punpcklwd   xmm2,       xmm0
+            punpckhwd   xmm4,       xmm0
+
+            paddd       xmm6,       xmm2
+            paddd       xmm7,       xmm4
+
+            pmullw      xmm1,       xmm1
+            movdqa      xmm2,       xmm1
+
+            punpcklwd   xmm1,       xmm0
+            psubd       xmm6,       xmm1
+
+            punpckhwd   xmm2,       xmm0
+            psubd       xmm7,       xmm2
+
+
+            movdqa      xmm3,       xmm6
+            pslld       xmm3,       4
+
+            psubd       xmm3,       xmm6
+            movdqa      xmm1,       xmm5
+
+            movdqa      xmm4,       xmm5
+            pmullw      xmm1,       xmm1
+
+            pmulhw      xmm4,       xmm4
+            movdqa      xmm2,       xmm1
+
+            punpcklwd   xmm1,       xmm4
+            punpckhwd   xmm2,       xmm4
+
+            movdqa      xmm4,       xmm7
+            pslld       xmm4,       4
+
+            psubd       xmm4,       xmm7
+
+            psubd       xmm3,       xmm1
+            psubd       xmm4,       xmm2
+
+            psubd       xmm3,       flimit4
+            psubd       xmm4,       flimit4
+
+            psrad       xmm3,       31
+            psrad       xmm4,       31
+
+            packssdw    xmm3,       xmm4
+            packsswb    xmm3,       xmm0
+
+            movq        xmm1,       QWORD PTR [rsi+rax*8]
+
+            movq        xmm2,       xmm1
+            punpcklbw   xmm1,       xmm0
+
+            paddw       xmm1,       xmm5
+            mov         rcx,        rdx
+
+            and         rcx,        127
+#if ABI_IS_32BIT && CONFIG_PIC
+            push        rax
+            lea         rax,        [GLOBAL (sym(vp8_rv))]
+            movdqu      xmm4,       [rax + rcx*2] //vp8_rv[rcx*2]
+            pop         rax
+#elif ! ABI_IS_32BIT
+            movdqu      xmm4,       [r8 + rcx*2] //vp8_rv[rcx*2]
+#else
+            movdqu      xmm4,       [sym(vp8_rv) + rcx*2]
+#endif
+
+            paddw       xmm1,       xmm4
+            //paddw     xmm1,       eight8s
+            psraw       xmm1,       4
+
+            packuswb    xmm1,       xmm0
+            pand        xmm1,       xmm3
+
+            pandn       xmm3,       xmm2
+            por         xmm1,       xmm3
+
+            and         rcx,        15
+            movq        QWORD PTR   [rsp + rcx*8], xmm1 //d[rcx*8]
+
+            mov         rcx,        rdx
+            sub         rcx,        8
+
+            and         rcx,        15
+            movq        mm0,        [rsp + rcx*8] //d[rcx*8]
+
+            movq        [rsi],      mm0
+            lea         rsi,        [rsi+rax]
+
+            lea         rdi,        [rdi+rax]
+            add         rdx,        1
+
+            cmp         edx,        dword ptr arg(2) //rows
+            jl          loop_row
+
+        add         dword ptr arg(0), 8 // s += 8
+        sub         dword ptr arg(3), 8 // cols -= 8
+        cmp         dword ptr arg(3), 0
+        jg          loop_col
+
+    add         rsp, 128+16
+    pop         rsp
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+#undef flimit4
+
+
+//void vp8_mbpost_proc_across_ip_xmm(unsigned char *src,
+//                                int pitch, int rows, int cols,int flimit)
+global sym(vp8_mbpost_proc_across_ip_xmm)
+sym(vp8_mbpost_proc_across_ip_xmm):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 5
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+    ALIGN_STACK 16, rax
+    sub         rsp, 16
+
+    // create flimit4 at [rsp]
+    mov         eax, dword ptr arg(4) //flimit
+    mov         [rsp], eax
+    mov         [rsp+4], eax
+    mov         [rsp+8], eax
+    mov         [rsp+12], eax
+#define flimit4 [rsp]
+
+
+    //for(r=0;r<rows;r++)
+ip_row_loop:
+
+        xor         rdx,    rdx //sumsq=0;
+        xor         rcx,    rcx //sum=0;
+        mov         rsi,    arg(0) //s
+        mov         rdi,    -8
+ip_var_loop:
+        //for(i=-8;i<=6;i++)
+        //{
+        //    sumsq += s[i]*s[i];
+        //    sum   += s[i];
+        //}
+        movzx       eax, byte ptr [rsi+rdi]
+        add         ecx, eax
+        mulb        al
+        add         edx, eax
+        add         rdi, 1
+        cmp         rdi, 6
+        jle         ip_var_loop
+
+
+            //mov         rax,    sumsq
+            //movd        xmm7,   rax
+            movd        xmm7,   edx
+
+            //mov         rax,    sum
+            //movd        xmm6,   rax
+            movd        xmm6,   ecx
+
+            mov         rsi,    arg(0) //s
+            xor         rcx,    rcx
+
+            movsxd      rdx,    dword ptr arg(3) //cols
+            add         rdx,    8
+            pxor        mm0,    mm0
+            pxor        mm1,    mm1
+
+            pxor        xmm0,   xmm0
+nextcol4:
+
+            movd        xmm1,   DWORD PTR [rsi+rcx-8]   // -8 -7 -6 -5
+            movd        xmm2,   DWORD PTR [rsi+rcx+7]   // +7 +8 +9 +10
+
+            punpcklbw   xmm1,   xmm0                    // expanding
+            punpcklbw   xmm2,   xmm0                    // expanding
+
+            punpcklwd   xmm1,   xmm0                    // expanding to dwords
+            punpcklwd   xmm2,   xmm0                    // expanding to dwords
+
+            psubd       xmm2,   xmm1                    // 7--8   8--7   9--6 10--5
+            paddd       xmm1,   xmm1                    // -8*2   -7*2   -6*2 -5*2
+
+            paddd       xmm1,   xmm2                    // 7+-8   8+-7   9+-6 10+-5
+            pmaddwd     xmm1,   xmm2                    // squared of 7+-8   8+-7   9+-6 10+-5
+
+            paddd       xmm6,   xmm2
+            paddd       xmm7,   xmm1
+
+            pshufd      xmm6,   xmm6,   0               // duplicate the last ones
+            pshufd      xmm7,   xmm7,   0               // duplicate the last ones
+
+            psrldq      xmm1,       4                   // 8--7   9--6 10--5  0000
+            psrldq      xmm2,       4                   // 8--7   9--6 10--5  0000
+
+            pshufd      xmm3,   xmm1,   3               // 0000  8--7   8--7   8--7 squared
+            pshufd      xmm4,   xmm2,   3               // 0000  8--7   8--7   8--7 squared
+
+            paddd       xmm6,   xmm4
+            paddd       xmm7,   xmm3
+
+            pshufd      xmm3,   xmm1,   0b01011111       // 0000  0000   9--6   9--6 squared
+            pshufd      xmm4,   xmm2,   0b01011111       // 0000  0000   9--6   9--6 squared
+
+            paddd       xmm7,   xmm3
+            paddd       xmm6,   xmm4
+
+            pshufd      xmm3,   xmm1,   0b10111111       // 0000  0000   8--7   8--7 squared
+            pshufd      xmm4,   xmm2,   0b10111111       // 0000  0000   8--7   8--7 squared
+
+            paddd       xmm7,   xmm3
+            paddd       xmm6,   xmm4
+
+            movdqa      xmm3,   xmm6
+            pmaddwd     xmm3,   xmm3
+
+            movdqa      xmm5,   xmm7
+            pslld       xmm5,   4
+
+            psubd       xmm5,   xmm7
+            psubd       xmm5,   xmm3
+
+            psubd       xmm5,   flimit4
+            psrad       xmm5,   31
+
+            packssdw    xmm5,   xmm0
+            packsswb    xmm5,   xmm0
+
+            movd        xmm1,   DWORD PTR [rsi+rcx]
+            movq        xmm2,   xmm1
+
+            punpcklbw   xmm1,   xmm0
+            punpcklwd   xmm1,   xmm0
+
+            paddd       xmm1,   xmm6
+            paddd       xmm1,   [GLOBAL (four8s)]
+
+            psrad       xmm1,   4
+            packssdw    xmm1,   xmm0
+
+            packuswb    xmm1,   xmm0
+            pand        xmm1,   xmm5
+
+            pandn       xmm5,   xmm2
+            por         xmm5,   xmm1
+
+            movd        [rsi+rcx-8],  mm0
+            movq        mm0,    mm1
+
+            movdq2q     mm1,    xmm5
+            psrldq      xmm7,   12
+
+            psrldq      xmm6,   12
+            add         rcx,    4
+
+            cmp         rcx,    rdx
+            jl          nextcol4
+
+        //s+=pitch;
+        movsxd rax, dword ptr arg(1)
+        add    arg(0), rax
+
+        sub dword ptr arg(2), 1 //rows-=1
+        cmp dword ptr arg(2), 0
+        jg ip_row_loop
+
+    add         rsp, 16
+    pop         rsp
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+#undef flimit4
+
+
+//void vp8_plane_add_noise_wmt (unsigned char *Start, unsigned char *noise,
+//                            unsigned char blackclamp[16],
+//                            unsigned char whiteclamp[16],
+//                            unsigned char bothclamp[16],
+//                            unsigned int Width, unsigned int Height, int Pitch)
+extern sym(rand)
+global sym(vp8_plane_add_noise_wmt)
+sym(vp8_plane_add_noise_wmt):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 8
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+addnoise_loop:
+    call WRT_PLT (sym (rand))
+    mov     rcx, arg(1) //noise
+    and     rax, 0xff
+    add     rcx, rax
+
+    // we rely on the fact that the clamping vectors are stored contiguously
+    // in black/white/both order. Note that we have to reload this here because
+    // rdx could be trashed by rand()
+    mov     rdx, arg(2) // blackclamp
+
+
+            mov     rdi, rcx
+            movsxd  rcx, dword ptr arg(5) //[Width]
+            mov     rsi, arg(0) //Pos
+            xor         rax,rax
+
+addnoise_nextset:
+            movdqu      xmm1,[rsi+rax]         // get the source
+
+            psubusb     xmm1, [rdx]    //blackclamp        ; clamp both sides so we don't outrange adding noise
+            paddusb     xmm1, [rdx+32] //bothclamp
+            psubusb     xmm1, [rdx+16] //whiteclamp
+
+            movdqu      xmm2,[rdi+rax]         // get the noise for this line
+            paddb       xmm1,xmm2              // add it in
+            movdqu      [rsi+rax],xmm1         // store the result
+
+            add         rax,16                 // move to the next line
+
+            cmp         rax, rcx
+            jl          addnoise_nextset
+
+    movsxd  rax, dword ptr arg(7) // Pitch
+    add     arg(0), rax // Start += Pitch
+    sub     dword ptr arg(6), 1   // Height -= 1
+    jg      addnoise_loop
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+SECTION_RODATA
+align 16
+rd42:
+    .fill 8, 2, 0x04
+four8s:
+    .fill 4, 4, 8
diff --git a/vp8/common/x86/postproc_sse2.asm b/vp8/common/x86/postproc_sse2.asm
deleted file mode 100644
index bfa36fa..0000000
--- a/vp8/common/x86/postproc_sse2.asm
+++ /dev/null
@@ -1,688 +0,0 @@
-;
-;  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
-;
-;  Use of this source code is governed by a BSD-style license and patent
-;  grant that can be found in the LICENSE file in the root of the source
-;  tree. All contributing project authors may be found in the AUTHORS
-;  file in the root of the source tree.
-;
-
-
-%include "vpx_ports/x86_abi_support.asm"
-
-;void vp8_post_proc_down_and_across_xmm
-;(
-;    unsigned char *src_ptr,
-;    unsigned char *dst_ptr,
-;    int src_pixels_per_line,
-;    int dst_pixels_per_line,
-;    int rows,
-;    int cols,
-;    int flimit
-;)
-global sym(vp8_post_proc_down_and_across_xmm)
-sym(vp8_post_proc_down_and_across_xmm):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 7
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-%if ABI_IS_32BIT=1 && CONFIG_PIC=1
-    ALIGN_STACK 16, rax
-    ; move the global rd onto the stack, since we don't have enough registers
-    ; to do PIC addressing
-    movdqa      xmm0, [rd42 GLOBAL]
-    sub         rsp, 16
-    movdqa      [rsp], xmm0
-%define RD42 [rsp]
-%else
-%define RD42 [rd42 GLOBAL]
-%endif
-
-
-        movd        xmm2,       dword ptr arg(6) ;flimit
-        punpcklwd   xmm2,       xmm2
-        punpckldq   xmm2,       xmm2
-        punpcklqdq  xmm2,       xmm2
-
-        mov         rsi,        arg(0) ;src_ptr
-        mov         rdi,        arg(1) ;dst_ptr
-
-        movsxd      rcx,        DWORD PTR arg(4) ;rows
-        movsxd      rax,        DWORD PTR arg(2) ;src_pixels_per_line ; destination pitch?
-        pxor        xmm0,       xmm0              ; mm0 = 00000000
-
-nextrow:
-
-        xor         rdx,        rdx       ; clear out rdx for use as loop counter
-nextcol:
-        movq        xmm3,       QWORD PTR [rsi]         ; mm4 = r0 p0..p7
-        punpcklbw   xmm3,       xmm0                    ; mm3 = p0..p3
-        movdqa      xmm1,       xmm3                    ; mm1 = p0..p3
-        psllw       xmm3,       2                       ;
-
-        movq        xmm5,       QWORD PTR [rsi + rax]   ; mm4 = r1 p0..p7
-        punpcklbw   xmm5,       xmm0                    ; mm5 = r1 p0..p3
-        paddusw     xmm3,       xmm5                    ; mm3 += mm6
-
-        ; thresholding
-        movdqa      xmm7,       xmm1                    ; mm7 = r0 p0..p3
-        psubusw     xmm7,       xmm5                    ; mm7 = r0 p0..p3 - r1 p0..p3
-        psubusw     xmm5,       xmm1                    ; mm5 = r1 p0..p3 - r0 p0..p3
-        paddusw     xmm7,       xmm5                    ; mm7 = abs(r0 p0..p3 - r1 p0..p3)
-        pcmpgtw     xmm7,       xmm2
-
-        movq        xmm5,       QWORD PTR [rsi + 2*rax] ; mm4 = r2 p0..p7
-        punpcklbw   xmm5,       xmm0                    ; mm5 = r2 p0..p3
-        paddusw     xmm3,       xmm5                    ; mm3 += mm5
-
-        ; thresholding
-        movdqa      xmm6,       xmm1                    ; mm6 = r0 p0..p3
-        psubusw     xmm6,       xmm5                    ; mm6 = r0 p0..p3 - r2 p0..p3
-        psubusw     xmm5,       xmm1                    ; mm5 = r2 p0..p3 - r2 p0..p3
-        paddusw     xmm6,       xmm5                    ; mm6 = abs(r0 p0..p3 - r2 p0..p3)
-        pcmpgtw     xmm6,       xmm2
-        por         xmm7,       xmm6                    ; accumulate thresholds
-
-
-        neg         rax
-        movq        xmm5,       QWORD PTR [rsi+2*rax]   ; mm4 = r-2 p0..p7
-        punpcklbw   xmm5,       xmm0                    ; mm5 = r-2 p0..p3
-        paddusw     xmm3,       xmm5                    ; mm3 += mm5
-
-        ; thresholding
-        movdqa      xmm6,       xmm1                    ; mm6 = r0 p0..p3
-        psubusw     xmm6,       xmm5                    ; mm6 = p0..p3 - r-2 p0..p3
-        psubusw     xmm5,       xmm1                    ; mm5 = r-2 p0..p3 - p0..p3
-        paddusw     xmm6,       xmm5                    ; mm6 = abs(r0 p0..p3 - r-2 p0..p3)
-        pcmpgtw     xmm6,       xmm2
-        por         xmm7,       xmm6                    ; accumulate thresholds
-
-        movq        xmm4,       QWORD PTR [rsi+rax]     ; mm4 = r-1 p0..p7
-        punpcklbw   xmm4,       xmm0                    ; mm4 = r-1 p0..p3
-        paddusw     xmm3,       xmm4                    ; mm3 += mm5
-
-        ; thresholding
-        movdqa      xmm6,       xmm1                    ; mm6 = r0 p0..p3
-        psubusw     xmm6,       xmm4                    ; mm6 = p0..p3 - r-2 p0..p3
-        psubusw     xmm4,       xmm1                    ; mm5 = r-1 p0..p3 - p0..p3
-        paddusw     xmm6,       xmm4                    ; mm6 = abs(r0 p0..p3 - r-1 p0..p3)
-        pcmpgtw     xmm6,       xmm2
-        por         xmm7,       xmm6                    ; accumulate thresholds
-
-
-        paddusw     xmm3,       RD42                    ; mm3 += round value
-        psraw       xmm3,       3                       ; mm3 /= 8
-
-        pand        xmm1,       xmm7                    ; mm1 select vals > thresh from source
-        pandn       xmm7,       xmm3                    ; mm7 select vals < thresh from blurred result
-        paddusw     xmm1,       xmm7                    ; combination
-
-        packuswb    xmm1,       xmm0                    ; pack to bytes
-        movq        QWORD PTR [rdi], xmm1             ;
-
-        neg         rax                   ; pitch is positive
-        add         rsi,        8
-        add         rdi,        8
-
-        add         rdx,        8
-        cmp         edx,        dword arg(5) ;cols
-
-        jl          nextcol
-
-        ; done with the all cols, start the across filtering in place
-        sub         rsi,        rdx
-        sub         rdi,        rdx
-
-        xor         rdx,        rdx
-        movq        mm0,        QWORD PTR [rdi-8];
-
-acrossnextcol:
-        movq        xmm7,       QWORD PTR [rdi +rdx -2]
-        movd        xmm4,       DWORD PTR [rdi +rdx +6]
-
-        pslldq      xmm4,       8
-        por         xmm4,       xmm7
-
-        movdqa      xmm3,       xmm4
-        psrldq      xmm3,       2
-        punpcklbw   xmm3,       xmm0              ; mm3 = p0..p3
-        movdqa      xmm1,       xmm3              ; mm1 = p0..p3
-        psllw       xmm3,       2
-
-
-        movdqa      xmm5,       xmm4
-        psrldq      xmm5,       3
-        punpcklbw   xmm5,       xmm0              ; mm5 = p1..p4
-        paddusw     xmm3,       xmm5              ; mm3 += mm6
-
-        ; thresholding
-        movdqa      xmm7,       xmm1              ; mm7 = p0..p3
-        psubusw     xmm7,       xmm5              ; mm7 = p0..p3 - p1..p4
-        psubusw     xmm5,       xmm1              ; mm5 = p1..p4 - p0..p3
-        paddusw     xmm7,       xmm5              ; mm7 = abs(p0..p3 - p1..p4)
-        pcmpgtw     xmm7,       xmm2
-
-        movdqa      xmm5,       xmm4
-        psrldq      xmm5,       4
-        punpcklbw   xmm5,       xmm0              ; mm5 = p2..p5
-        paddusw     xmm3,       xmm5              ; mm3 += mm5
-
-        ; thresholding
-        movdqa      xmm6,       xmm1              ; mm6 = p0..p3
-        psubusw     xmm6,       xmm5              ; mm6 = p0..p3 - p1..p4
-        psubusw     xmm5,       xmm1              ; mm5 = p1..p4 - p0..p3
-        paddusw     xmm6,       xmm5              ; mm6 = abs(p0..p3 - p1..p4)
-        pcmpgtw     xmm6,       xmm2
-        por         xmm7,       xmm6              ; accumulate thresholds
-
-
-        movdqa      xmm5,       xmm4              ; mm5 = p-2..p5
-        punpcklbw   xmm5,       xmm0              ; mm5 = p-2..p1
-        paddusw     xmm3,       xmm5              ; mm3 += mm5
-
-        ; thresholding
-        movdqa      xmm6,       xmm1              ; mm6 = p0..p3
-        psubusw     xmm6,       xmm5              ; mm6 = p0..p3 - p1..p4
-        psubusw     xmm5,       xmm1              ; mm5 = p1..p4 - p0..p3
-        paddusw     xmm6,       xmm5              ; mm6 = abs(p0..p3 - p1..p4)
-        pcmpgtw     xmm6,       xmm2
-        por         xmm7,       xmm6              ; accumulate thresholds
-
-        psrldq      xmm4,       1                   ; mm4 = p-1..p5
-        punpcklbw   xmm4,       xmm0              ; mm4 = p-1..p2
-        paddusw     xmm3,       xmm4              ; mm3 += mm5
-
-        ; thresholding
-        movdqa      xmm6,       xmm1              ; mm6 = p0..p3
-        psubusw     xmm6,       xmm4              ; mm6 = p0..p3 - p1..p4
-        psubusw     xmm4,       xmm1              ; mm5 = p1..p4 - p0..p3
-        paddusw     xmm6,       xmm4              ; mm6 = abs(p0..p3 - p1..p4)
-        pcmpgtw     xmm6,       xmm2
-        por         xmm7,       xmm6              ; accumulate thresholds
-
-        paddusw     xmm3,       RD42              ; mm3 += round value
-        psraw       xmm3,       3                 ; mm3 /= 8
-
-        pand        xmm1,       xmm7              ; mm1 select vals > thresh from source
-        pandn       xmm7,       xmm3              ; mm7 select vals < thresh from blurred result
-        paddusw     xmm1,       xmm7              ; combination
-
-        packuswb    xmm1,       xmm0              ; pack to bytes
-        movq        QWORD PTR [rdi+rdx-8],  mm0   ; store previous four bytes
-        movdq2q     mm0,        xmm1
-
-        add         rdx,        8
-        cmp         edx,        dword arg(5) ;cols
-        jl          acrossnextcol;
-
-        ; last 8 pixels
-        movq        QWORD PTR [rdi+rdx-8],  mm0
-
-        ; done with this rwo
-        add         rsi,rax               ; next line
-        mov         eax, dword arg(3) ;dst_pixels_per_line ; destination pitch?
-        add         rdi,rax               ; next destination
-        mov         eax, dword arg(2) ;src_pixels_per_line ; destination pitch?
-
-        dec         rcx                   ; decrement count
-        jnz         nextrow               ; next row
-
-%if ABI_IS_32BIT=1 && CONFIG_PIC=1
-    add rsp,16
-    pop rsp
-%endif
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-%undef RD42
-
-
-;void vp8_mbpost_proc_down_xmm(unsigned char *dst,
-;                            int pitch, int rows, int cols,int flimit)
-extern sym(vp8_rv)
-global sym(vp8_mbpost_proc_down_xmm)
-sym(vp8_mbpost_proc_down_xmm):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 5
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-    ALIGN_STACK 16, rax
-    sub         rsp, 128+16
-
-    ; unsigned char d[16][8] at [rsp]
-    ; create flimit2 at [rsp+128]
-    mov         eax, dword ptr arg(4) ;flimit
-    mov         [rsp+128], eax
-    mov         [rsp+128+4], eax
-    mov         [rsp+128+8], eax
-    mov         [rsp+128+12], eax
-%define flimit4 [rsp+128]
-
-%if ABI_IS_32BIT=0
-    lea         r8,       [sym(vp8_rv) GLOBAL]
-%endif
-
-    ;rows +=8;
-    add         dword arg(2), 8
-
-    ;for(c=0; c<cols; c+=8)
-loop_col:
-            mov         rsi,        arg(0) ; s
-            pxor        xmm0,       xmm0        ;
-
-            movsxd      rax,        dword ptr arg(1) ;pitch       ;
-            neg         rax                                     ; rax = -pitch
-
-            lea         rsi,        [rsi + rax*8];              ; rdi = s[-pitch*8]
-            neg         rax
-
-
-            pxor        xmm5,       xmm5
-            pxor        xmm6,       xmm6        ;
-
-            pxor        xmm7,       xmm7        ;
-            mov         rdi,        rsi
-
-            mov         rcx,        15          ;
-
-loop_initvar:
-            movq        xmm1,       QWORD PTR [rdi];
-            punpcklbw   xmm1,       xmm0        ;
-
-            paddw       xmm5,       xmm1        ;
-            pmullw      xmm1,       xmm1        ;
-
-            movdqa      xmm2,       xmm1        ;
-            punpcklwd   xmm1,       xmm0        ;
-
-            punpckhwd   xmm2,       xmm0        ;
-            paddd       xmm6,       xmm1        ;
-
-            paddd       xmm7,       xmm2        ;
-            lea         rdi,        [rdi+rax]   ;
-
-            dec         rcx
-            jne         loop_initvar
-            ;save the var and sum
-            xor         rdx,        rdx
-loop_row:
-            movq        xmm1,       QWORD PTR [rsi]     ; [s-pitch*8]
-            movq        xmm2,       QWORD PTR [rdi]     ; [s+pitch*7]
-
-            punpcklbw   xmm1,       xmm0
-            punpcklbw   xmm2,       xmm0
-
-            paddw       xmm5,       xmm2
-            psubw       xmm5,       xmm1
-
-            pmullw      xmm2,       xmm2
-            movdqa      xmm4,       xmm2
-
-            punpcklwd   xmm2,       xmm0
-            punpckhwd   xmm4,       xmm0
-
-            paddd       xmm6,       xmm2
-            paddd       xmm7,       xmm4
-
-            pmullw      xmm1,       xmm1
-            movdqa      xmm2,       xmm1
-
-            punpcklwd   xmm1,       xmm0
-            psubd       xmm6,       xmm1
-
-            punpckhwd   xmm2,       xmm0
-            psubd       xmm7,       xmm2
-
-
-            movdqa      xmm3,       xmm6
-            pslld       xmm3,       4
-
-            psubd       xmm3,       xmm6
-            movdqa      xmm1,       xmm5
-
-            movdqa      xmm4,       xmm5
-            pmullw      xmm1,       xmm1
-
-            pmulhw      xmm4,       xmm4
-            movdqa      xmm2,       xmm1
-
-            punpcklwd   xmm1,       xmm4
-            punpckhwd   xmm2,       xmm4
-
-            movdqa      xmm4,       xmm7
-            pslld       xmm4,       4
-
-            psubd       xmm4,       xmm7
-
-            psubd       xmm3,       xmm1
-            psubd       xmm4,       xmm2
-
-            psubd       xmm3,       flimit4
-            psubd       xmm4,       flimit4
-
-            psrad       xmm3,       31
-            psrad       xmm4,       31
-
-            packssdw    xmm3,       xmm4
-            packsswb    xmm3,       xmm0
-
-            movq        xmm1,       QWORD PTR [rsi+rax*8]
-
-            movq        xmm2,       xmm1
-            punpcklbw   xmm1,       xmm0
-
-            paddw       xmm1,       xmm5
-            mov         rcx,        rdx
-
-            and         rcx,        127
-%if ABI_IS_32BIT=1 && CONFIG_PIC=1
-            push        rax
-            lea         rax,        [sym(vp8_rv) GLOBAL]
-            movdqu      xmm4,       [rax + rcx*2] ;vp8_rv[rcx*2]
-            pop         rax
-%elif ABI_IS_32BIT=0
-            movdqu      xmm4,       [r8 + rcx*2] ;vp8_rv[rcx*2]
-%else
-            movdqu      xmm4,       [sym(vp8_rv) + rcx*2]
-%endif
-
-            paddw       xmm1,       xmm4
-            ;paddw     xmm1,       eight8s
-            psraw       xmm1,       4
-
-            packuswb    xmm1,       xmm0
-            pand        xmm1,       xmm3
-
-            pandn       xmm3,       xmm2
-            por         xmm1,       xmm3
-
-            and         rcx,        15
-            movq        QWORD PTR   [rsp + rcx*8], xmm1 ;d[rcx*8]
-
-            mov         rcx,        rdx
-            sub         rcx,        8
-
-            and         rcx,        15
-            movq        mm0,        [rsp + rcx*8] ;d[rcx*8]
-
-            movq        [rsi],      mm0
-            lea         rsi,        [rsi+rax]
-
-            lea         rdi,        [rdi+rax]
-            add         rdx,        1
-
-            cmp         edx,        dword arg(2) ;rows
-            jl          loop_row
-
-        add         dword arg(0), 8 ; s += 8
-        sub         dword arg(3), 8 ; cols -= 8
-        cmp         dword arg(3), 0
-        jg          loop_col
-
-    add         rsp, 128+16
-    pop         rsp
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-%undef flimit4
-
-
-;void vp8_mbpost_proc_across_ip_xmm(unsigned char *src,
-;                                int pitch, int rows, int cols,int flimit)
-global sym(vp8_mbpost_proc_across_ip_xmm)
-sym(vp8_mbpost_proc_across_ip_xmm):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 5
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-    ALIGN_STACK 16, rax
-    sub         rsp, 16
-
-    ; create flimit4 at [rsp]
-    mov         eax, dword ptr arg(4) ;flimit
-    mov         [rsp], eax
-    mov         [rsp+4], eax
-    mov         [rsp+8], eax
-    mov         [rsp+12], eax
-%define flimit4 [rsp]
-
-
-    ;for(r=0;r<rows;r++)
-ip_row_loop:
-
-        xor         rdx,    rdx ;sumsq=0;
-        xor         rcx,    rcx ;sum=0;
-        mov         rsi,    arg(0); s
-        mov         rdi,    -8
-ip_var_loop:
-        ;for(i=-8;i<=6;i++)
-        ;{
-        ;    sumsq += s[i]*s[i];
-        ;    sum   += s[i];
-        ;}
-        movzx       eax, byte [rsi+rdi]
-        add         ecx, eax
-        mul         al
-        add         edx, eax
-        add         rdi, 1
-        cmp         rdi, 6
-        jle         ip_var_loop
-
-
-            ;mov         rax,    sumsq
-            ;movd        xmm7,   rax
-            movd        xmm7,   edx
-
-            ;mov         rax,    sum
-            ;movd        xmm6,   rax
-            movd        xmm6,   ecx
-
-            mov         rsi,    arg(0) ;s
-            xor         rcx,    rcx
-
-            movsxd      rdx,    dword arg(3) ;cols
-            add         rdx,    8
-            pxor        mm0,    mm0
-            pxor        mm1,    mm1
-
-            pxor        xmm0,   xmm0
-nextcol4:
-
-            movd        xmm1,   DWORD PTR [rsi+rcx-8]   ; -8 -7 -6 -5
-            movd        xmm2,   DWORD PTR [rsi+rcx+7]   ; +7 +8 +9 +10
-
-            punpcklbw   xmm1,   xmm0                    ; expanding
-            punpcklbw   xmm2,   xmm0                    ; expanding
-
-            punpcklwd   xmm1,   xmm0                    ; expanding to dwords
-            punpcklwd   xmm2,   xmm0                    ; expanding to dwords
-
-            psubd       xmm2,   xmm1                    ; 7--8   8--7   9--6 10--5
-            paddd       xmm1,   xmm1                    ; -8*2   -7*2   -6*2 -5*2
-
-            paddd       xmm1,   xmm2                    ; 7+-8   8+-7   9+-6 10+-5
-            pmaddwd     xmm1,   xmm2                    ; squared of 7+-8   8+-7   9+-6 10+-5
-
-            paddd       xmm6,   xmm2
-            paddd       xmm7,   xmm1
-
-            pshufd      xmm6,   xmm6,   0               ; duplicate the last ones
-            pshufd      xmm7,   xmm7,   0               ; duplicate the last ones
-
-            psrldq      xmm1,       4                   ; 8--7   9--6 10--5  0000
-            psrldq      xmm2,       4                   ; 8--7   9--6 10--5  0000
-
-            pshufd      xmm3,   xmm1,   3               ; 0000  8--7   8--7   8--7 squared
-            pshufd      xmm4,   xmm2,   3               ; 0000  8--7   8--7   8--7 squared
-
-            paddd       xmm6,   xmm4
-            paddd       xmm7,   xmm3
-
-            pshufd      xmm3,   xmm1,   01011111b       ; 0000  0000   9--6   9--6 squared
-            pshufd      xmm4,   xmm2,   01011111b       ; 0000  0000   9--6   9--6 squared
-
-            paddd       xmm7,   xmm3
-            paddd       xmm6,   xmm4
-
-            pshufd      xmm3,   xmm1,   10111111b       ; 0000  0000   8--7   8--7 squared
-            pshufd      xmm4,   xmm2,   10111111b       ; 0000  0000   8--7   8--7 squared
-
-            paddd       xmm7,   xmm3
-            paddd       xmm6,   xmm4
-
-            movdqa      xmm3,   xmm6
-            pmaddwd     xmm3,   xmm3
-
-            movdqa      xmm5,   xmm7
-            pslld       xmm5,   4
-
-            psubd       xmm5,   xmm7
-            psubd       xmm5,   xmm3
-
-            psubd       xmm5,   flimit4
-            psrad       xmm5,   31
-
-            packssdw    xmm5,   xmm0
-            packsswb    xmm5,   xmm0
-
-            movd        xmm1,   DWORD PTR [rsi+rcx]
-            movq        xmm2,   xmm1
-
-            punpcklbw   xmm1,   xmm0
-            punpcklwd   xmm1,   xmm0
-
-            paddd       xmm1,   xmm6
-            paddd       xmm1,   [four8s GLOBAL]
-
-            psrad       xmm1,   4
-            packssdw    xmm1,   xmm0
-
-            packuswb    xmm1,   xmm0
-            pand        xmm1,   xmm5
-
-            pandn       xmm5,   xmm2
-            por         xmm5,   xmm1
-
-            movd        [rsi+rcx-8],  mm0
-            movq        mm0,    mm1
-
-            movdq2q     mm1,    xmm5
-            psrldq      xmm7,   12
-
-            psrldq      xmm6,   12
-            add         rcx,    4
-
-            cmp         rcx,    rdx
-            jl          nextcol4
-
-        ;s+=pitch;
-        movsxd rax, dword arg(1)
-        add    arg(0), rax
-
-        sub dword arg(2), 1 ;rows-=1
-        cmp dword arg(2), 0
-        jg ip_row_loop
-
-    add         rsp, 16
-    pop         rsp
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-%undef flimit4
-
-
-;void vp8_plane_add_noise_wmt (unsigned char *Start, unsigned char *noise,
-;                            unsigned char blackclamp[16],
-;                            unsigned char whiteclamp[16],
-;                            unsigned char bothclamp[16],
-;                            unsigned int Width, unsigned int Height, int Pitch)
-extern sym(rand)
-global sym(vp8_plane_add_noise_wmt)
-sym(vp8_plane_add_noise_wmt):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 8
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-addnoise_loop:
-    call sym(rand) WRT_PLT
-    mov     rcx, arg(1) ;noise
-    and     rax, 0xff
-    add     rcx, rax
-
-    ; we rely on the fact that the clamping vectors are stored contiguously
-    ; in black/white/both order. Note that we have to reload this here because
-    ; rdx could be trashed by rand()
-    mov     rdx, arg(2) ; blackclamp
-
-
-            mov     rdi, rcx
-            movsxd  rcx, dword arg(5) ;[Width]
-            mov     rsi, arg(0) ;Pos
-            xor         rax,rax
-
-addnoise_nextset:
-            movdqu      xmm1,[rsi+rax]         ; get the source
-
-            psubusb     xmm1, [rdx]    ;blackclamp        ; clamp both sides so we don't outrange adding noise
-            paddusb     xmm1, [rdx+32] ;bothclamp
-            psubusb     xmm1, [rdx+16] ;whiteclamp
-
-            movdqu      xmm2,[rdi+rax]         ; get the noise for this line
-            paddb       xmm1,xmm2              ; add it in
-            movdqu      [rsi+rax],xmm1         ; store the result
-
-            add         rax,16                 ; move to the next line
-
-            cmp         rax, rcx
-            jl          addnoise_nextset
-
-    movsxd  rax, dword arg(7) ; Pitch
-    add     arg(0), rax ; Start += Pitch
-    sub     dword arg(6), 1   ; Height -= 1
-    jg      addnoise_loop
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-SECTION_RODATA
-align 16
-rd42:
-    times 8 dw 0x04
-four8s:
-    times 4 dd 8
diff --git a/vp8/common/x86/recon_mmx.S b/vp8/common/x86/recon_mmx.S
new file mode 100644
index 0000000..1f738a7
--- /dev/null
+++ b/vp8/common/x86/recon_mmx.S
@@ -0,0 +1,320 @@
+//
+//  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
+//
+//  Use of this source code is governed by a BSD-style license and patent
+//  grant that can be found in the LICENSE file in the root of the source
+//  tree. All contributing project authors may be found in the AUTHORS
+//  file in the root of the source tree.
+//
+
+
+#include "vpx_ports/x86_abi_support.S"
+//void vp8_recon_b_mmx(unsigned char *s, short *q, unsigned char *d, int stride)
+global sym(vp8_recon_b_mmx)
+sym(vp8_recon_b_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 4
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov       rsi, arg(0) //s
+        mov       rdi, arg(2) //d
+        mov       rdx, arg(1) //q
+        movsxd    rax, dword ptr arg(3) //stride
+        pxor      mm0, mm0
+
+        movd      mm1, [rsi]
+        punpcklbw mm1, mm0
+        paddsw    mm1, [rdx]
+        packuswb  mm1,  mm0              // pack and unpack to saturate
+        movd      [rdi], mm1
+
+        movd      mm2, [rsi+16]
+        punpcklbw mm2, mm0
+        paddsw    mm2, [rdx+32]
+        packuswb  mm2, mm0              // pack and unpack to saturate
+        movd      [rdi+rax], mm2
+
+        movd      mm3, [rsi+32]
+        punpcklbw mm3, mm0
+        paddsw    mm3, [rdx+64]
+        packuswb  mm3,  mm0              // pack and unpack to saturate
+        movd      [rdi+2*rax], mm3
+
+        add       rdi, rax
+        movd      mm4, [rsi+48]
+        punpcklbw mm4, mm0
+        paddsw    mm4, [rdx+96]
+        packuswb  mm4, mm0              // pack and unpack to saturate
+        movd      [rdi+2*rax], mm4
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void copy_mem8x8_mmx(
+//    unsigned char *src,
+//    int src_stride,
+//    unsigned char *dst,
+//    int dst_stride
+//    )
+global sym(vp8_copy_mem8x8_mmx)
+sym(vp8_copy_mem8x8_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 4
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov         rsi,        arg(0) //src;
+        movq        mm0,        [rsi]
+
+        movsxd      rax,        dword ptr arg(1) //src_stride;
+        mov         rdi,        arg(2) //dst;
+
+        movq        mm1,        [rsi+rax]
+        movq        mm2,        [rsi+rax*2]
+
+        movsxd      rcx,        dword ptr arg(3) //dst_stride
+        lea         rsi,        [rsi+rax*2]
+
+        movq        [rdi],      mm0
+        add         rsi,        rax
+
+        movq        [rdi+rcx],      mm1
+        movq        [rdi+rcx*2],    mm2
+
+
+        lea         rdi,        [rdi+rcx*2]
+        movq        mm3,        [rsi]
+
+        add         rdi,        rcx
+        movq        mm4,        [rsi+rax]
+
+        movq        mm5,        [rsi+rax*2]
+        movq        [rdi],      mm3
+
+        lea         rsi,        [rsi+rax*2]
+        movq        [rdi+rcx],  mm4
+
+        movq        [rdi+rcx*2],    mm5
+        lea         rdi,        [rdi+rcx*2]
+
+        movq        mm0,        [rsi+rax]
+        movq        mm1,        [rsi+rax*2]
+
+        movq        [rdi+rcx],  mm0
+        movq        [rdi+rcx*2],mm1
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void copy_mem8x4_mmx(
+//    unsigned char *src,
+//    int src_stride,
+//    unsigned char *dst,
+//    int dst_stride
+//    )
+global sym(vp8_copy_mem8x4_mmx)
+sym(vp8_copy_mem8x4_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 4
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov         rsi,        arg(0) //src;
+        movq        mm0,        [rsi]
+
+        movsxd      rax,        dword ptr arg(1) //src_stride;
+        mov         rdi,        arg(2) //dst;
+
+        movq        mm1,        [rsi+rax]
+        movq        mm2,        [rsi+rax*2]
+
+        movsxd      rcx,        dword ptr arg(3) //dst_stride
+        lea         rsi,        [rsi+rax*2]
+
+        movq        [rdi],      mm0
+        movq        [rdi+rcx],      mm1
+
+        movq        [rdi+rcx*2],    mm2
+        lea         rdi,        [rdi+rcx*2]
+
+        movq        mm3,        [rsi+rax]
+        movq        [rdi+rcx],      mm3
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void copy_mem16x16_mmx(
+//    unsigned char *src,
+//    int src_stride,
+//    unsigned char *dst,
+//    int dst_stride
+//    )
+global sym(vp8_copy_mem16x16_mmx)
+sym(vp8_copy_mem16x16_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 4
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov         rsi,        arg(0) //src;
+        movsxd      rax,        dword ptr arg(1) //src_stride;
+
+        mov         rdi,        arg(2) //dst;
+        movsxd      rcx,        dword ptr arg(3) //dst_stride
+
+        movq        mm0,            [rsi]
+        movq        mm3,            [rsi+8];
+
+        movq        mm1,            [rsi+rax]
+        movq        mm4,            [rsi+rax+8]
+
+        movq        mm2,            [rsi+rax*2]
+        movq        mm5,            [rsi+rax*2+8]
+
+        lea         rsi,            [rsi+rax*2]
+        add         rsi,            rax
+
+        movq        [rdi],          mm0
+        movq        [rdi+8],        mm3
+
+        movq        [rdi+rcx],      mm1
+        movq        [rdi+rcx+8],    mm4
+
+        movq        [rdi+rcx*2],    mm2
+        movq        [rdi+rcx*2+8],  mm5
+
+        lea         rdi,            [rdi+rcx*2]
+        add         rdi,            rcx
+
+        movq        mm0,            [rsi]
+        movq        mm3,            [rsi+8];
+
+        movq        mm1,            [rsi+rax]
+        movq        mm4,            [rsi+rax+8]
+
+        movq        mm2,            [rsi+rax*2]
+        movq        mm5,            [rsi+rax*2+8]
+
+        lea         rsi,            [rsi+rax*2]
+        add         rsi,            rax
+
+        movq        [rdi],          mm0
+        movq        [rdi+8],        mm3
+
+        movq        [rdi+rcx],      mm1
+        movq        [rdi+rcx+8],    mm4
+
+        movq        [rdi+rcx*2],    mm2
+        movq        [rdi+rcx*2+8],  mm5
+
+        lea         rdi,            [rdi+rcx*2]
+        add         rdi,            rcx
+
+        movq        mm0,            [rsi]
+        movq        mm3,            [rsi+8];
+
+        movq        mm1,            [rsi+rax]
+        movq        mm4,            [rsi+rax+8]
+
+        movq        mm2,            [rsi+rax*2]
+        movq        mm5,            [rsi+rax*2+8]
+
+        lea         rsi,            [rsi+rax*2]
+        add         rsi,            rax
+
+        movq        [rdi],          mm0
+        movq        [rdi+8],        mm3
+
+        movq        [rdi+rcx],      mm1
+        movq        [rdi+rcx+8],    mm4
+
+        movq        [rdi+rcx*2],    mm2
+        movq        [rdi+rcx*2+8],  mm5
+
+        lea         rdi,            [rdi+rcx*2]
+        add         rdi,            rcx
+
+        movq        mm0,            [rsi]
+        movq        mm3,            [rsi+8];
+
+        movq        mm1,            [rsi+rax]
+        movq        mm4,            [rsi+rax+8]
+
+        movq        mm2,            [rsi+rax*2]
+        movq        mm5,            [rsi+rax*2+8]
+
+        lea         rsi,            [rsi+rax*2]
+        add         rsi,            rax
+
+        movq        [rdi],          mm0
+        movq        [rdi+8],        mm3
+
+        movq        [rdi+rcx],      mm1
+        movq        [rdi+rcx+8],    mm4
+
+        movq        [rdi+rcx*2],    mm2
+        movq        [rdi+rcx*2+8],  mm5
+
+        lea         rdi,            [rdi+rcx*2]
+        add         rdi,            rcx
+
+        movq        mm0,            [rsi]
+        movq        mm3,            [rsi+8];
+
+        movq        mm1,            [rsi+rax]
+        movq        mm4,            [rsi+rax+8]
+
+        movq        mm2,            [rsi+rax*2]
+        movq        mm5,            [rsi+rax*2+8]
+
+        lea         rsi,            [rsi+rax*2]
+        add         rsi,            rax
+
+        movq        [rdi],          mm0
+        movq        [rdi+8],        mm3
+
+        movq        [rdi+rcx],      mm1
+        movq        [rdi+rcx+8],    mm4
+
+        movq        [rdi+rcx*2],    mm2
+        movq        [rdi+rcx*2+8],  mm5
+
+        lea         rdi,            [rdi+rcx*2]
+        add         rdi,            rcx
+
+        movq        mm0,            [rsi]
+        movq        mm3,            [rsi+8];
+
+        movq        [rdi],          mm0
+        movq        [rdi+8],        mm3
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
diff --git a/vp8/common/x86/recon_mmx.asm b/vp8/common/x86/recon_mmx.asm
deleted file mode 100644
index ba60c5d..0000000
--- a/vp8/common/x86/recon_mmx.asm
+++ /dev/null
@@ -1,320 +0,0 @@
-;
-;  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
-;
-;  Use of this source code is governed by a BSD-style license and patent
-;  grant that can be found in the LICENSE file in the root of the source
-;  tree. All contributing project authors may be found in the AUTHORS
-;  file in the root of the source tree.
-;
-
-
-%include "vpx_ports/x86_abi_support.asm"
-;void vp8_recon_b_mmx(unsigned char *s, short *q, unsigned char *d, int stride)
-global sym(vp8_recon_b_mmx)
-sym(vp8_recon_b_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 4
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov       rsi, arg(0) ;s
-        mov       rdi, arg(2) ;d
-        mov       rdx, arg(1) ;q
-        movsxd    rax, dword ptr arg(3) ;stride
-        pxor      mm0, mm0
-
-        movd      mm1, [rsi]
-        punpcklbw mm1, mm0
-        paddsw    mm1, [rdx]
-        packuswb  mm1,  mm0              ; pack and unpack to saturate
-        movd      [rdi], mm1
-
-        movd      mm2, [rsi+16]
-        punpcklbw mm2, mm0
-        paddsw    mm2, [rdx+32]
-        packuswb  mm2, mm0              ; pack and unpack to saturate
-        movd      [rdi+rax], mm2
-
-        movd      mm3, [rsi+32]
-        punpcklbw mm3, mm0
-        paddsw    mm3, [rdx+64]
-        packuswb  mm3,  mm0              ; pack and unpack to saturate
-        movd      [rdi+2*rax], mm3
-
-        add       rdi, rax
-        movd      mm4, [rsi+48]
-        punpcklbw mm4, mm0
-        paddsw    mm4, [rdx+96]
-        packuswb  mm4, mm0              ; pack and unpack to saturate
-        movd      [rdi+2*rax], mm4
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void copy_mem8x8_mmx(
-;    unsigned char *src,
-;    int src_stride,
-;    unsigned char *dst,
-;    int dst_stride
-;    )
-global sym(vp8_copy_mem8x8_mmx)
-sym(vp8_copy_mem8x8_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 4
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov         rsi,        arg(0) ;src;
-        movq        mm0,        [rsi]
-
-        movsxd      rax,        dword ptr arg(1) ;src_stride;
-        mov         rdi,        arg(2) ;dst;
-
-        movq        mm1,        [rsi+rax]
-        movq        mm2,        [rsi+rax*2]
-
-        movsxd      rcx,        dword ptr arg(3) ;dst_stride
-        lea         rsi,        [rsi+rax*2]
-
-        movq        [rdi],      mm0
-        add         rsi,        rax
-
-        movq        [rdi+rcx],      mm1
-        movq        [rdi+rcx*2],    mm2
-
-
-        lea         rdi,        [rdi+rcx*2]
-        movq        mm3,        [rsi]
-
-        add         rdi,        rcx
-        movq        mm4,        [rsi+rax]
-
-        movq        mm5,        [rsi+rax*2]
-        movq        [rdi],      mm3
-
-        lea         rsi,        [rsi+rax*2]
-        movq        [rdi+rcx],  mm4
-
-        movq        [rdi+rcx*2],    mm5
-        lea         rdi,        [rdi+rcx*2]
-
-        movq        mm0,        [rsi+rax]
-        movq        mm1,        [rsi+rax*2]
-
-        movq        [rdi+rcx],  mm0
-        movq        [rdi+rcx*2],mm1
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void copy_mem8x4_mmx(
-;    unsigned char *src,
-;    int src_stride,
-;    unsigned char *dst,
-;    int dst_stride
-;    )
-global sym(vp8_copy_mem8x4_mmx)
-sym(vp8_copy_mem8x4_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 4
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov         rsi,        arg(0) ;src;
-        movq        mm0,        [rsi]
-
-        movsxd      rax,        dword ptr arg(1) ;src_stride;
-        mov         rdi,        arg(2) ;dst;
-
-        movq        mm1,        [rsi+rax]
-        movq        mm2,        [rsi+rax*2]
-
-        movsxd      rcx,        dword ptr arg(3) ;dst_stride
-        lea         rsi,        [rsi+rax*2]
-
-        movq        [rdi],      mm0
-        movq        [rdi+rcx],      mm1
-
-        movq        [rdi+rcx*2],    mm2
-        lea         rdi,        [rdi+rcx*2]
-
-        movq        mm3,        [rsi+rax]
-        movq        [rdi+rcx],      mm3
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void copy_mem16x16_mmx(
-;    unsigned char *src,
-;    int src_stride,
-;    unsigned char *dst,
-;    int dst_stride
-;    )
-global sym(vp8_copy_mem16x16_mmx)
-sym(vp8_copy_mem16x16_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 4
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov         rsi,        arg(0) ;src;
-        movsxd      rax,        dword ptr arg(1) ;src_stride;
-
-        mov         rdi,        arg(2) ;dst;
-        movsxd      rcx,        dword ptr arg(3) ;dst_stride
-
-        movq        mm0,            [rsi]
-        movq        mm3,            [rsi+8];
-
-        movq        mm1,            [rsi+rax]
-        movq        mm4,            [rsi+rax+8]
-
-        movq        mm2,            [rsi+rax*2]
-        movq        mm5,            [rsi+rax*2+8]
-
-        lea         rsi,            [rsi+rax*2]
-        add         rsi,            rax
-
-        movq        [rdi],          mm0
-        movq        [rdi+8],        mm3
-
-        movq        [rdi+rcx],      mm1
-        movq        [rdi+rcx+8],    mm4
-
-        movq        [rdi+rcx*2],    mm2
-        movq        [rdi+rcx*2+8],  mm5
-
-        lea         rdi,            [rdi+rcx*2]
-        add         rdi,            rcx
-
-        movq        mm0,            [rsi]
-        movq        mm3,            [rsi+8];
-
-        movq        mm1,            [rsi+rax]
-        movq        mm4,            [rsi+rax+8]
-
-        movq        mm2,            [rsi+rax*2]
-        movq        mm5,            [rsi+rax*2+8]
-
-        lea         rsi,            [rsi+rax*2]
-        add         rsi,            rax
-
-        movq        [rdi],          mm0
-        movq        [rdi+8],        mm3
-
-        movq        [rdi+rcx],      mm1
-        movq        [rdi+rcx+8],    mm4
-
-        movq        [rdi+rcx*2],    mm2
-        movq        [rdi+rcx*2+8],  mm5
-
-        lea         rdi,            [rdi+rcx*2]
-        add         rdi,            rcx
-
-        movq        mm0,            [rsi]
-        movq        mm3,            [rsi+8];
-
-        movq        mm1,            [rsi+rax]
-        movq        mm4,            [rsi+rax+8]
-
-        movq        mm2,            [rsi+rax*2]
-        movq        mm5,            [rsi+rax*2+8]
-
-        lea         rsi,            [rsi+rax*2]
-        add         rsi,            rax
-
-        movq        [rdi],          mm0
-        movq        [rdi+8],        mm3
-
-        movq        [rdi+rcx],      mm1
-        movq        [rdi+rcx+8],    mm4
-
-        movq        [rdi+rcx*2],    mm2
-        movq        [rdi+rcx*2+8],  mm5
-
-        lea         rdi,            [rdi+rcx*2]
-        add         rdi,            rcx
-
-        movq        mm0,            [rsi]
-        movq        mm3,            [rsi+8];
-
-        movq        mm1,            [rsi+rax]
-        movq        mm4,            [rsi+rax+8]
-
-        movq        mm2,            [rsi+rax*2]
-        movq        mm5,            [rsi+rax*2+8]
-
-        lea         rsi,            [rsi+rax*2]
-        add         rsi,            rax
-
-        movq        [rdi],          mm0
-        movq        [rdi+8],        mm3
-
-        movq        [rdi+rcx],      mm1
-        movq        [rdi+rcx+8],    mm4
-
-        movq        [rdi+rcx*2],    mm2
-        movq        [rdi+rcx*2+8],  mm5
-
-        lea         rdi,            [rdi+rcx*2]
-        add         rdi,            rcx
-
-        movq        mm0,            [rsi]
-        movq        mm3,            [rsi+8];
-
-        movq        mm1,            [rsi+rax]
-        movq        mm4,            [rsi+rax+8]
-
-        movq        mm2,            [rsi+rax*2]
-        movq        mm5,            [rsi+rax*2+8]
-
-        lea         rsi,            [rsi+rax*2]
-        add         rsi,            rax
-
-        movq        [rdi],          mm0
-        movq        [rdi+8],        mm3
-
-        movq        [rdi+rcx],      mm1
-        movq        [rdi+rcx+8],    mm4
-
-        movq        [rdi+rcx*2],    mm2
-        movq        [rdi+rcx*2+8],  mm5
-
-        lea         rdi,            [rdi+rcx*2]
-        add         rdi,            rcx
-
-        movq        mm0,            [rsi]
-        movq        mm3,            [rsi+8];
-
-        movq        [rdi],          mm0
-        movq        [rdi+8],        mm3
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
diff --git a/vp8/common/x86/recon_sse2.S b/vp8/common/x86/recon_sse2.S
new file mode 100644
index 0000000..3324523
--- /dev/null
+++ b/vp8/common/x86/recon_sse2.S
@@ -0,0 +1,228 @@
+//
+//  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
+//
+//  Use of this source code is governed by a BSD-style license and patent
+//  grant that can be found in the LICENSE file in the root of the source
+//  tree. All contributing project authors may be found in the AUTHORS
+//  file in the root of the source tree.
+//
+
+
+#include "vpx_ports/x86_abi_support.S"
+//void vp8_recon2b_sse2(unsigned char *s, short *q, unsigned char *d, int stride)
+global sym(vp8_recon2b_sse2)
+sym(vp8_recon2b_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 4
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov         rsi,        arg(0) //s
+        mov         rdi,        arg(2) //d
+        mov         rdx,        arg(1) //q
+        movsxd      rax,        dword ptr arg(3) //stride
+        pxor        xmm0,       xmm0
+
+        movq        xmm1,       MMWORD PTR [rsi]
+        punpcklbw   xmm1,       xmm0
+        paddsw      xmm1,       XMMWORD PTR [rdx]
+        packuswb    xmm1,       xmm0              // pack and unpack to saturate
+        movq        MMWORD PTR [rdi],   xmm1
+
+
+        movq        xmm2,       MMWORD PTR [rsi+8]
+        punpcklbw   xmm2,       xmm0
+        paddsw      xmm2,       XMMWORD PTR [rdx+16]
+        packuswb    xmm2,       xmm0              // pack and unpack to saturate
+        movq        MMWORD PTR [rdi+rax],   xmm2
+
+
+        movq        xmm3,       MMWORD PTR [rsi+16]
+        punpcklbw   xmm3,       xmm0
+        paddsw      xmm3,       XMMWORD PTR [rdx+32]
+        packuswb    xmm3,       xmm0              // pack and unpack to saturate
+        movq        MMWORD PTR [rdi+rax*2], xmm3
+
+        add         rdi, rax
+        movq        xmm4,       MMWORD PTR [rsi+24]
+        punpcklbw   xmm4,       xmm0
+        paddsw      xmm4,       XMMWORD PTR [rdx+48]
+        packuswb    xmm4,       xmm0              // pack and unpack to saturate
+        movq        MMWORD PTR [rdi+rax*2], xmm4
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void vp8_recon4b_sse2(unsigned char *s, short *q, unsigned char *d, int stride)
+global sym(vp8_recon4b_sse2)
+sym(vp8_recon4b_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 4
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov         rsi,        arg(0) //s
+        mov         rdi,        arg(2) //d
+        mov         rdx,        arg(1) //q
+        movsxd      rax,        dword ptr arg(3) //stride
+        pxor        xmm0,       xmm0
+
+        movdqa      xmm1,       XMMWORD PTR [rsi]
+        movdqa      xmm5,       xmm1
+        punpcklbw   xmm1,       xmm0
+        punpckhbw   xmm5,       xmm0
+        paddsw      xmm1,       XMMWORD PTR [rdx]
+        paddsw      xmm5,       XMMWORD PTR [rdx+16]
+        packuswb    xmm1,       xmm5              // pack and unpack to saturate
+        movdqa      XMMWORD PTR [rdi],  xmm1
+
+
+        movdqa      xmm2,       XMMWORD PTR [rsi+16]
+        movdqa      xmm6,       xmm2
+        punpcklbw   xmm2,       xmm0
+        punpckhbw   xmm6,       xmm0
+        paddsw      xmm2,       XMMWORD PTR [rdx+32]
+        paddsw      xmm6,       XMMWORD PTR [rdx+48]
+        packuswb    xmm2,       xmm6              // pack and unpack to saturate
+        movdqa      XMMWORD PTR [rdi+rax],  xmm2
+
+
+        movdqa      xmm3,       XMMWORD PTR [rsi+32]
+        movdqa      xmm7,       xmm3
+        punpcklbw   xmm3,       xmm0
+        punpckhbw   xmm7,       xmm0
+        paddsw      xmm3,       XMMWORD PTR [rdx+64]
+        paddsw      xmm7,       XMMWORD PTR [rdx+80]
+        packuswb    xmm3,       xmm7              // pack and unpack to saturate
+        movdqa      XMMWORD PTR [rdi+rax*2],    xmm3
+
+        add       rdi, rax
+        movdqa      xmm4,       XMMWORD PTR [rsi+48]
+        movdqa      xmm5,       xmm4
+        punpcklbw   xmm4,       xmm0
+        punpckhbw   xmm5,       xmm0
+        paddsw      xmm4,       XMMWORD PTR [rdx+96]
+        paddsw      xmm5,       XMMWORD PTR [rdx+112]
+        packuswb    xmm4,       xmm5              // pack and unpack to saturate
+        movdqa      XMMWORD PTR [rdi+rax*2],    xmm4
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void copy_mem16x16_sse2(
+//    unsigned char *src,
+//    int src_stride,
+//    unsigned char *dst,
+//    int dst_stride
+//    )
+global sym(vp8_copy_mem16x16_sse2)
+sym(vp8_copy_mem16x16_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 4
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov         rsi,        arg(0) //src;
+        movdqu      xmm0,       [rsi]
+
+        movsxd      rax,        dword ptr arg(1) //src_stride;
+        mov         rdi,        arg(2) //dst;
+
+        movdqu      xmm1,       [rsi+rax]
+        movdqu      xmm2,       [rsi+rax*2]
+
+        movsxd      rcx,        dword ptr arg(3) //dst_stride
+        lea         rsi,        [rsi+rax*2]
+
+        movdqa      [rdi],      xmm0
+        add         rsi,        rax
+
+        movdqa      [rdi+rcx],  xmm1
+        movdqa      [rdi+rcx*2],xmm2
+
+        lea         rdi,        [rdi+rcx*2]
+        movdqu      xmm3,       [rsi]
+
+        add         rdi,        rcx
+        movdqu      xmm4,       [rsi+rax]
+
+        movdqu      xmm5,       [rsi+rax*2]
+        lea         rsi,        [rsi+rax*2]
+
+        movdqa      [rdi],  xmm3
+        add         rsi,        rax
+
+        movdqa      [rdi+rcx],  xmm4
+        movdqa      [rdi+rcx*2],xmm5
+
+        lea         rdi,        [rdi+rcx*2]
+        movdqu      xmm0,       [rsi]
+
+        add         rdi,        rcx
+        movdqu      xmm1,       [rsi+rax]
+
+        movdqu      xmm2,       [rsi+rax*2]
+        lea         rsi,        [rsi+rax*2]
+
+        movdqa      [rdi],      xmm0
+        add         rsi,        rax
+
+        movdqa      [rdi+rcx],  xmm1
+
+        movdqa      [rdi+rcx*2],    xmm2
+        movdqu      xmm3,       [rsi]
+
+        movdqu      xmm4,       [rsi+rax]
+        lea         rdi,        [rdi+rcx*2]
+
+        add         rdi,        rcx
+        movdqu      xmm5,       [rsi+rax*2]
+
+        lea         rsi,        [rsi+rax*2]
+        movdqa      [rdi],  xmm3
+
+        add         rsi,        rax
+        movdqa      [rdi+rcx],  xmm4
+
+        movdqa      [rdi+rcx*2],xmm5
+        movdqu      xmm0,       [rsi]
+
+        lea         rdi,        [rdi+rcx*2]
+        movdqu      xmm1,       [rsi+rax]
+
+        add         rdi,        rcx
+        movdqu      xmm2,       [rsi+rax*2]
+
+        lea         rsi,        [rsi+rax*2]
+        movdqa      [rdi],      xmm0
+
+        movdqa      [rdi+rcx],  xmm1
+        movdqa      [rdi+rcx*2],xmm2
+
+        movdqu      xmm3,       [rsi+rax]
+        lea         rdi,        [rdi+rcx*2]
+
+        movdqa      [rdi+rcx],  xmm3
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
diff --git a/vp8/common/x86/recon_sse2.asm b/vp8/common/x86/recon_sse2.asm
deleted file mode 100644
index f2685a7..0000000
--- a/vp8/common/x86/recon_sse2.asm
+++ /dev/null
@@ -1,228 +0,0 @@
-;
-;  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
-;
-;  Use of this source code is governed by a BSD-style license and patent
-;  grant that can be found in the LICENSE file in the root of the source
-;  tree. All contributing project authors may be found in the AUTHORS
-;  file in the root of the source tree.
-;
-
-
-%include "vpx_ports/x86_abi_support.asm"
-;void vp8_recon2b_sse2(unsigned char *s, short *q, unsigned char *d, int stride)
-global sym(vp8_recon2b_sse2)
-sym(vp8_recon2b_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 4
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov         rsi,        arg(0) ;s
-        mov         rdi,        arg(2) ;d
-        mov         rdx,        arg(1) ;q
-        movsxd      rax,        dword ptr arg(3) ;stride
-        pxor        xmm0,       xmm0
-
-        movq        xmm1,       MMWORD PTR [rsi]
-        punpcklbw   xmm1,       xmm0
-        paddsw      xmm1,       XMMWORD PTR [rdx]
-        packuswb    xmm1,       xmm0              ; pack and unpack to saturate
-        movq        MMWORD PTR [rdi],   xmm1
-
-
-        movq        xmm2,       MMWORD PTR [rsi+8]
-        punpcklbw   xmm2,       xmm0
-        paddsw      xmm2,       XMMWORD PTR [rdx+16]
-        packuswb    xmm2,       xmm0              ; pack and unpack to saturate
-        movq        MMWORD PTR [rdi+rax],   xmm2
-
-
-        movq        xmm3,       MMWORD PTR [rsi+16]
-        punpcklbw   xmm3,       xmm0
-        paddsw      xmm3,       XMMWORD PTR [rdx+32]
-        packuswb    xmm3,       xmm0              ; pack and unpack to saturate
-        movq        MMWORD PTR [rdi+rax*2], xmm3
-
-        add         rdi, rax
-        movq        xmm4,       MMWORD PTR [rsi+24]
-        punpcklbw   xmm4,       xmm0
-        paddsw      xmm4,       XMMWORD PTR [rdx+48]
-        packuswb    xmm4,       xmm0              ; pack and unpack to saturate
-        movq        MMWORD PTR [rdi+rax*2], xmm4
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void vp8_recon4b_sse2(unsigned char *s, short *q, unsigned char *d, int stride)
-global sym(vp8_recon4b_sse2)
-sym(vp8_recon4b_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 4
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov         rsi,        arg(0) ;s
-        mov         rdi,        arg(2) ;d
-        mov         rdx,        arg(1) ;q
-        movsxd      rax,        dword ptr arg(3) ;stride
-        pxor        xmm0,       xmm0
-
-        movdqa      xmm1,       XMMWORD PTR [rsi]
-        movdqa      xmm5,       xmm1
-        punpcklbw   xmm1,       xmm0
-        punpckhbw   xmm5,       xmm0
-        paddsw      xmm1,       XMMWORD PTR [rdx]
-        paddsw      xmm5,       XMMWORD PTR [rdx+16]
-        packuswb    xmm1,       xmm5              ; pack and unpack to saturate
-        movdqa      XMMWORD PTR [rdi],  xmm1
-
-
-        movdqa      xmm2,       XMMWORD PTR [rsi+16]
-        movdqa      xmm6,       xmm2
-        punpcklbw   xmm2,       xmm0
-        punpckhbw   xmm6,       xmm0
-        paddsw      xmm2,       XMMWORD PTR [rdx+32]
-        paddsw      xmm6,       XMMWORD PTR [rdx+48]
-        packuswb    xmm2,       xmm6              ; pack and unpack to saturate
-        movdqa      XMMWORD PTR [rdi+rax],  xmm2
-
-
-        movdqa      xmm3,       XMMWORD PTR [rsi+32]
-        movdqa      xmm7,       xmm3
-        punpcklbw   xmm3,       xmm0
-        punpckhbw   xmm7,       xmm0
-        paddsw      xmm3,       XMMWORD PTR [rdx+64]
-        paddsw      xmm7,       XMMWORD PTR [rdx+80]
-        packuswb    xmm3,       xmm7              ; pack and unpack to saturate
-        movdqa      XMMWORD PTR [rdi+rax*2],    xmm3
-
-        add       rdi, rax
-        movdqa      xmm4,       XMMWORD PTR [rsi+48]
-        movdqa      xmm5,       xmm4
-        punpcklbw   xmm4,       xmm0
-        punpckhbw   xmm5,       xmm0
-        paddsw      xmm4,       XMMWORD PTR [rdx+96]
-        paddsw      xmm5,       XMMWORD PTR [rdx+112]
-        packuswb    xmm4,       xmm5              ; pack and unpack to saturate
-        movdqa      XMMWORD PTR [rdi+rax*2],    xmm4
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void copy_mem16x16_sse2(
-;    unsigned char *src,
-;    int src_stride,
-;    unsigned char *dst,
-;    int dst_stride
-;    )
-global sym(vp8_copy_mem16x16_sse2)
-sym(vp8_copy_mem16x16_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 4
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov         rsi,        arg(0) ;src;
-        movdqu      xmm0,       [rsi]
-
-        movsxd      rax,        dword ptr arg(1) ;src_stride;
-        mov         rdi,        arg(2) ;dst;
-
-        movdqu      xmm1,       [rsi+rax]
-        movdqu      xmm2,       [rsi+rax*2]
-
-        movsxd      rcx,        dword ptr arg(3) ;dst_stride
-        lea         rsi,        [rsi+rax*2]
-
-        movdqa      [rdi],      xmm0
-        add         rsi,        rax
-
-        movdqa      [rdi+rcx],  xmm1
-        movdqa      [rdi+rcx*2],xmm2
-
-        lea         rdi,        [rdi+rcx*2]
-        movdqu      xmm3,       [rsi]
-
-        add         rdi,        rcx
-        movdqu      xmm4,       [rsi+rax]
-
-        movdqu      xmm5,       [rsi+rax*2]
-        lea         rsi,        [rsi+rax*2]
-
-        movdqa      [rdi],  xmm3
-        add         rsi,        rax
-
-        movdqa      [rdi+rcx],  xmm4
-        movdqa      [rdi+rcx*2],xmm5
-
-        lea         rdi,        [rdi+rcx*2]
-        movdqu      xmm0,       [rsi]
-
-        add         rdi,        rcx
-        movdqu      xmm1,       [rsi+rax]
-
-        movdqu      xmm2,       [rsi+rax*2]
-        lea         rsi,        [rsi+rax*2]
-
-        movdqa      [rdi],      xmm0
-        add         rsi,        rax
-
-        movdqa      [rdi+rcx],  xmm1
-
-        movdqa      [rdi+rcx*2],    xmm2
-        movdqu      xmm3,       [rsi]
-
-        movdqu      xmm4,       [rsi+rax]
-        lea         rdi,        [rdi+rcx*2]
-
-        add         rdi,        rcx
-        movdqu      xmm5,       [rsi+rax*2]
-
-        lea         rsi,        [rsi+rax*2]
-        movdqa      [rdi],  xmm3
-
-        add         rsi,        rax
-        movdqa      [rdi+rcx],  xmm4
-
-        movdqa      [rdi+rcx*2],xmm5
-        movdqu      xmm0,       [rsi]
-
-        lea         rdi,        [rdi+rcx*2]
-        movdqu      xmm1,       [rsi+rax]
-
-        add         rdi,        rcx
-        movdqu      xmm2,       [rsi+rax*2]
-
-        lea         rsi,        [rsi+rax*2]
-        movdqa      [rdi],      xmm0
-
-        movdqa      [rdi+rcx],  xmm1
-        movdqa      [rdi+rcx*2],xmm2
-
-        movdqu      xmm3,       [rsi+rax]
-        lea         rdi,        [rdi+rcx*2]
-
-        movdqa      [rdi+rcx],  xmm3
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
diff --git a/vp8/common/x86/subpixel_mmx.S b/vp8/common/x86/subpixel_mmx.S
new file mode 100644
index 0000000..a6a5795
--- /dev/null
+++ b/vp8/common/x86/subpixel_mmx.S
@@ -0,0 +1,817 @@
+//
+//  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
+//
+//  Use of this source code is governed by a BSD-style license and patent
+//  grant that can be found in the LICENSE file in the root of the source
+//  tree. All contributing project authors may be found in the AUTHORS
+//  file in the root of the source tree.
+//
+
+
+#include "vpx_ports/x86_abi_support.S"
+
+
+#define BLOCK_HEIGHT_WIDTH 4
+#define vp8_filter_weight 128
+#define VP8_FILTER_SHIFT  7
+
+
+//void vp8_filter_block1d_h6_mmx
+//(
+//    unsigned char   *src_ptr,
+//    unsigned short  *output_ptr,
+//    unsigned int    src_pixels_per_line,
+//    unsigned int    pixel_step,
+//    unsigned int    output_height,
+//    unsigned int    output_width,
+//    short           * vp8_filter
+//)
+global sym(vp8_filter_block1d_h6_mmx)
+sym(vp8_filter_block1d_h6_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 7
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov         rdx,    arg(6) //vp8_filter
+
+        movq        mm1,    [rdx + 16]             // do both the negative taps first!!!
+        movq        mm2,    [rdx + 32]         //
+        movq        mm6,    [rdx + 48]        //
+        movq        mm7,    [rdx + 64]        //
+
+        mov         rdi,    arg(1) //output_ptr
+        mov         rsi,    arg(0) //src_ptr
+        movsxd      rcx,    dword ptr arg(4) //output_height
+        movsxd      rax,    dword ptr arg(5) //output_width      ; destination pitch?
+        pxor        mm0,    mm0              // mm0 = 00000000
+
+nextrow:
+        movq        mm3,    [rsi-2]          // mm3 = p-2..p5
+        movq        mm4,    mm3              // mm4 = p-2..p5
+        psrlq       mm3,    8                // mm3 = p-1..p5
+        punpcklbw   mm3,    mm0              // mm3 = p-1..p2
+        pmullw      mm3,    mm1              // mm3 *= kernel 1 modifiers.
+
+        movq        mm5,    mm4              // mm5 = p-2..p5
+        punpckhbw   mm4,    mm0              // mm5 = p2..p5
+        pmullw      mm4,    mm7              // mm5 *= kernel 4 modifiers
+        paddsw      mm3,    mm4              // mm3 += mm5
+
+        movq        mm4,    mm5              // mm4 = p-2..p5;
+        psrlq       mm5,    16               // mm5 = p0..p5;
+        punpcklbw   mm5,    mm0              // mm5 = p0..p3
+        pmullw      mm5,    mm2              // mm5 *= kernel 2 modifiers
+        paddsw      mm3,    mm5              // mm3 += mm5
+
+        movq        mm5,    mm4              // mm5 = p-2..p5
+        psrlq       mm4,    24               // mm4 = p1..p5
+        punpcklbw   mm4,    mm0              // mm4 = p1..p4
+        pmullw      mm4,    mm6              // mm5 *= kernel 3 modifiers
+        paddsw      mm3,    mm4              // mm3 += mm5
+
+        // do outer positive taps
+        movd        mm4,    [rsi+3]
+        punpcklbw   mm4,    mm0              // mm5 = p3..p6
+        pmullw      mm4,    [rdx+80]         // mm5 *= kernel 0 modifiers
+        paddsw      mm3,    mm4              // mm3 += mm5
+
+        punpcklbw   mm5,    mm0              // mm5 = p-2..p1
+        pmullw      mm5,    [rdx]            // mm5 *= kernel 5 modifiers
+        paddsw      mm3,    mm5              // mm3 += mm5
+
+        paddsw      mm3,    [GLOBAL (rd)]               // mm3 += round value
+        psraw       mm3,    VP8_FILTER_SHIFT     // mm3 /= 128
+        packuswb    mm3,    mm0              // pack and unpack to saturate
+        punpcklbw   mm3,    mm0              //
+
+        movq        [rdi],  mm3              // store the results in the destination
+
+#if ABI_IS_32BIT
+        add         rsi,    dword ptr arg(2) //src_pixels_per_line ; next line
+        add         rdi,    rax;
+#else
+        movsxd      r8,     dword ptr arg(2) //src_pixels_per_line
+        add         rdi,    rax;
+
+        add         rsi,    r8               // next line
+#endif
+
+        dec         rcx                      // decrement count
+        jnz         nextrow                  // next row
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//
+// THIS FUNCTION APPEARS TO BE UNUSED
+//
+//void vp8_filter_block1d_v6_mmx
+//(
+//   short *src_ptr,
+//   unsigned char *output_ptr,
+//   unsigned int pixels_per_line,
+//   unsigned int pixel_step,
+//   unsigned int output_height,
+//   unsigned int output_width,
+//   short * vp8_filter
+//)
+global sym(vp8_filter_block1d_v6_mmx)
+sym(vp8_filter_block1d_v6_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 7
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+        movq      mm5, [GLOBAL (rd)]
+        push        rbx
+        mov         rbx, arg(6) //vp8_filter
+        movq      mm1, [rbx + 16]             // do both the negative taps first!!!
+        movq      mm2, [rbx + 32]         //
+        movq      mm6, [rbx + 48]        //
+        movq      mm7, [rbx + 64]        //
+
+        movsxd      rdx, dword ptr arg(2) //pixels_per_line
+        mov         rdi, arg(1) //output_ptr
+        mov         rsi, arg(0) //src_ptr
+        sub         rsi, rdx
+        sub         rsi, rdx
+        movsxd      rcx, DWORD PTR arg(4) //output_height
+        movsxd      rax, DWORD PTR arg(5) //output_width      ; destination pitch?
+        pxor        mm0, mm0              // mm0 = 00000000
+
+
+nextrow_v:
+        movq        mm3, [rsi+rdx]        // mm3 = p0..p8  = row -1
+        pmullw      mm3, mm1              // mm3 *= kernel 1 modifiers.
+
+
+        movq        mm4, [rsi + 4*rdx]      // mm4 = p0..p3  = row 2
+        pmullw      mm4, mm7              // mm4 *= kernel 4 modifiers.
+        paddsw      mm3, mm4              // mm3 += mm4
+
+        movq        mm4, [rsi + 2*rdx]           // mm4 = p0..p3  = row 0
+        pmullw      mm4, mm2              // mm4 *= kernel 2 modifiers.
+        paddsw      mm3, mm4              // mm3 += mm4
+
+        movq        mm4, [rsi]            // mm4 = p0..p3  = row -2
+        pmullw      mm4, [rbx]            // mm4 *= kernel 0 modifiers.
+        paddsw      mm3, mm4              // mm3 += mm4
+
+
+        add         rsi, rdx              // move source forward 1 line to avoid 3 * pitch
+        movq        mm4, [rsi + 2*rdx]     // mm4 = p0..p3  = row 1
+        pmullw      mm4, mm6              // mm4 *= kernel 3 modifiers.
+        paddsw      mm3, mm4              // mm3 += mm4
+
+        movq        mm4, [rsi + 4*rdx]    // mm4 = p0..p3  = row 3
+        pmullw      mm4, [rbx +80]        // mm4 *= kernel 3 modifiers.
+        paddsw      mm3, mm4              // mm3 += mm4
+
+
+        paddsw      mm3, mm5               // mm3 += round value
+        psraw       mm3, VP8_FILTER_SHIFT     // mm3 /= 128
+        packuswb    mm3, mm0              // pack and saturate
+
+        movd        [rdi],mm3             // store the results in the destination
+
+        add         rdi,rax;
+
+        dec         rcx                   // decrement count
+        jnz         nextrow_v             // next row
+
+        pop         rbx
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void vp8_filter_block1dc_v6_mmx
+//(
+//   short *src_ptr,
+//   unsigned char *output_ptr,
+//    int output_pitch,
+//   unsigned int pixels_per_line,
+//   unsigned int pixel_step,
+//   unsigned int output_height,
+//   unsigned int output_width,
+//   short * vp8_filter
+//)
+global sym(vp8_filter_block1dc_v6_mmx)
+sym(vp8_filter_block1dc_v6_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 8
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+        movq      mm5, [GLOBAL (rd)]
+        push        rbx
+        mov         rbx, arg(7) //vp8_filter
+        movq      mm1, [rbx + 16]             // do both the negative taps first!!!
+        movq      mm2, [rbx + 32]         //
+        movq      mm6, [rbx + 48]        //
+        movq      mm7, [rbx + 64]        //
+
+        movsxd      rdx, dword ptr arg(3) //pixels_per_line
+        mov         rdi, arg(1) //output_ptr
+        mov         rsi, arg(0) //src_ptr
+        sub         rsi, rdx
+        sub         rsi, rdx
+        movsxd      rcx, DWORD PTR arg(5) //output_height
+        movsxd      rax, DWORD PTR arg(2) //output_pitch      ; destination pitch?
+        pxor        mm0, mm0              // mm0 = 00000000
+
+
+nextrow_cv:
+        movq        mm3, [rsi+rdx]        // mm3 = p0..p8  = row -1
+        pmullw      mm3, mm1              // mm3 *= kernel 1 modifiers.
+
+
+        movq        mm4, [rsi + 4*rdx]      // mm4 = p0..p3  = row 2
+        pmullw      mm4, mm7              // mm4 *= kernel 4 modifiers.
+        paddsw      mm3, mm4              // mm3 += mm4
+
+        movq        mm4, [rsi + 2*rdx]           // mm4 = p0..p3  = row 0
+        pmullw      mm4, mm2              // mm4 *= kernel 2 modifiers.
+        paddsw      mm3, mm4              // mm3 += mm4
+
+        movq        mm4, [rsi]            // mm4 = p0..p3  = row -2
+        pmullw      mm4, [rbx]            // mm4 *= kernel 0 modifiers.
+        paddsw      mm3, mm4              // mm3 += mm4
+
+
+        add         rsi, rdx              // move source forward 1 line to avoid 3 * pitch
+        movq        mm4, [rsi + 2*rdx]     // mm4 = p0..p3  = row 1
+        pmullw      mm4, mm6              // mm4 *= kernel 3 modifiers.
+        paddsw      mm3, mm4              // mm3 += mm4
+
+        movq        mm4, [rsi + 4*rdx]    // mm4 = p0..p3  = row 3
+        pmullw      mm4, [rbx +80]        // mm4 *= kernel 3 modifiers.
+        paddsw      mm3, mm4              // mm3 += mm4
+
+
+        paddsw      mm3, mm5               // mm3 += round value
+        psraw       mm3, VP8_FILTER_SHIFT     // mm3 /= 128
+        packuswb    mm3, mm0              // pack and saturate
+
+        movd        [rdi],mm3             // store the results in the destination
+        // the subsequent iterations repeat 3 out of 4 of these reads.  Since the
+        // recon block should be in cache this shouldn't cost much.  Its obviously
+        // avoidable!!!.
+        lea         rdi,  [rdi+rax] //
+        dec         rcx                   // decrement count
+        jnz         nextrow_cv             // next row
+
+        pop         rbx
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void bilinear_predict8x8_mmx
+//(
+//    unsigned char  *src_ptr,
+//    int   src_pixels_per_line,
+//    int  xoffset,
+//    int  yoffset,
+//   unsigned char *dst_ptr,
+//    int dst_pitch
+//)
+global sym(vp8_bilinear_predict8x8_mmx)
+sym(vp8_bilinear_predict8x8_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 6
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+    //const short *HFilter = bilinear_filters_mmx[xoffset];
+    //const short *VFilter = bilinear_filters_mmx[yoffset];
+
+        movsxd      rax,        dword ptr arg(2) //xoffset
+        mov         rdi,        arg(4) //dst_ptr           ;
+
+        shl         rax,        5 // offset * 32
+        lea         rcx,        [GLOBAL (sym(vp8_bilinear_filters_mmx))]
+
+        add         rax,        rcx // HFilter
+        mov         rsi,        arg(0) //src_ptr              ;
+
+        movsxd      rdx,        dword ptr arg(5) //dst_pitch
+        movq        mm1,        [rax]               //
+
+        movq        mm2,        [rax+16]            //
+        movsxd      rax,        dword ptr arg(3) //yoffset
+
+        pxor        mm0,        mm0                 //
+
+        shl         rax,        5 // offset*32
+        add         rax,        rcx // VFilter
+
+        lea         rcx,        [rdi+rdx*8]          //
+        movsxd      rdx,        dword ptr arg(1) //src_pixels_per_line    ;
+
+
+
+        // get the first horizontal line done       ;
+        movq        mm3,        [rsi]               // xx 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14
+        movq        mm4,        mm3                 // make a copy of current line
+
+        punpcklbw   mm3,        mm0                 // xx 00 01 02 03 04 05 06
+        punpckhbw   mm4,        mm0                 //
+
+        pmullw      mm3,        mm1                 //
+        pmullw      mm4,        mm1                 //
+
+        movq        mm5,        [rsi+1]             //
+        movq        mm6,        mm5                 //
+
+        punpcklbw   mm5,        mm0                 //
+        punpckhbw   mm6,        mm0                 //
+
+        pmullw      mm5,        mm2                 //
+        pmullw      mm6,        mm2                 //
+
+        paddw       mm3,        mm5                 //
+        paddw       mm4,        mm6                 //
+
+        paddw       mm3,        [GLOBAL (rd)]                  // xmm3 += round value
+        psraw       mm3,        VP8_FILTER_SHIFT        // xmm3 /= 128
+
+        paddw       mm4,        [GLOBAL (rd)]                  //
+        psraw       mm4,        VP8_FILTER_SHIFT        //
+
+        movq        mm7,        mm3                 //
+        packuswb    mm7,        mm4                 //
+
+        add         rsi,        rdx                 // next line
+next_row_8x8:
+        movq        mm3,        [rsi]               // xx 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14
+        movq        mm4,        mm3                 // make a copy of current line
+
+        punpcklbw   mm3,        mm0                 // xx 00 01 02 03 04 05 06
+        punpckhbw   mm4,        mm0                 //
+
+        pmullw      mm3,        mm1                 //
+        pmullw      mm4,        mm1                 //
+
+        movq        mm5,        [rsi+1]             //
+        movq        mm6,        mm5                 //
+
+        punpcklbw   mm5,        mm0                 //
+        punpckhbw   mm6,        mm0                 //
+
+        pmullw      mm5,        mm2                 //
+        pmullw      mm6,        mm2                 //
+
+        paddw       mm3,        mm5                 //
+        paddw       mm4,        mm6                 //
+
+        movq        mm5,        mm7                 //
+        movq        mm6,        mm7                 //
+
+        punpcklbw   mm5,        mm0                 //
+        punpckhbw   mm6,        mm0
+
+        pmullw      mm5,        [rax]               //
+        pmullw      mm6,        [rax]               //
+
+        paddw       mm3,        [GLOBAL (rd)]                  // xmm3 += round value
+        psraw       mm3,        VP8_FILTER_SHIFT        // xmm3 /= 128
+
+        paddw       mm4,        [GLOBAL (rd)]                  //
+        psraw       mm4,        VP8_FILTER_SHIFT        //
+
+        movq        mm7,        mm3                 //
+        packuswb    mm7,        mm4                 //
+
+
+        pmullw      mm3,        [rax+16]            //
+        pmullw      mm4,        [rax+16]            //
+
+        paddw       mm3,        mm5                 //
+        paddw       mm4,        mm6                 //
+
+
+        paddw       mm3,        [GLOBAL (rd)]                  // xmm3 += round value
+        psraw       mm3,        VP8_FILTER_SHIFT        // xmm3 /= 128
+
+        paddw       mm4,        [GLOBAL (rd)]                  //
+        psraw       mm4,        VP8_FILTER_SHIFT        //
+
+        packuswb    mm3,        mm4
+
+        movq        [rdi],      mm3                 // store the results in the destination
+
+#if ABI_IS_32BIT
+        add         rsi,        rdx                 // next line
+        add         rdi,        dword ptr arg(5) //dst_pitch                   ;
+#else
+        movsxd      r8,         dword ptr arg(5) //dst_pitch
+        add         rsi,        rdx                 // next line
+        add         rdi,        r8                  //dst_pitch
+#endif
+        cmp         rdi,        rcx                 //
+        jne         next_row_8x8
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void bilinear_predict8x4_mmx
+//(
+//    unsigned char  *src_ptr,
+//    int   src_pixels_per_line,
+//    int  xoffset,
+//    int  yoffset,
+//    unsigned char *dst_ptr,
+//    int dst_pitch
+//)
+global sym(vp8_bilinear_predict8x4_mmx)
+sym(vp8_bilinear_predict8x4_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 6
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+    //const short *HFilter = bilinear_filters_mmx[xoffset];
+    //const short *VFilter = bilinear_filters_mmx[yoffset];
+
+        movsxd      rax,        dword ptr arg(2) //xoffset
+        mov         rdi,        arg(4) //dst_ptr           ;
+
+        lea         rcx,        [GLOBAL (sym(vp8_bilinear_filters_mmx))]
+        shl         rax,        5
+
+        mov         rsi,        arg(0) //src_ptr              ;
+        add         rax,        rcx
+
+        movsxd      rdx,        dword ptr arg(5) //dst_pitch
+        movq        mm1,        [rax]               //
+
+        movq        mm2,        [rax+16]            //
+        movsxd      rax,        dword ptr arg(3) //yoffset
+
+        pxor        mm0,        mm0                 //
+        shl         rax,        5
+
+        add         rax,        rcx
+        lea         rcx,        [rdi+rdx*4]          //
+
+        movsxd      rdx,        dword ptr arg(1) //src_pixels_per_line    ;
+
+        // get the first horizontal line done       ;
+        movq        mm3,        [rsi]               // xx 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14
+        movq        mm4,        mm3                 // make a copy of current line
+
+        punpcklbw   mm3,        mm0                 // xx 00 01 02 03 04 05 06
+        punpckhbw   mm4,        mm0                 //
+
+        pmullw      mm3,        mm1                 //
+        pmullw      mm4,        mm1                 //
+
+        movq        mm5,        [rsi+1]             //
+        movq        mm6,        mm5                 //
+
+        punpcklbw   mm5,        mm0                 //
+        punpckhbw   mm6,        mm0                 //
+
+        pmullw      mm5,        mm2                 //
+        pmullw      mm6,        mm2                 //
+
+        paddw       mm3,        mm5                 //
+        paddw       mm4,        mm6                 //
+
+        paddw       mm3,        [GLOBAL (rd)]                  // xmm3 += round value
+        psraw       mm3,        VP8_FILTER_SHIFT        // xmm3 /= 128
+
+        paddw       mm4,        [GLOBAL (rd)]                  //
+        psraw       mm4,        VP8_FILTER_SHIFT        //
+
+        movq        mm7,        mm3                 //
+        packuswb    mm7,        mm4                 //
+
+        add         rsi,        rdx                 // next line
+next_row_8x4:
+        movq        mm3,        [rsi]               // xx 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14
+        movq        mm4,        mm3                 // make a copy of current line
+
+        punpcklbw   mm3,        mm0                 // xx 00 01 02 03 04 05 06
+        punpckhbw   mm4,        mm0                 //
+
+        pmullw      mm3,        mm1                 //
+        pmullw      mm4,        mm1                 //
+
+        movq        mm5,        [rsi+1]             //
+        movq        mm6,        mm5                 //
+
+        punpcklbw   mm5,        mm0                 //
+        punpckhbw   mm6,        mm0                 //
+
+        pmullw      mm5,        mm2                 //
+        pmullw      mm6,        mm2                 //
+
+        paddw       mm3,        mm5                 //
+        paddw       mm4,        mm6                 //
+
+        movq        mm5,        mm7                 //
+        movq        mm6,        mm7                 //
+
+        punpcklbw   mm5,        mm0                 //
+        punpckhbw   mm6,        mm0
+
+        pmullw      mm5,        [rax]               //
+        pmullw      mm6,        [rax]               //
+
+        paddw       mm3,        [GLOBAL (rd)]                  // xmm3 += round value
+        psraw       mm3,        VP8_FILTER_SHIFT        // xmm3 /= 128
+
+        paddw       mm4,        [GLOBAL (rd)]                  //
+        psraw       mm4,        VP8_FILTER_SHIFT        //
+
+        movq        mm7,        mm3                 //
+        packuswb    mm7,        mm4                 //
+
+
+        pmullw      mm3,        [rax+16]            //
+        pmullw      mm4,        [rax+16]            //
+
+        paddw       mm3,        mm5                 //
+        paddw       mm4,        mm6                 //
+
+
+        paddw       mm3,        [GLOBAL (rd)]                  // xmm3 += round value
+        psraw       mm3,        VP8_FILTER_SHIFT        // xmm3 /= 128
+
+        paddw       mm4,        [GLOBAL (rd)]                  //
+        psraw       mm4,        VP8_FILTER_SHIFT        //
+
+        packuswb    mm3,        mm4
+
+        movq        [rdi],      mm3                 // store the results in the destination
+
+#if ABI_IS_32BIT
+        add         rsi,        rdx                 // next line
+        add         rdi,        dword ptr arg(5) //dst_pitch                   ;
+#else
+        movsxd      r8,         dword ptr arg(5) //dst_pitch
+        add         rsi,        rdx                 // next line
+        add         rdi,        r8
+#endif
+        cmp         rdi,        rcx                 //
+        jne         next_row_8x4
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void bilinear_predict4x4_mmx
+//(
+//    unsigned char  *src_ptr,
+//    int   src_pixels_per_line,
+//    int  xoffset,
+//    int  yoffset,
+//    unsigned char *dst_ptr,
+//    int dst_pitch
+//)
+global sym(vp8_bilinear_predict4x4_mmx)
+sym(vp8_bilinear_predict4x4_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 6
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+    //const short *HFilter = bilinear_filters_mmx[xoffset];
+    //const short *VFilter = bilinear_filters_mmx[yoffset];
+
+        movsxd      rax,        dword ptr arg(2) //xoffset
+        mov         rdi,        arg(4) //dst_ptr           ;
+
+        lea         rcx,        [GLOBAL (sym(vp8_bilinear_filters_mmx))]
+        shl         rax,        5
+
+        add         rax,        rcx // HFilter
+        mov         rsi,        arg(0) //src_ptr              ;
+
+        movsxd      rdx,        dword ptr arg(5) //ldst_pitch
+        movq        mm1,        [rax]               //
+
+        movq        mm2,        [rax+16]            //
+        movsxd      rax,        dword ptr arg(3) //yoffset
+
+        pxor        mm0,        mm0                 //
+        shl         rax,        5
+
+        add         rax,        rcx
+        lea         rcx,        [rdi+rdx*4]          //
+
+        movsxd      rdx,        dword ptr arg(1) //src_pixels_per_line    ;
+
+        // get the first horizontal line done       ;
+        movd        mm3,        [rsi]               // xx 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14
+        punpcklbw   mm3,        mm0                 // xx 00 01 02 03 04 05 06
+
+        pmullw      mm3,        mm1                 //
+        movd        mm5,        [rsi+1]             //
+
+        punpcklbw   mm5,        mm0                 //
+        pmullw      mm5,        mm2                 //
+
+        paddw       mm3,        mm5                 //
+        paddw       mm3,        [GLOBAL (rd)]                  // xmm3 += round value
+
+        psraw       mm3,        VP8_FILTER_SHIFT        // xmm3 /= 128
+
+        movq        mm7,        mm3                 //
+        packuswb    mm7,        mm0                 //
+
+        add         rsi,        rdx                 // next line
+next_row_4x4:
+        movd        mm3,        [rsi]               // xx 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14
+        punpcklbw   mm3,        mm0                 // xx 00 01 02 03 04 05 06
+
+        pmullw      mm3,        mm1                 //
+        movd        mm5,        [rsi+1]             //
+
+        punpcklbw   mm5,        mm0                 //
+        pmullw      mm5,        mm2                 //
+
+        paddw       mm3,        mm5                 //
+
+        movq        mm5,        mm7                 //
+        punpcklbw   mm5,        mm0                 //
+
+        pmullw      mm5,        [rax]               //
+        paddw       mm3,        [GLOBAL (rd)]                  // xmm3 += round value
+
+        psraw       mm3,        VP8_FILTER_SHIFT        // xmm3 /= 128
+        movq        mm7,        mm3                 //
+
+        packuswb    mm7,        mm0                 //
+
+        pmullw      mm3,        [rax+16]            //
+        paddw       mm3,        mm5                 //
+
+
+        paddw       mm3,        [GLOBAL (rd)]                  // xmm3 += round value
+        psraw       mm3,        VP8_FILTER_SHIFT        // xmm3 /= 128
+
+        packuswb    mm3,        mm0
+        movd        [rdi],      mm3                 // store the results in the destination
+
+#if ABI_IS_32BIT
+        add         rsi,        rdx                 // next line
+        add         rdi,        dword ptr arg(5) //dst_pitch                   ;
+#else
+        movsxd      r8,         dword ptr arg(5) //dst_pitch                   ;
+        add         rsi,        rdx                 // next line
+        add         rdi,        r8
+#endif
+
+        cmp         rdi,        rcx                 //
+        jne         next_row_4x4
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+
+SECTION_RODATA
+align 16
+rd:
+    .fill 4, 2, 0x40
+
+align 16
+global sym(vp8_six_tap_mmx)
+sym(vp8_six_tap_mmx):
+    .fill 8, 2, 0
+    .fill 8, 2, 0
+    .fill 8, 2, 128
+    .fill 8, 2, 0
+    .fill 8, 2, 0
+    .fill 8, 2, 0
+
+    .fill 8, 2, 0
+    .fill 8, 2, -6
+    .fill 8, 2, 123
+    .fill 8, 2, 12
+    .fill 8, 2, -1
+    .fill 8, 2, 0
+
+    .fill 8, 2, 2
+    .fill 8, 2, -11
+    .fill 8, 2, 108
+    .fill 8, 2, 36
+    .fill 8, 2, -8
+    .fill 8, 2, 1
+
+    .fill 8, 2, 0
+    .fill 8, 2, -9
+    .fill 8, 2, 93
+    .fill 8, 2, 50
+    .fill 8, 2, -6
+    .fill 8, 2, 0
+
+    .fill 8, 2, 3
+    .fill 8, 2, -16
+    .fill 8, 2, 77
+    .fill 8, 2, 77
+    .fill 8, 2, -16
+    .fill 8, 2, 3
+
+    .fill 8, 2, 0
+    .fill 8, 2, -6
+    .fill 8, 2, 50
+    .fill 8, 2, 93
+    .fill 8, 2, -9
+    .fill 8, 2, 0
+
+    .fill 8, 2, 1
+    .fill 8, 2, -8
+    .fill 8, 2, 36
+    .fill 8, 2, 108
+    .fill 8, 2, -11
+    .fill 8, 2, 2
+
+    .fill 8, 2, 0
+    .fill 8, 2, -1
+    .fill 8, 2, 12
+    .fill 8, 2, 123
+    .fill 8, 2, -6
+    .fill 8, 2, 0
+
+
+align 16
+global sym(vp8_bilinear_filters_mmx)
+sym(vp8_bilinear_filters_mmx):
+    .fill 8, 2, 128
+    .fill 8, 2, 0
+
+    .fill 8, 2, 112
+    .fill 8, 2, 16
+
+    .fill 8, 2, 96
+    .fill 8, 2, 32
+
+    .fill 8, 2, 80
+    .fill 8, 2, 48
+
+    .fill 8, 2, 64
+    .fill 8, 2, 64
+
+    .fill 8, 2, 48
+    .fill 8, 2, 80
+
+    .fill 8, 2, 32
+    .fill 8, 2, 96
+
+    .fill 8, 2, 16
+    .fill 8, 2, 112
diff --git a/vp8/common/x86/subpixel_mmx.asm b/vp8/common/x86/subpixel_mmx.asm
deleted file mode 100644
index c502118..0000000
--- a/vp8/common/x86/subpixel_mmx.asm
+++ /dev/null
@@ -1,817 +0,0 @@
-;
-;  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
-;
-;  Use of this source code is governed by a BSD-style license and patent
-;  grant that can be found in the LICENSE file in the root of the source
-;  tree. All contributing project authors may be found in the AUTHORS
-;  file in the root of the source tree.
-;
-
-
-%include "vpx_ports/x86_abi_support.asm"
-
-
-%define BLOCK_HEIGHT_WIDTH 4
-%define vp8_filter_weight 128
-%define VP8_FILTER_SHIFT  7
-
-
-;void vp8_filter_block1d_h6_mmx
-;(
-;    unsigned char   *src_ptr,
-;    unsigned short  *output_ptr,
-;    unsigned int    src_pixels_per_line,
-;    unsigned int    pixel_step,
-;    unsigned int    output_height,
-;    unsigned int    output_width,
-;    short           * vp8_filter
-;)
-global sym(vp8_filter_block1d_h6_mmx)
-sym(vp8_filter_block1d_h6_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 7
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov         rdx,    arg(6) ;vp8_filter
-
-        movq        mm1,    [rdx + 16]             ; do both the negative taps first!!!
-        movq        mm2,    [rdx + 32]         ;
-        movq        mm6,    [rdx + 48]        ;
-        movq        mm7,    [rdx + 64]        ;
-
-        mov         rdi,    arg(1) ;output_ptr
-        mov         rsi,    arg(0) ;src_ptr
-        movsxd      rcx,    dword ptr arg(4) ;output_height
-        movsxd      rax,    dword ptr arg(5) ;output_width      ; destination pitch?
-        pxor        mm0,    mm0              ; mm0 = 00000000
-
-nextrow:
-        movq        mm3,    [rsi-2]          ; mm3 = p-2..p5
-        movq        mm4,    mm3              ; mm4 = p-2..p5
-        psrlq       mm3,    8                ; mm3 = p-1..p5
-        punpcklbw   mm3,    mm0              ; mm3 = p-1..p2
-        pmullw      mm3,    mm1              ; mm3 *= kernel 1 modifiers.
-
-        movq        mm5,    mm4              ; mm5 = p-2..p5
-        punpckhbw   mm4,    mm0              ; mm5 = p2..p5
-        pmullw      mm4,    mm7              ; mm5 *= kernel 4 modifiers
-        paddsw      mm3,    mm4              ; mm3 += mm5
-
-        movq        mm4,    mm5              ; mm4 = p-2..p5;
-        psrlq       mm5,    16               ; mm5 = p0..p5;
-        punpcklbw   mm5,    mm0              ; mm5 = p0..p3
-        pmullw      mm5,    mm2              ; mm5 *= kernel 2 modifiers
-        paddsw      mm3,    mm5              ; mm3 += mm5
-
-        movq        mm5,    mm4              ; mm5 = p-2..p5
-        psrlq       mm4,    24               ; mm4 = p1..p5
-        punpcklbw   mm4,    mm0              ; mm4 = p1..p4
-        pmullw      mm4,    mm6              ; mm5 *= kernel 3 modifiers
-        paddsw      mm3,    mm4              ; mm3 += mm5
-
-        ; do outer positive taps
-        movd        mm4,    [rsi+3]
-        punpcklbw   mm4,    mm0              ; mm5 = p3..p6
-        pmullw      mm4,    [rdx+80]         ; mm5 *= kernel 0 modifiers
-        paddsw      mm3,    mm4              ; mm3 += mm5
-
-        punpcklbw   mm5,    mm0              ; mm5 = p-2..p1
-        pmullw      mm5,    [rdx]            ; mm5 *= kernel 5 modifiers
-        paddsw      mm3,    mm5              ; mm3 += mm5
-
-        paddsw      mm3,    [rd GLOBAL]               ; mm3 += round value
-        psraw       mm3,    VP8_FILTER_SHIFT     ; mm3 /= 128
-        packuswb    mm3,    mm0              ; pack and unpack to saturate
-        punpcklbw   mm3,    mm0              ;
-
-        movq        [rdi],  mm3              ; store the results in the destination
-
-%if ABI_IS_32BIT
-        add         rsi,    dword ptr arg(2) ;src_pixels_per_line ; next line
-        add         rdi,    rax;
-%else
-        movsxd      r8,     dword ptr arg(2) ;src_pixels_per_line
-        add         rdi,    rax;
-
-        add         rsi,    r8               ; next line
-%endif
-
-        dec         rcx                      ; decrement count
-        jnz         nextrow                  ; next row
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;
-; THIS FUNCTION APPEARS TO BE UNUSED
-;
-;void vp8_filter_block1d_v6_mmx
-;(
-;   short *src_ptr,
-;   unsigned char *output_ptr,
-;   unsigned int pixels_per_line,
-;   unsigned int pixel_step,
-;   unsigned int output_height,
-;   unsigned int output_width,
-;   short * vp8_filter
-;)
-global sym(vp8_filter_block1d_v6_mmx)
-sym(vp8_filter_block1d_v6_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 7
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        movq      mm5, [rd GLOBAL]
-        push        rbx
-        mov         rbx, arg(6) ;vp8_filter
-        movq      mm1, [rbx + 16]             ; do both the negative taps first!!!
-        movq      mm2, [rbx + 32]         ;
-        movq      mm6, [rbx + 48]        ;
-        movq      mm7, [rbx + 64]        ;
-
-        movsxd      rdx, dword ptr arg(2) ;pixels_per_line
-        mov         rdi, arg(1) ;output_ptr
-        mov         rsi, arg(0) ;src_ptr
-        sub         rsi, rdx
-        sub         rsi, rdx
-        movsxd      rcx, DWORD PTR arg(4) ;output_height
-        movsxd      rax, DWORD PTR arg(5) ;output_width      ; destination pitch?
-        pxor        mm0, mm0              ; mm0 = 00000000
-
-
-nextrow_v:
-        movq        mm3, [rsi+rdx]        ; mm3 = p0..p8  = row -1
-        pmullw      mm3, mm1              ; mm3 *= kernel 1 modifiers.
-
-
-        movq        mm4, [rsi + 4*rdx]      ; mm4 = p0..p3  = row 2
-        pmullw      mm4, mm7              ; mm4 *= kernel 4 modifiers.
-        paddsw      mm3, mm4              ; mm3 += mm4
-
-        movq        mm4, [rsi + 2*rdx]           ; mm4 = p0..p3  = row 0
-        pmullw      mm4, mm2              ; mm4 *= kernel 2 modifiers.
-        paddsw      mm3, mm4              ; mm3 += mm4
-
-        movq        mm4, [rsi]            ; mm4 = p0..p3  = row -2
-        pmullw      mm4, [rbx]            ; mm4 *= kernel 0 modifiers.
-        paddsw      mm3, mm4              ; mm3 += mm4
-
-
-        add         rsi, rdx              ; move source forward 1 line to avoid 3 * pitch
-        movq        mm4, [rsi + 2*rdx]     ; mm4 = p0..p3  = row 1
-        pmullw      mm4, mm6              ; mm4 *= kernel 3 modifiers.
-        paddsw      mm3, mm4              ; mm3 += mm4
-
-        movq        mm4, [rsi + 4*rdx]    ; mm4 = p0..p3  = row 3
-        pmullw      mm4, [rbx +80]        ; mm4 *= kernel 3 modifiers.
-        paddsw      mm3, mm4              ; mm3 += mm4
-
-
-        paddsw      mm3, mm5               ; mm3 += round value
-        psraw       mm3, VP8_FILTER_SHIFT     ; mm3 /= 128
-        packuswb    mm3, mm0              ; pack and saturate
-
-        movd        [rdi],mm3             ; store the results in the destination
-
-        add         rdi,rax;
-
-        dec         rcx                   ; decrement count
-        jnz         nextrow_v             ; next row
-
-        pop         rbx
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void vp8_filter_block1dc_v6_mmx
-;(
-;   short *src_ptr,
-;   unsigned char *output_ptr,
-;    int output_pitch,
-;   unsigned int pixels_per_line,
-;   unsigned int pixel_step,
-;   unsigned int output_height,
-;   unsigned int output_width,
-;   short * vp8_filter
-;)
-global sym(vp8_filter_block1dc_v6_mmx)
-sym(vp8_filter_block1dc_v6_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 8
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        movq      mm5, [rd GLOBAL]
-        push        rbx
-        mov         rbx, arg(7) ;vp8_filter
-        movq      mm1, [rbx + 16]             ; do both the negative taps first!!!
-        movq      mm2, [rbx + 32]         ;
-        movq      mm6, [rbx + 48]        ;
-        movq      mm7, [rbx + 64]        ;
-
-        movsxd      rdx, dword ptr arg(3) ;pixels_per_line
-        mov         rdi, arg(1) ;output_ptr
-        mov         rsi, arg(0) ;src_ptr
-        sub         rsi, rdx
-        sub         rsi, rdx
-        movsxd      rcx, DWORD PTR arg(5) ;output_height
-        movsxd      rax, DWORD PTR arg(2) ;output_pitch      ; destination pitch?
-        pxor        mm0, mm0              ; mm0 = 00000000
-
-
-nextrow_cv:
-        movq        mm3, [rsi+rdx]        ; mm3 = p0..p8  = row -1
-        pmullw      mm3, mm1              ; mm3 *= kernel 1 modifiers.
-
-
-        movq        mm4, [rsi + 4*rdx]      ; mm4 = p0..p3  = row 2
-        pmullw      mm4, mm7              ; mm4 *= kernel 4 modifiers.
-        paddsw      mm3, mm4              ; mm3 += mm4
-
-        movq        mm4, [rsi + 2*rdx]           ; mm4 = p0..p3  = row 0
-        pmullw      mm4, mm2              ; mm4 *= kernel 2 modifiers.
-        paddsw      mm3, mm4              ; mm3 += mm4
-
-        movq        mm4, [rsi]            ; mm4 = p0..p3  = row -2
-        pmullw      mm4, [rbx]            ; mm4 *= kernel 0 modifiers.
-        paddsw      mm3, mm4              ; mm3 += mm4
-
-
-        add         rsi, rdx              ; move source forward 1 line to avoid 3 * pitch
-        movq        mm4, [rsi + 2*rdx]     ; mm4 = p0..p3  = row 1
-        pmullw      mm4, mm6              ; mm4 *= kernel 3 modifiers.
-        paddsw      mm3, mm4              ; mm3 += mm4
-
-        movq        mm4, [rsi + 4*rdx]    ; mm4 = p0..p3  = row 3
-        pmullw      mm4, [rbx +80]        ; mm4 *= kernel 3 modifiers.
-        paddsw      mm3, mm4              ; mm3 += mm4
-
-
-        paddsw      mm3, mm5               ; mm3 += round value
-        psraw       mm3, VP8_FILTER_SHIFT     ; mm3 /= 128
-        packuswb    mm3, mm0              ; pack and saturate
-
-        movd        [rdi],mm3             ; store the results in the destination
-        ; the subsequent iterations repeat 3 out of 4 of these reads.  Since the
-        ; recon block should be in cache this shouldn't cost much.  Its obviously
-        ; avoidable!!!.
-        lea         rdi,  [rdi+rax] ;
-        dec         rcx                   ; decrement count
-        jnz         nextrow_cv             ; next row
-
-        pop         rbx
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void bilinear_predict8x8_mmx
-;(
-;    unsigned char  *src_ptr,
-;    int   src_pixels_per_line,
-;    int  xoffset,
-;    int  yoffset,
-;   unsigned char *dst_ptr,
-;    int dst_pitch
-;)
-global sym(vp8_bilinear_predict8x8_mmx)
-sym(vp8_bilinear_predict8x8_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 6
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-    ;const short *HFilter = bilinear_filters_mmx[xoffset];
-    ;const short *VFilter = bilinear_filters_mmx[yoffset];
-
-        movsxd      rax,        dword ptr arg(2) ;xoffset
-        mov         rdi,        arg(4) ;dst_ptr           ;
-
-        shl         rax,        5 ; offset * 32
-        lea         rcx,        [sym(vp8_bilinear_filters_mmx) GLOBAL]
-
-        add         rax,        rcx ; HFilter
-        mov         rsi,        arg(0) ;src_ptr              ;
-
-        movsxd      rdx,        dword ptr arg(5) ;dst_pitch
-        movq        mm1,        [rax]               ;
-
-        movq        mm2,        [rax+16]            ;
-        movsxd      rax,        dword ptr arg(3) ;yoffset
-
-        pxor        mm0,        mm0                 ;
-
-        shl         rax,        5 ; offset*32
-        add         rax,        rcx ; VFilter
-
-        lea         rcx,        [rdi+rdx*8]          ;
-        movsxd      rdx,        dword ptr arg(1) ;src_pixels_per_line    ;
-
-
-
-        ; get the first horizontal line done       ;
-        movq        mm3,        [rsi]               ; xx 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14
-        movq        mm4,        mm3                 ; make a copy of current line
-
-        punpcklbw   mm3,        mm0                 ; xx 00 01 02 03 04 05 06
-        punpckhbw   mm4,        mm0                 ;
-
-        pmullw      mm3,        mm1                 ;
-        pmullw      mm4,        mm1                 ;
-
-        movq        mm5,        [rsi+1]             ;
-        movq        mm6,        mm5                 ;
-
-        punpcklbw   mm5,        mm0                 ;
-        punpckhbw   mm6,        mm0                 ;
-
-        pmullw      mm5,        mm2                 ;
-        pmullw      mm6,        mm2                 ;
-
-        paddw       mm3,        mm5                 ;
-        paddw       mm4,        mm6                 ;
-
-        paddw       mm3,        [rd GLOBAL]                  ; xmm3 += round value
-        psraw       mm3,        VP8_FILTER_SHIFT        ; xmm3 /= 128
-
-        paddw       mm4,        [rd GLOBAL]                  ;
-        psraw       mm4,        VP8_FILTER_SHIFT        ;
-
-        movq        mm7,        mm3                 ;
-        packuswb    mm7,        mm4                 ;
-
-        add         rsi,        rdx                 ; next line
-next_row_8x8:
-        movq        mm3,        [rsi]               ; xx 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14
-        movq        mm4,        mm3                 ; make a copy of current line
-
-        punpcklbw   mm3,        mm0                 ; xx 00 01 02 03 04 05 06
-        punpckhbw   mm4,        mm0                 ;
-
-        pmullw      mm3,        mm1                 ;
-        pmullw      mm4,        mm1                 ;
-
-        movq        mm5,        [rsi+1]             ;
-        movq        mm6,        mm5                 ;
-
-        punpcklbw   mm5,        mm0                 ;
-        punpckhbw   mm6,        mm0                 ;
-
-        pmullw      mm5,        mm2                 ;
-        pmullw      mm6,        mm2                 ;
-
-        paddw       mm3,        mm5                 ;
-        paddw       mm4,        mm6                 ;
-
-        movq        mm5,        mm7                 ;
-        movq        mm6,        mm7                 ;
-
-        punpcklbw   mm5,        mm0                 ;
-        punpckhbw   mm6,        mm0
-
-        pmullw      mm5,        [rax]               ;
-        pmullw      mm6,        [rax]               ;
-
-        paddw       mm3,        [rd GLOBAL]                  ; xmm3 += round value
-        psraw       mm3,        VP8_FILTER_SHIFT        ; xmm3 /= 128
-
-        paddw       mm4,        [rd GLOBAL]                  ;
-        psraw       mm4,        VP8_FILTER_SHIFT        ;
-
-        movq        mm7,        mm3                 ;
-        packuswb    mm7,        mm4                 ;
-
-
-        pmullw      mm3,        [rax+16]            ;
-        pmullw      mm4,        [rax+16]            ;
-
-        paddw       mm3,        mm5                 ;
-        paddw       mm4,        mm6                 ;
-
-
-        paddw       mm3,        [rd GLOBAL]                  ; xmm3 += round value
-        psraw       mm3,        VP8_FILTER_SHIFT        ; xmm3 /= 128
-
-        paddw       mm4,        [rd GLOBAL]                  ;
-        psraw       mm4,        VP8_FILTER_SHIFT        ;
-
-        packuswb    mm3,        mm4
-
-        movq        [rdi],      mm3                 ; store the results in the destination
-
-%if ABI_IS_32BIT
-        add         rsi,        rdx                 ; next line
-        add         rdi,        dword ptr arg(5) ;dst_pitch                   ;
-%else
-        movsxd      r8,         dword ptr arg(5) ;dst_pitch
-        add         rsi,        rdx                 ; next line
-        add         rdi,        r8                  ;dst_pitch
-%endif
-        cmp         rdi,        rcx                 ;
-        jne         next_row_8x8
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void bilinear_predict8x4_mmx
-;(
-;    unsigned char  *src_ptr,
-;    int   src_pixels_per_line,
-;    int  xoffset,
-;    int  yoffset,
-;    unsigned char *dst_ptr,
-;    int dst_pitch
-;)
-global sym(vp8_bilinear_predict8x4_mmx)
-sym(vp8_bilinear_predict8x4_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 6
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-    ;const short *HFilter = bilinear_filters_mmx[xoffset];
-    ;const short *VFilter = bilinear_filters_mmx[yoffset];
-
-        movsxd      rax,        dword ptr arg(2) ;xoffset
-        mov         rdi,        arg(4) ;dst_ptr           ;
-
-        lea         rcx,        [sym(vp8_bilinear_filters_mmx) GLOBAL]
-        shl         rax,        5
-
-        mov         rsi,        arg(0) ;src_ptr              ;
-        add         rax,        rcx
-
-        movsxd      rdx,        dword ptr arg(5) ;dst_pitch
-        movq        mm1,        [rax]               ;
-
-        movq        mm2,        [rax+16]            ;
-        movsxd      rax,        dword ptr arg(3) ;yoffset
-
-        pxor        mm0,        mm0                 ;
-        shl         rax,        5
-
-        add         rax,        rcx
-        lea         rcx,        [rdi+rdx*4]          ;
-
-        movsxd      rdx,        dword ptr arg(1) ;src_pixels_per_line    ;
-
-        ; get the first horizontal line done       ;
-        movq        mm3,        [rsi]               ; xx 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14
-        movq        mm4,        mm3                 ; make a copy of current line
-
-        punpcklbw   mm3,        mm0                 ; xx 00 01 02 03 04 05 06
-        punpckhbw   mm4,        mm0                 ;
-
-        pmullw      mm3,        mm1                 ;
-        pmullw      mm4,        mm1                 ;
-
-        movq        mm5,        [rsi+1]             ;
-        movq        mm6,        mm5                 ;
-
-        punpcklbw   mm5,        mm0                 ;
-        punpckhbw   mm6,        mm0                 ;
-
-        pmullw      mm5,        mm2                 ;
-        pmullw      mm6,        mm2                 ;
-
-        paddw       mm3,        mm5                 ;
-        paddw       mm4,        mm6                 ;
-
-        paddw       mm3,        [rd GLOBAL]                  ; xmm3 += round value
-        psraw       mm3,        VP8_FILTER_SHIFT        ; xmm3 /= 128
-
-        paddw       mm4,        [rd GLOBAL]                  ;
-        psraw       mm4,        VP8_FILTER_SHIFT        ;
-
-        movq        mm7,        mm3                 ;
-        packuswb    mm7,        mm4                 ;
-
-        add         rsi,        rdx                 ; next line
-next_row_8x4:
-        movq        mm3,        [rsi]               ; xx 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14
-        movq        mm4,        mm3                 ; make a copy of current line
-
-        punpcklbw   mm3,        mm0                 ; xx 00 01 02 03 04 05 06
-        punpckhbw   mm4,        mm0                 ;
-
-        pmullw      mm3,        mm1                 ;
-        pmullw      mm4,        mm1                 ;
-
-        movq        mm5,        [rsi+1]             ;
-        movq        mm6,        mm5                 ;
-
-        punpcklbw   mm5,        mm0                 ;
-        punpckhbw   mm6,        mm0                 ;
-
-        pmullw      mm5,        mm2                 ;
-        pmullw      mm6,        mm2                 ;
-
-        paddw       mm3,        mm5                 ;
-        paddw       mm4,        mm6                 ;
-
-        movq        mm5,        mm7                 ;
-        movq        mm6,        mm7                 ;
-
-        punpcklbw   mm5,        mm0                 ;
-        punpckhbw   mm6,        mm0
-
-        pmullw      mm5,        [rax]               ;
-        pmullw      mm6,        [rax]               ;
-
-        paddw       mm3,        [rd GLOBAL]                  ; xmm3 += round value
-        psraw       mm3,        VP8_FILTER_SHIFT        ; xmm3 /= 128
-
-        paddw       mm4,        [rd GLOBAL]                  ;
-        psraw       mm4,        VP8_FILTER_SHIFT        ;
-
-        movq        mm7,        mm3                 ;
-        packuswb    mm7,        mm4                 ;
-
-
-        pmullw      mm3,        [rax+16]            ;
-        pmullw      mm4,        [rax+16]            ;
-
-        paddw       mm3,        mm5                 ;
-        paddw       mm4,        mm6                 ;
-
-
-        paddw       mm3,        [rd GLOBAL]                  ; xmm3 += round value
-        psraw       mm3,        VP8_FILTER_SHIFT        ; xmm3 /= 128
-
-        paddw       mm4,        [rd GLOBAL]                  ;
-        psraw       mm4,        VP8_FILTER_SHIFT        ;
-
-        packuswb    mm3,        mm4
-
-        movq        [rdi],      mm3                 ; store the results in the destination
-
-%if ABI_IS_32BIT
-        add         rsi,        rdx                 ; next line
-        add         rdi,        dword ptr arg(5) ;dst_pitch                   ;
-%else
-        movsxd      r8,         dword ptr arg(5) ;dst_pitch
-        add         rsi,        rdx                 ; next line
-        add         rdi,        r8
-%endif
-        cmp         rdi,        rcx                 ;
-        jne         next_row_8x4
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void bilinear_predict4x4_mmx
-;(
-;    unsigned char  *src_ptr,
-;    int   src_pixels_per_line,
-;    int  xoffset,
-;    int  yoffset,
-;    unsigned char *dst_ptr,
-;    int dst_pitch
-;)
-global sym(vp8_bilinear_predict4x4_mmx)
-sym(vp8_bilinear_predict4x4_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 6
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-    ;const short *HFilter = bilinear_filters_mmx[xoffset];
-    ;const short *VFilter = bilinear_filters_mmx[yoffset];
-
-        movsxd      rax,        dword ptr arg(2) ;xoffset
-        mov         rdi,        arg(4) ;dst_ptr           ;
-
-        lea         rcx,        [sym(vp8_bilinear_filters_mmx) GLOBAL]
-        shl         rax,        5
-
-        add         rax,        rcx ; HFilter
-        mov         rsi,        arg(0) ;src_ptr              ;
-
-        movsxd      rdx,        dword ptr arg(5) ;ldst_pitch
-        movq        mm1,        [rax]               ;
-
-        movq        mm2,        [rax+16]            ;
-        movsxd      rax,        dword ptr arg(3) ;yoffset
-
-        pxor        mm0,        mm0                 ;
-        shl         rax,        5
-
-        add         rax,        rcx
-        lea         rcx,        [rdi+rdx*4]          ;
-
-        movsxd      rdx,        dword ptr arg(1) ;src_pixels_per_line    ;
-
-        ; get the first horizontal line done       ;
-        movd        mm3,        [rsi]               ; xx 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14
-        punpcklbw   mm3,        mm0                 ; xx 00 01 02 03 04 05 06
-
-        pmullw      mm3,        mm1                 ;
-        movd        mm5,        [rsi+1]             ;
-
-        punpcklbw   mm5,        mm0                 ;
-        pmullw      mm5,        mm2                 ;
-
-        paddw       mm3,        mm5                 ;
-        paddw       mm3,        [rd GLOBAL]                  ; xmm3 += round value
-
-        psraw       mm3,        VP8_FILTER_SHIFT        ; xmm3 /= 128
-
-        movq        mm7,        mm3                 ;
-        packuswb    mm7,        mm0                 ;
-
-        add         rsi,        rdx                 ; next line
-next_row_4x4:
-        movd        mm3,        [rsi]               ; xx 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14
-        punpcklbw   mm3,        mm0                 ; xx 00 01 02 03 04 05 06
-
-        pmullw      mm3,        mm1                 ;
-        movd        mm5,        [rsi+1]             ;
-
-        punpcklbw   mm5,        mm0                 ;
-        pmullw      mm5,        mm2                 ;
-
-        paddw       mm3,        mm5                 ;
-
-        movq        mm5,        mm7                 ;
-        punpcklbw   mm5,        mm0                 ;
-
-        pmullw      mm5,        [rax]               ;
-        paddw       mm3,        [rd GLOBAL]                  ; xmm3 += round value
-
-        psraw       mm3,        VP8_FILTER_SHIFT        ; xmm3 /= 128
-        movq        mm7,        mm3                 ;
-
-        packuswb    mm7,        mm0                 ;
-
-        pmullw      mm3,        [rax+16]            ;
-        paddw       mm3,        mm5                 ;
-
-
-        paddw       mm3,        [rd GLOBAL]                  ; xmm3 += round value
-        psraw       mm3,        VP8_FILTER_SHIFT        ; xmm3 /= 128
-
-        packuswb    mm3,        mm0
-        movd        [rdi],      mm3                 ; store the results in the destination
-
-%if ABI_IS_32BIT
-        add         rsi,        rdx                 ; next line
-        add         rdi,        dword ptr arg(5) ;dst_pitch                   ;
-%else
-        movsxd      r8,         dword ptr arg(5) ;dst_pitch                   ;
-        add         rsi,        rdx                 ; next line
-        add         rdi,        r8
-%endif
-
-        cmp         rdi,        rcx                 ;
-        jne         next_row_4x4
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-
-SECTION_RODATA
-align 16
-rd:
-    times 4 dw 0x40
-
-align 16
-global sym(vp8_six_tap_mmx)
-sym(vp8_six_tap_mmx):
-    times 8 dw 0
-    times 8 dw 0
-    times 8 dw 128
-    times 8 dw 0
-    times 8 dw 0
-    times 8 dw 0
-
-    times 8 dw 0
-    times 8 dw -6
-    times 8 dw 123
-    times 8 dw 12
-    times 8 dw -1
-    times 8 dw 0
-
-    times 8 dw 2
-    times 8 dw -11
-    times 8 dw 108
-    times 8 dw 36
-    times 8 dw -8
-    times 8 dw 1
-
-    times 8 dw 0
-    times 8 dw -9
-    times 8 dw 93
-    times 8 dw 50
-    times 8 dw -6
-    times 8 dw 0
-
-    times 8 dw 3
-    times 8 dw -16
-    times 8 dw 77
-    times 8 dw 77
-    times 8 dw -16
-    times 8 dw 3
-
-    times 8 dw 0
-    times 8 dw -6
-    times 8 dw 50
-    times 8 dw 93
-    times 8 dw -9
-    times 8 dw 0
-
-    times 8 dw 1
-    times 8 dw -8
-    times 8 dw 36
-    times 8 dw 108
-    times 8 dw -11
-    times 8 dw 2
-
-    times 8 dw 0
-    times 8 dw -1
-    times 8 dw 12
-    times 8 dw 123
-    times 8 dw -6
-    times 8 dw 0
-
-
-align 16
-global sym(vp8_bilinear_filters_mmx)
-sym(vp8_bilinear_filters_mmx):
-    times 8 dw 128
-    times 8 dw 0
-
-    times 8 dw 112
-    times 8 dw 16
-
-    times 8 dw 96
-    times 8 dw 32
-
-    times 8 dw 80
-    times 8 dw 48
-
-    times 8 dw 64
-    times 8 dw 64
-
-    times 8 dw 48
-    times 8 dw 80
-
-    times 8 dw 32
-    times 8 dw 96
-
-    times 8 dw 16
-    times 8 dw 112
diff --git a/vp8/common/x86/subpixel_sse2.S b/vp8/common/x86/subpixel_sse2.S
new file mode 100644
index 0000000..585047c
--- /dev/null
+++ b/vp8/common/x86/subpixel_sse2.S
@@ -0,0 +1,1032 @@
+//
+//  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
+//
+//  Use of this source code is governed by a BSD-style license and patent
+//  grant that can be found in the LICENSE file in the root of the source
+//  tree. All contributing project authors may be found in the AUTHORS
+//  file in the root of the source tree.
+//
+
+
+#include "vpx_ports/x86_abi_support.S"
+
+#define BLOCK_HEIGHT_WIDTH 4
+#define VP8_FILTER_WEIGHT 128
+#define VP8_FILTER_SHIFT  7
+
+
+///************************************************************************************
+// Notes: filter_block1d_h6 applies a 6 tap filter horizontally to the input pixels. The
+// input pixel array has output_height rows. This routine assumes that output_height is an
+// even number. This function handles 8 pixels in horizontal direction, calculating ONE
+// rows each iteration to take advantage of the 128 bits operations.
+//*************************************************************************************/
+//void vp8_filter_block1d8_h6_sse2
+//(
+//    unsigned char  *src_ptr,
+//    unsigned short *output_ptr,
+//    unsigned int    src_pixels_per_line,
+//    unsigned int    pixel_step,
+//    unsigned int    output_height,
+//    unsigned int    output_width,
+//    short           *vp8_filter
+//)
+global sym(vp8_filter_block1d8_h6_sse2)
+sym(vp8_filter_block1d8_h6_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 7
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov         rdx,        arg(6) //vp8_filter
+        mov         rsi,        arg(0) //src_ptr
+
+        mov         rdi,        arg(1) //output_ptr
+
+        movsxd      rcx,        dword ptr arg(4) //output_height
+        movsxd      rax,        dword ptr arg(2) //src_pixels_per_line            ; Pitch for Source
+#if ! ABI_IS_32BIT
+        movsxd      r8,         dword ptr arg(5) //output_width
+#endif
+        pxor        xmm0,       xmm0                        // clear xmm0 for unpack
+
+filter_block1d8_h6_rowloop:
+        movq        xmm3,       MMWORD PTR [rsi - 2]
+        movq        xmm1,       MMWORD PTR [rsi + 6]
+
+        prefetcht2  [rsi+rax-2]
+
+        pslldq      xmm1,       8
+        por         xmm1,       xmm3
+
+        movdqa      xmm4,       xmm1
+        movdqa      xmm5,       xmm1
+
+        movdqa      xmm6,       xmm1
+        movdqa      xmm7,       xmm1
+
+        punpcklbw   xmm3,       xmm0                        // xx05 xx04 xx03 xx02 xx01 xx01 xx-1 xx-2
+        psrldq      xmm4,       1                           // xx 0d 0c 0b 0a 09 08 07 06 05 04 03 02 01 00 -1
+
+        pmullw      xmm3,       XMMWORD PTR [rdx]           // x[-2] * H[-2]; Tap 1
+        punpcklbw   xmm4,       xmm0                        // xx06 xx05 xx04 xx03 xx02 xx01 xx00 xx-1
+
+        psrldq      xmm5,       2                           // xx xx 0d 0c 0b 0a 09 08 07 06 05 04 03 02 01 00
+        pmullw      xmm4,       XMMWORD PTR [rdx+16]        // x[-1] * H[-1]; Tap 2
+
+
+        punpcklbw   xmm5,       xmm0                        // xx07 xx06 xx05 xx04 xx03 xx02 xx01 xx00
+        psrldq      xmm6,       3                           // xx xx xx 0d 0c 0b 0a 09 08 07 06 05 04 03 02 01
+
+        pmullw      xmm5,       [rdx+32]                    // x[ 0] * H[ 0]; Tap 3
+
+        punpcklbw   xmm6,       xmm0                        // xx08 xx07 xx06 xx05 xx04 xx03 xx02 xx01
+        psrldq      xmm7,       4                           // xx xx xx xx 0d 0c 0b 0a 09 08 07 06 05 04 03 02
+
+        pmullw      xmm6,       [rdx+48]                    // x[ 1] * h[ 1] ; Tap 4
+
+        punpcklbw   xmm7,       xmm0                        // xx09 xx08 xx07 xx06 xx05 xx04 xx03 xx02
+        psrldq      xmm1,       5                           // xx xx xx xx xx 0d 0c 0b 0a 09 08 07 06 05 04 03
+
+
+        pmullw      xmm7,       [rdx+64]                    // x[ 2] * h[ 2] ; Tap 5
+
+        punpcklbw   xmm1,       xmm0                        // xx0a xx09 xx08 xx07 xx06 xx05 xx04 xx03
+        pmullw      xmm1,       [rdx+80]                    // x[ 3] * h[ 3] ; Tap 6
+
+
+        paddsw      xmm4,       xmm7
+        paddsw      xmm4,       xmm5
+
+        paddsw      xmm4,       xmm3
+        paddsw      xmm4,       xmm6
+
+        paddsw      xmm4,       xmm1
+        paddsw      xmm4,       [GLOBAL (rd)]
+
+        psraw       xmm4,       7
+
+        packuswb    xmm4,       xmm0
+        punpcklbw   xmm4,       xmm0
+
+        movdqa      XMMWORD Ptr [rdi],         xmm4
+        lea         rsi,        [rsi + rax]
+
+#if ABI_IS_32BIT
+        add         rdi,        DWORD Ptr arg(5) //[output_width]
+#else
+        add         rdi,        r8
+#endif
+        dec         rcx
+
+        jnz         filter_block1d8_h6_rowloop                // next row
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void vp8_filter_block1d16_h6_sse2
+//(
+//    unsigned char  *src_ptr,
+//    unsigned short *output_ptr,
+//    unsigned int    src_pixels_per_line,
+//    unsigned int    pixel_step,
+//    unsigned int    output_height,
+//    unsigned int    output_width,
+//    short           *vp8_filter
+//)
+///************************************************************************************
+// Notes: filter_block1d_h6 applies a 6 tap filter horizontally to the input pixels. The
+// input pixel array has output_height rows. This routine assumes that output_height is an
+// even number. This function handles 8 pixels in horizontal direction, calculating ONE
+// rows each iteration to take advantage of the 128 bits operations.
+//*************************************************************************************/
+global sym(vp8_filter_block1d16_h6_sse2)
+sym(vp8_filter_block1d16_h6_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 7
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov         rdx,        arg(6) //vp8_filter
+        mov         rsi,        arg(0) //src_ptr
+
+        mov         rdi,        arg(1) //output_ptr
+
+        movsxd      rcx,        dword ptr arg(4) //output_height
+        movsxd      rax,        dword ptr arg(2) //src_pixels_per_line            ; Pitch for Source
+#if ! ABI_IS_32BIT
+        movsxd      r8,         dword ptr arg(5) //output_width
+#endif
+
+        pxor        xmm0,       xmm0                        // clear xmm0 for unpack
+
+filter_block1d16_h6_sse2_rowloop:
+        movq        xmm3,       MMWORD PTR [rsi - 2]
+        movq        xmm1,       MMWORD PTR [rsi + 6]
+
+        movq        xmm2,       MMWORD PTR [rsi +14]
+        pslldq      xmm2,       8
+
+        por         xmm2,       xmm1
+        prefetcht2  [rsi+rax-2]
+
+        pslldq      xmm1,       8
+        por         xmm1,       xmm3
+
+        movdqa      xmm4,       xmm1
+        movdqa      xmm5,       xmm1
+
+        movdqa      xmm6,       xmm1
+        movdqa      xmm7,       xmm1
+
+        punpcklbw   xmm3,       xmm0                        // xx05 xx04 xx03 xx02 xx01 xx01 xx-1 xx-2
+        psrldq      xmm4,       1                           // xx 0d 0c 0b 0a 09 08 07 06 05 04 03 02 01 00 -1
+
+        pmullw      xmm3,       XMMWORD PTR [rdx]           // x[-2] * H[-2]; Tap 1
+        punpcklbw   xmm4,       xmm0                        // xx06 xx05 xx04 xx03 xx02 xx01 xx00 xx-1
+
+        psrldq      xmm5,       2                           // xx xx 0d 0c 0b 0a 09 08 07 06 05 04 03 02 01 00
+        pmullw      xmm4,       XMMWORD PTR [rdx+16]        // x[-1] * H[-1]; Tap 2
+
+
+        punpcklbw   xmm5,       xmm0                        // xx07 xx06 xx05 xx04 xx03 xx02 xx01 xx00
+        psrldq      xmm6,       3                           // xx xx xx 0d 0c 0b 0a 09 08 07 06 05 04 03 02 01
+
+        pmullw      xmm5,       [rdx+32]                    // x[ 0] * H[ 0]; Tap 3
+
+        punpcklbw   xmm6,       xmm0                        // xx08 xx07 xx06 xx05 xx04 xx03 xx02 xx01
+        psrldq      xmm7,       4                           // xx xx xx xx 0d 0c 0b 0a 09 08 07 06 05 04 03 02
+
+        pmullw      xmm6,       [rdx+48]                    // x[ 1] * h[ 1] ; Tap 4
+
+        punpcklbw   xmm7,       xmm0                        // xx09 xx08 xx07 xx06 xx05 xx04 xx03 xx02
+        psrldq      xmm1,       5                           // xx xx xx xx xx 0d 0c 0b 0a 09 08 07 06 05 04 03
+
+
+        pmullw      xmm7,       [rdx+64]                    // x[ 2] * h[ 2] ; Tap 5
+
+        punpcklbw   xmm1,       xmm0                        // xx0a xx09 xx08 xx07 xx06 xx05 xx04 xx03
+        pmullw      xmm1,       [rdx+80]                    // x[ 3] * h[ 3] ; Tap 6
+
+        paddsw      xmm4,       xmm7
+        paddsw      xmm4,       xmm5
+
+        paddsw      xmm4,       xmm3
+        paddsw      xmm4,       xmm6
+
+        paddsw      xmm4,       xmm1
+        paddsw      xmm4,       [GLOBAL (rd)]
+
+        psraw       xmm4,       7
+
+        packuswb    xmm4,       xmm0
+        punpcklbw   xmm4,       xmm0
+
+        movdqa      XMMWORD Ptr [rdi],         xmm4
+
+        movdqa      xmm3,       xmm2
+        movdqa      xmm4,       xmm2
+
+        movdqa      xmm5,       xmm2
+        movdqa      xmm6,       xmm2
+
+        movdqa      xmm7,       xmm2
+
+        punpcklbw   xmm3,       xmm0                        // xx05 xx04 xx03 xx02 xx01 xx01 xx-1 xx-2
+        psrldq      xmm4,       1                           // xx 0d 0c 0b 0a 09 08 07 06 05 04 03 02 01 00 -1
+
+        pmullw      xmm3,       XMMWORD PTR [rdx]           // x[-2] * H[-2]; Tap 1
+        punpcklbw   xmm4,       xmm0                        // xx06 xx05 xx04 xx03 xx02 xx01 xx00 xx-1
+
+        psrldq      xmm5,       2                           // xx xx 0d 0c 0b 0a 09 08 07 06 05 04 03 02 01 00
+        pmullw      xmm4,       XMMWORD PTR [rdx+16]        // x[-1] * H[-1]; Tap 2
+
+
+        punpcklbw   xmm5,       xmm0                        // xx07 xx06 xx05 xx04 xx03 xx02 xx01 xx00
+        psrldq      xmm6,       3                           // xx xx xx 0d 0c 0b 0a 09 08 07 06 05 04 03 02 01
+
+        pmullw      xmm5,       [rdx+32]                    // x[ 0] * H[ 0]; Tap 3
+
+        punpcklbw   xmm6,       xmm0                        // xx08 xx07 xx06 xx05 xx04 xx03 xx02 xx01
+        psrldq      xmm7,       4                           // xx xx xx xx 0d 0c 0b 0a 09 08 07 06 05 04 03 02
+
+        pmullw      xmm6,       [rdx+48]                    // x[ 1] * h[ 1] ; Tap 4
+
+        punpcklbw   xmm7,       xmm0                        // xx09 xx08 xx07 xx06 xx05 xx04 xx03 xx02
+        psrldq      xmm2,       5                           // xx xx xx xx xx 0d 0c 0b 0a 09 08 07 06 05 04 03
+
+        pmullw      xmm7,       [rdx+64]                    // x[ 2] * h[ 2] ; Tap 5
+
+        punpcklbw   xmm2,       xmm0                        // xx0a xx09 xx08 xx07 xx06 xx05 xx04 xx03
+        pmullw      xmm2,       [rdx+80]                    // x[ 3] * h[ 3] ; Tap 6
+
+
+        paddsw      xmm4,       xmm7
+        paddsw      xmm4,       xmm5
+
+        paddsw      xmm4,       xmm3
+        paddsw      xmm4,       xmm6
+
+        paddsw      xmm4,       xmm2
+        paddsw      xmm4,       [GLOBAL (rd)]
+
+        psraw       xmm4,       7
+
+        packuswb    xmm4,       xmm0
+        punpcklbw   xmm4,       xmm0
+
+        movdqa      XMMWORD Ptr [rdi+16],      xmm4
+
+        lea         rsi,        [rsi + rax]
+#if ABI_IS_32BIT
+        add         rdi,        DWORD Ptr arg(5) //[output_width]
+#else
+        add         rdi,        r8
+#endif
+
+        dec         rcx
+        jnz         filter_block1d16_h6_sse2_rowloop                // next row
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void vp8_filter_block1d8_v6_sse2
+//(
+//    short *src_ptr,
+//    unsigned char *output_ptr,
+//    int dst_ptich,
+//    unsigned int pixels_per_line,
+//    unsigned int pixel_step,
+//    unsigned int output_height,
+//    unsigned int output_width,
+//    short * vp8_filter
+//)
+///************************************************************************************
+// Notes: filter_block1d8_v6 applies a 6 tap filter vertically to the input pixels. The
+// input pixel array has output_height rows.
+//*************************************************************************************/
+global sym(vp8_filter_block1d8_v6_sse2)
+sym(vp8_filter_block1d8_v6_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 8
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov         rax,        arg(7) //vp8_filter
+        movsxd      rdx,        dword ptr arg(3) //pixels_per_line
+
+        mov         rdi,        arg(1) //output_ptr
+        mov         rsi,        arg(0) //src_ptr
+
+        sub         rsi,        rdx
+        sub         rsi,        rdx
+
+        movsxd      rcx,        DWORD PTR arg(5) //[output_height]
+        pxor        xmm0,       xmm0                        // clear xmm0
+
+        movdqa      xmm7,       XMMWORD PTR [GLOBAL (rd)]
+#if ! ABI_IS_32BIT
+        movsxd      r8,         dword ptr arg(2) // dst_ptich
+#endif
+
+vp8_filter_block1d8_v6_sse2_loop:
+        movdqa      xmm1,       XMMWORD PTR [rsi]
+        pmullw      xmm1,       [rax]
+
+        movdqa      xmm2,       XMMWORD PTR [rsi + rdx]
+        pmullw      xmm2,       [rax + 16]
+
+        movdqa      xmm3,       XMMWORD PTR [rsi + rdx * 2]
+        pmullw      xmm3,       [rax + 32]
+
+        movdqa      xmm5,       XMMWORD PTR [rsi + rdx * 4]
+        pmullw      xmm5,       [rax + 64]
+
+        add         rsi,        rdx
+        movdqa      xmm4,       XMMWORD PTR [rsi + rdx * 2]
+
+        pmullw      xmm4,       [rax + 48]
+        movdqa      xmm6,       XMMWORD PTR [rsi + rdx * 4]
+
+        pmullw      xmm6,       [rax + 80]
+
+        paddsw      xmm2,       xmm5
+        paddsw      xmm2,       xmm3
+
+        paddsw      xmm2,       xmm1
+        paddsw      xmm2,       xmm4
+
+        paddsw      xmm2,       xmm6
+        paddsw      xmm2,       xmm7
+
+        psraw       xmm2,       7
+        packuswb    xmm2,       xmm0              // pack and saturate
+
+        movq        QWORD PTR [rdi], xmm2         // store the results in the destination
+#if ABI_IS_32BIT
+        add         rdi,        DWORD PTR arg(2) //[dst_ptich]
+#else
+        add         rdi,        r8
+#endif
+        dec         rcx         // decrement count
+        jnz         vp8_filter_block1d8_v6_sse2_loop               // next row
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void vp8_unpack_block1d16_h6_sse2
+//(
+//    unsigned char  *src_ptr,
+//    unsigned short *output_ptr,
+//    unsigned int    src_pixels_per_line,
+//    unsigned int    output_height,
+//    unsigned int    output_width
+//)
+global sym(vp8_unpack_block1d16_h6_sse2)
+sym(vp8_unpack_block1d16_h6_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 5
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov         rsi,        arg(0) //src_ptr
+        mov         rdi,        arg(1) //output_ptr
+
+        movsxd      rcx,        dword ptr arg(3) //output_height
+        movsxd      rax,        dword ptr arg(2) //src_pixels_per_line            ; Pitch for Source
+
+        pxor        xmm0,       xmm0                        // clear xmm0 for unpack
+#if ! ABI_IS_32BIT
+        movsxd      r8,         dword ptr arg(4) //output_width            ; Pitch for Source
+#endif
+
+unpack_block1d16_h6_sse2_rowloop:
+        movq        xmm1,       MMWORD PTR [rsi]            // 0d 0c 0b 0a 09 08 07 06 05 04 03 02 01 00 -1 -2
+        movq        xmm3,       MMWORD PTR [rsi+8]          // make copy of xmm1
+
+        punpcklbw   xmm3,       xmm0                        // xx05 xx04 xx03 xx02 xx01 xx01 xx-1 xx-2
+        punpcklbw   xmm1,       xmm0
+
+        movdqa      XMMWORD Ptr [rdi],         xmm1
+        movdqa      XMMWORD Ptr [rdi + 16],    xmm3
+
+        lea         rsi,        [rsi + rax]
+#if ABI_IS_32BIT
+        add         rdi,        DWORD Ptr arg(4) //[output_width]
+#else
+        add         rdi,        r8
+#endif
+        dec         rcx
+        jnz         unpack_block1d16_h6_sse2_rowloop                // next row
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void vp8_unpack_block1d8_h6_sse2
+//(
+//    unsigned char  *src_ptr,
+//    unsigned short *output_ptr,
+//    unsigned int    src_pixels_per_line,
+//    unsigned int    output_height,
+//    unsigned int    output_width
+//)
+global sym(vp8_unpack_block1d8_h6_sse2)
+sym(vp8_unpack_block1d8_h6_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 5
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov         rsi,        arg(0) //src_ptr
+        mov         rdi,        arg(1) //output_ptr
+
+        movsxd      rcx,        dword ptr arg(3) //output_height
+        movsxd      rax,        dword ptr arg(2) //src_pixels_per_line            ; Pitch for Source
+
+        pxor        xmm0,       xmm0                        // clear xmm0 for unpack
+#if ! ABI_IS_32BIT
+        movsxd      r8,         dword ptr arg(4) //output_width            ; Pitch for Source
+#endif
+
+unpack_block1d8_h6_sse2_rowloop:
+        movq        xmm1,       MMWORD PTR [rsi]            // 0d 0c 0b 0a 09 08 07 06 05 04 03 02 01 00 -1 -2
+        lea         rsi,        [rsi + rax]
+
+        punpcklbw   xmm1,       xmm0
+        movdqa      XMMWORD Ptr [rdi],         xmm1
+
+#if ABI_IS_32BIT
+        add         rdi,        DWORD Ptr arg(4) //[output_width]
+#else
+        add         rdi,        r8
+#endif
+        dec         rcx
+        jnz         unpack_block1d8_h6_sse2_rowloop                // next row
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void vp8_pack_block1d8_v6_sse2
+//(
+//    short *src_ptr,
+//    unsigned char *output_ptr,
+//    int dst_ptich,
+//    unsigned int pixels_per_line,
+//    unsigned int output_height,
+//    unsigned int output_width
+//)
+global sym(vp8_pack_block1d8_v6_sse2)
+sym(vp8_pack_block1d8_v6_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 6
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+        movsxd      rdx,        dword ptr arg(3) //pixels_per_line
+        mov         rdi,        arg(1) //output_ptr
+
+        mov         rsi,        arg(0) //src_ptr
+        movsxd      rcx,        DWORD PTR arg(4) //[output_height]
+#if ! ABI_IS_32BIT
+        movsxd      r8,         dword ptr arg(5) //output_width            ; Pitch for Source
+#endif
+
+pack_block1d8_v6_sse2_loop:
+        movdqa      xmm0,       XMMWORD PTR [rsi]
+        packuswb    xmm0,       xmm0
+
+        movq        QWORD PTR [rdi], xmm0         // store the results in the destination
+        lea         rsi,        [rsi+rdx]
+
+#if ABI_IS_32BIT
+        add         rdi,        DWORD Ptr arg(5) //[output_width]
+#else
+        add         rdi,        r8
+#endif
+        dec         rcx         // decrement count
+        jnz         pack_block1d8_v6_sse2_loop               // next row
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void vp8_pack_block1d16_v6_sse2
+//(
+//    short *src_ptr,
+//    unsigned char *output_ptr,
+//    int dst_ptich,
+//    unsigned int pixels_per_line,
+//    unsigned int output_height,
+//    unsigned int output_width
+//)
+global sym(vp8_pack_block1d16_v6_sse2)
+sym(vp8_pack_block1d16_v6_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 6
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+        movsxd      rdx,        dword ptr arg(3) //pixels_per_line
+        mov         rdi,        arg(1) //output_ptr
+
+        mov         rsi,        arg(0) //src_ptr
+        movsxd      rcx,        DWORD PTR arg(4) //[output_height]
+#if ! ABI_IS_32BIT
+        movsxd      r8,         dword ptr arg(2) //dst_pitch
+#endif
+
+pack_block1d16_v6_sse2_loop:
+        movdqa      xmm0,       XMMWORD PTR [rsi]
+        movdqa      xmm1,       XMMWORD PTR [rsi+16]
+
+        packuswb    xmm0,       xmm1
+        movdqa      XMMWORD PTR [rdi], xmm0         // store the results in the destination
+
+        add         rsi,        rdx
+#if ABI_IS_32BIT
+        add         rdi,        DWORD Ptr arg(2) //dst_pitch
+#else
+        add         rdi,        r8
+#endif
+        dec         rcx         // decrement count
+        jnz         pack_block1d16_v6_sse2_loop               // next row
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void vp8_bilinear_predict16x16_sse2
+//(
+//    unsigned char  *src_ptr,
+//    int   src_pixels_per_line,
+//    int  xoffset,
+//    int  yoffset,
+//    unsigned char *dst_ptr,
+//    int dst_pitch
+//)
+extern sym(vp8_bilinear_filters_mmx)
+global sym(vp8_bilinear_predict16x16_sse2)
+sym(vp8_bilinear_predict16x16_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 6
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+    //const short *HFilter = bilinear_filters_mmx[xoffset]
+    //const short *VFilter = bilinear_filters_mmx[yoffset]
+
+        lea         rcx,        [GLOBAL (sym(vp8_bilinear_filters_mmx))]
+        movsxd      rax,        dword ptr arg(2) //xoffset
+
+        cmp         rax,        0      //skip first_pass filter if xoffset=0
+        je          b16x16_sp_only
+
+        shl         rax,        5
+        add         rax,        rcx    //HFilter
+
+        mov         rdi,        arg(4) //dst_ptr
+        mov         rsi,        arg(0) //src_ptr
+        movsxd      rdx,        dword ptr arg(5) //dst_pitch
+
+        movdqa      xmm1,       [rax]
+        movdqa      xmm2,       [rax+16]
+
+        movsxd      rax,        dword ptr arg(3) //yoffset
+
+        cmp         rax,        0      //skip second_pass filter if yoffset=0
+        je          b16x16_fp_only
+
+        shl         rax,        5
+        add         rax,        rcx    //VFilter
+
+        lea         rcx,        [rdi+rdx*8]
+        lea         rcx,        [rcx+rdx*8]
+        movsxd      rdx,        dword ptr arg(1) //src_pixels_per_line
+
+        pxor        xmm0,       xmm0
+
+#if ! ABI_IS_32BIT
+        movsxd      r8,         dword ptr arg(5) //dst_pitch
+#endif
+        // get the first horizontal line done
+        movdqu      xmm3,       [rsi]               // xx 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14
+        movdqa      xmm4,       xmm3                 // make a copy of current line
+
+        punpcklbw   xmm3,       xmm0                 // xx 00 01 02 03 04 05 06
+        punpckhbw   xmm4,       xmm0
+
+        pmullw      xmm3,       xmm1
+        pmullw      xmm4,       xmm1
+
+        movdqu      xmm5,       [rsi+1]
+        movdqa      xmm6,       xmm5
+
+        punpcklbw   xmm5,       xmm0
+        punpckhbw   xmm6,       xmm0
+
+        pmullw      xmm5,       xmm2
+        pmullw      xmm6,       xmm2
+
+        paddw       xmm3,       xmm5
+        paddw       xmm4,       xmm6
+
+        paddw       xmm3,       [GLOBAL (rd)]         // xmm3 += round value
+        psraw       xmm3,       VP8_FILTER_SHIFT        // xmm3 /= 128
+
+        paddw       xmm4,       [GLOBAL (rd)]
+        psraw       xmm4,       VP8_FILTER_SHIFT
+
+        movdqa      xmm7,       xmm3
+        packuswb    xmm7,       xmm4
+
+        add         rsi,        rdx                 // next line
+next_row:
+        movdqu      xmm3,       [rsi]               // xx 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14
+        movdqa      xmm4,       xmm3                 // make a copy of current line
+
+        punpcklbw   xmm3,       xmm0                 // xx 00 01 02 03 04 05 06
+        punpckhbw   xmm4,       xmm0
+
+        pmullw      xmm3,       xmm1
+        pmullw      xmm4,       xmm1
+
+        movdqu      xmm5,       [rsi+1]
+        movdqa      xmm6,       xmm5
+
+        punpcklbw   xmm5,       xmm0
+        punpckhbw   xmm6,       xmm0
+
+        pmullw      xmm5,       xmm2
+        pmullw      xmm6,       xmm2
+
+        paddw       xmm3,       xmm5
+        paddw       xmm4,       xmm6
+
+        movdqa      xmm5,       xmm7
+        movdqa      xmm6,       xmm7
+
+        punpcklbw   xmm5,       xmm0
+        punpckhbw   xmm6,       xmm0
+
+        pmullw      xmm5,       [rax]
+        pmullw      xmm6,       [rax]
+
+        paddw       xmm3,       [GLOBAL (rd)]         // xmm3 += round value
+        psraw       xmm3,       VP8_FILTER_SHIFT        // xmm3 /= 128
+
+        paddw       xmm4,       [GLOBAL (rd)]
+        psraw       xmm4,       VP8_FILTER_SHIFT
+
+        movdqa      xmm7,       xmm3
+        packuswb    xmm7,       xmm4
+
+        pmullw      xmm3,       [rax+16]
+        pmullw      xmm4,       [rax+16]
+
+        paddw       xmm3,       xmm5
+        paddw       xmm4,       xmm6
+
+        paddw       xmm3,       [GLOBAL (rd)]         // xmm3 += round value
+        psraw       xmm3,       VP8_FILTER_SHIFT        // xmm3 /= 128
+
+        paddw       xmm4,       [GLOBAL (rd)]
+        psraw       xmm4,       VP8_FILTER_SHIFT
+
+        packuswb    xmm3,       xmm4
+        movdqa      [rdi],      xmm3                 // store the results in the destination
+
+        add         rsi,        rdx                 // next line
+#if ABI_IS_32BIT
+        add         rdi,        DWORD PTR arg(5) //dst_pitch
+#else
+        add         rdi,        r8
+#endif
+
+        cmp         rdi,        rcx
+        jne         next_row
+
+        jmp         done
+
+b16x16_sp_only:
+        movsxd      rax,        dword ptr arg(3) //yoffset
+        shl         rax,        5
+        add         rax,        rcx    //VFilter
+
+        mov         rdi,        arg(4) //dst_ptr
+        mov         rsi,        arg(0) //src_ptr
+        movsxd      rdx,        dword ptr arg(5) //dst_pitch
+
+        movdqa      xmm1,       [rax]
+        movdqa      xmm2,       [rax+16]
+
+        lea         rcx,        [rdi+rdx*8]
+        lea         rcx,        [rcx+rdx*8]
+        movsxd      rax,        dword ptr arg(1) //src_pixels_per_line
+
+        pxor        xmm0,       xmm0
+
+        // get the first horizontal line done
+        movdqu      xmm7,       [rsi]               // xx 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14
+
+        add         rsi,        rax                 // next line
+next_row_spo:
+        movdqu      xmm3,       [rsi]               // xx 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14
+
+        movdqa      xmm5,       xmm7
+        movdqa      xmm6,       xmm7
+
+        movdqa      xmm4,       xmm3                 // make a copy of current line
+        movdqa      xmm7,       xmm3
+
+        punpcklbw   xmm5,       xmm0
+        punpckhbw   xmm6,       xmm0
+        punpcklbw   xmm3,       xmm0                 // xx 00 01 02 03 04 05 06
+        punpckhbw   xmm4,       xmm0
+
+        pmullw      xmm5,       xmm1
+        pmullw      xmm6,       xmm1
+        pmullw      xmm3,       xmm2
+        pmullw      xmm4,       xmm2
+
+        paddw       xmm3,       xmm5
+        paddw       xmm4,       xmm6
+
+        paddw       xmm3,       [GLOBAL (rd)]         // xmm3 += round value
+        psraw       xmm3,       VP8_FILTER_SHIFT        // xmm3 /= 128
+
+        paddw       xmm4,       [GLOBAL (rd)]
+        psraw       xmm4,       VP8_FILTER_SHIFT
+
+        packuswb    xmm3,       xmm4
+        movdqa      [rdi],      xmm3                 // store the results in the destination
+
+        add         rsi,        rax                 // next line
+        add         rdi,        rdx                 //dst_pitch
+        cmp         rdi,        rcx
+        jne         next_row_spo
+
+        jmp         done
+
+b16x16_fp_only:
+        lea         rcx,        [rdi+rdx*8]
+        lea         rcx,        [rcx+rdx*8]
+        movsxd      rax,        dword ptr arg(1) //src_pixels_per_line
+        pxor        xmm0,       xmm0
+
+next_row_fpo:
+        movdqu      xmm3,       [rsi]               // xx 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14
+        movdqa      xmm4,       xmm3                 // make a copy of current line
+
+        punpcklbw   xmm3,       xmm0                 // xx 00 01 02 03 04 05 06
+        punpckhbw   xmm4,       xmm0
+
+        pmullw      xmm3,       xmm1
+        pmullw      xmm4,       xmm1
+
+        movdqu      xmm5,       [rsi+1]
+        movdqa      xmm6,       xmm5
+
+        punpcklbw   xmm5,       xmm0
+        punpckhbw   xmm6,       xmm0
+
+        pmullw      xmm5,       xmm2
+        pmullw      xmm6,       xmm2
+
+        paddw       xmm3,       xmm5
+        paddw       xmm4,       xmm6
+
+        paddw       xmm3,       [GLOBAL (rd)]         // xmm3 += round value
+        psraw       xmm3,       VP8_FILTER_SHIFT        // xmm3 /= 128
+
+        paddw       xmm4,       [GLOBAL (rd)]
+        psraw       xmm4,       VP8_FILTER_SHIFT
+
+        packuswb    xmm3,       xmm4
+        movdqa      [rdi],      xmm3                 // store the results in the destination
+
+        add         rsi,        rax                 // next line
+        add         rdi,        rdx                 // dst_pitch
+        cmp         rdi,        rcx
+        jne         next_row_fpo
+
+done:
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void vp8_bilinear_predict8x8_sse2
+//(
+//    unsigned char  *src_ptr,
+//    int   src_pixels_per_line,
+//    int  xoffset,
+//    int  yoffset,
+//    unsigned char *dst_ptr,
+//    int dst_pitch
+//)
+extern sym(vp8_bilinear_filters_mmx)
+global sym(vp8_bilinear_predict8x8_sse2)
+sym(vp8_bilinear_predict8x8_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 6
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+    ALIGN_STACK 16, rax
+    sub         rsp, 144                         // reserve 144 bytes
+
+    //const short *HFilter = bilinear_filters_mmx[xoffset]
+    //const short *VFilter = bilinear_filters_mmx[yoffset]
+        lea         rcx,        [GLOBAL (sym(vp8_bilinear_filters_mmx))]
+
+        mov         rsi,        arg(0) //src_ptr
+        movsxd      rdx,        dword ptr arg(1) //src_pixels_per_line
+
+    //Read 9-line unaligned data in and put them on stack. This gives a big
+    //performance boost.
+        movdqu      xmm0,       [rsi]
+        lea         rax,        [rdx + rdx*2]
+        movdqu      xmm1,       [rsi+rdx]
+        movdqu      xmm2,       [rsi+rdx*2]
+        add         rsi,        rax
+        movdqu      xmm3,       [rsi]
+        movdqu      xmm4,       [rsi+rdx]
+        movdqu      xmm5,       [rsi+rdx*2]
+        add         rsi,        rax
+        movdqu      xmm6,       [rsi]
+        movdqu      xmm7,       [rsi+rdx]
+
+        movdqa      XMMWORD PTR [rsp],            xmm0
+
+        movdqu      xmm0,       [rsi+rdx*2]
+
+        movdqa      XMMWORD PTR [rsp+16],         xmm1
+        movdqa      XMMWORD PTR [rsp+32],         xmm2
+        movdqa      XMMWORD PTR [rsp+48],         xmm3
+        movdqa      XMMWORD PTR [rsp+64],         xmm4
+        movdqa      XMMWORD PTR [rsp+80],         xmm5
+        movdqa      XMMWORD PTR [rsp+96],         xmm6
+        movdqa      XMMWORD PTR [rsp+112],        xmm7
+        movdqa      XMMWORD PTR [rsp+128],        xmm0
+
+        movsxd      rax,        dword ptr arg(2) //xoffset
+        shl         rax,        5
+        add         rax,        rcx    //HFilter
+
+        mov         rdi,        arg(4) //dst_ptr
+        movsxd      rdx,        dword ptr arg(5) //dst_pitch
+
+        movdqa      xmm1,       [rax]
+        movdqa      xmm2,       [rax+16]
+
+        movsxd      rax,        dword ptr arg(3) //yoffset
+        shl         rax,        5
+        add         rax,        rcx    //VFilter
+
+        lea         rcx,        [rdi+rdx*8]
+
+        movdqa      xmm5,       [rax]
+        movdqa      xmm6,       [rax+16]
+
+        pxor        xmm0,       xmm0
+
+        // get the first horizontal line done
+        movdqa      xmm3,       XMMWORD PTR [rsp]
+        movdqa      xmm4,       xmm3                 // make a copy of current line
+        psrldq      xmm4,       1
+
+        punpcklbw   xmm3,       xmm0                 // 00 01 02 03 04 05 06 07
+        punpcklbw   xmm4,       xmm0                 // 01 02 03 04 05 06 07 08
+
+        pmullw      xmm3,       xmm1
+        pmullw      xmm4,       xmm2
+
+        paddw       xmm3,       xmm4
+
+        paddw       xmm3,       [GLOBAL (rd)]         // xmm3 += round value
+        psraw       xmm3,       VP8_FILTER_SHIFT        // xmm3 /= 128
+
+        movdqa      xmm7,       xmm3
+        add         rsp,        16                 // next line
+next_row8x8:
+        movdqa      xmm3,       XMMWORD PTR [rsp]               // 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15
+        movdqa      xmm4,       xmm3                 // make a copy of current line
+        psrldq      xmm4,       1
+
+        punpcklbw   xmm3,       xmm0                 // 00 01 02 03 04 05 06 07
+        punpcklbw   xmm4,       xmm0                 // 01 02 03 04 05 06 07 08
+
+        pmullw      xmm3,       xmm1
+        pmullw      xmm4,       xmm2
+
+        paddw       xmm3,       xmm4
+        pmullw      xmm7,       xmm5
+
+        paddw       xmm3,       [GLOBAL (rd)]         // xmm3 += round value
+        psraw       xmm3,       VP8_FILTER_SHIFT        // xmm3 /= 128
+
+        movdqa      xmm4,       xmm3
+
+        pmullw      xmm3,       xmm6
+        paddw       xmm3,       xmm7
+
+        movdqa      xmm7,       xmm4
+
+        paddw       xmm3,       [GLOBAL (rd)]         // xmm3 += round value
+        psraw       xmm3,       VP8_FILTER_SHIFT        // xmm3 /= 128
+
+        packuswb    xmm3,       xmm0
+        movq        [rdi],      xmm3                 // store the results in the destination
+
+        add         rsp,        16                 // next line
+        add         rdi,        rdx
+
+        cmp         rdi,        rcx
+        jne         next_row8x8
+
+    //add rsp, 144
+    pop rsp
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+SECTION_RODATA
+align 16
+rd:
+    .fill 8, 2, 0x40
diff --git a/vp8/common/x86/subpixel_sse2.asm b/vp8/common/x86/subpixel_sse2.asm
deleted file mode 100644
index dee04f2..0000000
--- a/vp8/common/x86/subpixel_sse2.asm
+++ /dev/null
@@ -1,1032 +0,0 @@
-;
-;  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
-;
-;  Use of this source code is governed by a BSD-style license and patent
-;  grant that can be found in the LICENSE file in the root of the source
-;  tree. All contributing project authors may be found in the AUTHORS
-;  file in the root of the source tree.
-;
-
-
-%include "vpx_ports/x86_abi_support.asm"
-
-%define BLOCK_HEIGHT_WIDTH 4
-%define VP8_FILTER_WEIGHT 128
-%define VP8_FILTER_SHIFT  7
-
-
-;/************************************************************************************
-; Notes: filter_block1d_h6 applies a 6 tap filter horizontally to the input pixels. The
-; input pixel array has output_height rows. This routine assumes that output_height is an
-; even number. This function handles 8 pixels in horizontal direction, calculating ONE
-; rows each iteration to take advantage of the 128 bits operations.
-;*************************************************************************************/
-;void vp8_filter_block1d8_h6_sse2
-;(
-;    unsigned char  *src_ptr,
-;    unsigned short *output_ptr,
-;    unsigned int    src_pixels_per_line,
-;    unsigned int    pixel_step,
-;    unsigned int    output_height,
-;    unsigned int    output_width,
-;    short           *vp8_filter
-;)
-global sym(vp8_filter_block1d8_h6_sse2)
-sym(vp8_filter_block1d8_h6_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 7
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov         rdx,        arg(6) ;vp8_filter
-        mov         rsi,        arg(0) ;src_ptr
-
-        mov         rdi,        arg(1) ;output_ptr
-
-        movsxd      rcx,        dword ptr arg(4) ;output_height
-        movsxd      rax,        dword ptr arg(2) ;src_pixels_per_line            ; Pitch for Source
-%if ABI_IS_32BIT=0
-        movsxd      r8,         dword ptr arg(5) ;output_width
-%endif
-        pxor        xmm0,       xmm0                        ; clear xmm0 for unpack
-
-filter_block1d8_h6_rowloop:
-        movq        xmm3,       MMWORD PTR [rsi - 2]
-        movq        xmm1,       MMWORD PTR [rsi + 6]
-
-        prefetcht2  [rsi+rax-2]
-
-        pslldq      xmm1,       8
-        por         xmm1,       xmm3
-
-        movdqa      xmm4,       xmm1
-        movdqa      xmm5,       xmm1
-
-        movdqa      xmm6,       xmm1
-        movdqa      xmm7,       xmm1
-
-        punpcklbw   xmm3,       xmm0                        ; xx05 xx04 xx03 xx02 xx01 xx01 xx-1 xx-2
-        psrldq      xmm4,       1                           ; xx 0d 0c 0b 0a 09 08 07 06 05 04 03 02 01 00 -1
-
-        pmullw      xmm3,       XMMWORD PTR [rdx]           ; x[-2] * H[-2]; Tap 1
-        punpcklbw   xmm4,       xmm0                        ; xx06 xx05 xx04 xx03 xx02 xx01 xx00 xx-1
-
-        psrldq      xmm5,       2                           ; xx xx 0d 0c 0b 0a 09 08 07 06 05 04 03 02 01 00
-        pmullw      xmm4,       XMMWORD PTR [rdx+16]        ; x[-1] * H[-1]; Tap 2
-
-
-        punpcklbw   xmm5,       xmm0                        ; xx07 xx06 xx05 xx04 xx03 xx02 xx01 xx00
-        psrldq      xmm6,       3                           ; xx xx xx 0d 0c 0b 0a 09 08 07 06 05 04 03 02 01
-
-        pmullw      xmm5,       [rdx+32]                    ; x[ 0] * H[ 0]; Tap 3
-
-        punpcklbw   xmm6,       xmm0                        ; xx08 xx07 xx06 xx05 xx04 xx03 xx02 xx01
-        psrldq      xmm7,       4                           ; xx xx xx xx 0d 0c 0b 0a 09 08 07 06 05 04 03 02
-
-        pmullw      xmm6,       [rdx+48]                    ; x[ 1] * h[ 1] ; Tap 4
-
-        punpcklbw   xmm7,       xmm0                        ; xx09 xx08 xx07 xx06 xx05 xx04 xx03 xx02
-        psrldq      xmm1,       5                           ; xx xx xx xx xx 0d 0c 0b 0a 09 08 07 06 05 04 03
-
-
-        pmullw      xmm7,       [rdx+64]                    ; x[ 2] * h[ 2] ; Tap 5
-
-        punpcklbw   xmm1,       xmm0                        ; xx0a xx09 xx08 xx07 xx06 xx05 xx04 xx03
-        pmullw      xmm1,       [rdx+80]                    ; x[ 3] * h[ 3] ; Tap 6
-
-
-        paddsw      xmm4,       xmm7
-        paddsw      xmm4,       xmm5
-
-        paddsw      xmm4,       xmm3
-        paddsw      xmm4,       xmm6
-
-        paddsw      xmm4,       xmm1
-        paddsw      xmm4,       [rd GLOBAL]
-
-        psraw       xmm4,       7
-
-        packuswb    xmm4,       xmm0
-        punpcklbw   xmm4,       xmm0
-
-        movdqa      XMMWORD Ptr [rdi],         xmm4
-        lea         rsi,        [rsi + rax]
-
-%if ABI_IS_32BIT
-        add         rdi,        DWORD Ptr arg(5) ;[output_width]
-%else
-        add         rdi,        r8
-%endif
-        dec         rcx
-
-        jnz         filter_block1d8_h6_rowloop                ; next row
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void vp8_filter_block1d16_h6_sse2
-;(
-;    unsigned char  *src_ptr,
-;    unsigned short *output_ptr,
-;    unsigned int    src_pixels_per_line,
-;    unsigned int    pixel_step,
-;    unsigned int    output_height,
-;    unsigned int    output_width,
-;    short           *vp8_filter
-;)
-;/************************************************************************************
-; Notes: filter_block1d_h6 applies a 6 tap filter horizontally to the input pixels. The
-; input pixel array has output_height rows. This routine assumes that output_height is an
-; even number. This function handles 8 pixels in horizontal direction, calculating ONE
-; rows each iteration to take advantage of the 128 bits operations.
-;*************************************************************************************/
-global sym(vp8_filter_block1d16_h6_sse2)
-sym(vp8_filter_block1d16_h6_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 7
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov         rdx,        arg(6) ;vp8_filter
-        mov         rsi,        arg(0) ;src_ptr
-
-        mov         rdi,        arg(1) ;output_ptr
-
-        movsxd      rcx,        dword ptr arg(4) ;output_height
-        movsxd      rax,        dword ptr arg(2) ;src_pixels_per_line            ; Pitch for Source
-%if ABI_IS_32BIT=0
-        movsxd      r8,         dword ptr arg(5) ;output_width
-%endif
-
-        pxor        xmm0,       xmm0                        ; clear xmm0 for unpack
-
-filter_block1d16_h6_sse2_rowloop:
-        movq        xmm3,       MMWORD PTR [rsi - 2]
-        movq        xmm1,       MMWORD PTR [rsi + 6]
-
-        movq        xmm2,       MMWORD PTR [rsi +14]
-        pslldq      xmm2,       8
-
-        por         xmm2,       xmm1
-        prefetcht2  [rsi+rax-2]
-
-        pslldq      xmm1,       8
-        por         xmm1,       xmm3
-
-        movdqa      xmm4,       xmm1
-        movdqa      xmm5,       xmm1
-
-        movdqa      xmm6,       xmm1
-        movdqa      xmm7,       xmm1
-
-        punpcklbw   xmm3,       xmm0                        ; xx05 xx04 xx03 xx02 xx01 xx01 xx-1 xx-2
-        psrldq      xmm4,       1                           ; xx 0d 0c 0b 0a 09 08 07 06 05 04 03 02 01 00 -1
-
-        pmullw      xmm3,       XMMWORD PTR [rdx]           ; x[-2] * H[-2]; Tap 1
-        punpcklbw   xmm4,       xmm0                        ; xx06 xx05 xx04 xx03 xx02 xx01 xx00 xx-1
-
-        psrldq      xmm5,       2                           ; xx xx 0d 0c 0b 0a 09 08 07 06 05 04 03 02 01 00
-        pmullw      xmm4,       XMMWORD PTR [rdx+16]        ; x[-1] * H[-1]; Tap 2
-
-
-        punpcklbw   xmm5,       xmm0                        ; xx07 xx06 xx05 xx04 xx03 xx02 xx01 xx00
-        psrldq      xmm6,       3                           ; xx xx xx 0d 0c 0b 0a 09 08 07 06 05 04 03 02 01
-
-        pmullw      xmm5,       [rdx+32]                    ; x[ 0] * H[ 0]; Tap 3
-
-        punpcklbw   xmm6,       xmm0                        ; xx08 xx07 xx06 xx05 xx04 xx03 xx02 xx01
-        psrldq      xmm7,       4                           ; xx xx xx xx 0d 0c 0b 0a 09 08 07 06 05 04 03 02
-
-        pmullw      xmm6,       [rdx+48]                    ; x[ 1] * h[ 1] ; Tap 4
-
-        punpcklbw   xmm7,       xmm0                        ; xx09 xx08 xx07 xx06 xx05 xx04 xx03 xx02
-        psrldq      xmm1,       5                           ; xx xx xx xx xx 0d 0c 0b 0a 09 08 07 06 05 04 03
-
-
-        pmullw      xmm7,       [rdx+64]                    ; x[ 2] * h[ 2] ; Tap 5
-
-        punpcklbw   xmm1,       xmm0                        ; xx0a xx09 xx08 xx07 xx06 xx05 xx04 xx03
-        pmullw      xmm1,       [rdx+80]                    ; x[ 3] * h[ 3] ; Tap 6
-
-        paddsw      xmm4,       xmm7
-        paddsw      xmm4,       xmm5
-
-        paddsw      xmm4,       xmm3
-        paddsw      xmm4,       xmm6
-
-        paddsw      xmm4,       xmm1
-        paddsw      xmm4,       [rd GLOBAL]
-
-        psraw       xmm4,       7
-
-        packuswb    xmm4,       xmm0
-        punpcklbw   xmm4,       xmm0
-
-        movdqa      XMMWORD Ptr [rdi],         xmm4
-
-        movdqa      xmm3,       xmm2
-        movdqa      xmm4,       xmm2
-
-        movdqa      xmm5,       xmm2
-        movdqa      xmm6,       xmm2
-
-        movdqa      xmm7,       xmm2
-
-        punpcklbw   xmm3,       xmm0                        ; xx05 xx04 xx03 xx02 xx01 xx01 xx-1 xx-2
-        psrldq      xmm4,       1                           ; xx 0d 0c 0b 0a 09 08 07 06 05 04 03 02 01 00 -1
-
-        pmullw      xmm3,       XMMWORD PTR [rdx]           ; x[-2] * H[-2]; Tap 1
-        punpcklbw   xmm4,       xmm0                        ; xx06 xx05 xx04 xx03 xx02 xx01 xx00 xx-1
-
-        psrldq      xmm5,       2                           ; xx xx 0d 0c 0b 0a 09 08 07 06 05 04 03 02 01 00
-        pmullw      xmm4,       XMMWORD PTR [rdx+16]        ; x[-1] * H[-1]; Tap 2
-
-
-        punpcklbw   xmm5,       xmm0                        ; xx07 xx06 xx05 xx04 xx03 xx02 xx01 xx00
-        psrldq      xmm6,       3                           ; xx xx xx 0d 0c 0b 0a 09 08 07 06 05 04 03 02 01
-
-        pmullw      xmm5,       [rdx+32]                    ; x[ 0] * H[ 0]; Tap 3
-
-        punpcklbw   xmm6,       xmm0                        ; xx08 xx07 xx06 xx05 xx04 xx03 xx02 xx01
-        psrldq      xmm7,       4                           ; xx xx xx xx 0d 0c 0b 0a 09 08 07 06 05 04 03 02
-
-        pmullw      xmm6,       [rdx+48]                    ; x[ 1] * h[ 1] ; Tap 4
-
-        punpcklbw   xmm7,       xmm0                        ; xx09 xx08 xx07 xx06 xx05 xx04 xx03 xx02
-        psrldq      xmm2,       5                           ; xx xx xx xx xx 0d 0c 0b 0a 09 08 07 06 05 04 03
-
-        pmullw      xmm7,       [rdx+64]                    ; x[ 2] * h[ 2] ; Tap 5
-
-        punpcklbw   xmm2,       xmm0                        ; xx0a xx09 xx08 xx07 xx06 xx05 xx04 xx03
-        pmullw      xmm2,       [rdx+80]                    ; x[ 3] * h[ 3] ; Tap 6
-
-
-        paddsw      xmm4,       xmm7
-        paddsw      xmm4,       xmm5
-
-        paddsw      xmm4,       xmm3
-        paddsw      xmm4,       xmm6
-
-        paddsw      xmm4,       xmm2
-        paddsw      xmm4,       [rd GLOBAL]
-
-        psraw       xmm4,       7
-
-        packuswb    xmm4,       xmm0
-        punpcklbw   xmm4,       xmm0
-
-        movdqa      XMMWORD Ptr [rdi+16],      xmm4
-
-        lea         rsi,        [rsi + rax]
-%if ABI_IS_32BIT
-        add         rdi,        DWORD Ptr arg(5) ;[output_width]
-%else
-        add         rdi,        r8
-%endif
-
-        dec         rcx
-        jnz         filter_block1d16_h6_sse2_rowloop                ; next row
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void vp8_filter_block1d8_v6_sse2
-;(
-;    short *src_ptr,
-;    unsigned char *output_ptr,
-;    int dst_ptich,
-;    unsigned int pixels_per_line,
-;    unsigned int pixel_step,
-;    unsigned int output_height,
-;    unsigned int output_width,
-;    short * vp8_filter
-;)
-;/************************************************************************************
-; Notes: filter_block1d8_v6 applies a 6 tap filter vertically to the input pixels. The
-; input pixel array has output_height rows.
-;*************************************************************************************/
-global sym(vp8_filter_block1d8_v6_sse2)
-sym(vp8_filter_block1d8_v6_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 8
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov         rax,        arg(7) ;vp8_filter
-        movsxd      rdx,        dword ptr arg(3) ;pixels_per_line
-
-        mov         rdi,        arg(1) ;output_ptr
-        mov         rsi,        arg(0) ;src_ptr
-
-        sub         rsi,        rdx
-        sub         rsi,        rdx
-
-        movsxd      rcx,        DWORD PTR arg(5) ;[output_height]
-        pxor        xmm0,       xmm0                        ; clear xmm0
-
-        movdqa      xmm7,       XMMWORD PTR [rd GLOBAL]
-%if ABI_IS_32BIT=0
-        movsxd      r8,         dword ptr arg(2) ; dst_ptich
-%endif
-
-vp8_filter_block1d8_v6_sse2_loop:
-        movdqa      xmm1,       XMMWORD PTR [rsi]
-        pmullw      xmm1,       [rax]
-
-        movdqa      xmm2,       XMMWORD PTR [rsi + rdx]
-        pmullw      xmm2,       [rax + 16]
-
-        movdqa      xmm3,       XMMWORD PTR [rsi + rdx * 2]
-        pmullw      xmm3,       [rax + 32]
-
-        movdqa      xmm5,       XMMWORD PTR [rsi + rdx * 4]
-        pmullw      xmm5,       [rax + 64]
-
-        add         rsi,        rdx
-        movdqa      xmm4,       XMMWORD PTR [rsi + rdx * 2]
-
-        pmullw      xmm4,       [rax + 48]
-        movdqa      xmm6,       XMMWORD PTR [rsi + rdx * 4]
-
-        pmullw      xmm6,       [rax + 80]
-
-        paddsw      xmm2,       xmm5
-        paddsw      xmm2,       xmm3
-
-        paddsw      xmm2,       xmm1
-        paddsw      xmm2,       xmm4
-
-        paddsw      xmm2,       xmm6
-        paddsw      xmm2,       xmm7
-
-        psraw       xmm2,       7
-        packuswb    xmm2,       xmm0              ; pack and saturate
-
-        movq        QWORD PTR [rdi], xmm2         ; store the results in the destination
-%if ABI_IS_32BIT
-        add         rdi,        DWORD PTR arg(2) ;[dst_ptich]
-%else
-        add         rdi,        r8
-%endif
-        dec         rcx         ; decrement count
-        jnz         vp8_filter_block1d8_v6_sse2_loop               ; next row
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void vp8_unpack_block1d16_h6_sse2
-;(
-;    unsigned char  *src_ptr,
-;    unsigned short *output_ptr,
-;    unsigned int    src_pixels_per_line,
-;    unsigned int    output_height,
-;    unsigned int    output_width
-;)
-global sym(vp8_unpack_block1d16_h6_sse2)
-sym(vp8_unpack_block1d16_h6_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 5
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov         rsi,        arg(0) ;src_ptr
-        mov         rdi,        arg(1) ;output_ptr
-
-        movsxd      rcx,        dword ptr arg(3) ;output_height
-        movsxd      rax,        dword ptr arg(2) ;src_pixels_per_line            ; Pitch for Source
-
-        pxor        xmm0,       xmm0                        ; clear xmm0 for unpack
-%if ABI_IS_32BIT=0
-        movsxd      r8,         dword ptr arg(4) ;output_width            ; Pitch for Source
-%endif
-
-unpack_block1d16_h6_sse2_rowloop:
-        movq        xmm1,       MMWORD PTR [rsi]            ; 0d 0c 0b 0a 09 08 07 06 05 04 03 02 01 00 -1 -2
-        movq        xmm3,       MMWORD PTR [rsi+8]          ; make copy of xmm1
-
-        punpcklbw   xmm3,       xmm0                        ; xx05 xx04 xx03 xx02 xx01 xx01 xx-1 xx-2
-        punpcklbw   xmm1,       xmm0
-
-        movdqa      XMMWORD Ptr [rdi],         xmm1
-        movdqa      XMMWORD Ptr [rdi + 16],    xmm3
-
-        lea         rsi,        [rsi + rax]
-%if ABI_IS_32BIT
-        add         rdi,        DWORD Ptr arg(4) ;[output_width]
-%else
-        add         rdi,        r8
-%endif
-        dec         rcx
-        jnz         unpack_block1d16_h6_sse2_rowloop                ; next row
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void vp8_unpack_block1d8_h6_sse2
-;(
-;    unsigned char  *src_ptr,
-;    unsigned short *output_ptr,
-;    unsigned int    src_pixels_per_line,
-;    unsigned int    output_height,
-;    unsigned int    output_width
-;)
-global sym(vp8_unpack_block1d8_h6_sse2)
-sym(vp8_unpack_block1d8_h6_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 5
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov         rsi,        arg(0) ;src_ptr
-        mov         rdi,        arg(1) ;output_ptr
-
-        movsxd      rcx,        dword ptr arg(3) ;output_height
-        movsxd      rax,        dword ptr arg(2) ;src_pixels_per_line            ; Pitch for Source
-
-        pxor        xmm0,       xmm0                        ; clear xmm0 for unpack
-%if ABI_IS_32BIT=0
-        movsxd      r8,         dword ptr arg(4) ;output_width            ; Pitch for Source
-%endif
-
-unpack_block1d8_h6_sse2_rowloop:
-        movq        xmm1,       MMWORD PTR [rsi]            ; 0d 0c 0b 0a 09 08 07 06 05 04 03 02 01 00 -1 -2
-        lea         rsi,        [rsi + rax]
-
-        punpcklbw   xmm1,       xmm0
-        movdqa      XMMWORD Ptr [rdi],         xmm1
-
-%if ABI_IS_32BIT
-        add         rdi,        DWORD Ptr arg(4) ;[output_width]
-%else
-        add         rdi,        r8
-%endif
-        dec         rcx
-        jnz         unpack_block1d8_h6_sse2_rowloop                ; next row
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void vp8_pack_block1d8_v6_sse2
-;(
-;    short *src_ptr,
-;    unsigned char *output_ptr,
-;    int dst_ptich,
-;    unsigned int pixels_per_line,
-;    unsigned int output_height,
-;    unsigned int output_width
-;)
-global sym(vp8_pack_block1d8_v6_sse2)
-sym(vp8_pack_block1d8_v6_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 6
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        movsxd      rdx,        dword ptr arg(3) ;pixels_per_line
-        mov         rdi,        arg(1) ;output_ptr
-
-        mov         rsi,        arg(0) ;src_ptr
-        movsxd      rcx,        DWORD PTR arg(4) ;[output_height]
-%if ABI_IS_32BIT=0
-        movsxd      r8,         dword ptr arg(5) ;output_width            ; Pitch for Source
-%endif
-
-pack_block1d8_v6_sse2_loop:
-        movdqa      xmm0,       XMMWORD PTR [rsi]
-        packuswb    xmm0,       xmm0
-
-        movq        QWORD PTR [rdi], xmm0         ; store the results in the destination
-        lea         rsi,        [rsi+rdx]
-
-%if ABI_IS_32BIT
-        add         rdi,        DWORD Ptr arg(5) ;[output_width]
-%else
-        add         rdi,        r8
-%endif
-        dec         rcx         ; decrement count
-        jnz         pack_block1d8_v6_sse2_loop               ; next row
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void vp8_pack_block1d16_v6_sse2
-;(
-;    short *src_ptr,
-;    unsigned char *output_ptr,
-;    int dst_ptich,
-;    unsigned int pixels_per_line,
-;    unsigned int output_height,
-;    unsigned int output_width
-;)
-global sym(vp8_pack_block1d16_v6_sse2)
-sym(vp8_pack_block1d16_v6_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 6
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        movsxd      rdx,        dword ptr arg(3) ;pixels_per_line
-        mov         rdi,        arg(1) ;output_ptr
-
-        mov         rsi,        arg(0) ;src_ptr
-        movsxd      rcx,        DWORD PTR arg(4) ;[output_height]
-%if ABI_IS_32BIT=0
-        movsxd      r8,         dword ptr arg(2) ;dst_pitch
-%endif
-
-pack_block1d16_v6_sse2_loop:
-        movdqa      xmm0,       XMMWORD PTR [rsi]
-        movdqa      xmm1,       XMMWORD PTR [rsi+16]
-
-        packuswb    xmm0,       xmm1
-        movdqa      XMMWORD PTR [rdi], xmm0         ; store the results in the destination
-
-        add         rsi,        rdx
-%if ABI_IS_32BIT
-        add         rdi,        DWORD Ptr arg(2) ;dst_pitch
-%else
-        add         rdi,        r8
-%endif
-        dec         rcx         ; decrement count
-        jnz         pack_block1d16_v6_sse2_loop               ; next row
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void vp8_bilinear_predict16x16_sse2
-;(
-;    unsigned char  *src_ptr,
-;    int   src_pixels_per_line,
-;    int  xoffset,
-;    int  yoffset,
-;    unsigned char *dst_ptr,
-;    int dst_pitch
-;)
-extern sym(vp8_bilinear_filters_mmx)
-global sym(vp8_bilinear_predict16x16_sse2)
-sym(vp8_bilinear_predict16x16_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 6
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-    ;const short *HFilter = bilinear_filters_mmx[xoffset]
-    ;const short *VFilter = bilinear_filters_mmx[yoffset]
-
-        lea         rcx,        [sym(vp8_bilinear_filters_mmx) GLOBAL]
-        movsxd      rax,        dword ptr arg(2) ;xoffset
-
-        cmp         rax,        0      ;skip first_pass filter if xoffset=0
-        je          b16x16_sp_only
-
-        shl         rax,        5
-        add         rax,        rcx    ;HFilter
-
-        mov         rdi,        arg(4) ;dst_ptr
-        mov         rsi,        arg(0) ;src_ptr
-        movsxd      rdx,        dword ptr arg(5) ;dst_pitch
-
-        movdqa      xmm1,       [rax]
-        movdqa      xmm2,       [rax+16]
-
-        movsxd      rax,        dword ptr arg(3) ;yoffset
-
-        cmp         rax,        0      ;skip second_pass filter if yoffset=0
-        je          b16x16_fp_only
-
-        shl         rax,        5
-        add         rax,        rcx    ;VFilter
-
-        lea         rcx,        [rdi+rdx*8]
-        lea         rcx,        [rcx+rdx*8]
-        movsxd      rdx,        dword ptr arg(1) ;src_pixels_per_line
-
-        pxor        xmm0,       xmm0
-
-%if ABI_IS_32BIT=0
-        movsxd      r8,         dword ptr arg(5) ;dst_pitch
-%endif
-        ; get the first horizontal line done
-        movdqu      xmm3,       [rsi]               ; xx 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14
-        movdqa      xmm4,       xmm3                 ; make a copy of current line
-
-        punpcklbw   xmm3,       xmm0                 ; xx 00 01 02 03 04 05 06
-        punpckhbw   xmm4,       xmm0
-
-        pmullw      xmm3,       xmm1
-        pmullw      xmm4,       xmm1
-
-        movdqu      xmm5,       [rsi+1]
-        movdqa      xmm6,       xmm5
-
-        punpcklbw   xmm5,       xmm0
-        punpckhbw   xmm6,       xmm0
-
-        pmullw      xmm5,       xmm2
-        pmullw      xmm6,       xmm2
-
-        paddw       xmm3,       xmm5
-        paddw       xmm4,       xmm6
-
-        paddw       xmm3,       [rd GLOBAL]         ; xmm3 += round value
-        psraw       xmm3,       VP8_FILTER_SHIFT        ; xmm3 /= 128
-
-        paddw       xmm4,       [rd GLOBAL]
-        psraw       xmm4,       VP8_FILTER_SHIFT
-
-        movdqa      xmm7,       xmm3
-        packuswb    xmm7,       xmm4
-
-        add         rsi,        rdx                 ; next line
-next_row:
-        movdqu      xmm3,       [rsi]               ; xx 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14
-        movdqa      xmm4,       xmm3                 ; make a copy of current line
-
-        punpcklbw   xmm3,       xmm0                 ; xx 00 01 02 03 04 05 06
-        punpckhbw   xmm4,       xmm0
-
-        pmullw      xmm3,       xmm1
-        pmullw      xmm4,       xmm1
-
-        movdqu      xmm5,       [rsi+1]
-        movdqa      xmm6,       xmm5
-
-        punpcklbw   xmm5,       xmm0
-        punpckhbw   xmm6,       xmm0
-
-        pmullw      xmm5,       xmm2
-        pmullw      xmm6,       xmm2
-
-        paddw       xmm3,       xmm5
-        paddw       xmm4,       xmm6
-
-        movdqa      xmm5,       xmm7
-        movdqa      xmm6,       xmm7
-
-        punpcklbw   xmm5,       xmm0
-        punpckhbw   xmm6,       xmm0
-
-        pmullw      xmm5,       [rax]
-        pmullw      xmm6,       [rax]
-
-        paddw       xmm3,       [rd GLOBAL]         ; xmm3 += round value
-        psraw       xmm3,       VP8_FILTER_SHIFT        ; xmm3 /= 128
-
-        paddw       xmm4,       [rd GLOBAL]
-        psraw       xmm4,       VP8_FILTER_SHIFT
-
-        movdqa      xmm7,       xmm3
-        packuswb    xmm7,       xmm4
-
-        pmullw      xmm3,       [rax+16]
-        pmullw      xmm4,       [rax+16]
-
-        paddw       xmm3,       xmm5
-        paddw       xmm4,       xmm6
-
-        paddw       xmm3,       [rd GLOBAL]         ; xmm3 += round value
-        psraw       xmm3,       VP8_FILTER_SHIFT        ; xmm3 /= 128
-
-        paddw       xmm4,       [rd GLOBAL]
-        psraw       xmm4,       VP8_FILTER_SHIFT
-
-        packuswb    xmm3,       xmm4
-        movdqa      [rdi],      xmm3                 ; store the results in the destination
-
-        add         rsi,        rdx                 ; next line
-%if ABI_IS_32BIT
-        add         rdi,        DWORD PTR arg(5) ;dst_pitch
-%else
-        add         rdi,        r8
-%endif
-
-        cmp         rdi,        rcx
-        jne         next_row
-
-        jmp         done
-
-b16x16_sp_only:
-        movsxd      rax,        dword ptr arg(3) ;yoffset
-        shl         rax,        5
-        add         rax,        rcx    ;VFilter
-
-        mov         rdi,        arg(4) ;dst_ptr
-        mov         rsi,        arg(0) ;src_ptr
-        movsxd      rdx,        dword ptr arg(5) ;dst_pitch
-
-        movdqa      xmm1,       [rax]
-        movdqa      xmm2,       [rax+16]
-
-        lea         rcx,        [rdi+rdx*8]
-        lea         rcx,        [rcx+rdx*8]
-        movsxd      rax,        dword ptr arg(1) ;src_pixels_per_line
-
-        pxor        xmm0,       xmm0
-
-        ; get the first horizontal line done
-        movdqu      xmm7,       [rsi]               ; xx 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14
-
-        add         rsi,        rax                 ; next line
-next_row_spo:
-        movdqu      xmm3,       [rsi]               ; xx 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14
-
-        movdqa      xmm5,       xmm7
-        movdqa      xmm6,       xmm7
-
-        movdqa      xmm4,       xmm3                 ; make a copy of current line
-        movdqa      xmm7,       xmm3
-
-        punpcklbw   xmm5,       xmm0
-        punpckhbw   xmm6,       xmm0
-        punpcklbw   xmm3,       xmm0                 ; xx 00 01 02 03 04 05 06
-        punpckhbw   xmm4,       xmm0
-
-        pmullw      xmm5,       xmm1
-        pmullw      xmm6,       xmm1
-        pmullw      xmm3,       xmm2
-        pmullw      xmm4,       xmm2
-
-        paddw       xmm3,       xmm5
-        paddw       xmm4,       xmm6
-
-        paddw       xmm3,       [rd GLOBAL]         ; xmm3 += round value
-        psraw       xmm3,       VP8_FILTER_SHIFT        ; xmm3 /= 128
-
-        paddw       xmm4,       [rd GLOBAL]
-        psraw       xmm4,       VP8_FILTER_SHIFT
-
-        packuswb    xmm3,       xmm4
-        movdqa      [rdi],      xmm3                 ; store the results in the destination
-
-        add         rsi,        rax                 ; next line
-        add         rdi,        rdx                 ;dst_pitch
-        cmp         rdi,        rcx
-        jne         next_row_spo
-
-        jmp         done
-
-b16x16_fp_only:
-        lea         rcx,        [rdi+rdx*8]
-        lea         rcx,        [rcx+rdx*8]
-        movsxd      rax,        dword ptr arg(1) ;src_pixels_per_line
-        pxor        xmm0,       xmm0
-
-next_row_fpo:
-        movdqu      xmm3,       [rsi]               ; xx 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14
-        movdqa      xmm4,       xmm3                 ; make a copy of current line
-
-        punpcklbw   xmm3,       xmm0                 ; xx 00 01 02 03 04 05 06
-        punpckhbw   xmm4,       xmm0
-
-        pmullw      xmm3,       xmm1
-        pmullw      xmm4,       xmm1
-
-        movdqu      xmm5,       [rsi+1]
-        movdqa      xmm6,       xmm5
-
-        punpcklbw   xmm5,       xmm0
-        punpckhbw   xmm6,       xmm0
-
-        pmullw      xmm5,       xmm2
-        pmullw      xmm6,       xmm2
-
-        paddw       xmm3,       xmm5
-        paddw       xmm4,       xmm6
-
-        paddw       xmm3,       [rd GLOBAL]         ; xmm3 += round value
-        psraw       xmm3,       VP8_FILTER_SHIFT        ; xmm3 /= 128
-
-        paddw       xmm4,       [rd GLOBAL]
-        psraw       xmm4,       VP8_FILTER_SHIFT
-
-        packuswb    xmm3,       xmm4
-        movdqa      [rdi],      xmm3                 ; store the results in the destination
-
-        add         rsi,        rax                 ; next line
-        add         rdi,        rdx                 ; dst_pitch
-        cmp         rdi,        rcx
-        jne         next_row_fpo
-
-done:
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void vp8_bilinear_predict8x8_sse2
-;(
-;    unsigned char  *src_ptr,
-;    int   src_pixels_per_line,
-;    int  xoffset,
-;    int  yoffset,
-;    unsigned char *dst_ptr,
-;    int dst_pitch
-;)
-extern sym(vp8_bilinear_filters_mmx)
-global sym(vp8_bilinear_predict8x8_sse2)
-sym(vp8_bilinear_predict8x8_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 6
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-    ALIGN_STACK 16, rax
-    sub         rsp, 144                         ; reserve 144 bytes
-
-    ;const short *HFilter = bilinear_filters_mmx[xoffset]
-    ;const short *VFilter = bilinear_filters_mmx[yoffset]
-        lea         rcx,        [sym(vp8_bilinear_filters_mmx) GLOBAL]
-
-        mov         rsi,        arg(0) ;src_ptr
-        movsxd      rdx,        dword ptr arg(1) ;src_pixels_per_line
-
-    ;Read 9-line unaligned data in and put them on stack. This gives a big
-    ;performance boost.
-        movdqu      xmm0,       [rsi]
-        lea         rax,        [rdx + rdx*2]
-        movdqu      xmm1,       [rsi+rdx]
-        movdqu      xmm2,       [rsi+rdx*2]
-        add         rsi,        rax
-        movdqu      xmm3,       [rsi]
-        movdqu      xmm4,       [rsi+rdx]
-        movdqu      xmm5,       [rsi+rdx*2]
-        add         rsi,        rax
-        movdqu      xmm6,       [rsi]
-        movdqu      xmm7,       [rsi+rdx]
-
-        movdqa      XMMWORD PTR [rsp],            xmm0
-
-        movdqu      xmm0,       [rsi+rdx*2]
-
-        movdqa      XMMWORD PTR [rsp+16],         xmm1
-        movdqa      XMMWORD PTR [rsp+32],         xmm2
-        movdqa      XMMWORD PTR [rsp+48],         xmm3
-        movdqa      XMMWORD PTR [rsp+64],         xmm4
-        movdqa      XMMWORD PTR [rsp+80],         xmm5
-        movdqa      XMMWORD PTR [rsp+96],         xmm6
-        movdqa      XMMWORD PTR [rsp+112],        xmm7
-        movdqa      XMMWORD PTR [rsp+128],        xmm0
-
-        movsxd      rax,        dword ptr arg(2) ;xoffset
-        shl         rax,        5
-        add         rax,        rcx    ;HFilter
-
-        mov         rdi,        arg(4) ;dst_ptr
-        movsxd      rdx,        dword ptr arg(5) ;dst_pitch
-
-        movdqa      xmm1,       [rax]
-        movdqa      xmm2,       [rax+16]
-
-        movsxd      rax,        dword ptr arg(3) ;yoffset
-        shl         rax,        5
-        add         rax,        rcx    ;VFilter
-
-        lea         rcx,        [rdi+rdx*8]
-
-        movdqa      xmm5,       [rax]
-        movdqa      xmm6,       [rax+16]
-
-        pxor        xmm0,       xmm0
-
-        ; get the first horizontal line done
-        movdqa      xmm3,       XMMWORD PTR [rsp]
-        movdqa      xmm4,       xmm3                 ; make a copy of current line
-        psrldq      xmm4,       1
-
-        punpcklbw   xmm3,       xmm0                 ; 00 01 02 03 04 05 06 07
-        punpcklbw   xmm4,       xmm0                 ; 01 02 03 04 05 06 07 08
-
-        pmullw      xmm3,       xmm1
-        pmullw      xmm4,       xmm2
-
-        paddw       xmm3,       xmm4
-
-        paddw       xmm3,       [rd GLOBAL]         ; xmm3 += round value
-        psraw       xmm3,       VP8_FILTER_SHIFT        ; xmm3 /= 128
-
-        movdqa      xmm7,       xmm3
-        add         rsp,        16                 ; next line
-next_row8x8:
-        movdqa      xmm3,       XMMWORD PTR [rsp]               ; 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15
-        movdqa      xmm4,       xmm3                 ; make a copy of current line
-        psrldq      xmm4,       1
-
-        punpcklbw   xmm3,       xmm0                 ; 00 01 02 03 04 05 06 07
-        punpcklbw   xmm4,       xmm0                 ; 01 02 03 04 05 06 07 08
-
-        pmullw      xmm3,       xmm1
-        pmullw      xmm4,       xmm2
-
-        paddw       xmm3,       xmm4
-        pmullw      xmm7,       xmm5
-
-        paddw       xmm3,       [rd GLOBAL]         ; xmm3 += round value
-        psraw       xmm3,       VP8_FILTER_SHIFT        ; xmm3 /= 128
-
-        movdqa      xmm4,       xmm3
-
-        pmullw      xmm3,       xmm6
-        paddw       xmm3,       xmm7
-
-        movdqa      xmm7,       xmm4
-
-        paddw       xmm3,       [rd GLOBAL]         ; xmm3 += round value
-        psraw       xmm3,       VP8_FILTER_SHIFT        ; xmm3 /= 128
-
-        packuswb    xmm3,       xmm0
-        movq        [rdi],      xmm3                 ; store the results in the destination
-
-        add         rsp,        16                 ; next line
-        add         rdi,        rdx
-
-        cmp         rdi,        rcx
-        jne         next_row8x8
-
-    ;add rsp, 144
-    pop rsp
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-SECTION_RODATA
-align 16
-rd:
-    times 8 dw 0x40
diff --git a/vp8/decoder/x86/dequantize_mmx.S b/vp8/decoder/x86/dequantize_mmx.S
new file mode 100644
index 0000000..bd34179
--- /dev/null
+++ b/vp8/decoder/x86/dequantize_mmx.S
@@ -0,0 +1,410 @@
+//
+//  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
+//
+//  Use of this source code is governed by a BSD-style license and patent
+//  grant that can be found in the LICENSE file in the root of the source
+//  tree. All contributing project authors may be found in the AUTHORS
+//  file in the root of the source tree.
+//
+
+
+#include "vpx_ports/x86_abi_support.S"
+
+
+//void vp8_dequantize_b_impl_mmx(short *sq, short *dq, short *q)
+global sym(vp8_dequantize_b_impl_mmx)
+sym(vp8_dequantize_b_impl_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 3
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov       rsi, arg(0) //sq
+        mov       rdi, arg(1) //dq
+        mov       rax, arg(2) //q
+
+        movq      mm1, [rsi]
+        pmullw    mm1, [rax+0]            // mm4 *= kernel 0 modifiers.
+        movq      [rdi], mm1
+
+        movq      mm1, [rsi+8]
+        pmullw    mm1, [rax+8]            // mm4 *= kernel 0 modifiers.
+        movq      [rdi+8], mm1
+
+        movq      mm1, [rsi+16]
+        pmullw    mm1, [rax+16]            // mm4 *= kernel 0 modifiers.
+        movq      [rdi+16], mm1
+
+        movq      mm1, [rsi+24]
+        pmullw    mm1, [rax+24]            // mm4 *= kernel 0 modifiers.
+        movq      [rdi+24], mm1
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void dequant_idct_mmx(short *input, short *dq, short *output, int pitch)
+global sym(vp8_dequant_idct_mmx)
+sym(vp8_dequant_idct_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 4
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov         rax,    arg(0) //input
+        mov         rdx,    arg(1) //dq
+
+
+        movq        mm0,    [rax   ]
+        pmullw      mm0,    [rdx]
+
+        movq        mm1,    [rax +8]
+        pmullw      mm1,    [rdx +8]
+
+        movq        mm2,    [rax+16]
+        pmullw      mm2,    [rdx+16]
+
+        movq        mm3,    [rax+24]
+        pmullw      mm3,    [rdx+24]
+
+        mov         rdx,    arg(2) //output
+        pxor        mm7,    mm7
+
+
+        movq        [rax],   mm7
+        movq        [rax+8], mm7
+
+        movq        [rax+16],mm7
+        movq        [rax+24],mm7
+
+
+        movsxd      rax,            dword ptr arg(3) //pitch
+
+        psubw       mm0,            mm2             // b1= 0-2
+        paddw       mm2,            mm2             //
+
+        movq        mm5,            mm1
+        paddw       mm2,            mm0             // a1 =0+2
+
+        pmulhw      mm5,            [GLOBAL (x_s1sqr2)];
+        paddw       mm5,            mm1             // ip1 * sin(pi/8) * sqrt(2)
+
+        movq        mm7,            mm3             //
+        pmulhw      mm7,            [GLOBAL (x_c1sqr2less1)];
+
+        paddw       mm7,            mm3             // ip3 * cos(pi/8) * sqrt(2)
+        psubw       mm7,            mm5             // c1
+
+        movq        mm5,            mm1
+        movq        mm4,            mm3
+
+        pmulhw      mm5,            [GLOBAL (x_c1sqr2less1)]
+        paddw       mm5,            mm1
+
+        pmulhw      mm3,            [GLOBAL (x_s1sqr2)]
+        paddw       mm3,            mm4
+
+        paddw       mm3,            mm5             // d1
+        movq        mm6,            mm2             // a1
+
+        movq        mm4,            mm0             // b1
+        paddw       mm2,            mm3             //0
+
+        paddw       mm4,            mm7             //1
+        psubw       mm0,            mm7             //2
+
+        psubw       mm6,            mm3             //3
+
+        movq        mm1,            mm2             // 03 02 01 00
+        movq        mm3,            mm4             // 23 22 21 20
+
+        punpcklwd   mm1,            mm0             // 11 01 10 00
+        punpckhwd   mm2,            mm0             // 13 03 12 02
+
+        punpcklwd   mm3,            mm6             // 31 21 30 20
+        punpckhwd   mm4,            mm6             // 33 23 32 22
+
+        movq        mm0,            mm1             // 11 01 10 00
+        movq        mm5,            mm2             // 13 03 12 02
+
+        punpckldq   mm0,            mm3             // 30 20 10 00
+        punpckhdq   mm1,            mm3             // 31 21 11 01
+
+        punpckldq   mm2,            mm4             // 32 22 12 02
+        punpckhdq   mm5,            mm4             // 33 23 13 03
+
+        movq        mm3,            mm5             // 33 23 13 03
+
+        psubw       mm0,            mm2             // b1= 0-2
+        paddw       mm2,            mm2             //
+
+        movq        mm5,            mm1
+        paddw       mm2,            mm0             // a1 =0+2
+
+        pmulhw      mm5,            [GLOBAL (x_s1sqr2)];
+        paddw       mm5,            mm1             // ip1 * sin(pi/8) * sqrt(2)
+
+        movq        mm7,            mm3             //
+        pmulhw      mm7,            [GLOBAL (x_c1sqr2less1)];
+
+        paddw       mm7,            mm3             // ip3 * cos(pi/8) * sqrt(2)
+        psubw       mm7,            mm5             // c1
+
+        movq        mm5,            mm1
+        movq        mm4,            mm3
+
+        pmulhw      mm5,            [GLOBAL (x_c1sqr2less1)]
+        paddw       mm5,            mm1
+
+        pmulhw      mm3,            [GLOBAL (x_s1sqr2)]
+        paddw       mm3,            mm4
+
+        paddw       mm3,            mm5             // d1
+        paddw       mm0,            [GLOBAL (fours)]
+
+        paddw       mm2,            [GLOBAL (fours)]
+        movq        mm6,            mm2             // a1
+
+        movq        mm4,            mm0             // b1
+        paddw       mm2,            mm3             //0
+
+        paddw       mm4,            mm7             //1
+        psubw       mm0,            mm7             //2
+
+        psubw       mm6,            mm3             //3
+        psraw       mm2,            3
+
+        psraw       mm0,            3
+        psraw       mm4,            3
+
+        psraw       mm6,            3
+
+        movq        mm1,            mm2             // 03 02 01 00
+        movq        mm3,            mm4             // 23 22 21 20
+
+        punpcklwd   mm1,            mm0             // 11 01 10 00
+        punpckhwd   mm2,            mm0             // 13 03 12 02
+
+        punpcklwd   mm3,            mm6             // 31 21 30 20
+        punpckhwd   mm4,            mm6             // 33 23 32 22
+
+        movq        mm0,            mm1             // 11 01 10 00
+        movq        mm5,            mm2             // 13 03 12 02
+
+        punpckldq   mm0,            mm3             // 30 20 10 00
+        punpckhdq   mm1,            mm3             // 31 21 11 01
+
+        punpckldq   mm2,            mm4             // 32 22 12 02
+        punpckhdq   mm5,            mm4             // 33 23 13 03
+
+        movq        [rdx],          mm0
+
+        movq        [rdx+rax],      mm1
+        movq        [rdx+rax*2],    mm2
+
+        add         rdx,            rax
+        movq        [rdx+rax*2],    mm5
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void dequant_dc_idct_mmx(short *input, short *dq, short *output, int pitch, int Dc)
+global sym(vp8_dequant_dc_idct_mmx)
+sym(vp8_dequant_dc_idct_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 5
+    GET_GOT     rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov         rax,    arg(0) //input
+        mov         rdx,    arg(1) //dq
+
+        movsxd      rcx,    dword ptr arg(4) //Dc
+
+        movq        mm0,    [rax   ]
+        pmullw      mm0,    [rdx]
+
+        movq        mm1,    [rax +8]
+        pmullw      mm1,    [rdx +8]
+
+        movq        mm2,    [rax+16]
+        pmullw      mm2,    [rdx+16]
+
+        movq        mm3,    [rax+24]
+        pmullw      mm3,    [rdx+24]
+
+        mov         rdx,    arg(2) //output
+        pxor        mm7,    mm7
+
+
+        movq        [rax],   mm7
+        movq        [rax+8], mm7
+
+        movq        [rax+16],mm7
+        movq        [rax+24],mm7
+
+        pinsrw      mm0,    rcx,  0
+        movsxd      rax,            dword ptr arg(3) //pitch
+
+        psubw       mm0,            mm2             // b1= 0-2
+        paddw       mm2,            mm2             //
+
+        movq        mm5,            mm1
+        paddw       mm2,            mm0             // a1 =0+2
+
+        pmulhw      mm5,            [GLOBAL (x_s1sqr2)];
+        paddw       mm5,            mm1             // ip1 * sin(pi/8) * sqrt(2)
+
+        movq        mm7,            mm3             //
+        pmulhw      mm7,            [GLOBAL (x_c1sqr2less1)];
+
+        paddw       mm7,            mm3             // ip3 * cos(pi/8) * sqrt(2)
+        psubw       mm7,            mm5             // c1
+
+        movq        mm5,            mm1
+        movq        mm4,            mm3
+
+        pmulhw      mm5,            [GLOBAL (x_c1sqr2less1)]
+        paddw       mm5,            mm1
+
+        pmulhw      mm3,            [GLOBAL (x_s1sqr2)]
+        paddw       mm3,            mm4
+
+        paddw       mm3,            mm5             // d1
+        movq        mm6,            mm2             // a1
+
+        movq        mm4,            mm0             // b1
+        paddw       mm2,            mm3             //0
+
+        paddw       mm4,            mm7             //1
+        psubw       mm0,            mm7             //2
+
+        psubw       mm6,            mm3             //3
+
+        movq        mm1,            mm2             // 03 02 01 00
+        movq        mm3,            mm4             // 23 22 21 20
+
+        punpcklwd   mm1,            mm0             // 11 01 10 00
+        punpckhwd   mm2,            mm0             // 13 03 12 02
+
+        punpcklwd   mm3,            mm6             // 31 21 30 20
+        punpckhwd   mm4,            mm6             // 33 23 32 22
+
+        movq        mm0,            mm1             // 11 01 10 00
+        movq        mm5,            mm2             // 13 03 12 02
+
+        punpckldq   mm0,            mm3             // 30 20 10 00
+        punpckhdq   mm1,            mm3             // 31 21 11 01
+
+        punpckldq   mm2,            mm4             // 32 22 12 02
+        punpckhdq   mm5,            mm4             // 33 23 13 03
+
+        movq        mm3,            mm5             // 33 23 13 03
+
+        psubw       mm0,            mm2             // b1= 0-2
+        paddw       mm2,            mm2             //
+
+        movq        mm5,            mm1
+        paddw       mm2,            mm0             // a1 =0+2
+
+        pmulhw      mm5,            [GLOBAL (x_s1sqr2)];
+        paddw       mm5,            mm1             // ip1 * sin(pi/8) * sqrt(2)
+
+        movq        mm7,            mm3             //
+        pmulhw      mm7,            [GLOBAL (x_c1sqr2less1)];
+
+        paddw       mm7,            mm3             // ip3 * cos(pi/8) * sqrt(2)
+        psubw       mm7,            mm5             // c1
+
+        movq        mm5,            mm1
+        movq        mm4,            mm3
+
+        pmulhw      mm5,            [GLOBAL (x_c1sqr2less1)]
+        paddw       mm5,            mm1
+
+        pmulhw      mm3,            [GLOBAL (x_s1sqr2)]
+        paddw       mm3,            mm4
+
+        paddw       mm3,            mm5             // d1
+        paddw       mm0,            [GLOBAL (fours)]
+
+        paddw       mm2,            [GLOBAL (fours)]
+        movq        mm6,            mm2             // a1
+
+        movq        mm4,            mm0             // b1
+        paddw       mm2,            mm3             //0
+
+        paddw       mm4,            mm7             //1
+        psubw       mm0,            mm7             //2
+
+        psubw       mm6,            mm3             //3
+        psraw       mm2,            3
+
+        psraw       mm0,            3
+        psraw       mm4,            3
+
+        psraw       mm6,            3
+
+        movq        mm1,            mm2             // 03 02 01 00
+        movq        mm3,            mm4             // 23 22 21 20
+
+        punpcklwd   mm1,            mm0             // 11 01 10 00
+        punpckhwd   mm2,            mm0             // 13 03 12 02
+
+        punpcklwd   mm3,            mm6             // 31 21 30 20
+        punpckhwd   mm4,            mm6             // 33 23 32 22
+
+        movq        mm0,            mm1             // 11 01 10 00
+        movq        mm5,            mm2             // 13 03 12 02
+
+        punpckldq   mm0,            mm3             // 30 20 10 00
+        punpckhdq   mm1,            mm3             // 31 21 11 01
+
+        punpckldq   mm2,            mm4             // 32 22 12 02
+        punpckhdq   mm5,            mm4             // 33 23 13 03
+
+        movq        [rdx],          mm0
+
+        movq        [rdx+rax],      mm1
+        movq        [rdx+rax*2],    mm2
+
+        add         rdx,            rax
+        movq        [rdx+rax*2],    mm5
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+SECTION_RODATA
+align 16
+x_s1sqr2:
+    .fill 4, 2, 0x8A8C
+align 16
+x_c1sqr2less1:
+    .fill 4, 2, 0x4E7B
+align 16
+fours:
+    .fill 4, 2, 0x0004
diff --git a/vp8/decoder/x86/dequantize_mmx.asm b/vp8/decoder/x86/dequantize_mmx.asm
deleted file mode 100644
index 02be487..0000000
--- a/vp8/decoder/x86/dequantize_mmx.asm
+++ /dev/null
@@ -1,410 +0,0 @@
-;
-;  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
-;
-;  Use of this source code is governed by a BSD-style license and patent
-;  grant that can be found in the LICENSE file in the root of the source
-;  tree. All contributing project authors may be found in the AUTHORS
-;  file in the root of the source tree.
-;
-
-
-%include "vpx_ports/x86_abi_support.asm"
-
-
-;void vp8_dequantize_b_impl_mmx(short *sq, short *dq, short *q)
-global sym(vp8_dequantize_b_impl_mmx)
-sym(vp8_dequantize_b_impl_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 3
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov       rsi, arg(0) ;sq
-        mov       rdi, arg(1) ;dq
-        mov       rax, arg(2) ;q
-
-        movq      mm1, [rsi]
-        pmullw    mm1, [rax+0]            ; mm4 *= kernel 0 modifiers.
-        movq      [rdi], mm1
-
-        movq      mm1, [rsi+8]
-        pmullw    mm1, [rax+8]            ; mm4 *= kernel 0 modifiers.
-        movq      [rdi+8], mm1
-
-        movq      mm1, [rsi+16]
-        pmullw    mm1, [rax+16]            ; mm4 *= kernel 0 modifiers.
-        movq      [rdi+16], mm1
-
-        movq      mm1, [rsi+24]
-        pmullw    mm1, [rax+24]            ; mm4 *= kernel 0 modifiers.
-        movq      [rdi+24], mm1
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void dequant_idct_mmx(short *input, short *dq, short *output, int pitch)
-global sym(vp8_dequant_idct_mmx)
-sym(vp8_dequant_idct_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 4
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov         rax,    arg(0) ;input
-        mov         rdx,    arg(1) ;dq
-
-
-        movq        mm0,    [rax   ]
-        pmullw      mm0,    [rdx]
-
-        movq        mm1,    [rax +8]
-        pmullw      mm1,    [rdx +8]
-
-        movq        mm2,    [rax+16]
-        pmullw      mm2,    [rdx+16]
-
-        movq        mm3,    [rax+24]
-        pmullw      mm3,    [rdx+24]
-
-        mov         rdx,    arg(2) ;output
-        pxor        mm7,    mm7
-
-
-        movq        [rax],   mm7
-        movq        [rax+8], mm7
-
-        movq        [rax+16],mm7
-        movq        [rax+24],mm7
-
-
-        movsxd      rax,            dword ptr arg(3) ;pitch
-
-        psubw       mm0,            mm2             ; b1= 0-2
-        paddw       mm2,            mm2             ;
-
-        movq        mm5,            mm1
-        paddw       mm2,            mm0             ; a1 =0+2
-
-        pmulhw      mm5,            [x_s1sqr2 GLOBAL];
-        paddw       mm5,            mm1             ; ip1 * sin(pi/8) * sqrt(2)
-
-        movq        mm7,            mm3             ;
-        pmulhw      mm7,            [x_c1sqr2less1 GLOBAL];
-
-        paddw       mm7,            mm3             ; ip3 * cos(pi/8) * sqrt(2)
-        psubw       mm7,            mm5             ; c1
-
-        movq        mm5,            mm1
-        movq        mm4,            mm3
-
-        pmulhw      mm5,            [x_c1sqr2less1 GLOBAL]
-        paddw       mm5,            mm1
-
-        pmulhw      mm3,            [x_s1sqr2 GLOBAL]
-        paddw       mm3,            mm4
-
-        paddw       mm3,            mm5             ; d1
-        movq        mm6,            mm2             ; a1
-
-        movq        mm4,            mm0             ; b1
-        paddw       mm2,            mm3             ;0
-
-        paddw       mm4,            mm7             ;1
-        psubw       mm0,            mm7             ;2
-
-        psubw       mm6,            mm3             ;3
-
-        movq        mm1,            mm2             ; 03 02 01 00
-        movq        mm3,            mm4             ; 23 22 21 20
-
-        punpcklwd   mm1,            mm0             ; 11 01 10 00
-        punpckhwd   mm2,            mm0             ; 13 03 12 02
-
-        punpcklwd   mm3,            mm6             ; 31 21 30 20
-        punpckhwd   mm4,            mm6             ; 33 23 32 22
-
-        movq        mm0,            mm1             ; 11 01 10 00
-        movq        mm5,            mm2             ; 13 03 12 02
-
-        punpckldq   mm0,            mm3             ; 30 20 10 00
-        punpckhdq   mm1,            mm3             ; 31 21 11 01
-
-        punpckldq   mm2,            mm4             ; 32 22 12 02
-        punpckhdq   mm5,            mm4             ; 33 23 13 03
-
-        movq        mm3,            mm5             ; 33 23 13 03
-
-        psubw       mm0,            mm2             ; b1= 0-2
-        paddw       mm2,            mm2             ;
-
-        movq        mm5,            mm1
-        paddw       mm2,            mm0             ; a1 =0+2
-
-        pmulhw      mm5,            [x_s1sqr2 GLOBAL];
-        paddw       mm5,            mm1             ; ip1 * sin(pi/8) * sqrt(2)
-
-        movq        mm7,            mm3             ;
-        pmulhw      mm7,            [x_c1sqr2less1 GLOBAL];
-
-        paddw       mm7,            mm3             ; ip3 * cos(pi/8) * sqrt(2)
-        psubw       mm7,            mm5             ; c1
-
-        movq        mm5,            mm1
-        movq        mm4,            mm3
-
-        pmulhw      mm5,            [x_c1sqr2less1 GLOBAL]
-        paddw       mm5,            mm1
-
-        pmulhw      mm3,            [x_s1sqr2 GLOBAL]
-        paddw       mm3,            mm4
-
-        paddw       mm3,            mm5             ; d1
-        paddw       mm0,            [fours GLOBAL]
-
-        paddw       mm2,            [fours GLOBAL]
-        movq        mm6,            mm2             ; a1
-
-        movq        mm4,            mm0             ; b1
-        paddw       mm2,            mm3             ;0
-
-        paddw       mm4,            mm7             ;1
-        psubw       mm0,            mm7             ;2
-
-        psubw       mm6,            mm3             ;3
-        psraw       mm2,            3
-
-        psraw       mm0,            3
-        psraw       mm4,            3
-
-        psraw       mm6,            3
-
-        movq        mm1,            mm2             ; 03 02 01 00
-        movq        mm3,            mm4             ; 23 22 21 20
-
-        punpcklwd   mm1,            mm0             ; 11 01 10 00
-        punpckhwd   mm2,            mm0             ; 13 03 12 02
-
-        punpcklwd   mm3,            mm6             ; 31 21 30 20
-        punpckhwd   mm4,            mm6             ; 33 23 32 22
-
-        movq        mm0,            mm1             ; 11 01 10 00
-        movq        mm5,            mm2             ; 13 03 12 02
-
-        punpckldq   mm0,            mm3             ; 30 20 10 00
-        punpckhdq   mm1,            mm3             ; 31 21 11 01
-
-        punpckldq   mm2,            mm4             ; 32 22 12 02
-        punpckhdq   mm5,            mm4             ; 33 23 13 03
-
-        movq        [rdx],          mm0
-
-        movq        [rdx+rax],      mm1
-        movq        [rdx+rax*2],    mm2
-
-        add         rdx,            rax
-        movq        [rdx+rax*2],    mm5
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void dequant_dc_idct_mmx(short *input, short *dq, short *output, int pitch, int Dc)
-global sym(vp8_dequant_dc_idct_mmx)
-sym(vp8_dequant_dc_idct_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 5
-    GET_GOT     rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov         rax,    arg(0) ;input
-        mov         rdx,    arg(1) ;dq
-
-        movsxd      rcx,    dword ptr arg(4) ;Dc
-
-        movq        mm0,    [rax   ]
-        pmullw      mm0,    [rdx]
-
-        movq        mm1,    [rax +8]
-        pmullw      mm1,    [rdx +8]
-
-        movq        mm2,    [rax+16]
-        pmullw      mm2,    [rdx+16]
-
-        movq        mm3,    [rax+24]
-        pmullw      mm3,    [rdx+24]
-
-        mov         rdx,    arg(2) ;output
-        pxor        mm7,    mm7
-
-
-        movq        [rax],   mm7
-        movq        [rax+8], mm7
-
-        movq        [rax+16],mm7
-        movq        [rax+24],mm7
-
-        pinsrw      mm0,    rcx,  0
-        movsxd      rax,            dword ptr arg(3) ;pitch
-
-        psubw       mm0,            mm2             ; b1= 0-2
-        paddw       mm2,            mm2             ;
-
-        movq        mm5,            mm1
-        paddw       mm2,            mm0             ; a1 =0+2
-
-        pmulhw      mm5,            [x_s1sqr2 GLOBAL];
-        paddw       mm5,            mm1             ; ip1 * sin(pi/8) * sqrt(2)
-
-        movq        mm7,            mm3             ;
-        pmulhw      mm7,            [x_c1sqr2less1 GLOBAL];
-
-        paddw       mm7,            mm3             ; ip3 * cos(pi/8) * sqrt(2)
-        psubw       mm7,            mm5             ; c1
-
-        movq        mm5,            mm1
-        movq        mm4,            mm3
-
-        pmulhw      mm5,            [x_c1sqr2less1 GLOBAL]
-        paddw       mm5,            mm1
-
-        pmulhw      mm3,            [x_s1sqr2 GLOBAL]
-        paddw       mm3,            mm4
-
-        paddw       mm3,            mm5             ; d1
-        movq        mm6,            mm2             ; a1
-
-        movq        mm4,            mm0             ; b1
-        paddw       mm2,            mm3             ;0
-
-        paddw       mm4,            mm7             ;1
-        psubw       mm0,            mm7             ;2
-
-        psubw       mm6,            mm3             ;3
-
-        movq        mm1,            mm2             ; 03 02 01 00
-        movq        mm3,            mm4             ; 23 22 21 20
-
-        punpcklwd   mm1,            mm0             ; 11 01 10 00
-        punpckhwd   mm2,            mm0             ; 13 03 12 02
-
-        punpcklwd   mm3,            mm6             ; 31 21 30 20
-        punpckhwd   mm4,            mm6             ; 33 23 32 22
-
-        movq        mm0,            mm1             ; 11 01 10 00
-        movq        mm5,            mm2             ; 13 03 12 02
-
-        punpckldq   mm0,            mm3             ; 30 20 10 00
-        punpckhdq   mm1,            mm3             ; 31 21 11 01
-
-        punpckldq   mm2,            mm4             ; 32 22 12 02
-        punpckhdq   mm5,            mm4             ; 33 23 13 03
-
-        movq        mm3,            mm5             ; 33 23 13 03
-
-        psubw       mm0,            mm2             ; b1= 0-2
-        paddw       mm2,            mm2             ;
-
-        movq        mm5,            mm1
-        paddw       mm2,            mm0             ; a1 =0+2
-
-        pmulhw      mm5,            [x_s1sqr2 GLOBAL];
-        paddw       mm5,            mm1             ; ip1 * sin(pi/8) * sqrt(2)
-
-        movq        mm7,            mm3             ;
-        pmulhw      mm7,            [x_c1sqr2less1 GLOBAL];
-
-        paddw       mm7,            mm3             ; ip3 * cos(pi/8) * sqrt(2)
-        psubw       mm7,            mm5             ; c1
-
-        movq        mm5,            mm1
-        movq        mm4,            mm3
-
-        pmulhw      mm5,            [x_c1sqr2less1 GLOBAL]
-        paddw       mm5,            mm1
-
-        pmulhw      mm3,            [x_s1sqr2 GLOBAL]
-        paddw       mm3,            mm4
-
-        paddw       mm3,            mm5             ; d1
-        paddw       mm0,            [fours GLOBAL]
-
-        paddw       mm2,            [fours GLOBAL]
-        movq        mm6,            mm2             ; a1
-
-        movq        mm4,            mm0             ; b1
-        paddw       mm2,            mm3             ;0
-
-        paddw       mm4,            mm7             ;1
-        psubw       mm0,            mm7             ;2
-
-        psubw       mm6,            mm3             ;3
-        psraw       mm2,            3
-
-        psraw       mm0,            3
-        psraw       mm4,            3
-
-        psraw       mm6,            3
-
-        movq        mm1,            mm2             ; 03 02 01 00
-        movq        mm3,            mm4             ; 23 22 21 20
-
-        punpcklwd   mm1,            mm0             ; 11 01 10 00
-        punpckhwd   mm2,            mm0             ; 13 03 12 02
-
-        punpcklwd   mm3,            mm6             ; 31 21 30 20
-        punpckhwd   mm4,            mm6             ; 33 23 32 22
-
-        movq        mm0,            mm1             ; 11 01 10 00
-        movq        mm5,            mm2             ; 13 03 12 02
-
-        punpckldq   mm0,            mm3             ; 30 20 10 00
-        punpckhdq   mm1,            mm3             ; 31 21 11 01
-
-        punpckldq   mm2,            mm4             ; 32 22 12 02
-        punpckhdq   mm5,            mm4             ; 33 23 13 03
-
-        movq        [rdx],          mm0
-
-        movq        [rdx+rax],      mm1
-        movq        [rdx+rax*2],    mm2
-
-        add         rdx,            rax
-        movq        [rdx+rax*2],    mm5
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-SECTION_RODATA
-align 16
-x_s1sqr2:
-    times 4 dw 0x8A8C
-align 16
-x_c1sqr2less1:
-    times 4 dw 0x4E7B
-align 16
-fours:
-    times 4 dw 0x0004
diff --git a/vp8/encoder/x86/dct_mmx.S b/vp8/encoder/x86/dct_mmx.S
new file mode 100644
index 0000000..4266f0a
--- /dev/null
+++ b/vp8/encoder/x86/dct_mmx.S
@@ -0,0 +1,846 @@
+//
+//  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
+//
+//  Use of this source code is governed by a BSD-style license and patent
+//  grant that can be found in the LICENSE file in the root of the source
+//  tree. All contributing project authors may be found in the AUTHORS
+//  file in the root of the source tree.
+//
+
+
+#include "vpx_ports/x86_abi_support.S"
+
+.text
+    global sym(vp8_short_fdct4x4_mmx)
+    global sym(vp8_fast_fdct4x4_mmx)
+    global sym(vp8_fast_fdct8x4_wmt)
+
+
+#define         DCTCONSTANTSBITS         (16)
+#define         DCTROUNDINGVALUE         (1<< (DCTCONSTANTSBITS-1))
+#define         x_c1                      (60547)          // cos(pi  /8) * (1<<15)
+#define         x_c2                      (46341)          // cos(pi*2/8) * (1<<15)
+#define         x_c3                      (25080)          // cos(pi*3/8) * (1<<15)
+
+
+#define _1STSTAGESHIFT           14
+#define _2NDSTAGESHIFT           16
+
+// using matrix multiply with source and destbuffer has a pitch
+//void vp8_short_fdct4x4_mmx(short *input, short *output, int pitch)
+sym(vp8_short_fdct4x4_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 3
+    GET_GOT     rbx
+    push rsi
+    push rdi
+    // end prolog
+
+        mov         rsi,    arg(0) //input
+        mov         rdi,    arg(1) //output
+
+        movsxd      rax,    dword ptr arg(2) //pitch
+        lea         rdx,    [GLOBAL (dct_matrix)]
+
+        movq        mm0,    [rsi   ]
+        movq        mm1,    [rsi + rax]
+
+        movq        mm2,    [rsi + rax*2]
+        lea         rsi,    [rsi + rax*2]
+
+        movq        mm3,    [rsi + rax]
+
+        // first column
+        movq        mm4,    mm0
+        movq        mm7,    [rdx]
+
+        pmaddwd     mm4,    mm7
+        movq        mm5,    mm1
+
+        pmaddwd     mm5,    mm7
+        movq        mm6,    mm4
+
+        punpckldq   mm4,    mm5
+        punpckhdq   mm6,    mm5
+
+        paddd       mm4,    mm6
+        movq        mm5,    mm2
+
+
+        pmaddwd     mm5,    mm7
+        movq        mm6,    mm3
+
+        pmaddwd     mm6,    mm7
+        movq        mm7,    mm5
+
+        punpckldq   mm5,    mm6
+        punpckhdq   mm7,    mm6
+
+        paddd       mm5,    mm7
+        movq        mm6,    [GLOBAL (dct1st_stage_rounding_mmx)]
+
+        paddd       mm4,    mm6
+        paddd       mm5,    mm6
+
+        psrad       mm4,    _1STSTAGESHIFT
+        psrad       mm5,    _1STSTAGESHIFT
+
+        packssdw    mm4,    mm5
+        movq        [rdi],  mm4
+
+        //second column
+        movq        mm4,    mm0
+
+        pmaddwd     mm4,    [rdx+8]
+        movq        mm5,    mm1
+
+        pmaddwd     mm5,    [rdx+8]
+        movq        mm6,    mm4
+
+        punpckldq   mm4,    mm5
+        punpckhdq   mm6,    mm5
+
+        paddd       mm4,    mm6
+        movq        mm5,    mm2
+
+        pmaddwd     mm5,    [rdx+8]
+        movq        mm6,    mm3
+
+        pmaddwd     mm6,    [rdx+8]
+        movq        mm7,    mm5
+
+        punpckldq   mm5,    mm6
+        punpckhdq   mm7,    mm6
+
+        paddd       mm5,    mm7
+        movq        mm6,    [GLOBAL (dct1st_stage_rounding_mmx)]
+
+        paddd       mm4,    mm6
+        paddd       mm5,    mm6
+
+        psrad       mm4,    _1STSTAGESHIFT
+        psrad       mm5,    _1STSTAGESHIFT
+
+        packssdw    mm4,    mm5
+        movq        [rdi+8],  mm4
+
+
+        //third column
+        movq        mm4,    mm0
+
+        pmaddwd     mm4,    [rdx+16]
+        movq        mm5,    mm1
+
+        pmaddwd     mm5,    [rdx+16]
+        movq        mm6,    mm4
+
+        punpckldq   mm4,    mm5
+        punpckhdq   mm6,    mm5
+
+        paddd       mm4,    mm6
+        movq        mm5,    mm2
+
+        pmaddwd     mm5,    [rdx+16]
+        movq        mm6,    mm3
+
+        pmaddwd     mm6,    [rdx+16]
+        movq        mm7,    mm5
+
+        punpckldq   mm5,    mm6
+        punpckhdq   mm7,    mm6
+
+        paddd       mm5,    mm7
+        movq        mm6,    [GLOBAL (dct1st_stage_rounding_mmx)]
+
+        paddd       mm4,    mm6
+        paddd       mm5,    mm6
+
+        psrad       mm4,    _1STSTAGESHIFT
+        psrad       mm5,    _1STSTAGESHIFT
+
+        packssdw    mm4,    mm5
+        movq        [rdi+16],  mm4
+
+        //fourth column (this is the last column, so we do not have save the source any more)
+
+        pmaddwd     mm0,    [rdx+24]
+
+        pmaddwd     mm1,    [rdx+24]
+        movq        mm6,    mm0
+
+        punpckldq   mm0,    mm1
+        punpckhdq   mm6,    mm1
+
+        paddd       mm0,    mm6
+
+        pmaddwd     mm2,    [rdx+24]
+
+        pmaddwd     mm3,    [rdx+24]
+        movq        mm7,    mm2
+
+        punpckldq   mm2,    mm3
+        punpckhdq   mm7,    mm3
+
+        paddd       mm2,    mm7
+        movq        mm6,    [GLOBAL (dct1st_stage_rounding_mmx)]
+
+        paddd       mm0,    mm6
+        paddd       mm2,    mm6
+
+        psrad       mm0,    _1STSTAGESHIFT
+        psrad       mm2,    _1STSTAGESHIFT
+
+        packssdw    mm0,    mm2
+
+        movq        mm3,    mm0
+
+        // done with one pass
+        // now start second pass
+        movq        mm0,    [rdi   ]
+        movq        mm1,    [rdi+ 8]
+        movq        mm2,    [rdi+ 16]
+
+        movq        mm4,    mm0
+
+        pmaddwd     mm4,    [rdx]
+        movq        mm5,    mm1
+
+        pmaddwd     mm5,    [rdx]
+        movq        mm6,    mm4
+
+        punpckldq   mm4,    mm5
+        punpckhdq   mm6,    mm5
+
+        paddd       mm4,    mm6
+        movq        mm5,    mm2
+
+        pmaddwd     mm5,    [rdx]
+        movq        mm6,    mm3
+
+        pmaddwd     mm6,    [rdx]
+        movq        mm7,    mm5
+
+        punpckldq   mm5,    mm6
+        punpckhdq   mm7,    mm6
+
+        paddd       mm5,    mm7
+        movq        mm6,    [GLOBAL (dct2nd_stage_rounding_mmx)]
+
+        paddd       mm4,    mm6
+        paddd       mm5,    mm6
+
+        psrad       mm4,    _2NDSTAGESHIFT
+        psrad       mm5,    _2NDSTAGESHIFT
+
+        packssdw    mm4,    mm5
+        movq        [rdi],  mm4
+
+        //second column
+        movq        mm4,    mm0
+
+        pmaddwd     mm4,    [rdx+8]
+        movq        mm5,    mm1
+
+        pmaddwd     mm5,    [rdx+8]
+        movq        mm6,    mm4
+
+        punpckldq   mm4,    mm5
+        punpckhdq   mm6,    mm5
+
+        paddd       mm4,    mm6
+        movq        mm5,    mm2
+
+        pmaddwd     mm5,    [rdx+8]
+        movq        mm6,    mm3
+
+        pmaddwd     mm6,    [rdx+8]
+        movq        mm7,    mm5
+
+        punpckldq   mm5,    mm6
+        punpckhdq   mm7,    mm6
+
+        paddd       mm5,    mm7
+        movq        mm6,    [GLOBAL (dct2nd_stage_rounding_mmx)]
+
+        paddd       mm4,    mm6
+        paddd       mm5,    mm6
+
+        psrad       mm4,    _2NDSTAGESHIFT
+        psrad       mm5,    _2NDSTAGESHIFT
+
+        packssdw    mm4,    mm5
+        movq        [rdi+8],  mm4
+
+
+        //third column
+        movq        mm4,    mm0
+
+        pmaddwd     mm4,    [rdx+16]
+        movq        mm5,    mm1
+
+        pmaddwd     mm5,    [rdx+16]
+        movq        mm6,    mm4
+
+        punpckldq   mm4,    mm5
+        punpckhdq   mm6,    mm5
+
+        paddd       mm4,    mm6
+        movq        mm5,    mm2
+
+        pmaddwd     mm5,    [rdx+16]
+        movq        mm6,    mm3
+
+        pmaddwd     mm6,    [rdx+16]
+        movq        mm7,    mm5
+
+        punpckldq   mm5,    mm6
+        punpckhdq   mm7,    mm6
+
+        paddd       mm5,    mm7
+        movq        mm6,    [GLOBAL (dct2nd_stage_rounding_mmx)]
+
+        paddd       mm4,    mm6
+        paddd       mm5,    mm6
+
+        psrad       mm4,    _2NDSTAGESHIFT
+        psrad       mm5,    _2NDSTAGESHIFT
+
+        packssdw    mm4,    mm5
+        movq        [rdi+16],  mm4
+
+        //fourth column
+        movq        mm4,    mm0
+
+        pmaddwd     mm4,    [rdx+24]
+        movq        mm5,    mm1
+
+        pmaddwd     mm5,    [rdx+24]
+        movq        mm6,    mm4
+
+        punpckldq   mm4,    mm5
+        punpckhdq   mm6,    mm5
+
+        paddd       mm4,    mm6
+        movq        mm5,    mm2
+
+        pmaddwd     mm5,    [rdx+24]
+        movq        mm6,    mm3
+
+        pmaddwd     mm6,    [rdx+24]
+        movq        mm7,    mm5
+
+        punpckldq   mm5,    mm6
+        punpckhdq   mm7,    mm6
+
+        paddd       mm5,    mm7
+        movq        mm6,    [GLOBAL (dct2nd_stage_rounding_mmx)]
+
+        paddd       mm4,    mm6
+        paddd       mm5,    mm6
+
+        psrad       mm4,    _2NDSTAGESHIFT
+        psrad       mm5,    _2NDSTAGESHIFT
+
+        packssdw    mm4,    mm5
+        movq        [rdi+24],  mm4
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void vp8_fast_fdct4x4_mmx(short *input, short *output, int pitch)
+sym(vp8_fast_fdct4x4_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 3
+    GET_GOT     rbx
+    push rsi
+    push rdi
+    // end prolog
+        mov     rsi,    arg(0) //input
+        mov     rdi,    arg(1) //output
+
+        lea     rdx,    [GLOBAL (dct_const_mmx)]
+        movsxd  rax,    dword ptr arg(2) //pitch
+
+        lea     rcx,    [rsi + rax*2]
+        // read the input data
+        movq    mm0,    [rsi]
+        movq    mm1,    [rsi + rax    ]
+
+        movq    mm2,    [rcx]
+        movq    mm3,    [rcx + rax]
+        // get the constants
+        //shift to left by 1 for prescision
+        paddw   mm0,    mm0
+        paddw   mm1,    mm1
+
+        psllw   mm2,    1
+        psllw   mm3,    1
+
+        // transpose for the second stage
+        movq    mm4,    mm0         // 00 01 02 03
+        movq    mm5,    mm2         // 10 11 12 03
+
+        punpcklwd   mm0,    mm1     // 00 10 01 11
+        punpckhwd   mm4,    mm1     // 02 12 03 13
+
+        punpcklwd   mm2,    mm3     // 20 30 21 31
+        punpckhwd   mm5,    mm3     // 22 32 23 33
+
+
+        movq        mm1,    mm0     // 00 10 01 11
+        punpckldq   mm0,    mm2     // 00 10 20 30
+
+        punpckhdq   mm1,    mm2     // 01 11 21 31
+
+        movq        mm2,    mm4     // 02 12 03 13
+        punpckldq   mm2,    mm5     // 02 12 22 32
+
+        punpckhdq   mm4,    mm5     // 03 13 23 33
+        movq        mm3,    mm4
+
+
+        // first stage
+        movq    mm5,    mm0
+        movq    mm4,    mm1
+
+        paddw   mm0,    mm3         // a = 0 + 3
+        paddw   mm1,    mm2         // b = 1 + 2
+
+        psubw   mm4,    mm2         // c = 1 - 2
+        psubw   mm5,    mm3         // d = 0 - 3
+
+
+        // output 0 and 2
+        movq    mm6,    [rdx +  16] // c2
+        movq    mm2,    mm0         // a
+
+        paddw   mm0,    mm1         // a + b
+        psubw   mm2,    mm1         // a - b
+
+        movq    mm1,    mm0         // a + b
+        pmulhw  mm0,    mm6         // 00 01 02 03
+
+        paddw   mm0,    mm1         // output 00 01 02 03
+        pmulhw  mm6,    mm2         // 20 21 22 23
+
+        paddw   mm2,    mm6         // output 20 21 22 23
+
+        // output 1 and 3
+        movq    mm6,    [rdx +  8]  // c1
+        movq    mm7,    [rdx + 24]  // c3
+
+        movq    mm1,    mm4         // c
+        movq    mm3,    mm5         // d
+
+        pmulhw  mm1,    mm7         // c * c3
+        pmulhw  mm3,    mm6         // d * c1
+
+        paddw   mm3,    mm5         // d * c1 rounded
+        paddw   mm1,    mm3         // output 10 11 12 13
+
+        movq    mm3,    mm4         // c
+        pmulhw  mm5,    mm7         // d * c3
+
+        pmulhw  mm4,    mm6         // c * c1
+        paddw   mm3,    mm4         // round c* c1
+
+        psubw   mm5,    mm3         // output 30 31 32 33
+        movq    mm3,    mm5
+
+
+        // done with vertical
+        // transpose for the second stage
+        movq    mm4,    mm0         // 00 01 02 03
+        movq    mm5,    mm2         // 10 11 12 03
+
+        punpcklwd   mm0,    mm1     // 00 10 01 11
+        punpckhwd   mm4,    mm1     // 02 12 03 13
+
+        punpcklwd   mm2,    mm3     // 20 30 21 31
+        punpckhwd   mm5,    mm3     // 22 32 23 33
+
+
+        movq        mm1,    mm0     // 00 10 01 11
+        punpckldq   mm0,    mm2     // 00 10 20 30
+
+        punpckhdq   mm1,    mm2     // 01 11 21 31
+
+        movq        mm2,    mm4     // 02 12 03 13
+        punpckldq   mm2,    mm5     // 02 12 22 32
+
+        punpckhdq   mm4,    mm5     // 03 13 23 33
+        movq        mm3,    mm4
+
+
+        // first stage
+        movq    mm5,    mm0
+        movq    mm4,    mm1
+
+        paddw   mm0,    mm3         // a = 0 + 3
+        paddw   mm1,    mm2         // b = 1 + 2
+
+        psubw   mm4,    mm2         // c = 1 - 2
+        psubw   mm5,    mm3         // d = 0 - 3
+
+
+        // output 0 and 2
+        movq    mm6,    [rdx +  16] // c2
+        movq    mm2,    mm0         // a
+        paddw   mm0,    mm1         // a + b
+
+        psubw   mm2,    mm1         // a - b
+
+        movq    mm1,    mm0         // a + b
+        pmulhw  mm0,    mm6         // 00 01 02 03
+
+        paddw   mm0,    mm1         // output 00 01 02 03
+        pmulhw  mm6,    mm2         // 20 21 22 23
+
+        paddw   mm2,    mm6         // output 20 21 22 23
+
+
+        // output 1 and 3
+        movq    mm6,    [rdx +  8]  // c1
+        movq    mm7,    [rdx + 24]  // c3
+
+        movq    mm1,    mm4         // c
+        movq    mm3,    mm5         // d
+
+        pmulhw  mm1,    mm7         // c * c3
+        pmulhw  mm3,    mm6         // d * c1
+
+        paddw   mm3,    mm5         // d * c1 rounded
+        paddw   mm1,    mm3         // output 10 11 12 13
+
+        movq    mm3,    mm4         // c
+        pmulhw  mm5,    mm7         // d * c3
+
+        pmulhw  mm4,    mm6         // c * c1
+        paddw   mm3,    mm4         // round c* c1
+
+        psubw   mm5,    mm3         // output 30 31 32 33
+        movq    mm3,    mm5
+        // done with vertical
+
+		pcmpeqw	mm4,	mm4
+		pcmpeqw	mm5,	mm5
+		psrlw	mm4,	15
+		psrlw	mm5,	15
+
+        paddw   mm0,    mm4
+        paddw   mm1,    mm5
+        paddw   mm2,    mm4
+        paddw   mm3,    mm5
+
+        psraw   mm0, 1
+        psraw   mm1, 1
+        psraw   mm2, 1
+        psraw   mm3, 1
+
+        movq        [rdi   ],   mm0
+        movq        [rdi+ 8],   mm1
+        movq        [rdi+16],   mm2
+        movq        [rdi+24],   mm3
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void vp8_fast_fdct8x4_wmt(short *input, short *output, int pitch)
+sym(vp8_fast_fdct8x4_wmt):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 3
+    GET_GOT     rbx
+    push rsi
+    push rdi
+    // end prolog
+        mov         rsi,    arg(0) //input
+        mov         rdi,    arg(1) //output
+
+        lea         rdx,    [GLOBAL (dct_const_xmm)]
+        movsxd      rax,    dword ptr arg(2) //pitch
+
+        lea         rcx,    [rsi + rax*2]
+        // read the input data
+        movdqa      xmm0,       [rsi]
+        movdqa      xmm2,       [rsi + rax]
+
+        movdqa      xmm4,       [rcx]
+        movdqa      xmm3,       [rcx + rax]
+        // get the constants
+        //shift to left by 1 for prescision
+        psllw       xmm0,        1
+        psllw       xmm2,        1
+
+        psllw       xmm4,        1
+        psllw       xmm3,        1
+
+        // transpose for the second stage
+        movdqa      xmm1,       xmm0         // 00 01 02 03 04 05 06 07
+        movdqa      xmm5,       xmm4         // 20 21 22 23 24 25 26 27
+
+        punpcklwd   xmm0,       xmm2         // 00 10 01 11 02 12 03 13
+        punpckhwd   xmm1,       xmm2         // 04 14 05 15 06 16 07 17
+
+        punpcklwd   xmm4,       xmm3         // 20 30 21 31 22 32 23 33
+        punpckhwd   xmm5,       xmm3         // 24 34 25 35 26 36 27 37
+
+        movdqa      xmm2,       xmm0         // 00 10 01 11 02 12 03 13
+        punpckldq   xmm0,       xmm4         // 00 10 20 30 01 11 21 31
+
+        punpckhdq   xmm2,       xmm4         // 02 12 22 32 03 13 23 33
+
+
+        movdqa      xmm4,       xmm1         // 04 14 05 15 06 16 07 17
+        punpckldq   xmm4,       xmm5         // 04 14 24 34 05 15 25 35
+
+        punpckhdq   xmm1,       xmm5         // 06 16 26 36 07 17 27 37
+        movdqa      xmm3,       xmm2         // 02 12 22 32 03 13 23 33
+
+        punpckhqdq  xmm3,       xmm1         // 03 13 23 33 07 17 27 37
+        punpcklqdq  xmm2,       xmm1         // 02 12 22 32 06 16 26 36
+
+        movdqa      xmm1,       xmm0         // 00 10 20 30 01 11 21 31
+        punpcklqdq  xmm0,       xmm4         // 00 10 20 30 04 14 24 34
+
+        punpckhqdq  xmm1,       xmm4         // 01 11 21 32 05 15 25 35
+
+        // xmm0 0
+        // xmm1 1
+        // xmm2 2
+        // xmm3 3
+
+        // first stage
+        movdqa      xmm5,       xmm0
+        movdqa      xmm4,       xmm1
+
+        paddw       xmm0,       xmm3         // a = 0 + 3
+        paddw       xmm1,       xmm2         // b = 1 + 2
+
+        psubw       xmm4,       xmm2         // c = 1 - 2
+        psubw       xmm5,       xmm3         // d = 0 - 3
+
+
+        // output 0 and 2
+        movdqa      xmm6,       [rdx +  32] // c2
+        movdqa      xmm2,       xmm0         // a
+
+        paddw       xmm0,       xmm1         // a + b
+        psubw       xmm2,       xmm1         // a - b
+
+        movdqa      xmm1,       xmm0         // a + b
+        pmulhw      xmm0,       xmm6         // 00 01 02 03
+
+        paddw       xmm0,       xmm1         // output 00 01 02 03
+        pmulhw      xmm6,       xmm2         // 20 21 22 23
+
+        paddw       xmm2,       xmm6         // output 20 21 22 23
+
+        // output 1 and 3
+        movdqa      xmm6,       [rdx + 16]  // c1
+        movdqa      xmm7,       [rdx + 48]  // c3
+
+        movdqa      xmm1,       xmm4         // c
+        movdqa      xmm3,       xmm5         // d
+
+        pmulhw      xmm1,       xmm7         // c * c3
+        pmulhw      xmm3,       xmm6         // d * c1
+
+        paddw       xmm3,       xmm5         // d * c1 rounded
+        paddw       xmm1,       xmm3         // output 10 11 12 13
+
+        movdqa      xmm3,       xmm4         // c
+        pmulhw      xmm5,       xmm7         // d * c3
+
+        pmulhw      xmm4,       xmm6         // c * c1
+        paddw       xmm3,       xmm4         // round c* c1
+
+        psubw       xmm5,       xmm3         // output 30 31 32 33
+        movdqa      xmm3,       xmm5
+
+
+        // done with vertical
+        // transpose for the second stage
+        movdqa      xmm4,       xmm2         // 02 12 22 32 06 16 26 36
+        movdqa      xmm2,       xmm1         // 01 11 21 31 05 15 25 35
+
+        movdqa      xmm1,       xmm0         // 00 10 20 30 04 14 24 34
+        movdqa      xmm5,       xmm4         // 02 12 22 32 06 16 26 36
+
+        punpcklwd   xmm0,       xmm2         // 00 01 10 11 20 21 30 31
+        punpckhwd   xmm1,       xmm2         // 04 05 14 15 24 25 34 35
+
+        punpcklwd   xmm4,       xmm3         // 02 03 12 13 22 23 32 33
+        punpckhwd   xmm5,       xmm3         // 06 07 16 17 26 27 36 37
+
+        movdqa      xmm2,       xmm0         // 00 01 10 11 20 21 30 31
+        punpckldq   xmm0,       xmm4         // 00 01 02 03 10 11 12 13
+
+        punpckhdq   xmm2,       xmm4         // 20 21 22 23 30 31 32 33
+
+
+        movdqa      xmm4,       xmm1         // 04 05 14 15 24 25 34 35
+        punpckldq   xmm4,       xmm5         // 04 05 06 07 14 15 16 17
+
+        punpckhdq   xmm1,       xmm5         // 24 25 26 27 34 35 36 37
+        movdqa      xmm3,       xmm2         // 20 21 22 23 30 31 32 33
+
+        punpckhqdq  xmm3,       xmm1         // 30 31 32 33 34 35 36 37
+        punpcklqdq  xmm2,       xmm1         // 20 21 22 23 24 25 26 27
+
+        movdqa      xmm1,       xmm0         // 00 01 02 03 10 11 12 13
+        punpcklqdq  xmm0,       xmm4         // 00 01 02 03 04 05 06 07
+
+        punpckhqdq  xmm1,       xmm4         // 10 11 12 13 14 15 16 17
+
+        // first stage
+        movdqa      xmm5,       xmm0
+        movdqa      xmm4,       xmm1
+
+        paddw       xmm0,       xmm3         // a = 0 + 3
+        paddw       xmm1,       xmm2         // b = 1 + 2
+
+        psubw       xmm4,       xmm2         // c = 1 - 2
+        psubw       xmm5,       xmm3         // d = 0 - 3
+
+
+        // output 0 and 2
+        movdqa      xmm6,       [rdx +  32] // c2
+        movdqa      xmm2,       xmm0         // a
+
+        paddw       xmm0,       xmm1         // a + b
+        psubw       xmm2,       xmm1         // a - b
+
+        movdqa      xmm1,       xmm0         // a + b
+        pmulhw      xmm0,       xmm6         // 00 01 02 03
+
+        paddw       xmm0,       xmm1         // output 00 01 02 03
+        pmulhw      xmm6,       xmm2         // 20 21 22 23
+
+        paddw       xmm2,       xmm6         // output 20 21 22 23
+
+        // output 1 and 3
+        movdqa      xmm6,       [rdx + 16]  // c1
+        movdqa      xmm7,       [rdx + 48]  // c3
+
+        movdqa      xmm1,       xmm4         // c
+        movdqa      xmm3,       xmm5         // d
+
+        pmulhw      xmm1,       xmm7         // c * c3
+        pmulhw      xmm3,       xmm6         // d * c1
+
+        paddw       xmm3,       xmm5         // d * c1 rounded
+        paddw       xmm1,       xmm3         // output 10 11 12 13
+
+        movdqa      xmm3,       xmm4         // c
+        pmulhw      xmm5,       xmm7         // d * c3
+
+        pmulhw      xmm4,       xmm6         // c * c1
+        paddw       xmm3,       xmm4         // round c* c1
+
+        psubw       xmm5,       xmm3         // output 30 31 32 33
+        movdqa      xmm3,       xmm5
+        // done with vertical
+
+
+        pcmpeqw		xmm4,		xmm4
+        pcmpeqw		xmm5,		xmm5;
+        psrlw		xmm4,		15
+        psrlw		xmm5,		15
+
+        paddw       xmm0,       xmm4
+        paddw       xmm1,       xmm5
+        paddw       xmm2,       xmm4
+        paddw       xmm3,       xmm5
+
+        psraw       xmm0,       1
+        psraw       xmm1,       1
+        psraw       xmm2,       1
+        psraw       xmm3,       1
+
+        movq        QWORD PTR[rdi   ],   xmm0
+        movq        QWORD PTR[rdi+ 8],   xmm1
+        movq        QWORD PTR[rdi+16],   xmm2
+        movq        QWORD PTR[rdi+24],   xmm3
+
+        psrldq      xmm0,       8
+        psrldq      xmm1,       8
+        psrldq      xmm2,       8
+        psrldq      xmm3,       8
+
+        movq        QWORD PTR[rdi+32],   xmm0
+        movq        QWORD PTR[rdi+40],   xmm1
+        movq        QWORD PTR[rdi+48],   xmm2
+        movq        QWORD PTR[rdi+56],   xmm3
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+SECTION_RODATA
+//static const unsigned int dct1st_stage_rounding_mmx[2] =
+align 16
+dct1st_stage_rounding_mmx:
+    .fill 2, 4, 8192
+
+
+//static const unsigned int dct2nd_stage_rounding_mmx[2] =
+align 16
+dct2nd_stage_rounding_mmx:
+    .fill 2, 4, 32768
+
+
+//static const short dct_matrix[4][4]=
+align 16
+dct_matrix:
+    .fill 4, 2, 23170
+
+    .word  30274
+    .word  12540
+    .word -12540
+    .word -30274
+
+    .word 23170
+    .fill 2, 2, -23170
+    .word 23170
+
+    .word  12540
+    .word -30274
+    .word  30274
+    .word -12540
+
+
+//static const unsigned short dct_const_mmx[4 * 4]=
+align 16
+dct_const_mmx:
+    .fill 4, 2, 0
+    .fill 4, 2, 60547
+    .fill 4, 2, 46341
+    .fill 4, 2, 25080
+
+
+//static const unsigned short dct_const_xmm[8 * 4]=
+align 16
+dct_const_xmm:
+    .fill 8, 2, 0
+    .fill 8, 2, 60547
+    .fill 8, 2, 46341
+    .fill 8, 2, 25080
diff --git a/vp8/encoder/x86/dct_mmx.asm b/vp8/encoder/x86/dct_mmx.asm
deleted file mode 100644
index e134237..0000000
--- a/vp8/encoder/x86/dct_mmx.asm
+++ /dev/null
@@ -1,846 +0,0 @@
-;
-;  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
-;
-;  Use of this source code is governed by a BSD-style license and patent
-;  grant that can be found in the LICENSE file in the root of the source
-;  tree. All contributing project authors may be found in the AUTHORS
-;  file in the root of the source tree.
-;
-
-
-%include "vpx_ports/x86_abi_support.asm"
-
-section .text
-    global sym(vp8_short_fdct4x4_mmx)
-    global sym(vp8_fast_fdct4x4_mmx)
-    global sym(vp8_fast_fdct8x4_wmt)
-
-
-%define         DCTCONSTANTSBITS         (16)
-%define         DCTROUNDINGVALUE         (1<< (DCTCONSTANTSBITS-1))
-%define         x_c1                      (60547)          ; cos(pi  /8) * (1<<15)
-%define         x_c2                      (46341)          ; cos(pi*2/8) * (1<<15)
-%define         x_c3                      (25080)          ; cos(pi*3/8) * (1<<15)
-
-
-%define _1STSTAGESHIFT           14
-%define _2NDSTAGESHIFT           16
-
-; using matrix multiply with source and destbuffer has a pitch
-;void vp8_short_fdct4x4_mmx(short *input, short *output, int pitch)
-sym(vp8_short_fdct4x4_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 3
-    GET_GOT     rbx
-    push rsi
-    push rdi
-    ; end prolog
-
-        mov         rsi,    arg(0) ;input
-        mov         rdi,    arg(1) ;output
-
-        movsxd      rax,    dword ptr arg(2) ;pitch
-        lea         rdx,    [dct_matrix GLOBAL]
-
-        movq        mm0,    [rsi   ]
-        movq        mm1,    [rsi + rax]
-
-        movq        mm2,    [rsi + rax*2]
-        lea         rsi,    [rsi + rax*2]
-
-        movq        mm3,    [rsi + rax]
-
-        ; first column
-        movq        mm4,    mm0
-        movq        mm7,    [rdx]
-
-        pmaddwd     mm4,    mm7
-        movq        mm5,    mm1
-
-        pmaddwd     mm5,    mm7
-        movq        mm6,    mm4
-
-        punpckldq   mm4,    mm5
-        punpckhdq   mm6,    mm5
-
-        paddd       mm4,    mm6
-        movq        mm5,    mm2
-
-
-        pmaddwd     mm5,    mm7
-        movq        mm6,    mm3
-
-        pmaddwd     mm6,    mm7
-        movq        mm7,    mm5
-
-        punpckldq   mm5,    mm6
-        punpckhdq   mm7,    mm6
-
-        paddd       mm5,    mm7
-        movq        mm6,    [dct1st_stage_rounding_mmx GLOBAL]
-
-        paddd       mm4,    mm6
-        paddd       mm5,    mm6
-
-        psrad       mm4,    _1STSTAGESHIFT
-        psrad       mm5,    _1STSTAGESHIFT
-
-        packssdw    mm4,    mm5
-        movq        [rdi],  mm4
-
-        ;second column
-        movq        mm4,    mm0
-
-        pmaddwd     mm4,    [rdx+8]
-        movq        mm5,    mm1
-
-        pmaddwd     mm5,    [rdx+8]
-        movq        mm6,    mm4
-
-        punpckldq   mm4,    mm5
-        punpckhdq   mm6,    mm5
-
-        paddd       mm4,    mm6
-        movq        mm5,    mm2
-
-        pmaddwd     mm5,    [rdx+8]
-        movq        mm6,    mm3
-
-        pmaddwd     mm6,    [rdx+8]
-        movq        mm7,    mm5
-
-        punpckldq   mm5,    mm6
-        punpckhdq   mm7,    mm6
-
-        paddd       mm5,    mm7
-        movq        mm6,    [dct1st_stage_rounding_mmx GLOBAL]
-
-        paddd       mm4,    mm6
-        paddd       mm5,    mm6
-
-        psrad       mm4,    _1STSTAGESHIFT
-        psrad       mm5,    _1STSTAGESHIFT
-
-        packssdw    mm4,    mm5
-        movq        [rdi+8],  mm4
-
-
-        ;third column
-        movq        mm4,    mm0
-
-        pmaddwd     mm4,    [rdx+16]
-        movq        mm5,    mm1
-
-        pmaddwd     mm5,    [rdx+16]
-        movq        mm6,    mm4
-
-        punpckldq   mm4,    mm5
-        punpckhdq   mm6,    mm5
-
-        paddd       mm4,    mm6
-        movq        mm5,    mm2
-
-        pmaddwd     mm5,    [rdx+16]
-        movq        mm6,    mm3
-
-        pmaddwd     mm6,    [rdx+16]
-        movq        mm7,    mm5
-
-        punpckldq   mm5,    mm6
-        punpckhdq   mm7,    mm6
-
-        paddd       mm5,    mm7
-        movq        mm6,    [dct1st_stage_rounding_mmx GLOBAL]
-
-        paddd       mm4,    mm6
-        paddd       mm5,    mm6
-
-        psrad       mm4,    _1STSTAGESHIFT
-        psrad       mm5,    _1STSTAGESHIFT
-
-        packssdw    mm4,    mm5
-        movq        [rdi+16],  mm4
-
-        ;fourth column (this is the last column, so we do not have save the source any more)
-
-        pmaddwd     mm0,    [rdx+24]
-
-        pmaddwd     mm1,    [rdx+24]
-        movq        mm6,    mm0
-
-        punpckldq   mm0,    mm1
-        punpckhdq   mm6,    mm1
-
-        paddd       mm0,    mm6
-
-        pmaddwd     mm2,    [rdx+24]
-
-        pmaddwd     mm3,    [rdx+24]
-        movq        mm7,    mm2
-
-        punpckldq   mm2,    mm3
-        punpckhdq   mm7,    mm3
-
-        paddd       mm2,    mm7
-        movq        mm6,    [dct1st_stage_rounding_mmx GLOBAL]
-
-        paddd       mm0,    mm6
-        paddd       mm2,    mm6
-
-        psrad       mm0,    _1STSTAGESHIFT
-        psrad       mm2,    _1STSTAGESHIFT
-
-        packssdw    mm0,    mm2
-
-        movq        mm3,    mm0
-
-        ; done with one pass
-        ; now start second pass
-        movq        mm0,    [rdi   ]
-        movq        mm1,    [rdi+ 8]
-        movq        mm2,    [rdi+ 16]
-
-        movq        mm4,    mm0
-
-        pmaddwd     mm4,    [rdx]
-        movq        mm5,    mm1
-
-        pmaddwd     mm5,    [rdx]
-        movq        mm6,    mm4
-
-        punpckldq   mm4,    mm5
-        punpckhdq   mm6,    mm5
-
-        paddd       mm4,    mm6
-        movq        mm5,    mm2
-
-        pmaddwd     mm5,    [rdx]
-        movq        mm6,    mm3
-
-        pmaddwd     mm6,    [rdx]
-        movq        mm7,    mm5
-
-        punpckldq   mm5,    mm6
-        punpckhdq   mm7,    mm6
-
-        paddd       mm5,    mm7
-        movq        mm6,    [dct2nd_stage_rounding_mmx GLOBAL]
-
-        paddd       mm4,    mm6
-        paddd       mm5,    mm6
-
-        psrad       mm4,    _2NDSTAGESHIFT
-        psrad       mm5,    _2NDSTAGESHIFT
-
-        packssdw    mm4,    mm5
-        movq        [rdi],  mm4
-
-        ;second column
-        movq        mm4,    mm0
-
-        pmaddwd     mm4,    [rdx+8]
-        movq        mm5,    mm1
-
-        pmaddwd     mm5,    [rdx+8]
-        movq        mm6,    mm4
-
-        punpckldq   mm4,    mm5
-        punpckhdq   mm6,    mm5
-
-        paddd       mm4,    mm6
-        movq        mm5,    mm2
-
-        pmaddwd     mm5,    [rdx+8]
-        movq        mm6,    mm3
-
-        pmaddwd     mm6,    [rdx+8]
-        movq        mm7,    mm5
-
-        punpckldq   mm5,    mm6
-        punpckhdq   mm7,    mm6
-
-        paddd       mm5,    mm7
-        movq        mm6,    [dct2nd_stage_rounding_mmx GLOBAL]
-
-        paddd       mm4,    mm6
-        paddd       mm5,    mm6
-
-        psrad       mm4,    _2NDSTAGESHIFT
-        psrad       mm5,    _2NDSTAGESHIFT
-
-        packssdw    mm4,    mm5
-        movq        [rdi+8],  mm4
-
-
-        ;third column
-        movq        mm4,    mm0
-
-        pmaddwd     mm4,    [rdx+16]
-        movq        mm5,    mm1
-
-        pmaddwd     mm5,    [rdx+16]
-        movq        mm6,    mm4
-
-        punpckldq   mm4,    mm5
-        punpckhdq   mm6,    mm5
-
-        paddd       mm4,    mm6
-        movq        mm5,    mm2
-
-        pmaddwd     mm5,    [rdx+16]
-        movq        mm6,    mm3
-
-        pmaddwd     mm6,    [rdx+16]
-        movq        mm7,    mm5
-
-        punpckldq   mm5,    mm6
-        punpckhdq   mm7,    mm6
-
-        paddd       mm5,    mm7
-        movq        mm6,    [dct2nd_stage_rounding_mmx GLOBAL]
-
-        paddd       mm4,    mm6
-        paddd       mm5,    mm6
-
-        psrad       mm4,    _2NDSTAGESHIFT
-        psrad       mm5,    _2NDSTAGESHIFT
-
-        packssdw    mm4,    mm5
-        movq        [rdi+16],  mm4
-
-        ;fourth column
-        movq        mm4,    mm0
-
-        pmaddwd     mm4,    [rdx+24]
-        movq        mm5,    mm1
-
-        pmaddwd     mm5,    [rdx+24]
-        movq        mm6,    mm4
-
-        punpckldq   mm4,    mm5
-        punpckhdq   mm6,    mm5
-
-        paddd       mm4,    mm6
-        movq        mm5,    mm2
-
-        pmaddwd     mm5,    [rdx+24]
-        movq        mm6,    mm3
-
-        pmaddwd     mm6,    [rdx+24]
-        movq        mm7,    mm5
-
-        punpckldq   mm5,    mm6
-        punpckhdq   mm7,    mm6
-
-        paddd       mm5,    mm7
-        movq        mm6,    [dct2nd_stage_rounding_mmx GLOBAL]
-
-        paddd       mm4,    mm6
-        paddd       mm5,    mm6
-
-        psrad       mm4,    _2NDSTAGESHIFT
-        psrad       mm5,    _2NDSTAGESHIFT
-
-        packssdw    mm4,    mm5
-        movq        [rdi+24],  mm4
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void vp8_fast_fdct4x4_mmx(short *input, short *output, int pitch)
-sym(vp8_fast_fdct4x4_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 3
-    GET_GOT     rbx
-    push rsi
-    push rdi
-    ; end prolog
-        mov     rsi,    arg(0) ;input
-        mov     rdi,    arg(1) ;output
-
-        lea     rdx,    [dct_const_mmx GLOBAL]
-        movsxd  rax,    dword ptr arg(2) ;pitch
-
-        lea     rcx,    [rsi + rax*2]
-        ; read the input data
-        movq    mm0,    [rsi]
-        movq    mm1,    [rsi + rax    ]
-
-        movq    mm2,    [rcx]
-        movq    mm3,    [rcx + rax]
-        ; get the constants
-        ;shift to left by 1 for prescision
-        paddw   mm0,    mm0
-        paddw   mm1,    mm1
-
-        psllw   mm2,    1
-        psllw   mm3,    1
-
-        ; transpose for the second stage
-        movq    mm4,    mm0         ; 00 01 02 03
-        movq    mm5,    mm2         ; 10 11 12 03
-
-        punpcklwd   mm0,    mm1     ; 00 10 01 11
-        punpckhwd   mm4,    mm1     ; 02 12 03 13
-
-        punpcklwd   mm2,    mm3     ; 20 30 21 31
-        punpckhwd   mm5,    mm3     ; 22 32 23 33
-
-
-        movq        mm1,    mm0     ; 00 10 01 11
-        punpckldq   mm0,    mm2     ; 00 10 20 30
-
-        punpckhdq   mm1,    mm2     ; 01 11 21 31
-
-        movq        mm2,    mm4     ; 02 12 03 13
-        punpckldq   mm2,    mm5     ; 02 12 22 32
-
-        punpckhdq   mm4,    mm5     ; 03 13 23 33
-        movq        mm3,    mm4
-
-
-        ; first stage
-        movq    mm5,    mm0
-        movq    mm4,    mm1
-
-        paddw   mm0,    mm3         ; a = 0 + 3
-        paddw   mm1,    mm2         ; b = 1 + 2
-
-        psubw   mm4,    mm2         ; c = 1 - 2
-        psubw   mm5,    mm3         ; d = 0 - 3
-
-
-        ; output 0 and 2
-        movq    mm6,    [rdx +  16] ; c2
-        movq    mm2,    mm0         ; a
-
-        paddw   mm0,    mm1         ; a + b
-        psubw   mm2,    mm1         ; a - b
-
-        movq    mm1,    mm0         ; a + b
-        pmulhw  mm0,    mm6         ; 00 01 02 03
-
-        paddw   mm0,    mm1         ; output 00 01 02 03
-        pmulhw  mm6,    mm2         ; 20 21 22 23
-
-        paddw   mm2,    mm6         ; output 20 21 22 23
-
-        ; output 1 and 3
-        movq    mm6,    [rdx +  8]  ; c1
-        movq    mm7,    [rdx + 24]  ; c3
-
-        movq    mm1,    mm4         ; c
-        movq    mm3,    mm5         ; d
-
-        pmulhw  mm1,    mm7         ; c * c3
-        pmulhw  mm3,    mm6         ; d * c1
-
-        paddw   mm3,    mm5         ; d * c1 rounded
-        paddw   mm1,    mm3         ; output 10 11 12 13
-
-        movq    mm3,    mm4         ; c
-        pmulhw  mm5,    mm7         ; d * c3
-
-        pmulhw  mm4,    mm6         ; c * c1
-        paddw   mm3,    mm4         ; round c* c1
-
-        psubw   mm5,    mm3         ; output 30 31 32 33
-        movq    mm3,    mm5
-
-
-        ; done with vertical
-        ; transpose for the second stage
-        movq    mm4,    mm0         ; 00 01 02 03
-        movq    mm5,    mm2         ; 10 11 12 03
-
-        punpcklwd   mm0,    mm1     ; 00 10 01 11
-        punpckhwd   mm4,    mm1     ; 02 12 03 13
-
-        punpcklwd   mm2,    mm3     ; 20 30 21 31
-        punpckhwd   mm5,    mm3     ; 22 32 23 33
-
-
-        movq        mm1,    mm0     ; 00 10 01 11
-        punpckldq   mm0,    mm2     ; 00 10 20 30
-
-        punpckhdq   mm1,    mm2     ; 01 11 21 31
-
-        movq        mm2,    mm4     ; 02 12 03 13
-        punpckldq   mm2,    mm5     ; 02 12 22 32
-
-        punpckhdq   mm4,    mm5     ; 03 13 23 33
-        movq        mm3,    mm4
-
-
-        ; first stage
-        movq    mm5,    mm0
-        movq    mm4,    mm1
-
-        paddw   mm0,    mm3         ; a = 0 + 3
-        paddw   mm1,    mm2         ; b = 1 + 2
-
-        psubw   mm4,    mm2         ; c = 1 - 2
-        psubw   mm5,    mm3         ; d = 0 - 3
-
-
-        ; output 0 and 2
-        movq    mm6,    [rdx +  16] ; c2
-        movq    mm2,    mm0         ; a
-        paddw   mm0,    mm1         ; a + b
-
-        psubw   mm2,    mm1         ; a - b
-
-        movq    mm1,    mm0         ; a + b
-        pmulhw  mm0,    mm6         ; 00 01 02 03
-
-        paddw   mm0,    mm1         ; output 00 01 02 03
-        pmulhw  mm6,    mm2         ; 20 21 22 23
-
-        paddw   mm2,    mm6         ; output 20 21 22 23
-
-
-        ; output 1 and 3
-        movq    mm6,    [rdx +  8]  ; c1
-        movq    mm7,    [rdx + 24]  ; c3
-
-        movq    mm1,    mm4         ; c
-        movq    mm3,    mm5         ; d
-
-        pmulhw  mm1,    mm7         ; c * c3
-        pmulhw  mm3,    mm6         ; d * c1
-
-        paddw   mm3,    mm5         ; d * c1 rounded
-        paddw   mm1,    mm3         ; output 10 11 12 13
-
-        movq    mm3,    mm4         ; c
-        pmulhw  mm5,    mm7         ; d * c3
-
-        pmulhw  mm4,    mm6         ; c * c1
-        paddw   mm3,    mm4         ; round c* c1
-
-        psubw   mm5,    mm3         ; output 30 31 32 33
-        movq    mm3,    mm5
-        ; done with vertical
-
-		pcmpeqw	mm4,	mm4
-		pcmpeqw	mm5,	mm5
-		psrlw	mm4,	15
-		psrlw	mm5,	15
-
-        paddw   mm0,    mm4
-        paddw   mm1,    mm5
-        paddw   mm2,    mm4
-        paddw   mm3,    mm5
-
-        psraw   mm0, 1
-        psraw   mm1, 1
-        psraw   mm2, 1
-        psraw   mm3, 1
-
-        movq        [rdi   ],   mm0
-        movq        [rdi+ 8],   mm1
-        movq        [rdi+16],   mm2
-        movq        [rdi+24],   mm3
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void vp8_fast_fdct8x4_wmt(short *input, short *output, int pitch)
-sym(vp8_fast_fdct8x4_wmt):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 3
-    GET_GOT     rbx
-    push rsi
-    push rdi
-    ; end prolog
-        mov         rsi,    arg(0) ;input
-        mov         rdi,    arg(1) ;output
-
-        lea         rdx,    [dct_const_xmm GLOBAL]
-        movsxd      rax,    dword ptr arg(2) ;pitch
-
-        lea         rcx,    [rsi + rax*2]
-        ; read the input data
-        movdqa      xmm0,       [rsi]
-        movdqa      xmm2,       [rsi + rax]
-
-        movdqa      xmm4,       [rcx]
-        movdqa      xmm3,       [rcx + rax]
-        ; get the constants
-        ;shift to left by 1 for prescision
-        psllw       xmm0,        1
-        psllw       xmm2,        1
-
-        psllw       xmm4,        1
-        psllw       xmm3,        1
-
-        ; transpose for the second stage
-        movdqa      xmm1,       xmm0         ; 00 01 02 03 04 05 06 07
-        movdqa      xmm5,       xmm4         ; 20 21 22 23 24 25 26 27
-
-        punpcklwd   xmm0,       xmm2         ; 00 10 01 11 02 12 03 13
-        punpckhwd   xmm1,       xmm2         ; 04 14 05 15 06 16 07 17
-
-        punpcklwd   xmm4,       xmm3         ; 20 30 21 31 22 32 23 33
-        punpckhwd   xmm5,       xmm3         ; 24 34 25 35 26 36 27 37
-
-        movdqa      xmm2,       xmm0         ; 00 10 01 11 02 12 03 13
-        punpckldq   xmm0,       xmm4         ; 00 10 20 30 01 11 21 31
-
-        punpckhdq   xmm2,       xmm4         ; 02 12 22 32 03 13 23 33
-
-
-        movdqa      xmm4,       xmm1         ; 04 14 05 15 06 16 07 17
-        punpckldq   xmm4,       xmm5         ; 04 14 24 34 05 15 25 35
-
-        punpckhdq   xmm1,       xmm5         ; 06 16 26 36 07 17 27 37
-        movdqa      xmm3,       xmm2         ; 02 12 22 32 03 13 23 33
-
-        punpckhqdq  xmm3,       xmm1         ; 03 13 23 33 07 17 27 37
-        punpcklqdq  xmm2,       xmm1         ; 02 12 22 32 06 16 26 36
-
-        movdqa      xmm1,       xmm0         ; 00 10 20 30 01 11 21 31
-        punpcklqdq  xmm0,       xmm4         ; 00 10 20 30 04 14 24 34
-
-        punpckhqdq  xmm1,       xmm4         ; 01 11 21 32 05 15 25 35
-
-        ; xmm0 0
-        ; xmm1 1
-        ; xmm2 2
-        ; xmm3 3
-
-        ; first stage
-        movdqa      xmm5,       xmm0
-        movdqa      xmm4,       xmm1
-
-        paddw       xmm0,       xmm3         ; a = 0 + 3
-        paddw       xmm1,       xmm2         ; b = 1 + 2
-
-        psubw       xmm4,       xmm2         ; c = 1 - 2
-        psubw       xmm5,       xmm3         ; d = 0 - 3
-
-
-        ; output 0 and 2
-        movdqa      xmm6,       [rdx +  32] ; c2
-        movdqa      xmm2,       xmm0         ; a
-
-        paddw       xmm0,       xmm1         ; a + b
-        psubw       xmm2,       xmm1         ; a - b
-
-        movdqa      xmm1,       xmm0         ; a + b
-        pmulhw      xmm0,       xmm6         ; 00 01 02 03
-
-        paddw       xmm0,       xmm1         ; output 00 01 02 03
-        pmulhw      xmm6,       xmm2         ; 20 21 22 23
-
-        paddw       xmm2,       xmm6         ; output 20 21 22 23
-
-        ; output 1 and 3
-        movdqa      xmm6,       [rdx + 16]  ; c1
-        movdqa      xmm7,       [rdx + 48]  ; c3
-
-        movdqa      xmm1,       xmm4         ; c
-        movdqa      xmm3,       xmm5         ; d
-
-        pmulhw      xmm1,       xmm7         ; c * c3
-        pmulhw      xmm3,       xmm6         ; d * c1
-
-        paddw       xmm3,       xmm5         ; d * c1 rounded
-        paddw       xmm1,       xmm3         ; output 10 11 12 13
-
-        movdqa      xmm3,       xmm4         ; c
-        pmulhw      xmm5,       xmm7         ; d * c3
-
-        pmulhw      xmm4,       xmm6         ; c * c1
-        paddw       xmm3,       xmm4         ; round c* c1
-
-        psubw       xmm5,       xmm3         ; output 30 31 32 33
-        movdqa      xmm3,       xmm5
-
-
-        ; done with vertical
-        ; transpose for the second stage
-        movdqa      xmm4,       xmm2         ; 02 12 22 32 06 16 26 36
-        movdqa      xmm2,       xmm1         ; 01 11 21 31 05 15 25 35
-
-        movdqa      xmm1,       xmm0         ; 00 10 20 30 04 14 24 34
-        movdqa      xmm5,       xmm4         ; 02 12 22 32 06 16 26 36
-
-        punpcklwd   xmm0,       xmm2         ; 00 01 10 11 20 21 30 31
-        punpckhwd   xmm1,       xmm2         ; 04 05 14 15 24 25 34 35
-
-        punpcklwd   xmm4,       xmm3         ; 02 03 12 13 22 23 32 33
-        punpckhwd   xmm5,       xmm3         ; 06 07 16 17 26 27 36 37
-
-        movdqa      xmm2,       xmm0         ; 00 01 10 11 20 21 30 31
-        punpckldq   xmm0,       xmm4         ; 00 01 02 03 10 11 12 13
-
-        punpckhdq   xmm2,       xmm4         ; 20 21 22 23 30 31 32 33
-
-
-        movdqa      xmm4,       xmm1         ; 04 05 14 15 24 25 34 35
-        punpckldq   xmm4,       xmm5         ; 04 05 06 07 14 15 16 17
-
-        punpckhdq   xmm1,       xmm5         ; 24 25 26 27 34 35 36 37
-        movdqa      xmm3,       xmm2         ; 20 21 22 23 30 31 32 33
-
-        punpckhqdq  xmm3,       xmm1         ; 30 31 32 33 34 35 36 37
-        punpcklqdq  xmm2,       xmm1         ; 20 21 22 23 24 25 26 27
-
-        movdqa      xmm1,       xmm0         ; 00 01 02 03 10 11 12 13
-        punpcklqdq  xmm0,       xmm4         ; 00 01 02 03 04 05 06 07
-
-        punpckhqdq  xmm1,       xmm4         ; 10 11 12 13 14 15 16 17
-
-        ; first stage
-        movdqa      xmm5,       xmm0
-        movdqa      xmm4,       xmm1
-
-        paddw       xmm0,       xmm3         ; a = 0 + 3
-        paddw       xmm1,       xmm2         ; b = 1 + 2
-
-        psubw       xmm4,       xmm2         ; c = 1 - 2
-        psubw       xmm5,       xmm3         ; d = 0 - 3
-
-
-        ; output 0 and 2
-        movdqa      xmm6,       [rdx +  32] ; c2
-        movdqa      xmm2,       xmm0         ; a
-
-        paddw       xmm0,       xmm1         ; a + b
-        psubw       xmm2,       xmm1         ; a - b
-
-        movdqa      xmm1,       xmm0         ; a + b
-        pmulhw      xmm0,       xmm6         ; 00 01 02 03
-
-        paddw       xmm0,       xmm1         ; output 00 01 02 03
-        pmulhw      xmm6,       xmm2         ; 20 21 22 23
-
-        paddw       xmm2,       xmm6         ; output 20 21 22 23
-
-        ; output 1 and 3
-        movdqa      xmm6,       [rdx + 16]  ; c1
-        movdqa      xmm7,       [rdx + 48]  ; c3
-
-        movdqa      xmm1,       xmm4         ; c
-        movdqa      xmm3,       xmm5         ; d
-
-        pmulhw      xmm1,       xmm7         ; c * c3
-        pmulhw      xmm3,       xmm6         ; d * c1
-
-        paddw       xmm3,       xmm5         ; d * c1 rounded
-        paddw       xmm1,       xmm3         ; output 10 11 12 13
-
-        movdqa      xmm3,       xmm4         ; c
-        pmulhw      xmm5,       xmm7         ; d * c3
-
-        pmulhw      xmm4,       xmm6         ; c * c1
-        paddw       xmm3,       xmm4         ; round c* c1
-
-        psubw       xmm5,       xmm3         ; output 30 31 32 33
-        movdqa      xmm3,       xmm5
-        ; done with vertical
-
-
-        pcmpeqw		xmm4,		xmm4
-        pcmpeqw		xmm5,		xmm5;
-        psrlw		xmm4,		15
-        psrlw		xmm5,		15
-
-        paddw       xmm0,       xmm4
-        paddw       xmm1,       xmm5
-        paddw       xmm2,       xmm4
-        paddw       xmm3,       xmm5
-
-        psraw       xmm0,       1
-        psraw       xmm1,       1
-        psraw       xmm2,       1
-        psraw       xmm3,       1
-
-        movq        QWORD PTR[rdi   ],   xmm0
-        movq        QWORD PTR[rdi+ 8],   xmm1
-        movq        QWORD PTR[rdi+16],   xmm2
-        movq        QWORD PTR[rdi+24],   xmm3
-
-        psrldq      xmm0,       8
-        psrldq      xmm1,       8
-        psrldq      xmm2,       8
-        psrldq      xmm3,       8
-
-        movq        QWORD PTR[rdi+32],   xmm0
-        movq        QWORD PTR[rdi+40],   xmm1
-        movq        QWORD PTR[rdi+48],   xmm2
-        movq        QWORD PTR[rdi+56],   xmm3
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-SECTION_RODATA
-;static const unsigned int dct1st_stage_rounding_mmx[2] =
-align 16
-dct1st_stage_rounding_mmx:
-    times 2 dd 8192
-
-
-;static const unsigned int dct2nd_stage_rounding_mmx[2] =
-align 16
-dct2nd_stage_rounding_mmx:
-    times 2 dd 32768
-
-
-;static const short dct_matrix[4][4]=
-align 16
-dct_matrix:
-    times 4 dw 23170
-
-    dw  30274
-    dw  12540
-    dw -12540
-    dw -30274
-
-    dw 23170
-    times 2 dw -23170
-    dw 23170
-
-    dw  12540
-    dw -30274
-    dw  30274
-    dw -12540
-
-
-;static const unsigned short dct_const_mmx[4 * 4]=
-align 16
-dct_const_mmx:
-    times 4 dw 0
-    times 4 dw 60547
-    times 4 dw 46341
-    times 4 dw 25080
-
-
-;static const unsigned short dct_const_xmm[8 * 4]=
-align 16
-dct_const_xmm:
-    times 8 dw 0
-    times 8 dw 60547
-    times 8 dw 46341
-    times 8 dw 25080
diff --git a/vp8/encoder/x86/dct_sse2.S b/vp8/encoder/x86/dct_sse2.S
new file mode 100644
index 0000000..b8215d5
--- /dev/null
+++ b/vp8/encoder/x86/dct_sse2.S
@@ -0,0 +1,260 @@
+//
+//  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
+//
+//  Use of this source code is governed by a BSD-style license and patent
+//  grant that can be found in the LICENSE file in the root of the source
+//  tree. All contributing project authors may be found in the AUTHORS
+//  file in the root of the source tree.
+//
+
+
+#include "vpx_ports/x86_abi_support.S"
+
+global sym(vp8_short_fdct4x4_wmt)
+
+#define         DCTCONSTANTSBITS         (16)
+#define         DCTROUNDINGVALUE         (1<< (DCTCONSTANTSBITS-1))
+#define         x_c1                      (60547)          // cos(pi  /8) * (1<<15)
+#define         x_c2                      (46341)          // cos(pi*2/8) * (1<<15)
+#define         x_c3                      (25080)          // cos(pi*3/8) * (1<<15)
+
+#define _1STSTAGESHIFT           14
+#define _2NDSTAGESHIFT           16
+
+
+//; using matrix multiply
+//void vp8_short_fdct4x4_wmt(short *input, short *output)
+sym(vp8_short_fdct4x4_wmt):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 2
+    GET_GOT     rbx
+    // end prolog
+
+        mov         rax,        arg(0) //input
+        mov         rcx,        arg(1) //output
+
+        lea         rdx,        [GLOBAL (dct_matrix_sse2)]
+
+        movdqu      xmm0,       [rax   ]
+        movdqu      xmm1,       [rax+16]
+
+        // first column
+        movdqa      xmm2,       xmm0
+        movdqa      xmm7,       [rdx]
+
+        pmaddwd     xmm2,       xmm7
+        movdqa      xmm3,       xmm1
+
+        pmaddwd     xmm3,       xmm7
+        movdqa      xmm4,       xmm2
+
+        punpckldq   xmm2,       xmm3
+        punpckhdq   xmm4,       xmm3
+
+        movdqa      xmm3,       xmm2
+        punpckldq   xmm2,       xmm4
+
+        punpckhdq   xmm3,       xmm4
+        paddd       xmm2,       xmm3
+
+
+        paddd       xmm2,       XMMWORD PTR [GLOBAL (dct1st_stage_rounding_sse2)]
+        psrad       xmm2,       _1STSTAGESHIFT
+        //second column
+        movdqa      xmm3,       xmm0
+        pmaddwd     xmm3,       [rdx+16]
+
+        movdqa      xmm4,       xmm1
+        pmaddwd     xmm4,       [rdx+16]
+
+        movdqa      xmm5,       xmm3
+        punpckldq   xmm3,       xmm4
+
+        punpckhdq   xmm5,       xmm4
+        movdqa      xmm4,       xmm3
+
+        punpckldq   xmm3,       xmm5
+        punpckhdq   xmm4,       xmm5
+
+        paddd       xmm3,       xmm4
+        paddd       xmm3,       XMMWORD PTR [GLOBAL (dct1st_stage_rounding_sse2)]
+
+
+        psrad       xmm3,       _1STSTAGESHIFT
+        packssdw    xmm2,       xmm3
+
+        //third column
+        movdqa      xmm3,       xmm0
+        pmaddwd     xmm3,       [rdx+32]
+
+        movdqa      xmm4,       xmm1
+        pmaddwd     xmm4,       [rdx+32]
+
+        movdqa      xmm5,       xmm3
+        punpckldq   xmm3,       xmm4
+
+        punpckhdq   xmm5,       xmm4
+        movdqa      xmm4,       xmm3
+
+        punpckldq   xmm3,       xmm5
+        punpckhdq   xmm4,       xmm5
+
+        paddd       xmm3,       xmm4
+        paddd       xmm3,       XMMWORD PTR [GLOBAL (dct1st_stage_rounding_sse2)]
+
+        psrad       xmm3,       _1STSTAGESHIFT
+
+        //fourth column (this is the last column, so we do not have save the source any more)
+        pmaddwd     xmm0,       [rdx+48]
+        pmaddwd     xmm1,       [rdx+48]
+
+        movdqa      xmm4,       xmm0
+        punpckldq   xmm0,       xmm1
+
+        punpckhdq   xmm4,       xmm1
+        movdqa      xmm1,       xmm0
+
+        punpckldq   xmm0,       xmm4
+        punpckhdq   xmm1,       xmm4
+
+        paddd       xmm0,       xmm1
+        paddd       xmm0,       XMMWORD PTR [GLOBAL (dct1st_stage_rounding_sse2)]
+
+
+        psrad       xmm0,       _1STSTAGESHIFT
+        packssdw    xmm3,       xmm0
+        // done with one pass
+        // now start second pass
+        movdqa      xmm0,       xmm2
+        movdqa      xmm1,       xmm3
+
+        pmaddwd     xmm2,       xmm7
+        pmaddwd     xmm3,       xmm7
+
+        movdqa      xmm4,       xmm2
+        punpckldq   xmm2,       xmm3
+
+        punpckhdq   xmm4,       xmm3
+        movdqa      xmm3,       xmm2
+
+        punpckldq   xmm2,       xmm4
+        punpckhdq   xmm3,       xmm4
+
+        paddd       xmm2,       xmm3
+        paddd       xmm2,       XMMWORD PTR [GLOBAL (dct2nd_stage_rounding_sse2)]
+
+        psrad       xmm2,       _2NDSTAGESHIFT
+
+        //second column
+        movdqa      xmm3,       xmm0
+        pmaddwd     xmm3,       [rdx+16]
+
+        movdqa      xmm4,       xmm1
+        pmaddwd     xmm4,       [rdx+16]
+
+        movdqa      xmm5,       xmm3
+        punpckldq   xmm3,       xmm4
+
+        punpckhdq   xmm5,       xmm4
+        movdqa      xmm4,       xmm3
+
+        punpckldq   xmm3,       xmm5
+        punpckhdq   xmm4,       xmm5
+
+        paddd       xmm3,       xmm4
+        paddd       xmm3,       XMMWORD PTR [GLOBAL (dct2nd_stage_rounding_sse2)]
+
+        psrad       xmm3,       _2NDSTAGESHIFT
+        packssdw    xmm2,       xmm3
+
+        movdqu      [rcx],      xmm2
+        //third column
+        movdqa      xmm3,       xmm0
+        pmaddwd     xmm3,       [rdx+32]
+
+        movdqa      xmm4,       xmm1
+        pmaddwd     xmm4,       [rdx+32]
+
+        movdqa      xmm5,       xmm3
+        punpckldq   xmm3,       xmm4
+
+        punpckhdq   xmm5,       xmm4
+        movdqa      xmm4,       xmm3
+
+        punpckldq   xmm3,       xmm5
+        punpckhdq   xmm4,       xmm5
+
+        paddd       xmm3,       xmm4
+        paddd       xmm3,       XMMWORD PTR [GLOBAL (dct2nd_stage_rounding_sse2)]
+
+        psrad       xmm3,       _2NDSTAGESHIFT
+        //fourth column
+        pmaddwd     xmm0,       [rdx+48]
+        pmaddwd     xmm1,       [rdx+48]
+
+        movdqa      xmm4,       xmm0
+        punpckldq   xmm0,       xmm1
+
+        punpckhdq   xmm4,       xmm1
+        movdqa      xmm1,       xmm0
+
+        punpckldq   xmm0,       xmm4
+        punpckhdq   xmm1,       xmm4
+
+        paddd       xmm0,       xmm1
+        paddd       xmm0,       XMMWORD PTR [GLOBAL (dct2nd_stage_rounding_sse2)]
+
+        psrad       xmm0,       _2NDSTAGESHIFT
+        packssdw    xmm3,       xmm0
+
+        movdqu     [rcx+16],   xmm3
+
+    mov rsp, rbp
+    // begin epilog
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+SECTION_RODATA
+//static unsigned int dct1st_stage_rounding_sse2[4] =
+align 16
+dct1st_stage_rounding_sse2:
+    .fill 4, 4, 8192
+
+
+//static unsigned int dct2nd_stage_rounding_sse2[4] =
+align 16
+dct2nd_stage_rounding_sse2:
+    .fill 4, 4, 32768
+
+//static short dct_matrix_sse2[4][8]=
+align 16
+dct_matrix_sse2:
+    .fill 8, 2, 23170
+
+    .word  30274
+    .word  12540
+    .word -12540
+    .word -30274
+    .word  30274
+    .word  12540
+    .word -12540
+    .word -30274
+
+    .word  23170
+    .fill 2, 2, -23170
+    .fill 2, 2,  23170
+    .fill 2, 2, -23170
+    .word  23170
+
+    .word  12540
+    .word -30274
+    .word  30274
+    .word -12540
+    .word  12540
+    .word -30274
+    .word  30274
+    .word -12540
diff --git a/vp8/encoder/x86/dct_sse2.asm b/vp8/encoder/x86/dct_sse2.asm
deleted file mode 100644
index 3e5e9a7..0000000
--- a/vp8/encoder/x86/dct_sse2.asm
+++ /dev/null
@@ -1,260 +0,0 @@
-;
-;  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
-;
-;  Use of this source code is governed by a BSD-style license and patent
-;  grant that can be found in the LICENSE file in the root of the source
-;  tree. All contributing project authors may be found in the AUTHORS
-;  file in the root of the source tree.
-;
-
-
-%include "vpx_ports/x86_abi_support.asm"
-
-global sym(vp8_short_fdct4x4_wmt)
-
-%define         DCTCONSTANTSBITS         (16)
-%define         DCTROUNDINGVALUE         (1<< (DCTCONSTANTSBITS-1))
-%define         x_c1                      (60547)          ; cos(pi  /8) * (1<<15)
-%define         x_c2                      (46341)          ; cos(pi*2/8) * (1<<15)
-%define         x_c3                      (25080)          ; cos(pi*3/8) * (1<<15)
-
-%define _1STSTAGESHIFT           14
-%define _2NDSTAGESHIFT           16
-
-
-;; using matrix multiply
-;void vp8_short_fdct4x4_wmt(short *input, short *output)
-sym(vp8_short_fdct4x4_wmt):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 2
-    GET_GOT     rbx
-    ; end prolog
-
-        mov         rax,        arg(0) ;input
-        mov         rcx,        arg(1) ;output
-
-        lea         rdx,        [dct_matrix_sse2 GLOBAL]
-
-        movdqu      xmm0,       [rax   ]
-        movdqu      xmm1,       [rax+16]
-
-        ; first column
-        movdqa      xmm2,       xmm0
-        movdqa      xmm7,       [rdx]
-
-        pmaddwd     xmm2,       xmm7
-        movdqa      xmm3,       xmm1
-
-        pmaddwd     xmm3,       xmm7
-        movdqa      xmm4,       xmm2
-
-        punpckldq   xmm2,       xmm3
-        punpckhdq   xmm4,       xmm3
-
-        movdqa      xmm3,       xmm2
-        punpckldq   xmm2,       xmm4
-
-        punpckhdq   xmm3,       xmm4
-        paddd       xmm2,       xmm3
-
-
-        paddd       xmm2,       XMMWORD PTR [dct1st_stage_rounding_sse2 GLOBAL]
-        psrad       xmm2,       _1STSTAGESHIFT
-        ;second column
-        movdqa      xmm3,       xmm0
-        pmaddwd     xmm3,       [rdx+16]
-
-        movdqa      xmm4,       xmm1
-        pmaddwd     xmm4,       [rdx+16]
-
-        movdqa      xmm5,       xmm3
-        punpckldq   xmm3,       xmm4
-
-        punpckhdq   xmm5,       xmm4
-        movdqa      xmm4,       xmm3
-
-        punpckldq   xmm3,       xmm5
-        punpckhdq   xmm4,       xmm5
-
-        paddd       xmm3,       xmm4
-        paddd       xmm3,       XMMWORD PTR [dct1st_stage_rounding_sse2 GLOBAL]
-
-
-        psrad       xmm3,       _1STSTAGESHIFT
-        packssdw    xmm2,       xmm3
-
-        ;third column
-        movdqa      xmm3,       xmm0
-        pmaddwd     xmm3,       [rdx+32]
-
-        movdqa      xmm4,       xmm1
-        pmaddwd     xmm4,       [rdx+32]
-
-        movdqa      xmm5,       xmm3
-        punpckldq   xmm3,       xmm4
-
-        punpckhdq   xmm5,       xmm4
-        movdqa      xmm4,       xmm3
-
-        punpckldq   xmm3,       xmm5
-        punpckhdq   xmm4,       xmm5
-
-        paddd       xmm3,       xmm4
-        paddd       xmm3,       XMMWORD PTR [dct1st_stage_rounding_sse2 GLOBAL]
-
-        psrad       xmm3,       _1STSTAGESHIFT
-
-        ;fourth column (this is the last column, so we do not have save the source any more)
-        pmaddwd     xmm0,       [rdx+48]
-        pmaddwd     xmm1,       [rdx+48]
-
-        movdqa      xmm4,       xmm0
-        punpckldq   xmm0,       xmm1
-
-        punpckhdq   xmm4,       xmm1
-        movdqa      xmm1,       xmm0
-
-        punpckldq   xmm0,       xmm4
-        punpckhdq   xmm1,       xmm4
-
-        paddd       xmm0,       xmm1
-        paddd       xmm0,       XMMWORD PTR [dct1st_stage_rounding_sse2 GLOBAL]
-
-
-        psrad       xmm0,       _1STSTAGESHIFT
-        packssdw    xmm3,       xmm0
-        ; done with one pass
-        ; now start second pass
-        movdqa      xmm0,       xmm2
-        movdqa      xmm1,       xmm3
-
-        pmaddwd     xmm2,       xmm7
-        pmaddwd     xmm3,       xmm7
-
-        movdqa      xmm4,       xmm2
-        punpckldq   xmm2,       xmm3
-
-        punpckhdq   xmm4,       xmm3
-        movdqa      xmm3,       xmm2
-
-        punpckldq   xmm2,       xmm4
-        punpckhdq   xmm3,       xmm4
-
-        paddd       xmm2,       xmm3
-        paddd       xmm2,       XMMWORD PTR [dct2nd_stage_rounding_sse2 GLOBAL]
-
-        psrad       xmm2,       _2NDSTAGESHIFT
-
-        ;second column
-        movdqa      xmm3,       xmm0
-        pmaddwd     xmm3,       [rdx+16]
-
-        movdqa      xmm4,       xmm1
-        pmaddwd     xmm4,       [rdx+16]
-
-        movdqa      xmm5,       xmm3
-        punpckldq   xmm3,       xmm4
-
-        punpckhdq   xmm5,       xmm4
-        movdqa      xmm4,       xmm3
-
-        punpckldq   xmm3,       xmm5
-        punpckhdq   xmm4,       xmm5
-
-        paddd       xmm3,       xmm4
-        paddd       xmm3,       XMMWORD PTR [dct2nd_stage_rounding_sse2 GLOBAL]
-
-        psrad       xmm3,       _2NDSTAGESHIFT
-        packssdw    xmm2,       xmm3
-
-        movdqu      [rcx],      xmm2
-        ;third column
-        movdqa      xmm3,       xmm0
-        pmaddwd     xmm3,       [rdx+32]
-
-        movdqa      xmm4,       xmm1
-        pmaddwd     xmm4,       [rdx+32]
-
-        movdqa      xmm5,       xmm3
-        punpckldq   xmm3,       xmm4
-
-        punpckhdq   xmm5,       xmm4
-        movdqa      xmm4,       xmm3
-
-        punpckldq   xmm3,       xmm5
-        punpckhdq   xmm4,       xmm5
-
-        paddd       xmm3,       xmm4
-        paddd       xmm3,       XMMWORD PTR [dct2nd_stage_rounding_sse2 GLOBAL]
-
-        psrad       xmm3,       _2NDSTAGESHIFT
-        ;fourth column
-        pmaddwd     xmm0,       [rdx+48]
-        pmaddwd     xmm1,       [rdx+48]
-
-        movdqa      xmm4,       xmm0
-        punpckldq   xmm0,       xmm1
-
-        punpckhdq   xmm4,       xmm1
-        movdqa      xmm1,       xmm0
-
-        punpckldq   xmm0,       xmm4
-        punpckhdq   xmm1,       xmm4
-
-        paddd       xmm0,       xmm1
-        paddd       xmm0,       XMMWORD PTR [dct2nd_stage_rounding_sse2 GLOBAL]
-
-        psrad       xmm0,       _2NDSTAGESHIFT
-        packssdw    xmm3,       xmm0
-
-        movdqu     [rcx+16],   xmm3
-
-    mov rsp, rbp
-    ; begin epilog
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-SECTION_RODATA
-;static unsigned int dct1st_stage_rounding_sse2[4] =
-align 16
-dct1st_stage_rounding_sse2:
-    times 4 dd 8192
-
-
-;static unsigned int dct2nd_stage_rounding_sse2[4] =
-align 16
-dct2nd_stage_rounding_sse2:
-    times 4 dd 32768
-
-;static short dct_matrix_sse2[4][8]=
-align 16
-dct_matrix_sse2:
-    times 8 dw 23170
-
-    dw  30274
-    dw  12540
-    dw -12540
-    dw -30274
-    dw  30274
-    dw  12540
-    dw -12540
-    dw -30274
-
-    dw  23170
-    times 2 dw -23170
-    times 2 dw  23170
-    times 2 dw -23170
-    dw  23170
-
-    dw  12540
-    dw -30274
-    dw  30274
-    dw -12540
-    dw  12540
-    dw -30274
-    dw  30274
-    dw -12540
diff --git a/vp8/encoder/x86/encodeopt.S b/vp8/encoder/x86/encodeopt.S
new file mode 100644
index 0000000..347ed5a
--- /dev/null
+++ b/vp8/encoder/x86/encodeopt.S
@@ -0,0 +1,393 @@
+//
+//  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
+//
+//  Use of this source code is governed by a BSD-style license and patent
+//  grant that can be found in the LICENSE file in the root of the source
+//  tree. All contributing project authors may be found in the AUTHORS
+//  file in the root of the source tree.
+//
+
+
+#include "vpx_ports/x86_abi_support.S"
+
+
+//int vp8_block_error_xmm(short *coeff_ptr,  short *dcoef_ptr)
+global sym(vp8_block_error_xmm)
+sym(vp8_block_error_xmm):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 2
+    push rsi
+    push rdi
+    // end prolog
+
+
+        mov         rsi,        arg(0) //coeff_ptr
+        pxor        xmm7,       xmm7
+
+        mov         rdi,        arg(1) //dcoef_ptr
+        movdqa      xmm3,       [rsi]
+
+        movdqa      xmm4,       [rdi]
+        movdqa      xmm5,       [rsi+16]
+
+        movdqa      xmm6,       [rdi+16]
+        pxor        xmm1,       xmm1    // from movd xmm1, dc; dc=0
+
+        movdqa      xmm2,       xmm7
+        psubw       xmm5,       xmm6
+
+        por         xmm1,       xmm2
+        pmaddwd     xmm5,       xmm5
+
+        pcmpeqw     xmm1,       xmm7
+        psubw       xmm3,       xmm4
+
+        pand        xmm1,       xmm3
+        pmaddwd     xmm1,       xmm1
+
+        paddd       xmm1,       xmm5
+        movdqa      xmm0,       xmm1
+
+        punpckldq   xmm0,       xmm7
+        punpckhdq   xmm1,       xmm7
+
+        paddd       xmm0,       xmm1
+        movdqa      xmm1,       xmm0
+
+        psrldq      xmm0,       8
+        paddd       xmm0,       xmm1
+
+        movd        rax,        xmm0
+
+    pop rdi
+    pop rsi
+    // begin epilog
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//int vp8_block_error_mmx(short *coeff_ptr,  short *dcoef_ptr)
+global sym(vp8_block_error_mmx)
+sym(vp8_block_error_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 2
+    push rsi
+    push rdi
+    // end prolog
+
+
+        mov         rsi,        arg(0) //coeff_ptr
+        pxor        mm7,        mm7
+
+        mov         rdi,        arg(1) //dcoef_ptr
+        movq        mm3,        [rsi]
+
+        movq        mm4,        [rdi]
+        movq        mm5,        [rsi+8]
+
+        movq        mm6,        [rdi+8]
+        pxor        mm1,        mm1 // from movd mm1, dc ; dc =0
+
+        movq        mm2,        mm7
+        psubw       mm5,        mm6
+
+        por         mm1,        mm2
+        pmaddwd     mm5,        mm5
+
+        pcmpeqw     mm1,        mm7
+        psubw       mm3,        mm4
+
+        pand        mm1,        mm3
+        pmaddwd     mm1,        mm1
+
+        paddd       mm1,        mm5
+        movq        mm3,        [rsi+16]
+
+        movq        mm4,        [rdi+16]
+        movq        mm5,        [rsi+24]
+
+        movq        mm6,        [rdi+24]
+        psubw       mm5,        mm6
+
+        pmaddwd     mm5,        mm5
+        psubw       mm3,        mm4
+
+        pmaddwd     mm3,        mm3
+        paddd       mm3,        mm5
+
+        paddd       mm1,        mm3
+        movq        mm0,        mm1
+
+        psrlq       mm1,        32
+        paddd       mm0,        mm1
+
+        movd        rax,        mm0
+
+    pop rdi
+    pop rsi
+    // begin epilog
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//int vp8_mbblock_error_mmx_impl(short *coeff_ptr, short *dcoef_ptr, int dc);
+global sym(vp8_mbblock_error_mmx_impl)
+sym(vp8_mbblock_error_mmx_impl):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 3
+    push rsi
+    push rdi
+    // end prolog
+
+
+        mov         rsi,        arg(0) //coeff_ptr
+        pxor        mm7,        mm7
+
+        mov         rdi,        arg(1) //dcoef_ptr
+        pxor        mm2,        mm2
+
+        movd        mm1,        dword ptr arg(2) //dc
+        por         mm1,        mm2
+
+        pcmpeqw     mm1,        mm7
+        mov         rcx,        16
+
+mberror_loop_mmx:
+        movq        mm3,       [rsi]
+        movq        mm4,       [rdi]
+
+        movq        mm5,       [rsi+8]
+        movq        mm6,       [rdi+8]
+
+
+        psubw       mm5,        mm6
+        pmaddwd     mm5,        mm5
+
+        psubw       mm3,        mm4
+        pand        mm3,        mm1
+
+        pmaddwd     mm3,        mm3
+        paddd       mm2,        mm5
+
+        paddd       mm2,        mm3
+        movq        mm3,       [rsi+16]
+
+        movq        mm4,       [rdi+16]
+        movq        mm5,       [rsi+24]
+
+        movq        mm6,       [rdi+24]
+        psubw       mm5,        mm6
+
+        pmaddwd     mm5,        mm5
+        psubw       mm3,        mm4
+
+        pmaddwd     mm3,        mm3
+        paddd       mm2,        mm5
+
+        paddd       mm2,        mm3
+        add         rsi,        32
+
+        add         rdi,        32
+        sub         rcx,        1
+
+        jnz         mberror_loop_mmx
+
+        movq        mm0,        mm2
+        psrlq       mm2,        32
+
+        paddd       mm0,        mm2
+        movd        rax,        mm0
+
+    pop rdi
+    pop rsi
+    // begin epilog
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//int vp8_mbblock_error_xmm_impl(short *coeff_ptr, short *dcoef_ptr, int dc);
+global sym(vp8_mbblock_error_xmm_impl)
+sym(vp8_mbblock_error_xmm_impl):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 3
+    push rsi
+    push rdi
+    // end prolog
+
+
+        mov         rsi,        arg(0) //coeff_ptr
+        pxor        xmm7,       xmm7
+
+        mov         rdi,        arg(1) //dcoef_ptr
+        pxor        xmm2,       xmm2
+
+        movd        xmm1,       dword ptr arg(2) //dc
+        por         xmm1,       xmm2
+
+        pcmpeqw     xmm1,       xmm7
+        mov         rcx,        16
+
+mberror_loop:
+        movdqa      xmm3,       [rsi]
+        movdqa      xmm4,       [rdi]
+
+        movdqa      xmm5,       [rsi+16]
+        movdqa      xmm6,       [rdi+16]
+
+
+        psubw       xmm5,       xmm6
+        pmaddwd     xmm5,       xmm5
+
+        psubw       xmm3,       xmm4
+        pand        xmm3,       xmm1
+
+        pmaddwd     xmm3,       xmm3
+        add         rsi,        32
+
+        add         rdi,        32
+
+        sub         rcx,        1
+        paddd       xmm2,       xmm5
+
+        paddd       xmm2,       xmm3
+        jnz         mberror_loop
+
+        movdqa      xmm0,       xmm2
+        punpckldq   xmm0,       xmm7
+
+        punpckhdq   xmm2,       xmm7
+        paddd       xmm0,       xmm2
+
+        movdqa      xmm1,       xmm0
+        psrldq      xmm0,       8
+
+        paddd       xmm0,       xmm1
+        movd        rax,        xmm0
+
+    pop rdi
+    pop rsi
+    // begin epilog
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//int vp8_mbuverror_mmx_impl(short *s_ptr, short *d_ptr);
+global sym(vp8_mbuverror_mmx_impl)
+sym(vp8_mbuverror_mmx_impl):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 2
+    push rsi
+    push rdi
+    // end prolog
+
+
+        mov             rsi,        arg(0) //s_ptr
+        mov             rdi,        arg(1) //d_ptr
+
+        mov             rcx,        16
+        pxor            mm7,        mm7
+
+mbuverror_loop_mmx:
+
+        movq            mm1,        [rsi]
+        movq            mm2,        [rdi]
+
+        psubw           mm1,        mm2
+        pmaddwd         mm1,        mm1
+
+
+        movq            mm3,        [rsi+8]
+        movq            mm4,        [rdi+8]
+
+        psubw           mm3,        mm4
+        pmaddwd         mm3,        mm3
+
+
+        paddd           mm7,        mm1
+        paddd           mm7,        mm3
+
+
+        add             rsi,        16
+        add             rdi,        16
+
+        dec             rcx
+        jnz             mbuverror_loop_mmx
+
+        movq            mm0,        mm7
+        psrlq           mm7,        32
+
+        paddd           mm0,        mm7
+        movd            rax,        mm0
+
+    pop rdi
+    pop rsi
+    // begin epilog
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//int vp8_mbuverror_xmm_impl(short *s_ptr, short *d_ptr);
+global sym(vp8_mbuverror_xmm_impl)
+sym(vp8_mbuverror_xmm_impl):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 2
+    push rsi
+    push rdi
+    // end prolog
+
+
+        mov             rsi,        arg(0) //s_ptr
+        mov             rdi,        arg(1) //d_ptr
+
+        mov             rcx,        16
+        pxor            xmm7,       xmm7
+
+mbuverror_loop:
+
+        movdqa          xmm1,       [rsi]
+        movdqa          xmm2,       [rdi]
+
+        psubw           xmm1,       xmm2
+        pmaddwd         xmm1,       xmm1
+
+        paddd           xmm7,       xmm1
+
+        add             rsi,        16
+        add             rdi,        16
+
+        dec             rcx
+        jnz             mbuverror_loop
+
+        pxor        xmm0,           xmm0
+        movdqa      xmm1,           xmm7
+
+        movdqa      xmm2,           xmm1
+        punpckldq   xmm1,           xmm0
+
+        punpckhdq   xmm2,           xmm0
+        paddd       xmm1,           xmm2
+
+        movdqa      xmm2,           xmm1
+
+        psrldq      xmm1,           8
+        paddd       xmm1,           xmm2
+
+        movd            rax,            xmm1
+
+    pop rdi
+    pop rsi
+    // begin epilog
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
diff --git a/vp8/encoder/x86/encodeopt.asm b/vp8/encoder/x86/encodeopt.asm
deleted file mode 100644
index 1940471..0000000
--- a/vp8/encoder/x86/encodeopt.asm
+++ /dev/null
@@ -1,393 +0,0 @@
-;
-;  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
-;
-;  Use of this source code is governed by a BSD-style license and patent
-;  grant that can be found in the LICENSE file in the root of the source
-;  tree. All contributing project authors may be found in the AUTHORS
-;  file in the root of the source tree.
-;
-
-
-%include "vpx_ports/x86_abi_support.asm"
-
-
-;int vp8_block_error_xmm(short *coeff_ptr,  short *dcoef_ptr)
-global sym(vp8_block_error_xmm)
-sym(vp8_block_error_xmm):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 2
-    push rsi
-    push rdi
-    ; end prolog
-
-
-        mov         rsi,        arg(0) ;coeff_ptr
-        pxor        xmm7,       xmm7
-
-        mov         rdi,        arg(1) ;dcoef_ptr
-        movdqa      xmm3,       [rsi]
-
-        movdqa      xmm4,       [rdi]
-        movdqa      xmm5,       [rsi+16]
-
-        movdqa      xmm6,       [rdi+16]
-        pxor        xmm1,       xmm1    ; from movd xmm1, dc; dc=0
-
-        movdqa      xmm2,       xmm7
-        psubw       xmm5,       xmm6
-
-        por         xmm1,       xmm2
-        pmaddwd     xmm5,       xmm5
-
-        pcmpeqw     xmm1,       xmm7
-        psubw       xmm3,       xmm4
-
-        pand        xmm1,       xmm3
-        pmaddwd     xmm1,       xmm1
-
-        paddd       xmm1,       xmm5
-        movdqa      xmm0,       xmm1
-
-        punpckldq   xmm0,       xmm7
-        punpckhdq   xmm1,       xmm7
-
-        paddd       xmm0,       xmm1
-        movdqa      xmm1,       xmm0
-
-        psrldq      xmm0,       8
-        paddd       xmm0,       xmm1
-
-        movd        rax,        xmm0
-
-    pop rdi
-    pop rsi
-    ; begin epilog
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;int vp8_block_error_mmx(short *coeff_ptr,  short *dcoef_ptr)
-global sym(vp8_block_error_mmx)
-sym(vp8_block_error_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 2
-    push rsi
-    push rdi
-    ; end prolog
-
-
-        mov         rsi,        arg(0) ;coeff_ptr
-        pxor        mm7,        mm7
-
-        mov         rdi,        arg(1) ;dcoef_ptr
-        movq        mm3,        [rsi]
-
-        movq        mm4,        [rdi]
-        movq        mm5,        [rsi+8]
-
-        movq        mm6,        [rdi+8]
-        pxor        mm1,        mm1 ; from movd mm1, dc ; dc =0
-
-        movq        mm2,        mm7
-        psubw       mm5,        mm6
-
-        por         mm1,        mm2
-        pmaddwd     mm5,        mm5
-
-        pcmpeqw     mm1,        mm7
-        psubw       mm3,        mm4
-
-        pand        mm1,        mm3
-        pmaddwd     mm1,        mm1
-
-        paddd       mm1,        mm5
-        movq        mm3,        [rsi+16]
-
-        movq        mm4,        [rdi+16]
-        movq        mm5,        [rsi+24]
-
-        movq        mm6,        [rdi+24]
-        psubw       mm5,        mm6
-
-        pmaddwd     mm5,        mm5
-        psubw       mm3,        mm4
-
-        pmaddwd     mm3,        mm3
-        paddd       mm3,        mm5
-
-        paddd       mm1,        mm3
-        movq        mm0,        mm1
-
-        psrlq       mm1,        32
-        paddd       mm0,        mm1
-
-        movd        rax,        mm0
-
-    pop rdi
-    pop rsi
-    ; begin epilog
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;int vp8_mbblock_error_mmx_impl(short *coeff_ptr, short *dcoef_ptr, int dc);
-global sym(vp8_mbblock_error_mmx_impl)
-sym(vp8_mbblock_error_mmx_impl):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 3
-    push rsi
-    push rdi
-    ; end prolog
-
-
-        mov         rsi,        arg(0) ;coeff_ptr
-        pxor        mm7,        mm7
-
-        mov         rdi,        arg(1) ;dcoef_ptr
-        pxor        mm2,        mm2
-
-        movd        mm1,        dword ptr arg(2) ;dc
-        por         mm1,        mm2
-
-        pcmpeqw     mm1,        mm7
-        mov         rcx,        16
-
-mberror_loop_mmx:
-        movq        mm3,       [rsi]
-        movq        mm4,       [rdi]
-
-        movq        mm5,       [rsi+8]
-        movq        mm6,       [rdi+8]
-
-
-        psubw       mm5,        mm6
-        pmaddwd     mm5,        mm5
-
-        psubw       mm3,        mm4
-        pand        mm3,        mm1
-
-        pmaddwd     mm3,        mm3
-        paddd       mm2,        mm5
-
-        paddd       mm2,        mm3
-        movq        mm3,       [rsi+16]
-
-        movq        mm4,       [rdi+16]
-        movq        mm5,       [rsi+24]
-
-        movq        mm6,       [rdi+24]
-        psubw       mm5,        mm6
-
-        pmaddwd     mm5,        mm5
-        psubw       mm3,        mm4
-
-        pmaddwd     mm3,        mm3
-        paddd       mm2,        mm5
-
-        paddd       mm2,        mm3
-        add         rsi,        32
-
-        add         rdi,        32
-        sub         rcx,        1
-
-        jnz         mberror_loop_mmx
-
-        movq        mm0,        mm2
-        psrlq       mm2,        32
-
-        paddd       mm0,        mm2
-        movd        rax,        mm0
-
-    pop rdi
-    pop rsi
-    ; begin epilog
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;int vp8_mbblock_error_xmm_impl(short *coeff_ptr, short *dcoef_ptr, int dc);
-global sym(vp8_mbblock_error_xmm_impl)
-sym(vp8_mbblock_error_xmm_impl):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 3
-    push rsi
-    push rdi
-    ; end prolog
-
-
-        mov         rsi,        arg(0) ;coeff_ptr
-        pxor        xmm7,       xmm7
-
-        mov         rdi,        arg(1) ;dcoef_ptr
-        pxor        xmm2,       xmm2
-
-        movd        xmm1,       dword ptr arg(2) ;dc
-        por         xmm1,       xmm2
-
-        pcmpeqw     xmm1,       xmm7
-        mov         rcx,        16
-
-mberror_loop:
-        movdqa      xmm3,       [rsi]
-        movdqa      xmm4,       [rdi]
-
-        movdqa      xmm5,       [rsi+16]
-        movdqa      xmm6,       [rdi+16]
-
-
-        psubw       xmm5,       xmm6
-        pmaddwd     xmm5,       xmm5
-
-        psubw       xmm3,       xmm4
-        pand        xmm3,       xmm1
-
-        pmaddwd     xmm3,       xmm3
-        add         rsi,        32
-
-        add         rdi,        32
-
-        sub         rcx,        1
-        paddd       xmm2,       xmm5
-
-        paddd       xmm2,       xmm3
-        jnz         mberror_loop
-
-        movdqa      xmm0,       xmm2
-        punpckldq   xmm0,       xmm7
-
-        punpckhdq   xmm2,       xmm7
-        paddd       xmm0,       xmm2
-
-        movdqa      xmm1,       xmm0
-        psrldq      xmm0,       8
-
-        paddd       xmm0,       xmm1
-        movd        rax,        xmm0
-
-    pop rdi
-    pop rsi
-    ; begin epilog
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;int vp8_mbuverror_mmx_impl(short *s_ptr, short *d_ptr);
-global sym(vp8_mbuverror_mmx_impl)
-sym(vp8_mbuverror_mmx_impl):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 2
-    push rsi
-    push rdi
-    ; end prolog
-
-
-        mov             rsi,        arg(0) ;s_ptr
-        mov             rdi,        arg(1) ;d_ptr
-
-        mov             rcx,        16
-        pxor            mm7,        mm7
-
-mbuverror_loop_mmx:
-
-        movq            mm1,        [rsi]
-        movq            mm2,        [rdi]
-
-        psubw           mm1,        mm2
-        pmaddwd         mm1,        mm1
-
-
-        movq            mm3,        [rsi+8]
-        movq            mm4,        [rdi+8]
-
-        psubw           mm3,        mm4
-        pmaddwd         mm3,        mm3
-
-
-        paddd           mm7,        mm1
-        paddd           mm7,        mm3
-
-
-        add             rsi,        16
-        add             rdi,        16
-
-        dec             rcx
-        jnz             mbuverror_loop_mmx
-
-        movq            mm0,        mm7
-        psrlq           mm7,        32
-
-        paddd           mm0,        mm7
-        movd            rax,        mm0
-
-    pop rdi
-    pop rsi
-    ; begin epilog
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;int vp8_mbuverror_xmm_impl(short *s_ptr, short *d_ptr);
-global sym(vp8_mbuverror_xmm_impl)
-sym(vp8_mbuverror_xmm_impl):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 2
-    push rsi
-    push rdi
-    ; end prolog
-
-
-        mov             rsi,        arg(0) ;s_ptr
-        mov             rdi,        arg(1) ;d_ptr
-
-        mov             rcx,        16
-        pxor            xmm7,       xmm7
-
-mbuverror_loop:
-
-        movdqa          xmm1,       [rsi]
-        movdqa          xmm2,       [rdi]
-
-        psubw           xmm1,       xmm2
-        pmaddwd         xmm1,       xmm1
-
-        paddd           xmm7,       xmm1
-
-        add             rsi,        16
-        add             rdi,        16
-
-        dec             rcx
-        jnz             mbuverror_loop
-
-        pxor        xmm0,           xmm0
-        movdqa      xmm1,           xmm7
-
-        movdqa      xmm2,           xmm1
-        punpckldq   xmm1,           xmm0
-
-        punpckhdq   xmm2,           xmm0
-        paddd       xmm1,           xmm2
-
-        movdqa      xmm2,           xmm1
-
-        psrldq      xmm1,           8
-        paddd       xmm1,           xmm2
-
-        movd            rax,            xmm1
-
-    pop rdi
-    pop rsi
-    ; begin epilog
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
diff --git a/vp8/encoder/x86/fwalsh_sse2.S b/vp8/encoder/x86/fwalsh_sse2.S
new file mode 100644
index 0000000..2405d37
--- /dev/null
+++ b/vp8/encoder/x86/fwalsh_sse2.S
@@ -0,0 +1,117 @@
+//
+//  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
+//
+//  Use of this source code is governed by a BSD-style license and patent
+//  grant that can be found in the LICENSE file in the root of the source
+//  tree. All contributing project authors may be found in the AUTHORS
+//  file in the root of the source tree.
+//
+
+
+#include "vpx_ports/x86_abi_support.S"
+
+//void vp8_short_walsh4x4_sse2(short *input, short *output, int pitch)
+global sym(vp8_short_walsh4x4_sse2)
+sym(vp8_short_walsh4x4_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 3
+    push        rsi
+    push        rdi
+    // end prolog
+
+    mov     rsi, arg(0)
+    mov     rdi, arg(1)
+
+    movdqu    xmm4, [rsi + 0]       //ip[4] ip[0]
+    movdqu    xmm0, [rsi + 16]      //ip[12] ip[8]
+
+    pxor  xmm7, xmm7
+    //~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+    // 13 12 11 10 03 02 01 00
+    //
+    // 33 32 31 30 23 22 21 20
+    //
+    movdqa    xmm3, xmm4          // 13 12 11 10 03 02 01 00
+    punpcklwd xmm4, xmm0          // 23 03 22 02 21 01 20 00
+    punpckhwd xmm3, xmm0          // 33 13 32 12 31 11 30 10
+    movdqa    xmm1, xmm4          // 23 03 22 02 21 01 20 00
+    punpcklwd xmm4, xmm3          // 31 21 11 01 30 20 10 00
+    punpckhwd xmm1, xmm3          // 33 23 13 03 32 22 12 02
+    //~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+    pshufd    xmm2, xmm1, 0x4e       //ip[8] ip[12]
+    movdqa    xmm3, xmm4          //ip[4] ip[0]
+
+    paddw   xmm4, xmm2          //ip[4]+ip[8] ip[0]+ip[12] aka b1 a1
+    psubw   xmm3, xmm2          //ip[4]-ip[8] ip[0]-ip[12] aka c1 d1
+
+    movdqa    xmm5, xmm4
+    punpcklqdq  xmm4, xmm3          //d1 a1
+    punpckhqdq  xmm5, xmm3          //c1 b1
+
+    movdqa    xmm1, xmm5          //c1 b1
+    paddw   xmm5, xmm4          //dl+cl a1+b1 aka op[4] op[0]
+    psubw   xmm4, xmm1          //d1-c1 a1-b1 aka op[12] op[8]
+    //~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+    // 13 12 11 10 03 02 01 00
+    //
+    // 33 32 31 30 23 22 21 20
+    //
+    movdqa    xmm0, xmm5          // 13 12 11 10 03 02 01 00
+    punpcklwd xmm5, xmm4          // 23 03 22 02 21 01 20 00
+    punpckhwd xmm0, xmm4          // 33 13 32 12 31 11 30 10
+    movdqa    xmm1, xmm5          // 23 03 22 02 21 01 20 00
+    punpcklwd xmm5, xmm0          // 31 21 11 01 30 20 10 00
+    punpckhwd xmm1, xmm0          // 33 23 13 03 32 22 12 02
+    //~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+    pshufd    xmm2, xmm1, 0x4e       //ip[8] ip[12]
+    movdqa    xmm3, xmm5          //ip[4] ip[0]
+
+    paddw   xmm5, xmm2          //ip[4]+ip[8] ip[0]+ip[12] aka b1 a1
+    psubw   xmm3, xmm2          //ip[4]-ip[8] ip[0]-ip[12] aka c1 d1
+
+    movdqa    xmm6, xmm5
+    punpcklqdq  xmm5, xmm3          //d1 a1
+    punpckhqdq  xmm6, xmm3          //c1 b1
+
+    movdqa    xmm1, xmm6          //c1 b1
+    paddw   xmm6, xmm5          //dl+cl a1+b1 aka op[4] op[0]
+    psubw   xmm5, xmm1          //d1-c1 a1-b1 aka op[12] op[8]
+
+    movdqa    xmm0, xmm6          //aka b2 a2
+    movdqa    xmm1, xmm5          //aka d2 c2
+
+    pcmpgtw   xmm0, xmm7
+    pcmpgtw   xmm1, xmm7
+
+    psrlw   xmm0, 15
+    psrlw   xmm1, 15
+
+    paddw   xmm6, xmm0
+    paddw   xmm5, xmm1
+
+    psraw   xmm6, 1
+    psraw   xmm5, 1
+
+    //   a2 = a1 + b1;
+    //   b2 = c1 + d1;
+    //   c2 = a1 - b1;
+    //   d2 = d1 - c1;
+    //        a2 += (a2>0);
+    //        b2 += (b2>0);
+    //        c2 += (c2>0);
+    //        d2 += (d2>0);
+    //   op[0] = (a2)>>1;
+    //   op[4] = (b2)>>1;
+    //   op[8] = (c2)>>1;
+    //   op[12]= (d2)>>1;
+
+    movdqu  [rdi + 0], xmm6
+    movdqu  [rdi + 16], xmm5
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
diff --git a/vp8/encoder/x86/fwalsh_sse2.asm b/vp8/encoder/x86/fwalsh_sse2.asm
deleted file mode 100644
index 7d86201..0000000
--- a/vp8/encoder/x86/fwalsh_sse2.asm
+++ /dev/null
@@ -1,117 +0,0 @@
-;
-;  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
-;
-;  Use of this source code is governed by a BSD-style license and patent
-;  grant that can be found in the LICENSE file in the root of the source
-;  tree. All contributing project authors may be found in the AUTHORS
-;  file in the root of the source tree.
-;
-
-
-%include "vpx_ports/x86_abi_support.asm"
-
-;void vp8_short_walsh4x4_sse2(short *input, short *output, int pitch)
-global sym(vp8_short_walsh4x4_sse2)
-sym(vp8_short_walsh4x4_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 3
-    push        rsi
-    push        rdi
-    ; end prolog
-
-    mov     rsi, arg(0)
-    mov     rdi, arg(1)
-
-    movdqu    xmm4, [rsi + 0]       ;ip[4] ip[0]
-    movdqu    xmm0, [rsi + 16]      ;ip[12] ip[8]
-
-    pxor  xmm7, xmm7
-    ;~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-    ; 13 12 11 10 03 02 01 00
-    ;
-    ; 33 32 31 30 23 22 21 20
-    ;
-    movdqa    xmm3, xmm4          ; 13 12 11 10 03 02 01 00
-    punpcklwd xmm4, xmm0          ; 23 03 22 02 21 01 20 00
-    punpckhwd xmm3, xmm0          ; 33 13 32 12 31 11 30 10
-    movdqa    xmm1, xmm4          ; 23 03 22 02 21 01 20 00
-    punpcklwd xmm4, xmm3          ; 31 21 11 01 30 20 10 00
-    punpckhwd xmm1, xmm3          ; 33 23 13 03 32 22 12 02
-    ;~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-    pshufd    xmm2, xmm1, 4eh       ;ip[8] ip[12]
-    movdqa    xmm3, xmm4          ;ip[4] ip[0]
-
-    paddw   xmm4, xmm2          ;ip[4]+ip[8] ip[0]+ip[12] aka b1 a1
-    psubw   xmm3, xmm2          ;ip[4]-ip[8] ip[0]-ip[12] aka c1 d1
-
-    movdqa    xmm5, xmm4
-    punpcklqdq  xmm4, xmm3          ;d1 a1
-    punpckhqdq  xmm5, xmm3          ;c1 b1
-
-    movdqa    xmm1, xmm5          ;c1 b1
-    paddw   xmm5, xmm4          ;dl+cl a1+b1 aka op[4] op[0]
-    psubw   xmm4, xmm1          ;d1-c1 a1-b1 aka op[12] op[8]
-    ;~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-    ; 13 12 11 10 03 02 01 00
-    ;
-    ; 33 32 31 30 23 22 21 20
-    ;
-    movdqa    xmm0, xmm5          ; 13 12 11 10 03 02 01 00
-    punpcklwd xmm5, xmm4          ; 23 03 22 02 21 01 20 00
-    punpckhwd xmm0, xmm4          ; 33 13 32 12 31 11 30 10
-    movdqa    xmm1, xmm5          ; 23 03 22 02 21 01 20 00
-    punpcklwd xmm5, xmm0          ; 31 21 11 01 30 20 10 00
-    punpckhwd xmm1, xmm0          ; 33 23 13 03 32 22 12 02
-    ;~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-    pshufd    xmm2, xmm1, 4eh       ;ip[8] ip[12]
-    movdqa    xmm3, xmm5          ;ip[4] ip[0]
-
-    paddw   xmm5, xmm2          ;ip[4]+ip[8] ip[0]+ip[12] aka b1 a1
-    psubw   xmm3, xmm2          ;ip[4]-ip[8] ip[0]-ip[12] aka c1 d1
-
-    movdqa    xmm6, xmm5
-    punpcklqdq  xmm5, xmm3          ;d1 a1
-    punpckhqdq  xmm6, xmm3          ;c1 b1
-
-    movdqa    xmm1, xmm6          ;c1 b1
-    paddw   xmm6, xmm5          ;dl+cl a1+b1 aka op[4] op[0]
-    psubw   xmm5, xmm1          ;d1-c1 a1-b1 aka op[12] op[8]
-
-    movdqa    xmm0, xmm6          ;aka b2 a2
-    movdqa    xmm1, xmm5          ;aka d2 c2
-
-    pcmpgtw   xmm0, xmm7
-    pcmpgtw   xmm1, xmm7
-
-    psrlw   xmm0, 15
-    psrlw   xmm1, 15
-
-    paddw   xmm6, xmm0
-    paddw   xmm5, xmm1
-
-    psraw   xmm6, 1
-    psraw   xmm5, 1
-
-    ;   a2 = a1 + b1;
-    ;   b2 = c1 + d1;
-    ;   c2 = a1 - b1;
-    ;   d2 = d1 - c1;
-    ;        a2 += (a2>0);
-    ;        b2 += (b2>0);
-    ;        c2 += (c2>0);
-    ;        d2 += (d2>0);
-    ;   op[0] = (a2)>>1;
-    ;   op[4] = (b2)>>1;
-    ;   op[8] = (c2)>>1;
-    ;   op[12]= (d2)>>1;
-
-    movdqu  [rdi + 0], xmm6
-    movdqu  [rdi + 16], xmm5
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
diff --git a/vp8/encoder/x86/quantize_mmx.S b/vp8/encoder/x86/quantize_mmx.S
new file mode 100644
index 0000000..5c64da9
--- /dev/null
+++ b/vp8/encoder/x86/quantize_mmx.S
@@ -0,0 +1,438 @@
+//
+//  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
+//
+//  Use of this source code is governed by a BSD-style license and patent
+//  grant that can be found in the LICENSE file in the root of the source
+//  tree. All contributing project authors may be found in the AUTHORS
+//  file in the root of the source tree.
+//
+
+
+#include "vpx_ports/x86_abi_support.S"
+
+//int vp8_fast_quantize_b_impl_mmx(short *coeff_ptr, short *zbin_ptr,
+//                           short *qcoeff_ptr,short *dequant_ptr,
+//                           short *scan_mask, short *round_ptr,
+//                           short *quant_ptr, short *dqcoeff_ptr);
+global sym(vp8_fast_quantize_b_impl_mmx)
+sym(vp8_fast_quantize_b_impl_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 8
+    push rsi
+    push rdi
+    // end prolog
+
+
+        mov             rsi,        arg(0) //coeff_ptr
+        movq            mm0,        [rsi]
+
+        mov             rax,        arg(1) //zbin_ptr
+        movq            mm1,        [rax]
+
+        movq            mm3,        mm0
+        psraw           mm0,        15
+
+        pxor            mm3,        mm0
+        psubw           mm3,        mm0         // abs
+
+        movq            mm2,        mm3
+        pcmpgtw         mm1,        mm2
+
+        pandn           mm1,        mm2
+        movq            mm3,        mm1
+
+        mov             rdx,        arg(6) //quant_ptr
+        movq            mm1,        [rdx]
+
+        mov             rcx,        arg(5) //round_ptr
+        movq            mm2,        [rcx]
+
+        paddw           mm3,        mm2
+        pmulhuw         mm3,        mm1
+
+        pxor            mm3,        mm0
+        psubw           mm3,        mm0     //gain the sign back
+
+        mov             rdi,        arg(2) //qcoeff_ptr
+        movq            mm0,        mm3
+
+        movq            [rdi],      mm3
+
+        mov             rax,        arg(3) //dequant_ptr
+        movq            mm2,        [rax]
+
+        pmullw          mm3,        mm2
+        mov             rax,        arg(7) //dqcoeff_ptr
+
+        movq            [rax],      mm3
+
+        // next 8
+        movq            mm4,        [rsi+8]
+
+        mov             rax,        arg(1) //zbin_ptr
+        movq            mm5,        [rax+8]
+
+        movq            mm7,        mm4
+        psraw           mm4,        15
+
+        pxor            mm7,        mm4
+        psubw           mm7,        mm4         // abs
+
+        movq            mm6,        mm7
+        pcmpgtw         mm5,        mm6
+
+        pandn           mm5,        mm6
+        movq            mm7,        mm5
+
+        movq            mm5,        [rdx+8]
+        movq            mm6,        [rcx+8]
+
+        paddw           mm7,        mm6
+        pmulhuw         mm7,        mm5
+
+        pxor            mm7,        mm4
+        psubw           mm7,        mm4 // gain the sign back
+
+        mov             rdi,        arg(2) //qcoeff_ptr
+
+        movq            mm1,        mm7
+        movq            [rdi+8],    mm7
+
+        mov             rax,        arg(3) //dequant_ptr
+        movq            mm6,        [rax+8]
+
+        pmullw          mm7,        mm6
+        mov             rax,        arg(7) //dqcoeff_ptr
+
+        movq            [rax+8],    mm7
+
+
+                // next 8
+        movq            mm4,        [rsi+16]
+
+        mov             rax,        arg(1) //zbin_ptr
+        movq            mm5,        [rax+16]
+
+        movq            mm7,        mm4
+        psraw           mm4,        15
+
+        pxor            mm7,        mm4
+        psubw           mm7,        mm4         // abs
+
+        movq            mm6,        mm7
+        pcmpgtw         mm5,        mm6
+
+        pandn           mm5,        mm6
+        movq            mm7,        mm5
+
+        movq            mm5,        [rdx+16]
+        movq            mm6,        [rcx+16]
+
+        paddw           mm7,        mm6
+        pmulhuw         mm7,        mm5
+
+        pxor            mm7,        mm4
+        psubw           mm7,        mm4 // gain the sign back
+
+        mov             rdi,        arg(2) //qcoeff_ptr
+
+        movq            mm1,        mm7
+        movq            [rdi+16],   mm7
+
+        mov             rax,        arg(3) //dequant_ptr
+        movq            mm6,        [rax+16]
+
+        pmullw          mm7,        mm6
+        mov             rax,        arg(7) //dqcoeff_ptr
+
+        movq            [rax+16],   mm7
+
+
+                // next 8
+        movq            mm4,        [rsi+24]
+
+        mov             rax,        arg(1) //zbin_ptr
+        movq            mm5,        [rax+24]
+
+        movq            mm7,        mm4
+        psraw           mm4,        15
+
+        pxor            mm7,        mm4
+        psubw           mm7,        mm4         // abs
+
+        movq            mm6,        mm7
+        pcmpgtw         mm5,        mm6
+
+        pandn           mm5,        mm6
+        movq            mm7,        mm5
+
+        movq            mm5,        [rdx+24]
+        movq            mm6,        [rcx+24]
+
+        paddw           mm7,        mm6
+        pmulhuw         mm7,        mm5
+
+        pxor            mm7,        mm4
+        psubw           mm7,        mm4 // gain the sign back
+
+        mov             rdi,        arg(2) //qcoeff_ptr
+
+        movq            mm1,        mm7
+        movq            [rdi+24],   mm7
+
+        mov             rax,        arg(3) //dequant_ptr
+        movq            mm6,        [rax+24]
+
+        pmullw          mm7,        mm6
+        mov             rax,        arg(7) //dqcoeff_ptr
+
+        movq            [rax+24],   mm7
+
+
+
+        mov             rdi,        arg(4) //scan_mask
+        mov             rsi,        arg(2) //qcoeff_ptr
+
+        pxor            mm5,        mm5
+        pxor            mm7,        mm7
+
+        movq            mm0,        [rsi]
+        movq            mm1,        [rsi+8]
+
+        movq            mm2,        [rdi]
+        movq            mm3,        [rdi+8];
+
+        pcmpeqw         mm0,        mm7
+        pcmpeqw         mm1,        mm7
+
+        pcmpeqw         mm6,        mm6
+        pxor            mm0,        mm6
+
+        pxor            mm1,        mm6
+        psrlw           mm0,        15
+
+        psrlw           mm1,        15
+        pmaddwd         mm0,        mm2
+
+        pmaddwd         mm1,        mm3
+        movq            mm5,        mm0
+
+        paddd           mm5,        mm1
+
+        movq            mm0,        [rsi+16]
+        movq            mm1,        [rsi+24]
+
+        movq            mm2,        [rdi+16]
+        movq            mm3,        [rdi+24];
+
+        pcmpeqw         mm0,        mm7
+        pcmpeqw         mm1,        mm7
+
+        pcmpeqw         mm6,        mm6
+        pxor            mm0,        mm6
+
+        pxor            mm1,        mm6
+        psrlw           mm0,        15
+
+        psrlw           mm1,        15
+        pmaddwd         mm0,        mm2
+
+        pmaddwd         mm1,        mm3
+        paddd           mm5,        mm0
+
+        paddd           mm5,        mm1
+        movq            mm0,        mm5
+
+        psrlq           mm5,        32
+        paddd           mm0,        mm5
+
+        // eob adjustment begins here
+        movd            rcx,        mm0
+        and             rcx,        0xffff
+
+        xor             rdx,        rdx
+        sub             rdx,        rcx // rdx=-rcx
+
+        bsr             rax,        rcx
+        inc             rax
+
+        sar             rdx,        31
+        and             rax,        rdx
+        // Substitute the sse assembly for the old mmx mixed assembly/C. The
+        // following is kept as reference
+        //    movd            rcx,        mm0
+        //    bsr             rax,        rcx
+        //
+        //    mov             eob,        rax
+        //    mov             eee,        rcx
+        //
+        //if(eee==0)
+        //{
+        //    eob=-1;
+        //}
+        //else if(eee<0)
+        //{
+        //    eob=15;
+        //}
+        //d->eob = eob+1;
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//int vp8_fast_quantize_b_impl_sse(short *coeff_ptr, short *zbin_ptr,
+//                           short *qcoeff_ptr,short *dequant_ptr,
+//                           short *scan_mask, short *round_ptr,
+//                           short *quant_ptr, short *dqcoeff_ptr);
+global sym(vp8_fast_quantize_b_impl_sse)
+sym(vp8_fast_quantize_b_impl_sse):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 8
+    push rsi
+    push rdi
+    // end prolog
+
+
+        mov             rsi,        arg(0) //coeff_ptr
+        movdqa          xmm0,       [rsi]
+
+        mov             rax,        arg(1) //zbin_ptr
+        movdqa          xmm1,       [rax]
+
+        movdqa          xmm3,       xmm0
+        psraw           xmm0,       15
+
+        pxor            xmm3,       xmm0
+        psubw           xmm3,       xmm0            // abs
+
+        movdqa          xmm2,       xmm3
+        pcmpgtw         xmm1,       xmm2
+
+        pandn           xmm1,       xmm2
+        movdqa          xmm3,       xmm1
+
+        mov             rdx,        arg(6) // quant_ptr
+        movdqa          xmm1,       [rdx]
+
+        mov             rcx,        arg(5) // round_ptr
+        movdqa          xmm2,       [rcx]
+
+        paddw           xmm3,       xmm2
+        pmulhuw         xmm3,       xmm1
+
+        pxor            xmm3,       xmm0
+        psubw           xmm3,       xmm0        //gain the sign back
+
+        mov             rdi,        arg(2) //qcoeff_ptr
+        movdqa          xmm0,       xmm3
+
+        movdqa          [rdi],      xmm3
+
+        mov             rax,        arg(3) //dequant_ptr
+        movdqa          xmm2,       [rax]
+
+        pmullw          xmm3,       xmm2
+        mov             rax,        arg(7) //dqcoeff_ptr
+
+        movdqa          [rax],      xmm3
+
+        // next 8
+        movdqa          xmm4,       [rsi+16]
+
+        mov             rax,        arg(1) //zbin_ptr
+        movdqa          xmm5,       [rax+16]
+
+        movdqa          xmm7,       xmm4
+        psraw           xmm4,       15
+
+        pxor            xmm7,       xmm4
+        psubw           xmm7,       xmm4            // abs
+
+        movdqa          xmm6,       xmm7
+        pcmpgtw         xmm5,       xmm6
+
+        pandn           xmm5,       xmm6
+        movdqa          xmm7,       xmm5
+
+        movdqa          xmm5,       [rdx+16]
+        movdqa          xmm6,       [rcx+16]
+
+
+        paddw           xmm7,       xmm6
+        pmulhuw         xmm7,       xmm5
+
+        pxor            xmm7,       xmm4
+        psubw           xmm7,       xmm4 // gain the sign back
+
+        mov             rdi,        arg(2) //qcoeff_ptr
+
+        movdqa          xmm1,       xmm7
+        movdqa          [rdi+16],   xmm7
+
+        mov             rax,        arg(3) //dequant_ptr
+        movdqa          xmm6,       [rax+16]
+
+        pmullw          xmm7,       xmm6
+        mov             rax,        arg(7) //dqcoeff_ptr
+
+        movdqa          [rax+16],   xmm7
+        mov             rdi,        arg(4) //scan_mask
+
+        pxor            xmm7,       xmm7
+        movdqa          xmm2,       [rdi]
+
+        movdqa          xmm3,       [rdi+16];
+        pcmpeqw         xmm0,       xmm7
+
+        pcmpeqw         xmm1,       xmm7
+        pcmpeqw         xmm6,       xmm6
+
+        pxor            xmm0,       xmm6
+        pxor            xmm1,       xmm6
+
+        psrlw           xmm0,       15
+        psrlw           xmm1,       15
+
+        pmaddwd         xmm0,       xmm2
+        pmaddwd         xmm1,       xmm3
+
+        movq            xmm2,       xmm0
+        movq            xmm3,       xmm1
+
+        psrldq          xmm0,       8
+        psrldq          xmm1,       8
+
+        paddd           xmm0,       xmm1
+        paddd           xmm2,       xmm3
+
+        paddd           xmm0,       xmm2
+        movq            xmm1,       xmm0
+
+        psrldq          xmm0,       4
+        paddd           xmm1,       xmm0
+
+        movd            rcx,        xmm1
+        and             rcx,        0xffff
+
+        xor             rdx,        rdx
+        sub             rdx,        rcx
+
+        bsr             rax,        rcx
+        inc             rax
+
+        sar             rdx,        31
+        and             rax,        rdx
+
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
diff --git a/vp8/encoder/x86/quantize_mmx.asm b/vp8/encoder/x86/quantize_mmx.asm
deleted file mode 100644
index 847fc6e..0000000
--- a/vp8/encoder/x86/quantize_mmx.asm
+++ /dev/null
@@ -1,438 +0,0 @@
-;
-;  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
-;
-;  Use of this source code is governed by a BSD-style license and patent
-;  grant that can be found in the LICENSE file in the root of the source
-;  tree. All contributing project authors may be found in the AUTHORS
-;  file in the root of the source tree.
-;
-
-
-%include "vpx_ports/x86_abi_support.asm"
-
-;int vp8_fast_quantize_b_impl_mmx(short *coeff_ptr, short *zbin_ptr,
-;                           short *qcoeff_ptr,short *dequant_ptr,
-;                           short *scan_mask, short *round_ptr,
-;                           short *quant_ptr, short *dqcoeff_ptr);
-global sym(vp8_fast_quantize_b_impl_mmx)
-sym(vp8_fast_quantize_b_impl_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 8
-    push rsi
-    push rdi
-    ; end prolog
-
-
-        mov             rsi,        arg(0) ;coeff_ptr
-        movq            mm0,        [rsi]
-
-        mov             rax,        arg(1) ;zbin_ptr
-        movq            mm1,        [rax]
-
-        movq            mm3,        mm0
-        psraw           mm0,        15
-
-        pxor            mm3,        mm0
-        psubw           mm3,        mm0         ; abs
-
-        movq            mm2,        mm3
-        pcmpgtw         mm1,        mm2
-
-        pandn           mm1,        mm2
-        movq            mm3,        mm1
-
-        mov             rdx,        arg(6) ;quant_ptr
-        movq            mm1,        [rdx]
-
-        mov             rcx,        arg(5) ;round_ptr
-        movq            mm2,        [rcx]
-
-        paddw           mm3,        mm2
-        pmulhuw         mm3,        mm1
-
-        pxor            mm3,        mm0
-        psubw           mm3,        mm0     ;gain the sign back
-
-        mov             rdi,        arg(2) ;qcoeff_ptr
-        movq            mm0,        mm3
-
-        movq            [rdi],      mm3
-
-        mov             rax,        arg(3) ;dequant_ptr
-        movq            mm2,        [rax]
-
-        pmullw          mm3,        mm2
-        mov             rax,        arg(7) ;dqcoeff_ptr
-
-        movq            [rax],      mm3
-
-        ; next 8
-        movq            mm4,        [rsi+8]
-
-        mov             rax,        arg(1) ;zbin_ptr
-        movq            mm5,        [rax+8]
-
-        movq            mm7,        mm4
-        psraw           mm4,        15
-
-        pxor            mm7,        mm4
-        psubw           mm7,        mm4         ; abs
-
-        movq            mm6,        mm7
-        pcmpgtw         mm5,        mm6
-
-        pandn           mm5,        mm6
-        movq            mm7,        mm5
-
-        movq            mm5,        [rdx+8]
-        movq            mm6,        [rcx+8]
-
-        paddw           mm7,        mm6
-        pmulhuw         mm7,        mm5
-
-        pxor            mm7,        mm4
-        psubw           mm7,        mm4;gain the sign back
-
-        mov             rdi,        arg(2) ;qcoeff_ptr
-
-        movq            mm1,        mm7
-        movq            [rdi+8],    mm7
-
-        mov             rax,        arg(3) ;dequant_ptr
-        movq            mm6,        [rax+8]
-
-        pmullw          mm7,        mm6
-        mov             rax,        arg(7) ;dqcoeff_ptr
-
-        movq            [rax+8],    mm7
-
-
-                ; next 8
-        movq            mm4,        [rsi+16]
-
-        mov             rax,        arg(1) ;zbin_ptr
-        movq            mm5,        [rax+16]
-
-        movq            mm7,        mm4
-        psraw           mm4,        15
-
-        pxor            mm7,        mm4
-        psubw           mm7,        mm4         ; abs
-
-        movq            mm6,        mm7
-        pcmpgtw         mm5,        mm6
-
-        pandn           mm5,        mm6
-        movq            mm7,        mm5
-
-        movq            mm5,        [rdx+16]
-        movq            mm6,        [rcx+16]
-
-        paddw           mm7,        mm6
-        pmulhuw         mm7,        mm5
-
-        pxor            mm7,        mm4
-        psubw           mm7,        mm4;gain the sign back
-
-        mov             rdi,        arg(2) ;qcoeff_ptr
-
-        movq            mm1,        mm7
-        movq            [rdi+16],   mm7
-
-        mov             rax,        arg(3) ;dequant_ptr
-        movq            mm6,        [rax+16]
-
-        pmullw          mm7,        mm6
-        mov             rax,        arg(7) ;dqcoeff_ptr
-
-        movq            [rax+16],   mm7
-
-
-                ; next 8
-        movq            mm4,        [rsi+24]
-
-        mov             rax,        arg(1) ;zbin_ptr
-        movq            mm5,        [rax+24]
-
-        movq            mm7,        mm4
-        psraw           mm4,        15
-
-        pxor            mm7,        mm4
-        psubw           mm7,        mm4         ; abs
-
-        movq            mm6,        mm7
-        pcmpgtw         mm5,        mm6
-
-        pandn           mm5,        mm6
-        movq            mm7,        mm5
-
-        movq            mm5,        [rdx+24]
-        movq            mm6,        [rcx+24]
-
-        paddw           mm7,        mm6
-        pmulhuw         mm7,        mm5
-
-        pxor            mm7,        mm4
-        psubw           mm7,        mm4;gain the sign back
-
-        mov             rdi,        arg(2) ;qcoeff_ptr
-
-        movq            mm1,        mm7
-        movq            [rdi+24],   mm7
-
-        mov             rax,        arg(3) ;dequant_ptr
-        movq            mm6,        [rax+24]
-
-        pmullw          mm7,        mm6
-        mov             rax,        arg(7) ;dqcoeff_ptr
-
-        movq            [rax+24],   mm7
-
-
-
-        mov             rdi,        arg(4) ;scan_mask
-        mov             rsi,        arg(2) ;qcoeff_ptr
-
-        pxor            mm5,        mm5
-        pxor            mm7,        mm7
-
-        movq            mm0,        [rsi]
-        movq            mm1,        [rsi+8]
-
-        movq            mm2,        [rdi]
-        movq            mm3,        [rdi+8];
-
-        pcmpeqw         mm0,        mm7
-        pcmpeqw         mm1,        mm7
-
-        pcmpeqw         mm6,        mm6
-        pxor            mm0,        mm6
-
-        pxor            mm1,        mm6
-        psrlw           mm0,        15
-
-        psrlw           mm1,        15
-        pmaddwd         mm0,        mm2
-
-        pmaddwd         mm1,        mm3
-        movq            mm5,        mm0
-
-        paddd           mm5,        mm1
-
-        movq            mm0,        [rsi+16]
-        movq            mm1,        [rsi+24]
-
-        movq            mm2,        [rdi+16]
-        movq            mm3,        [rdi+24];
-
-        pcmpeqw         mm0,        mm7
-        pcmpeqw         mm1,        mm7
-
-        pcmpeqw         mm6,        mm6
-        pxor            mm0,        mm6
-
-        pxor            mm1,        mm6
-        psrlw           mm0,        15
-
-        psrlw           mm1,        15
-        pmaddwd         mm0,        mm2
-
-        pmaddwd         mm1,        mm3
-        paddd           mm5,        mm0
-
-        paddd           mm5,        mm1
-        movq            mm0,        mm5
-
-        psrlq           mm5,        32
-        paddd           mm0,        mm5
-
-        ; eob adjustment begins here
-        movd            rcx,        mm0
-        and             rcx,        0xffff
-
-        xor             rdx,        rdx
-        sub             rdx,        rcx ; rdx=-rcx
-
-        bsr             rax,        rcx
-        inc             rax
-
-        sar             rdx,        31
-        and             rax,        rdx
-        ; Substitute the sse assembly for the old mmx mixed assembly/C. The
-        ; following is kept as reference
-        ;    movd            rcx,        mm0
-        ;    bsr             rax,        rcx
-        ;
-        ;    mov             eob,        rax
-        ;    mov             eee,        rcx
-        ;
-        ;if(eee==0)
-        ;{
-        ;    eob=-1;
-        ;}
-        ;else if(eee<0)
-        ;{
-        ;    eob=15;
-        ;}
-        ;d->eob = eob+1;
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;int vp8_fast_quantize_b_impl_sse(short *coeff_ptr, short *zbin_ptr,
-;                           short *qcoeff_ptr,short *dequant_ptr,
-;                           short *scan_mask, short *round_ptr,
-;                           short *quant_ptr, short *dqcoeff_ptr);
-global sym(vp8_fast_quantize_b_impl_sse)
-sym(vp8_fast_quantize_b_impl_sse):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 8
-    push rsi
-    push rdi
-    ; end prolog
-
-
-        mov             rsi,        arg(0) ;coeff_ptr
-        movdqa          xmm0,       [rsi]
-
-        mov             rax,        arg(1) ;zbin_ptr
-        movdqa          xmm1,       [rax]
-
-        movdqa          xmm3,       xmm0
-        psraw           xmm0,       15
-
-        pxor            xmm3,       xmm0
-        psubw           xmm3,       xmm0            ; abs
-
-        movdqa          xmm2,       xmm3
-        pcmpgtw         xmm1,       xmm2
-
-        pandn           xmm1,       xmm2
-        movdqa          xmm3,       xmm1
-
-        mov             rdx,        arg(6) ; quant_ptr
-        movdqa          xmm1,       [rdx]
-
-        mov             rcx,        arg(5) ; round_ptr
-        movdqa          xmm2,       [rcx]
-
-        paddw           xmm3,       xmm2
-        pmulhuw         xmm3,       xmm1
-
-        pxor            xmm3,       xmm0
-        psubw           xmm3,       xmm0        ;gain the sign back
-
-        mov             rdi,        arg(2) ;qcoeff_ptr
-        movdqa          xmm0,       xmm3
-
-        movdqa          [rdi],      xmm3
-
-        mov             rax,        arg(3) ;dequant_ptr
-        movdqa          xmm2,       [rax]
-
-        pmullw          xmm3,       xmm2
-        mov             rax,        arg(7) ;dqcoeff_ptr
-
-        movdqa          [rax],      xmm3
-
-        ; next 8
-        movdqa          xmm4,       [rsi+16]
-
-        mov             rax,        arg(1) ;zbin_ptr
-        movdqa          xmm5,       [rax+16]
-
-        movdqa          xmm7,       xmm4
-        psraw           xmm4,       15
-
-        pxor            xmm7,       xmm4
-        psubw           xmm7,       xmm4            ; abs
-
-        movdqa          xmm6,       xmm7
-        pcmpgtw         xmm5,       xmm6
-
-        pandn           xmm5,       xmm6
-        movdqa          xmm7,       xmm5
-
-        movdqa          xmm5,       [rdx+16]
-        movdqa          xmm6,       [rcx+16]
-
-
-        paddw           xmm7,       xmm6
-        pmulhuw         xmm7,       xmm5
-
-        pxor            xmm7,       xmm4
-        psubw           xmm7,       xmm4;gain the sign back
-
-        mov             rdi,        arg(2) ;qcoeff_ptr
-
-        movdqa          xmm1,       xmm7
-        movdqa          [rdi+16],   xmm7
-
-        mov             rax,        arg(3) ;dequant_ptr
-        movdqa          xmm6,       [rax+16]
-
-        pmullw          xmm7,       xmm6
-        mov             rax,        arg(7) ;dqcoeff_ptr
-
-        movdqa          [rax+16],   xmm7
-        mov             rdi,        arg(4) ;scan_mask
-
-        pxor            xmm7,       xmm7
-        movdqa          xmm2,       [rdi]
-
-        movdqa          xmm3,       [rdi+16];
-        pcmpeqw         xmm0,       xmm7
-
-        pcmpeqw         xmm1,       xmm7
-        pcmpeqw         xmm6,       xmm6
-
-        pxor            xmm0,       xmm6
-        pxor            xmm1,       xmm6
-
-        psrlw           xmm0,       15
-        psrlw           xmm1,       15
-
-        pmaddwd         xmm0,       xmm2
-        pmaddwd         xmm1,       xmm3
-
-        movq            xmm2,       xmm0
-        movq            xmm3,       xmm1
-
-        psrldq          xmm0,       8
-        psrldq          xmm1,       8
-
-        paddd           xmm0,       xmm1
-        paddd           xmm2,       xmm3
-
-        paddd           xmm0,       xmm2
-        movq            xmm1,       xmm0
-
-        psrldq          xmm0,       4
-        paddd           xmm1,       xmm0
-
-        movd            rcx,        xmm1
-        and             rcx,        0xffff
-
-        xor             rdx,        rdx
-        sub             rdx,        rcx
-
-        bsr             rax,        rcx
-        inc             rax
-
-        sar             rdx,        31
-        and             rax,        rdx
-
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
diff --git a/vp8/encoder/x86/sad_mmx.S b/vp8/encoder/x86/sad_mmx.S
new file mode 100644
index 0000000..4fc3b8a
--- /dev/null
+++ b/vp8/encoder/x86/sad_mmx.S
@@ -0,0 +1,426 @@
+//
+//  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
+//
+//  Use of this source code is governed by a BSD-style license and patent
+//  grant that can be found in the LICENSE file in the root of the source
+//  tree. All contributing project authors may be found in the AUTHORS
+//  file in the root of the source tree.
+//
+
+
+#include "vpx_ports/x86_abi_support.S"
+
+global sym(vp8_sad16x16_mmx)
+global sym(vp8_sad8x16_mmx)
+global sym(vp8_sad8x8_mmx)
+global sym(vp8_sad4x4_mmx)
+global sym(vp8_sad16x8_mmx)
+
+//unsigned int vp8_sad16x16_mmx(
+//    unsigned char *src_ptr,
+//    int  src_stride,
+//    unsigned char *ref_ptr,
+//    int  ref_stride)
+sym(vp8_sad16x16_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 4
+    push rsi
+    push rdi
+    // end prolog
+
+        mov             rsi,        arg(0) //src_ptr
+        mov             rdi,        arg(2) //ref_ptr
+
+        movsxd          rax,        dword ptr arg(1) //src_stride
+        movsxd          rdx,        dword ptr arg(3) //ref_stride
+
+        lea             rcx,        [rsi+rax*8]
+
+        lea             rcx,        [rcx+rax*8]
+        pxor            mm7,        mm7
+
+        pxor            mm6,        mm6
+
+x16x16sad_mmx_loop:
+
+        movq            mm0,        QWORD PTR [rsi]
+        movq            mm2,        QWORD PTR [rsi+8]
+
+        movq            mm1,        QWORD PTR [rdi]
+        movq            mm3,        QWORD PTR [rdi+8]
+
+        movq            mm4,        mm0
+        movq            mm5,        mm2
+
+        psubusb         mm0,        mm1
+        psubusb         mm1,        mm4
+
+        psubusb         mm2,        mm3
+        psubusb         mm3,        mm5
+
+        por             mm0,        mm1
+        por             mm2,        mm3
+
+        movq            mm1,        mm0
+        movq            mm3,        mm2
+
+        punpcklbw       mm0,        mm6
+        punpcklbw       mm2,        mm6
+
+        punpckhbw       mm1,        mm6
+        punpckhbw       mm3,        mm6
+
+        paddw           mm0,        mm2
+        paddw           mm1,        mm3
+
+
+        lea             rsi,        [rsi+rax]
+        add             rdi,        rdx
+
+        paddw           mm7,        mm0
+        paddw           mm7,        mm1
+
+        cmp             rsi,        rcx
+        jne             x16x16sad_mmx_loop
+
+
+        movq            mm0,        mm7
+
+        punpcklwd       mm0,        mm6
+        punpckhwd       mm7,        mm6
+
+        paddw           mm0,        mm7
+        movq            mm7,        mm0
+
+
+        psrlq           mm0,        32
+        paddw           mm7,        mm0
+
+        movd            rax,        mm7
+
+    pop rdi
+    pop rsi
+    mov rsp, rbp
+    // begin epilog
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//unsigned int vp8_sad8x16_mmx(
+//    unsigned char *src_ptr,
+//    int  src_stride,
+//    unsigned char *ref_ptr,
+//    int  ref_stride)
+sym(vp8_sad8x16_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 4
+    push rsi
+    push rdi
+    // end prolog
+
+        mov             rsi,        arg(0) //src_ptr
+        mov             rdi,        arg(2) //ref_ptr
+
+        movsxd          rax,        dword ptr arg(1) //src_stride
+        movsxd          rdx,        dword ptr arg(3) //ref_stride
+
+        lea             rcx,        [rsi+rax*8]
+
+        lea             rcx,        [rcx+rax*8]
+        pxor            mm7,        mm7
+
+        pxor            mm6,        mm6
+
+x8x16sad_mmx_loop:
+
+        movq            mm0,        QWORD PTR [rsi]
+        movq            mm1,        QWORD PTR [rdi]
+
+        movq            mm2,        mm0
+        psubusb         mm0,        mm1
+
+        psubusb         mm1,        mm2
+        por             mm0,        mm1
+
+        movq            mm2,        mm0
+        punpcklbw       mm0,        mm6
+
+        punpckhbw       mm2,        mm6
+        lea             rsi,        [rsi+rax]
+
+        add             rdi,        rdx
+        paddw           mm7,        mm0
+
+        paddw           mm7,        mm2
+        cmp             rsi,        rcx
+
+        jne             x8x16sad_mmx_loop
+
+        movq            mm0,        mm7
+        punpcklwd       mm0,        mm6
+
+        punpckhwd       mm7,        mm6
+        paddw           mm0,        mm7
+
+        movq            mm7,        mm0
+        psrlq           mm0,        32
+
+        paddw           mm7,        mm0
+        movd            rax,        mm7
+
+    pop rdi
+    pop rsi
+    mov rsp, rbp
+    // begin epilog
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//unsigned int vp8_sad8x8_mmx(
+//    unsigned char *src_ptr,
+//    int  src_stride,
+//    unsigned char *ref_ptr,
+//    int  ref_stride)
+sym(vp8_sad8x8_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 4
+    push rsi
+    push rdi
+    // end prolog
+
+        mov             rsi,        arg(0) //src_ptr
+        mov             rdi,        arg(2) //ref_ptr
+
+        movsxd          rax,        dword ptr arg(1) //src_stride
+        movsxd          rdx,        dword ptr arg(3) //ref_stride
+
+        lea             rcx,        [rsi+rax*8]
+        pxor            mm7,        mm7
+
+        pxor            mm6,        mm6
+
+x8x8sad_mmx_loop:
+
+        movq            mm0,        QWORD PTR [rsi]
+        movq            mm1,        QWORD PTR [rdi]
+
+        movq            mm2,        mm0
+        psubusb         mm0,        mm1
+
+        psubusb         mm1,        mm2
+        por             mm0,        mm1
+
+        movq            mm2,        mm0
+        punpcklbw       mm0,        mm6
+
+        punpckhbw       mm2,        mm6
+        paddw           mm0,        mm2
+
+        lea             rsi,       [rsi+rax]
+        add             rdi,        rdx
+
+        paddw           mm7,       mm0
+        cmp             rsi,        rcx
+
+        jne             x8x8sad_mmx_loop
+
+        movq            mm0,        mm7
+        punpcklwd       mm0,        mm6
+
+        punpckhwd       mm7,        mm6
+        paddw           mm0,        mm7
+
+        movq            mm7,        mm0
+        psrlq           mm0,        32
+
+        paddw           mm7,        mm0
+        movd            rax,        mm7
+
+    pop rdi
+    pop rsi
+    mov rsp, rbp
+    // begin epilog
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//unsigned int vp8_sad4x4_mmx(
+//    unsigned char *src_ptr,
+//    int  src_stride,
+//    unsigned char *ref_ptr,
+//    int  ref_stride)
+sym(vp8_sad4x4_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 4
+    push rsi
+    push rdi
+    // end prolog
+
+        mov             rsi,        arg(0) //src_ptr
+        mov             rdi,        arg(2) //ref_ptr
+
+        movsxd          rax,        dword ptr arg(1) //src_stride
+        movsxd          rdx,        dword ptr arg(3) //ref_stride
+
+        movd            mm0,       DWORD PTR [rsi]
+        movd            mm1,       DWORD PTR [rdi]
+
+        movd            mm2,       DWORD PTR [rsi+rax]
+        movd            mm3,       DWORD PTR [rdi+rdx]
+
+        punpcklbw       mm0,        mm2
+        punpcklbw       mm1,        mm3
+
+        movq            mm2,        mm0
+        psubusb         mm0,        mm1
+
+        psubusb         mm1,        mm2
+        por             mm0,        mm1
+
+        movq            mm2,        mm0
+        pxor            mm3,        mm3
+
+        punpcklbw       mm0,        mm3
+        punpckhbw       mm2,        mm3
+
+        paddw           mm0,        mm2
+
+        lea             rsi,        [rsi+rax*2]
+        lea             rdi,        [rdi+rdx*2]
+
+        movd            mm4,       DWORD PTR [rsi]
+        movd            mm5,       DWORD PTR [rdi]
+
+        movd            mm6,       DWORD PTR [rsi+rax]
+        movd            mm7,       DWORD PTR [rdi+rdx]
+
+        punpcklbw       mm4,        mm6
+        punpcklbw       mm5,        mm7
+
+        movq            mm6,        mm4
+        psubusb         mm4,        mm5
+
+        psubusb         mm5,        mm6
+        por             mm4,        mm5
+
+        movq            mm5,        mm4
+        punpcklbw       mm4,        mm3
+
+        punpckhbw       mm5,        mm3
+        paddw           mm4,        mm5
+
+        paddw           mm0,        mm4
+        movq            mm1,        mm0
+
+        punpcklwd       mm0,        mm3
+        punpckhwd       mm1,        mm3
+
+        paddw           mm0,        mm1
+        movq            mm1,        mm0
+
+        psrlq           mm0,        32
+        paddw           mm0,        mm1
+
+        movd            rax,        mm0
+
+    pop rdi
+    pop rsi
+    mov rsp, rbp
+    // begin epilog
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//unsigned int vp8_sad16x8_mmx(
+//    unsigned char *src_ptr,
+//    int  src_stride,
+//    unsigned char *ref_ptr,
+//    int  ref_stride)
+sym(vp8_sad16x8_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 4
+    push rsi
+    push rdi
+    // end prolog
+
+        mov             rsi,        arg(0) //src_ptr
+        mov             rdi,        arg(2) //ref_ptr
+
+        movsxd          rax,        dword ptr arg(1) //src_stride
+        movsxd          rdx,        dword ptr arg(3) //ref_stride
+
+        lea             rcx,        [rsi+rax*8]
+        pxor            mm7,        mm7
+
+        pxor            mm6,        mm6
+
+x16x8sad_mmx_loop:
+
+        movq            mm0,       [rsi]
+        movq            mm1,       [rdi]
+
+        movq            mm2,        [rsi+8]
+        movq            mm3,        [rdi+8]
+
+        movq            mm4,        mm0
+        movq            mm5,        mm2
+
+        psubusb         mm0,        mm1
+        psubusb         mm1,        mm4
+
+        psubusb         mm2,        mm3
+        psubusb         mm3,        mm5
+
+        por             mm0,        mm1
+        por             mm2,        mm3
+
+        movq            mm1,        mm0
+        movq            mm3,        mm2
+
+        punpcklbw       mm0,        mm6
+        punpckhbw       mm1,        mm6
+
+        punpcklbw       mm2,        mm6
+        punpckhbw       mm3,        mm6
+
+
+        paddw           mm0,        mm2
+        paddw           mm1,        mm3
+
+        paddw           mm0,        mm1
+        lea             rsi,        [rsi+rax]
+
+        add             rdi,        rdx
+        paddw           mm7,        mm0
+
+        cmp             rsi,        rcx
+        jne             x16x8sad_mmx_loop
+
+        movq            mm0,        mm7
+        punpcklwd       mm0,        mm6
+
+        punpckhwd       mm7,        mm6
+        paddw           mm0,        mm7
+
+        movq            mm7,        mm0
+        psrlq           mm0,        32
+
+        paddw           mm7,        mm0
+        movd            rax,        mm7
+
+    pop rdi
+    pop rsi
+    mov rsp, rbp
+    // begin epilog
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
diff --git a/vp8/encoder/x86/sad_mmx.asm b/vp8/encoder/x86/sad_mmx.asm
deleted file mode 100644
index a825698..0000000
--- a/vp8/encoder/x86/sad_mmx.asm
+++ /dev/null
@@ -1,428 +0,0 @@
-;
-;  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
-;
-;  Use of this source code is governed by a BSD-style license and patent
-;  grant that can be found in the LICENSE file in the root of the source
-;  tree. All contributing project authors may be found in the AUTHORS
-;  file in the root of the source tree.
-;
-
-
-%include "vpx_ports/x86_abi_support.asm"
-
-global sym(vp8_sad16x16_mmx)
-global sym(vp8_sad8x16_mmx)
-global sym(vp8_sad8x8_mmx)
-global sym(vp8_sad4x4_mmx)
-global sym(vp8_sad16x8_mmx)
-
-%idefine QWORD
-
-;unsigned int vp8_sad16x16_mmx(
-;    unsigned char *src_ptr,
-;    int  src_stride,
-;    unsigned char *ref_ptr,
-;    int  ref_stride)
-sym(vp8_sad16x16_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 4
-    push rsi
-    push rdi
-    ; end prolog
-
-        mov             rsi,        arg(0) ;src_ptr
-        mov             rdi,        arg(2) ;ref_ptr
-
-        movsxd          rax,        dword ptr arg(1) ;src_stride
-        movsxd          rdx,        dword ptr arg(3) ;ref_stride
-
-        lea             rcx,        [rsi+rax*8]
-
-        lea             rcx,        [rcx+rax*8]
-        pxor            mm7,        mm7
-
-        pxor            mm6,        mm6
-
-x16x16sad_mmx_loop:
-
-        movq            mm0,        QWORD PTR [rsi]
-        movq            mm2,        QWORD PTR [rsi+8]
-
-        movq            mm1,        QWORD PTR [rdi]
-        movq            mm3,        QWORD PTR [rdi+8]
-
-        movq            mm4,        mm0
-        movq            mm5,        mm2
-
-        psubusb         mm0,        mm1
-        psubusb         mm1,        mm4
-
-        psubusb         mm2,        mm3
-        psubusb         mm3,        mm5
-
-        por             mm0,        mm1
-        por             mm2,        mm3
-
-        movq            mm1,        mm0
-        movq            mm3,        mm2
-
-        punpcklbw       mm0,        mm6
-        punpcklbw       mm2,        mm6
-
-        punpckhbw       mm1,        mm6
-        punpckhbw       mm3,        mm6
-
-        paddw           mm0,        mm2
-        paddw           mm1,        mm3
-
-
-        lea             rsi,        [rsi+rax]
-        add             rdi,        rdx
-
-        paddw           mm7,        mm0
-        paddw           mm7,        mm1
-
-        cmp             rsi,        rcx
-        jne             x16x16sad_mmx_loop
-
-
-        movq            mm0,        mm7
-
-        punpcklwd       mm0,        mm6
-        punpckhwd       mm7,        mm6
-
-        paddw           mm0,        mm7
-        movq            mm7,        mm0
-
-
-        psrlq           mm0,        32
-        paddw           mm7,        mm0
-
-        movd            rax,        mm7
-
-    pop rdi
-    pop rsi
-    mov rsp, rbp
-    ; begin epilog
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;unsigned int vp8_sad8x16_mmx(
-;    unsigned char *src_ptr,
-;    int  src_stride,
-;    unsigned char *ref_ptr,
-;    int  ref_stride)
-sym(vp8_sad8x16_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 4
-    push rsi
-    push rdi
-    ; end prolog
-
-        mov             rsi,        arg(0) ;src_ptr
-        mov             rdi,        arg(2) ;ref_ptr
-
-        movsxd          rax,        dword ptr arg(1) ;src_stride
-        movsxd          rdx,        dword ptr arg(3) ;ref_stride
-
-        lea             rcx,        [rsi+rax*8]
-
-        lea             rcx,        [rcx+rax*8]
-        pxor            mm7,        mm7
-
-        pxor            mm6,        mm6
-
-x8x16sad_mmx_loop:
-
-        movq            mm0,        QWORD PTR [rsi]
-        movq            mm1,        QWORD PTR [rdi]
-
-        movq            mm2,        mm0
-        psubusb         mm0,        mm1
-
-        psubusb         mm1,        mm2
-        por             mm0,        mm1
-
-        movq            mm2,        mm0
-        punpcklbw       mm0,        mm6
-
-        punpckhbw       mm2,        mm6
-        lea             rsi,        [rsi+rax]
-
-        add             rdi,        rdx
-        paddw           mm7,        mm0
-
-        paddw           mm7,        mm2
-        cmp             rsi,        rcx
-
-        jne             x8x16sad_mmx_loop
-
-        movq            mm0,        mm7
-        punpcklwd       mm0,        mm6
-
-        punpckhwd       mm7,        mm6
-        paddw           mm0,        mm7
-
-        movq            mm7,        mm0
-        psrlq           mm0,        32
-
-        paddw           mm7,        mm0
-        movd            rax,        mm7
-
-    pop rdi
-    pop rsi
-    mov rsp, rbp
-    ; begin epilog
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;unsigned int vp8_sad8x8_mmx(
-;    unsigned char *src_ptr,
-;    int  src_stride,
-;    unsigned char *ref_ptr,
-;    int  ref_stride)
-sym(vp8_sad8x8_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 4
-    push rsi
-    push rdi
-    ; end prolog
-
-        mov             rsi,        arg(0) ;src_ptr
-        mov             rdi,        arg(2) ;ref_ptr
-
-        movsxd          rax,        dword ptr arg(1) ;src_stride
-        movsxd          rdx,        dword ptr arg(3) ;ref_stride
-
-        lea             rcx,        [rsi+rax*8]
-        pxor            mm7,        mm7
-
-        pxor            mm6,        mm6
-
-x8x8sad_mmx_loop:
-
-        movq            mm0,        QWORD PTR [rsi]
-        movq            mm1,        QWORD PTR [rdi]
-
-        movq            mm2,        mm0
-        psubusb         mm0,        mm1
-
-        psubusb         mm1,        mm2
-        por             mm0,        mm1
-
-        movq            mm2,        mm0
-        punpcklbw       mm0,        mm6
-
-        punpckhbw       mm2,        mm6
-        paddw           mm0,        mm2
-
-        lea             rsi,       [rsi+rax]
-        add             rdi,        rdx
-
-        paddw           mm7,       mm0
-        cmp             rsi,        rcx
-
-        jne             x8x8sad_mmx_loop
-
-        movq            mm0,        mm7
-        punpcklwd       mm0,        mm6
-
-        punpckhwd       mm7,        mm6
-        paddw           mm0,        mm7
-
-        movq            mm7,        mm0
-        psrlq           mm0,        32
-
-        paddw           mm7,        mm0
-        movd            rax,        mm7
-
-    pop rdi
-    pop rsi
-    mov rsp, rbp
-    ; begin epilog
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;unsigned int vp8_sad4x4_mmx(
-;    unsigned char *src_ptr,
-;    int  src_stride,
-;    unsigned char *ref_ptr,
-;    int  ref_stride)
-sym(vp8_sad4x4_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 4
-    push rsi
-    push rdi
-    ; end prolog
-
-        mov             rsi,        arg(0) ;src_ptr
-        mov             rdi,        arg(2) ;ref_ptr
-
-        movsxd          rax,        dword ptr arg(1) ;src_stride
-        movsxd          rdx,        dword ptr arg(3) ;ref_stride
-
-        movd            mm0,       QWORD PTR [rsi]
-        movd            mm1,       QWORD PTR [rdi]
-
-        movd            mm2,       QWORD PTR [rsi+rax]
-        movd            mm3,       QWORD PTR [rdi+rdx]
-
-        punpcklbw       mm0,        mm2
-        punpcklbw       mm1,        mm3
-
-        movq            mm2,        mm0
-        psubusb         mm0,        mm1
-
-        psubusb         mm1,        mm2
-        por             mm0,        mm1
-
-        movq            mm2,        mm0
-        pxor            mm3,        mm3
-
-        punpcklbw       mm0,        mm3
-        punpckhbw       mm2,        mm3
-
-        paddw           mm0,        mm2
-
-        lea             rsi,        [rsi+rax*2]
-        lea             rdi,        [rdi+rdx*2]
-
-        movd            mm4,       QWORD PTR [rsi]
-        movd            mm5,       QWORD PTR [rdi]
-
-        movd            mm6,       QWORD PTR [rsi+rax]
-        movd            mm7,       QWORD PTR [rdi+rdx]
-
-        punpcklbw       mm4,        mm6
-        punpcklbw       mm5,        mm7
-
-        movq            mm6,        mm4
-        psubusb         mm4,        mm5
-
-        psubusb         mm5,        mm6
-        por             mm4,        mm5
-
-        movq            mm5,        mm4
-        punpcklbw       mm4,        mm3
-
-        punpckhbw       mm5,        mm3
-        paddw           mm4,        mm5
-
-        paddw           mm0,        mm4
-        movq            mm1,        mm0
-
-        punpcklwd       mm0,        mm3
-        punpckhwd       mm1,        mm3
-
-        paddw           mm0,        mm1
-        movq            mm1,        mm0
-
-        psrlq           mm0,        32
-        paddw           mm0,        mm1
-
-        movd            rax,        mm0
-
-    pop rdi
-    pop rsi
-    mov rsp, rbp
-    ; begin epilog
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;unsigned int vp8_sad16x8_mmx(
-;    unsigned char *src_ptr,
-;    int  src_stride,
-;    unsigned char *ref_ptr,
-;    int  ref_stride)
-sym(vp8_sad16x8_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 4
-    push rsi
-    push rdi
-    ; end prolog
-
-        mov             rsi,        arg(0) ;src_ptr
-        mov             rdi,        arg(2) ;ref_ptr
-
-        movsxd          rax,        dword ptr arg(1) ;src_stride
-        movsxd          rdx,        dword ptr arg(3) ;ref_stride
-
-        lea             rcx,        [rsi+rax*8]
-        pxor            mm7,        mm7
-
-        pxor            mm6,        mm6
-
-x16x8sad_mmx_loop:
-
-        movq            mm0,       [rsi]
-        movq            mm1,       [rdi]
-
-        movq            mm2,        [rsi+8]
-        movq            mm3,        [rdi+8]
-
-        movq            mm4,        mm0
-        movq            mm5,        mm2
-
-        psubusb         mm0,        mm1
-        psubusb         mm1,        mm4
-
-        psubusb         mm2,        mm3
-        psubusb         mm3,        mm5
-
-        por             mm0,        mm1
-        por             mm2,        mm3
-
-        movq            mm1,        mm0
-        movq            mm3,        mm2
-
-        punpcklbw       mm0,        mm6
-        punpckhbw       mm1,        mm6
-
-        punpcklbw       mm2,        mm6
-        punpckhbw       mm3,        mm6
-
-
-        paddw           mm0,        mm2
-        paddw           mm1,        mm3
-
-        paddw           mm0,        mm1
-        lea             rsi,        [rsi+rax]
-
-        add             rdi,        rdx
-        paddw           mm7,        mm0
-
-        cmp             rsi,        rcx
-        jne             x16x8sad_mmx_loop
-
-        movq            mm0,        mm7
-        punpcklwd       mm0,        mm6
-
-        punpckhwd       mm7,        mm6
-        paddw           mm0,        mm7
-
-        movq            mm7,        mm0
-        psrlq           mm0,        32
-
-        paddw           mm7,        mm0
-        movd            rax,        mm7
-
-    pop rdi
-    pop rsi
-    mov rsp, rbp
-    ; begin epilog
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
diff --git a/vp8/encoder/x86/sad_sse2.S b/vp8/encoder/x86/sad_sse2.S
new file mode 100644
index 0000000..e926085
--- /dev/null
+++ b/vp8/encoder/x86/sad_sse2.S
@@ -0,0 +1,327 @@
+//
+//  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
+//
+//  Use of this source code is governed by a BSD-style license and patent
+//  grant that can be found in the LICENSE file in the root of the source
+//  tree. All contributing project authors may be found in the AUTHORS
+//  file in the root of the source tree.
+//
+
+
+#include "vpx_ports/x86_abi_support.S"
+
+//unsigned int vp8_sad16x16_wmt(
+//    unsigned char *src_ptr,
+//    int  src_stride,
+//    unsigned char *ref_ptr,
+//    int  ref_stride)
+global sym(vp8_sad16x16_wmt)
+sym(vp8_sad16x16_wmt):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 4
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov             rsi,        arg(0) //src_ptr
+        mov             rdi,        arg(2) //ref_ptr
+
+        movsxd          rax,        dword ptr arg(1) //src_stride
+        movsxd          rdx,        dword ptr arg(3) //ref_stride
+
+        lea             rcx,        [rsi+rax*8]
+
+        lea             rcx,        [rcx+rax*8]
+        pxor            xmm7,       xmm7
+
+x16x16sad_wmt_loop:
+
+        movq            xmm0,       QWORD PTR [rsi]
+        movq            xmm2,       QWORD PTR [rsi+8]
+
+        movq            xmm1,       QWORD PTR [rdi]
+        movq            xmm3,       QWORD PTR [rdi+8]
+
+        movq            xmm4,       QWORD PTR [rsi+rax]
+        movq            xmm5,       QWORD PTR [rdi+rdx]
+
+
+        punpcklbw       xmm0,       xmm2
+        punpcklbw       xmm1,       xmm3
+
+        psadbw          xmm0,       xmm1
+        movq            xmm6,       QWORD PTR [rsi+rax+8]
+
+        movq            xmm3,       QWORD PTR [rdi+rdx+8]
+        lea             rsi,        [rsi+rax*2]
+
+        lea             rdi,        [rdi+rdx*2]
+        punpcklbw       xmm4,       xmm6
+
+        punpcklbw       xmm5,       xmm3
+        psadbw          xmm4,       xmm5
+
+        paddw           xmm7,       xmm0
+        paddw           xmm7,       xmm4
+
+        cmp             rsi,        rcx
+        jne             x16x16sad_wmt_loop
+
+        movq            xmm0,       xmm7
+        psrldq          xmm7,       8
+
+        paddw           xmm0,       xmm7
+        movd            rax,        xmm0
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+//unsigned int vp8_sad8x16_wmt(
+//    unsigned char *src_ptr,
+//    int  src_stride,
+//    unsigned char *ref_ptr,
+//    int  ref_stride,
+//    int  max_err)
+global sym(vp8_sad8x16_wmt)
+sym(vp8_sad8x16_wmt):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 5
+    push        rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov             rsi,        arg(0) //src_ptr
+        mov             rdi,        arg(2) //ref_ptr
+
+        movsxd          rbx,        dword ptr arg(1) //src_stride
+        movsxd          rdx,        dword ptr arg(3) //ref_stride
+
+        lea             rcx,        [rsi+rbx*8]
+
+        lea             rcx,        [rcx+rbx*8]
+        pxor            mm7,        mm7
+
+x8x16sad_wmt_loop:
+
+        movd            rax,        mm7
+        cmp             rax,        arg(4)
+        jg              x8x16sad_wmt_early_exit
+
+        movq            mm0,        QWORD PTR [rsi]
+        movq            mm1,        QWORD PTR [rdi]
+
+        movq            mm2,        QWORD PTR [rsi+rbx]
+        movq            mm3,        QWORD PTR [rdi+rdx]
+
+        psadbw          mm0,        mm1
+        psadbw          mm2,        mm3
+
+        lea             rsi,        [rsi+rbx*2]
+        lea             rdi,        [rdi+rdx*2]
+
+        paddw           mm7,        mm0
+        paddw           mm7,        mm2
+
+        cmp             rsi,        rcx
+        jne             x8x16sad_wmt_loop
+
+        movd            rax,        mm7
+
+x8x16sad_wmt_early_exit:
+
+    // begin epilog
+    pop         rdi
+    pop         rsi
+    pop         rbx
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//unsigned int vp8_sad8x8_wmt(
+//    unsigned char *src_ptr,
+//    int  src_stride,
+//    unsigned char *ref_ptr,
+//    int  ref_stride)
+global sym(vp8_sad8x8_wmt)
+sym(vp8_sad8x8_wmt):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 5
+    push        rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov             rsi,        arg(0) //src_ptr
+        mov             rdi,        arg(2) //ref_ptr
+
+        movsxd          rbx,        dword ptr arg(1) //src_stride
+        movsxd          rdx,        dword ptr arg(3) //ref_stride
+
+        lea             rcx,        [rsi+rbx*8]
+        pxor            mm7,        mm7
+
+x8x8sad_wmt_loop:
+
+        movd            rax,        mm7
+        cmp             rax,        arg(4)
+        jg              x8x8sad_wmt_early_exit
+
+        movq            mm0,        QWORD PTR [rsi]
+        movq            mm1,        QWORD PTR [rdi]
+
+        psadbw          mm0,        mm1
+        lea             rsi,        [rsi+rbx]
+
+        add             rdi,        rdx
+        paddw           mm7,        mm0
+
+        cmp             rsi,        rcx
+        jne             x8x8sad_wmt_loop
+
+        movd            rax,        mm7
+x8x8sad_wmt_early_exit:
+
+    // begin epilog
+    pop         rdi
+    pop         rsi
+    pop         rbx
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+//unsigned int vp8_sad4x4_wmt(
+//    unsigned char *src_ptr,
+//    int  src_stride,
+//    unsigned char *ref_ptr,
+//    int  ref_stride)
+global sym(vp8_sad4x4_wmt)
+sym(vp8_sad4x4_wmt):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 4
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov             rsi,        arg(0) //src_ptr
+        mov             rdi,        arg(2) //ref_ptr
+
+        movsxd          rax,        dword ptr arg(1) //src_stride
+        movsxd          rdx,        dword ptr arg(3) //ref_stride
+
+        movd            mm0,       DWORD PTR [rsi]
+        movd            mm1,       DWORD PTR [rdi]
+
+        movd            mm2,       DWORD PTR [rsi+rax]
+        movd            mm3,       DWORD PTR [rdi+rdx]
+
+        punpcklbw       mm0,        mm2
+        punpcklbw       mm1,        mm3
+
+        psadbw          mm0,        mm1
+        lea             rsi,        [rsi+rax*2]
+
+        lea             rdi,        [rdi+rdx*2]
+        movd            mm4,       DWORD PTR [rsi]
+
+        movd            mm5,       DWORD PTR [rdi]
+        movd            mm6,       DWORD PTR [rsi+rax]
+
+        movd            mm7,       DWORD PTR [rdi+rdx]
+        punpcklbw       mm4,        mm6
+
+        punpcklbw       mm5,        mm7
+        psadbw          mm4,        mm5
+
+        paddw           mm0,        mm4
+        movd            rax,        mm0
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//unsigned int vp8_sad16x8_wmt(
+//    unsigned char *src_ptr,
+//    int  src_stride,
+//    unsigned char *ref_ptr,
+//    int  ref_stride)
+global sym(vp8_sad16x8_wmt)
+sym(vp8_sad16x8_wmt):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 5
+    push        rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+
+        mov             rsi,        arg(0) //src_ptr
+        mov             rdi,        arg(2) //ref_ptr
+
+        movsxd          rbx,        dword ptr arg(1) //src_stride
+        movsxd          rdx,        dword ptr arg(3) //ref_stride
+
+        lea             rcx,        [rsi+rbx*8]
+        pxor            mm7,        mm7
+
+x16x8sad_wmt_loop:
+
+        movd            rax,        mm7
+        cmp             rax,        arg(4)
+        jg              x16x8sad_wmt_early_exit
+
+        movq            mm0,        QWORD PTR [rsi]
+        movq            mm2,        QWORD PTR [rsi+8]
+
+        movq            mm1,        QWORD PTR [rdi]
+        movq            mm3,        QWORD PTR [rdi+8]
+
+        movq            mm4,        QWORD PTR [rsi+rbx]
+        movq            mm5,        QWORD PTR [rdi+rdx]
+
+        psadbw          mm0,        mm1
+        psadbw          mm2,        mm3
+
+        movq            mm1,        QWORD PTR [rsi+rbx+8]
+        movq            mm3,        QWORD PTR [rdi+rdx+8]
+
+        psadbw          mm4,        mm5
+        psadbw          mm1,        mm3
+
+        lea             rsi,        [rsi+rbx*2]
+        lea             rdi,        [rdi+rdx*2]
+
+        paddw           mm0,        mm2
+        paddw           mm4,        mm1
+
+        paddw           mm7,        mm0
+        paddw           mm7,        mm4
+
+        cmp             rsi,        rcx
+        jne             x16x8sad_wmt_loop
+
+        movd            rax,        mm7
+
+x16x8sad_wmt_early_exit:
+
+    // begin epilog
+    pop         rdi
+    pop         rsi
+    pop         rbx
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
diff --git a/vp8/encoder/x86/sad_sse2.asm b/vp8/encoder/x86/sad_sse2.asm
deleted file mode 100644
index 53240bb..0000000
--- a/vp8/encoder/x86/sad_sse2.asm
+++ /dev/null
@@ -1,329 +0,0 @@
-;
-;  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
-;
-;  Use of this source code is governed by a BSD-style license and patent
-;  grant that can be found in the LICENSE file in the root of the source
-;  tree. All contributing project authors may be found in the AUTHORS
-;  file in the root of the source tree.
-;
-
-
-%include "vpx_ports/x86_abi_support.asm"
-
-%idefine QWORD
-
-;unsigned int vp8_sad16x16_wmt(
-;    unsigned char *src_ptr,
-;    int  src_stride,
-;    unsigned char *ref_ptr,
-;    int  ref_stride)
-global sym(vp8_sad16x16_wmt)
-sym(vp8_sad16x16_wmt):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 4
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov             rsi,        arg(0) ;src_ptr
-        mov             rdi,        arg(2) ;ref_ptr
-
-        movsxd          rax,        dword ptr arg(1) ;src_stride
-        movsxd          rdx,        dword ptr arg(3) ;ref_stride
-
-        lea             rcx,        [rsi+rax*8]
-
-        lea             rcx,        [rcx+rax*8]
-        pxor            xmm7,       xmm7
-
-x16x16sad_wmt_loop:
-
-        movq            xmm0,       QWORD PTR [rsi]
-        movq            xmm2,       QWORD PTR [rsi+8]
-
-        movq            xmm1,       QWORD PTR [rdi]
-        movq            xmm3,       QWORD PTR [rdi+8]
-
-        movq            xmm4,       QWORD PTR [rsi+rax]
-        movq            xmm5,       QWORD PTR [rdi+rdx]
-
-
-        punpcklbw       xmm0,       xmm2
-        punpcklbw       xmm1,       xmm3
-
-        psadbw          xmm0,       xmm1
-        movq            xmm6,       QWORD PTR [rsi+rax+8]
-
-        movq            xmm3,       QWORD PTR [rdi+rdx+8]
-        lea             rsi,        [rsi+rax*2]
-
-        lea             rdi,        [rdi+rdx*2]
-        punpcklbw       xmm4,       xmm6
-
-        punpcklbw       xmm5,       xmm3
-        psadbw          xmm4,       xmm5
-
-        paddw           xmm7,       xmm0
-        paddw           xmm7,       xmm4
-
-        cmp             rsi,        rcx
-        jne             x16x16sad_wmt_loop
-
-        movq            xmm0,       xmm7
-        psrldq          xmm7,       8
-
-        paddw           xmm0,       xmm7
-        movd            rax,        xmm0
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-;unsigned int vp8_sad8x16_wmt(
-;    unsigned char *src_ptr,
-;    int  src_stride,
-;    unsigned char *ref_ptr,
-;    int  ref_stride,
-;    int  max_err)
-global sym(vp8_sad8x16_wmt)
-sym(vp8_sad8x16_wmt):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 5
-    push        rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov             rsi,        arg(0) ;src_ptr
-        mov             rdi,        arg(2) ;ref_ptr
-
-        movsxd          rbx,        dword ptr arg(1) ;src_stride
-        movsxd          rdx,        dword ptr arg(3) ;ref_stride
-
-        lea             rcx,        [rsi+rbx*8]
-
-        lea             rcx,        [rcx+rbx*8]
-        pxor            mm7,        mm7
-
-x8x16sad_wmt_loop:
-
-        movd            rax,        mm7
-        cmp             rax,        arg(4)
-        jg              x8x16sad_wmt_early_exit
-
-        movq            mm0,        QWORD PTR [rsi]
-        movq            mm1,        QWORD PTR [rdi]
-
-        movq            mm2,        QWORD PTR [rsi+rbx]
-        movq            mm3,        QWORD PTR [rdi+rdx]
-
-        psadbw          mm0,        mm1
-        psadbw          mm2,        mm3
-
-        lea             rsi,        [rsi+rbx*2]
-        lea             rdi,        [rdi+rdx*2]
-
-        paddw           mm7,        mm0
-        paddw           mm7,        mm2
-
-        cmp             rsi,        rcx
-        jne             x8x16sad_wmt_loop
-
-        movd            rax,        mm7
-
-x8x16sad_wmt_early_exit:
-
-    ; begin epilog
-    pop         rdi
-    pop         rsi
-    pop         rbx
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;unsigned int vp8_sad8x8_wmt(
-;    unsigned char *src_ptr,
-;    int  src_stride,
-;    unsigned char *ref_ptr,
-;    int  ref_stride)
-global sym(vp8_sad8x8_wmt)
-sym(vp8_sad8x8_wmt):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 5
-    push        rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov             rsi,        arg(0) ;src_ptr
-        mov             rdi,        arg(2) ;ref_ptr
-
-        movsxd          rbx,        dword ptr arg(1) ;src_stride
-        movsxd          rdx,        dword ptr arg(3) ;ref_stride
-
-        lea             rcx,        [rsi+rbx*8]
-        pxor            mm7,        mm7
-
-x8x8sad_wmt_loop:
-
-        movd            rax,        mm7
-        cmp             rax,        arg(4)
-        jg              x8x8sad_wmt_early_exit
-
-        movq            mm0,        QWORD PTR [rsi]
-        movq            mm1,        QWORD PTR [rdi]
-
-        psadbw          mm0,        mm1
-        lea             rsi,        [rsi+rbx]
-
-        add             rdi,        rdx
-        paddw           mm7,        mm0
-
-        cmp             rsi,        rcx
-        jne             x8x8sad_wmt_loop
-
-        movd            rax,        mm7
-x8x8sad_wmt_early_exit:
-
-    ; begin epilog
-    pop         rdi
-    pop         rsi
-    pop         rbx
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-;unsigned int vp8_sad4x4_wmt(
-;    unsigned char *src_ptr,
-;    int  src_stride,
-;    unsigned char *ref_ptr,
-;    int  ref_stride)
-global sym(vp8_sad4x4_wmt)
-sym(vp8_sad4x4_wmt):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 4
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov             rsi,        arg(0) ;src_ptr
-        mov             rdi,        arg(2) ;ref_ptr
-
-        movsxd          rax,        dword ptr arg(1) ;src_stride
-        movsxd          rdx,        dword ptr arg(3) ;ref_stride
-
-        movd            mm0,       QWORD PTR [rsi]
-        movd            mm1,       QWORD PTR [rdi]
-
-        movd            mm2,       QWORD PTR [rsi+rax]
-        movd            mm3,       QWORD PTR [rdi+rdx]
-
-        punpcklbw       mm0,        mm2
-        punpcklbw       mm1,        mm3
-
-        psadbw          mm0,        mm1
-        lea             rsi,        [rsi+rax*2]
-
-        lea             rdi,        [rdi+rdx*2]
-        movd            mm4,       QWORD PTR [rsi]
-
-        movd            mm5,       QWORD PTR [rdi]
-        movd            mm6,       QWORD PTR [rsi+rax]
-
-        movd            mm7,       QWORD PTR [rdi+rdx]
-        punpcklbw       mm4,        mm6
-
-        punpcklbw       mm5,        mm7
-        psadbw          mm4,        mm5
-
-        paddw           mm0,        mm4
-        movd            rax,        mm0
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;unsigned int vp8_sad16x8_wmt(
-;    unsigned char *src_ptr,
-;    int  src_stride,
-;    unsigned char *ref_ptr,
-;    int  ref_stride)
-global sym(vp8_sad16x8_wmt)
-sym(vp8_sad16x8_wmt):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 5
-    push        rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-
-        mov             rsi,        arg(0) ;src_ptr
-        mov             rdi,        arg(2) ;ref_ptr
-
-        movsxd          rbx,        dword ptr arg(1) ;src_stride
-        movsxd          rdx,        dword ptr arg(3) ;ref_stride
-
-        lea             rcx,        [rsi+rbx*8]
-        pxor            mm7,        mm7
-
-x16x8sad_wmt_loop:
-
-        movd            rax,        mm7
-        cmp             rax,        arg(4)
-        jg              x16x8sad_wmt_early_exit
-
-        movq            mm0,        QWORD PTR [rsi]
-        movq            mm2,        QWORD PTR [rsi+8]
-
-        movq            mm1,        QWORD PTR [rdi]
-        movq            mm3,        QWORD PTR [rdi+8]
-
-        movq            mm4,        QWORD PTR [rsi+rbx]
-        movq            mm5,        QWORD PTR [rdi+rdx]
-
-        psadbw          mm0,        mm1
-        psadbw          mm2,        mm3
-
-        movq            mm1,        QWORD PTR [rsi+rbx+8]
-        movq            mm3,        QWORD PTR [rdi+rdx+8]
-
-        psadbw          mm4,        mm5
-        psadbw          mm1,        mm3
-
-        lea             rsi,        [rsi+rbx*2]
-        lea             rdi,        [rdi+rdx*2]
-
-        paddw           mm0,        mm2
-        paddw           mm4,        mm1
-
-        paddw           mm7,        mm0
-        paddw           mm7,        mm4
-
-        cmp             rsi,        rcx
-        jne             x16x8sad_wmt_loop
-
-        movd            rax,        mm7
-
-x16x8sad_wmt_early_exit:
-
-    ; begin epilog
-    pop         rdi
-    pop         rsi
-    pop         rbx
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
diff --git a/vp8/encoder/x86/sad_sse3.S b/vp8/encoder/x86/sad_sse3.S
new file mode 100644
index 0000000..b23faff
--- /dev/null
+++ b/vp8/encoder/x86/sad_sse3.S
@@ -0,0 +1,938 @@
+//
+//  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
+//
+//  Use of this source code is governed by a BSD-style license and patent
+//  grant that can be found in the LICENSE file in the root of the source
+//  tree. All contributing project authors may be found in the AUTHORS
+//  file in the root of the source tree.
+//
+
+
+#include "vpx_ports/x86_abi_support.S"
+
+        .macro PROCESS_16X2X3 first
+.ifne \first
+        movdqa          xmm0,       [rsi]
+        lddqu           xmm5,       [rdi]
+        lddqu           xmm6,       [rdi+1]
+        lddqu           xmm7,       [rdi+2]
+
+        psadbw          xmm5,       xmm0
+        psadbw          xmm6,       xmm0
+        psadbw          xmm7,       xmm0
+.else
+        movdqa          xmm0,       [rsi]
+        lddqu           xmm1,       [rdi]
+        lddqu           xmm2,       [rdi+1]
+        lddqu           xmm3,       [rdi+2]
+
+        psadbw          xmm1,       xmm0
+        psadbw          xmm2,       xmm0
+        psadbw          xmm3,       xmm0
+
+        paddw           xmm5,       xmm1
+        paddw           xmm6,       xmm2
+        paddw           xmm7,       xmm3
+.endif
+
+        movdqa          xmm0,       xmmword ptr [rsi+rax]
+        lddqu           xmm1,       xmmword ptr [rdi+rdx]
+        lddqu           xmm2,       xmmword ptr [rdi+rdx+1]
+        lddqu           xmm3,       xmmword ptr [rdi+rdx+2]
+
+        lea             rsi,        [rsi+rax*2]
+        lea             rdi,        [rdi+rdx*2]
+
+        psadbw          xmm1,       xmm0
+        psadbw          xmm2,       xmm0
+        psadbw          xmm3,       xmm0
+
+        paddw           xmm5,       xmm1
+        paddw           xmm6,       xmm2
+        paddw           xmm7,       xmm3
+        .endm
+
+        .macro PROCESS_8X2X3 first
+.ifne \first
+        movq            mm0,       [rsi]
+        movq            mm5,       [rdi]
+        movq            mm6,       [rdi+1]
+        movq            mm7,       [rdi+2]
+
+        psadbw          mm5,       mm0
+        psadbw          mm6,       mm0
+        psadbw          mm7,       mm0
+.else
+        movq            mm0,       [rsi]
+        movq            mm1,       [rdi]
+        movq            mm2,       [rdi+1]
+        movq            mm3,       [rdi+2]
+
+        psadbw          mm1,       mm0
+        psadbw          mm2,       mm0
+        psadbw          mm3,       mm0
+
+        paddw           mm5,       mm1
+        paddw           mm6,       mm2
+        paddw           mm7,       mm3
+.endif
+
+        movq            mm0,       QWORD PTR [rsi+rax]
+        movq            mm1,       QWORD PTR [rdi+rdx]
+        movq            mm2,       QWORD PTR [rdi+rdx+1]
+        movq            mm3,       QWORD PTR [rdi+rdx+2]
+
+        lea             rsi,       [rsi+rax*2]
+        lea             rdi,       [rdi+rdx*2]
+
+        psadbw          mm1,       mm0
+        psadbw          mm2,       mm0
+        psadbw          mm3,       mm0
+
+        paddw           mm5,       mm1
+        paddw           mm6,       mm2
+        paddw           mm7,       mm3
+        .endm
+
+
+        .macro LOAD_X4_ADDRESSES src reg0 reg1 reg2 reg3
+        mov             \reg0,      [\src + REG_SZ_BYTES*0]
+        mov             \reg1,      [\src + REG_SZ_BYTES*1]
+
+        mov             \reg2,      [\src + REG_SZ_BYTES*2]
+        mov             \reg3,      [\src + REG_SZ_BYTES*3]
+        .endm
+
+        .macro PROCESS_16X2X4 first
+.ifne \first
+        movdqa          xmm0,       [rsi]
+        lddqu           xmm4,       [rcx]
+        lddqu           xmm5,       [rdx]
+        lddqu           xmm6,       [rbx]
+        lddqu           xmm7,       [rdi]
+
+        psadbw          xmm4,       xmm0
+        psadbw          xmm5,       xmm0
+        psadbw          xmm6,       xmm0
+        psadbw          xmm7,       xmm0
+.else
+        movdqa          xmm0,       [rsi]
+        lddqu           xmm1,       [rcx]
+        lddqu           xmm2,       [rdx]
+        lddqu           xmm3,       [rbx]
+
+        psadbw          xmm1,       xmm0
+        psadbw          xmm2,       xmm0
+        psadbw          xmm3,       xmm0
+
+        paddw           xmm4,       xmm1
+        lddqu           xmm1,       [rdi]
+        paddw           xmm5,       xmm2
+        paddw           xmm6,       xmm3
+
+        psadbw          xmm1,       xmm0
+        paddw           xmm7,       xmm1
+.endif
+        movdqa          xmm0,       xmmword ptr [rsi+rax]
+        lddqu           xmm1,       xmmword ptr [rcx+rbp]
+        lddqu           xmm2,       xmmword ptr [rdx+rbp]
+        lddqu           xmm3,       xmmword ptr [rbx+rbp]
+
+        psadbw          xmm1,       xmm0
+        psadbw          xmm2,       xmm0
+        psadbw          xmm3,       xmm0
+
+        paddw           xmm4,       xmm1
+        lddqu           xmm1,       xmmword ptr [rdi+rbp]
+        paddw           xmm5,       xmm2
+        paddw           xmm6,       xmm3
+
+        lea             rsi,        [rsi+rax*2]
+        lea             rcx,        [rcx+rbp*2]
+
+        lea             rdx,        [rdx+rbp*2]
+        lea             rbx,        [rbx+rbp*2]
+
+        lea             rdi,        [rdi+rbp*2]
+
+        psadbw          xmm1,       xmm0
+        paddw           xmm7,       xmm1
+        .endm
+
+        .macro PROCESS_8X2X4 first
+.ifne \first
+        movq            mm0,        [rsi]
+        movq            mm4,        [rcx]
+        movq            mm5,        [rdx]
+        movq            mm6,        [rbx]
+        movq            mm7,        [rdi]
+
+        psadbw          mm4,        mm0
+        psadbw          mm5,        mm0
+        psadbw          mm6,        mm0
+        psadbw          mm7,        mm0
+.else
+        movq            mm0,        [rsi]
+        movq            mm1,        [rcx]
+        movq            mm2,        [rdx]
+        movq            mm3,        [rbx]
+
+        psadbw          mm1,        mm0
+        psadbw          mm2,        mm0
+        psadbw          mm3,        mm0
+
+        paddw           mm4,        mm1
+        movq            mm1,        [rdi]
+        paddw           mm5,        mm2
+        paddw           mm6,        mm3
+
+        psadbw          mm1,        mm0
+        paddw           mm7,        mm1
+.endif
+        movq            mm0,        QWORD PTR [rsi+rax]
+        movq            mm1,        QWORD PTR [rcx+rbp]
+        movq            mm2,        QWORD PTR [rdx+rbp]
+        movq            mm3,        QWORD PTR [rbx+rbp]
+
+        psadbw          mm1,        mm0
+        psadbw          mm2,        mm0
+        psadbw          mm3,        mm0
+
+        paddw           mm4,        mm1
+        movq            mm1,        QWORD PTR [rdi+rbp]
+        paddw           mm5,        mm2
+        paddw           mm6,        mm3
+
+        lea             rsi,        [rsi+rax*2]
+        lea             rcx,        [rcx+rbp*2]
+
+        lea             rdx,        [rdx+rbp*2]
+        lea             rbx,        [rbx+rbp*2]
+
+        lea             rdi,        [rdi+rbp*2]
+
+        psadbw          mm1,        mm0
+        paddw           mm7,        mm1
+        .endm
+
+//void int vp8_sad16x16x3_sse3(
+//    unsigned char *src_ptr,
+//    int  src_stride,
+//    unsigned char *ref_ptr,
+//    int  ref_stride,
+//    int  *results)
+global sym(vp8_sad16x16x3_sse3)
+sym(vp8_sad16x16x3_sse3):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 5
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov             rsi,        arg(0) //src_ptr
+        mov             rdi,        arg(2) //ref_ptr
+
+        movsxd          rax,        dword ptr arg(1) //src_stride
+        movsxd          rdx,        dword ptr arg(3) //ref_stride
+
+        PROCESS_16X2X3 1
+        PROCESS_16X2X3 0
+        PROCESS_16X2X3 0
+        PROCESS_16X2X3 0
+        PROCESS_16X2X3 0
+        PROCESS_16X2X3 0
+        PROCESS_16X2X3 0
+        PROCESS_16X2X3 0
+
+        mov             rdi,        arg(4) //Results
+
+        movq            xmm0,       xmm5
+        psrldq          xmm5,       8
+
+        paddw           xmm0,       xmm5
+        movd            [rdi],      xmm0
+//-
+        movq            xmm0,       xmm6
+        psrldq          xmm6,       8
+
+        paddw           xmm0,       xmm6
+        movd            [rdi+4],    xmm0
+//-
+        movq            xmm0,       xmm7
+        psrldq          xmm7,       8
+
+        paddw           xmm0,       xmm7
+        movd            [rdi+8],    xmm0
+
+    // begin epilog
+    pop         rdi
+    pop         rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+//void int vp8_sad16x8x3_sse3(
+//    unsigned char *src_ptr,
+//    int  src_stride,
+//    unsigned char *ref_ptr,
+//    int  ref_stride,
+//    int  *results)
+global sym(vp8_sad16x8x3_sse3)
+sym(vp8_sad16x8x3_sse3):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 5
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov             rsi,        arg(0) //src_ptr
+        mov             rdi,        arg(2) //ref_ptr
+
+        movsxd          rax,        dword ptr arg(1) //src_stride
+        movsxd          rdx,        dword ptr arg(3) //ref_stride
+
+        PROCESS_16X2X3 1
+        PROCESS_16X2X3 0
+        PROCESS_16X2X3 0
+        PROCESS_16X2X3 0
+
+        mov             rdi,        arg(4) //Results
+
+        movq            xmm0,       xmm5
+        psrldq          xmm5,       8
+
+        paddw           xmm0,       xmm5
+        movd            [rdi],      xmm0
+//-
+        movq            xmm0,       xmm6
+        psrldq          xmm6,       8
+
+        paddw           xmm0,       xmm6
+        movd            [rdi+4],    xmm0
+//-
+        movq            xmm0,       xmm7
+        psrldq          xmm7,       8
+
+        paddw           xmm0,       xmm7
+        movd            [rdi+8],    xmm0
+
+    // begin epilog
+    pop         rdi
+    pop         rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+//void int vp8_sad8x16x3_sse3(
+//    unsigned char *src_ptr,
+//    int  src_stride,
+//    unsigned char *ref_ptr,
+//    int  ref_stride,
+//    int  *results)
+global sym(vp8_sad8x16x3_sse3)
+sym(vp8_sad8x16x3_sse3):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 5
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov             rsi,        arg(0) //src_ptr
+        mov             rdi,        arg(2) //ref_ptr
+
+        movsxd          rax,        dword ptr arg(1) //src_stride
+        movsxd          rdx,        dword ptr arg(3) //ref_stride
+
+        PROCESS_8X2X3 1
+        PROCESS_8X2X3 0
+        PROCESS_8X2X3 0
+        PROCESS_8X2X3 0
+        PROCESS_8X2X3 0
+        PROCESS_8X2X3 0
+        PROCESS_8X2X3 0
+        PROCESS_8X2X3 0
+
+        mov             rdi,        arg(4) //Results
+
+        movd            [rdi],      mm5
+        movd            [rdi+4],    mm6
+        movd            [rdi+8],    mm7
+
+    // begin epilog
+    pop         rdi
+    pop         rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+//void int vp8_sad8x8x3_sse3(
+//    unsigned char *src_ptr,
+//    int  src_stride,
+//    unsigned char *ref_ptr,
+//    int  ref_stride,
+//    int  *results)
+global sym(vp8_sad8x8x3_sse3)
+sym(vp8_sad8x8x3_sse3):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 5
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov             rsi,        arg(0) //src_ptr
+        mov             rdi,        arg(2) //ref_ptr
+
+        movsxd          rax,        dword ptr arg(1) //src_stride
+        movsxd          rdx,        dword ptr arg(3) //ref_stride
+
+        PROCESS_8X2X3 1
+        PROCESS_8X2X3 0
+        PROCESS_8X2X3 0
+        PROCESS_8X2X3 0
+
+        mov             rdi,        arg(4) //Results
+
+        movd            [rdi],      mm5
+        movd            [rdi+4],    mm6
+        movd            [rdi+8],    mm7
+
+    // begin epilog
+    pop         rdi
+    pop         rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+//void int vp8_sad4x4x3_sse3(
+//    unsigned char *src_ptr,
+//    int  src_stride,
+//    unsigned char *ref_ptr,
+//    int  ref_stride,
+//    int  *results)
+global sym(vp8_sad4x4x3_sse3)
+sym(vp8_sad4x4x3_sse3):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 5
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov             rsi,        arg(0) //src_ptr
+        mov             rdi,        arg(2) //ref_ptr
+
+        movsxd          rax,        dword ptr arg(1) //src_stride
+        movsxd          rdx,        dword ptr arg(3) //ref_stride
+
+        movd            mm0,        DWORD PTR [rsi]
+        movd            mm1,        DWORD PTR [rdi]
+
+        movd            mm2,        DWORD PTR [rsi+rax]
+        movd            mm3,        DWORD PTR [rdi+rdx]
+
+        punpcklbw       mm0,        mm2
+        punpcklbw       mm1,        mm3
+
+        movd            mm4,        DWORD PTR [rdi+1]
+        movd            mm5,        DWORD PTR [rdi+2]
+
+        movd            mm2,        DWORD PTR [rdi+rdx+1]
+        movd            mm3,        DWORD PTR [rdi+rdx+2]
+
+        psadbw          mm1,        mm0
+
+        punpcklbw       mm4,        mm2
+        punpcklbw       mm5,        mm3
+
+        psadbw          mm4,        mm0
+        psadbw          mm5,        mm0
+
+
+
+        lea             rsi,        [rsi+rax*2]
+        lea             rdi,        [rdi+rdx*2]
+
+        movd            mm0,        DWORD PTR [rsi]
+        movd            mm2,        DWORD PTR [rdi]
+
+        movd            mm3,        DWORD PTR [rsi+rax]
+        movd            mm6,        DWORD PTR [rdi+rdx]
+
+        punpcklbw       mm0,        mm3
+        punpcklbw       mm2,        mm6
+
+        movd            mm3,        DWORD PTR [rdi+1]
+        movd            mm7,        DWORD PTR [rdi+2]
+
+        psadbw          mm2,        mm0
+
+        paddw           mm1,        mm2
+
+        movd            mm2,        DWORD PTR [rdi+rdx+1]
+        movd            mm6,        DWORD PTR [rdi+rdx+2]
+
+        punpcklbw       mm3,        mm2
+        punpcklbw       mm7,        mm6
+
+        psadbw          mm3,        mm0
+        psadbw          mm7,        mm0
+
+        paddw           mm3,        mm4
+        paddw           mm7,        mm5
+
+        mov             rdi,        arg(4) //Results
+        movd            [rdi],      mm1
+
+        movd            [rdi+4],    mm3
+        movd            [rdi+8],    mm7
+
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+//unsigned int vp8_sad16x16_sse3(
+//    unsigned char *src_ptr,
+//    int  src_stride,
+//    unsigned char *ref_ptr,
+//    int  ref_stride,
+//    int  max_err)
+//#define lddqu movdqu
+global sym(vp8_sad16x16_sse3)
+sym(vp8_sad16x16_sse3):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 5
+    push        rbx
+    push        rsi
+    push        rdi
+    // end prolog
+
+        mov             rsi,        arg(0) //src_ptr
+        mov             rdi,        arg(2) //ref_ptr
+
+        movsxd          rbx,        dword ptr arg(1) //src_stride
+        movsxd          rdx,        dword ptr arg(3) //ref_stride
+
+        lea             rcx,        [rsi+rbx*8]
+
+        lea             rcx,        [rcx+rbx*8]
+        pxor            mm7,        mm7
+
+vp8_sad16x16_sse3_loop:
+
+        movd            rax,        mm7
+        cmp             rax,        arg(4)
+        jg              vp8_sad16x16_early_exit
+
+        movq            mm0,        QWORD PTR [rsi]
+        movq            mm2,        QWORD PTR [rsi+8]
+
+        movq            mm1,        QWORD PTR [rdi]
+        movq            mm3,        QWORD PTR [rdi+8]
+
+        movq            mm4,        QWORD PTR [rsi+rbx]
+        movq            mm5,        QWORD PTR [rdi+rdx]
+
+        psadbw          mm0,        mm1
+        psadbw          mm2,        mm3
+
+        movq            mm1,        QWORD PTR [rsi+rbx+8]
+        movq            mm3,        QWORD PTR [rdi+rdx+8]
+
+        psadbw          mm4,        mm5
+        psadbw          mm1,        mm3
+
+        lea             rsi,        [rsi+rbx*2]
+        lea             rdi,        [rdi+rdx*2]
+
+        paddw           mm0,        mm2
+        paddw           mm4,        mm1
+
+        paddw           mm7,        mm0
+        paddw           mm7,        mm4
+
+        cmp             rsi,        rcx
+        jne             vp8_sad16x16_sse3_loop
+
+        movd            rax,        mm7
+
+vp8_sad16x16_early_exit:
+
+    // begin epilog
+    pop         rdi
+    pop         rsi
+    pop         rbx
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+//void vp8_sad16x16x4d_sse3(
+//    unsigned char *src_ptr,
+//    int  src_stride,
+//    unsigned char *ref_ptr_base,
+//    int  ref_stride,
+//    int  *results)
+global sym(vp8_sad16x16x4d_sse3)
+sym(vp8_sad16x16x4d_sse3):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 5
+    push        rsi
+    push        rdi
+    push        rbx
+    // end prolog
+
+        push            rbp
+        mov             rdi,        arg(2) // ref_ptr_base
+
+        LOAD_X4_ADDRESSES rdi, rcx, rdx, rax, rdi
+
+        mov             rsi,        arg(0) //src_ptr
+
+        movsxd          rbx,        dword ptr arg(1) //src_stride
+        movsxd          rbp,        dword ptr arg(3) //ref_stride
+
+        xchg            rbx,        rax
+
+        PROCESS_16X2X4 1
+        PROCESS_16X2X4 0
+        PROCESS_16X2X4 0
+        PROCESS_16X2X4 0
+        PROCESS_16X2X4 0
+        PROCESS_16X2X4 0
+        PROCESS_16X2X4 0
+        PROCESS_16X2X4 0
+
+        pop             rbp
+        mov             rdi,        arg(4) //Results
+
+        movq            xmm0,       xmm4
+        psrldq          xmm4,       8
+
+        paddw           xmm0,       xmm4
+        movd            [rdi],      xmm0
+//-
+        movq            xmm0,       xmm5
+        psrldq          xmm5,       8
+
+        paddw           xmm0,       xmm5
+        movd            [rdi+4],    xmm0
+//-
+        movq            xmm0,       xmm6
+        psrldq          xmm6,       8
+
+        paddw           xmm0,       xmm6
+        movd            [rdi+8],    xmm0
+//-
+        movq            xmm0,       xmm7
+        psrldq          xmm7,       8
+
+        paddw           xmm0,       xmm7
+        movd            [rdi+12],   xmm0
+
+    // begin epilog
+    pop         rbx
+    pop         rdi
+    pop         rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+//void vp8_sad16x8x4d_sse3(
+//    unsigned char *src_ptr,
+//    int  src_stride,
+//    unsigned char *ref_ptr_base,
+//    int  ref_stride,
+//    int  *results)
+global sym(vp8_sad16x8x4d_sse3)
+sym(vp8_sad16x8x4d_sse3):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 5
+    push        rsi
+    push        rdi
+    push        rbx
+    // end prolog
+
+        push            rbp
+        mov             rdi,        arg(2) // ref_ptr_base
+
+        LOAD_X4_ADDRESSES rdi, rcx, rdx, rax, rdi
+
+        mov             rsi,        arg(0) //src_ptr
+
+        movsxd          rbx,        dword ptr arg(1) //src_stride
+        movsxd          rbp,        dword ptr arg(3) //ref_stride
+
+        xchg            rbx,        rax
+
+        PROCESS_16X2X4 1
+        PROCESS_16X2X4 0
+        PROCESS_16X2X4 0
+        PROCESS_16X2X4 0
+
+        pop             rbp
+        mov             rdi,        arg(4) //Results
+
+        movq            xmm0,       xmm4
+        psrldq          xmm4,       8
+
+        paddw           xmm0,       xmm4
+        movd            [rdi],      xmm0
+//-
+        movq            xmm0,       xmm5
+        psrldq          xmm5,       8
+
+        paddw           xmm0,       xmm5
+        movd            [rdi+4],    xmm0
+//-
+        movq            xmm0,       xmm6
+        psrldq          xmm6,       8
+
+        paddw           xmm0,       xmm6
+        movd            [rdi+8],    xmm0
+//-
+        movq            xmm0,       xmm7
+        psrldq          xmm7,       8
+
+        paddw           xmm0,       xmm7
+        movd            [rdi+12],   xmm0
+
+    // begin epilog
+    pop         rbx
+    pop         rdi
+    pop         rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+//void int vp8_sad8x16x4d_sse3(
+//    unsigned char *src_ptr,
+//    int  src_stride,
+//    unsigned char *ref_ptr,
+//    int  ref_stride,
+//    int  *results)
+global sym(vp8_sad8x16x4d_sse3)
+sym(vp8_sad8x16x4d_sse3):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 5
+    push        rsi
+    push        rdi
+    push        rbx
+    // end prolog
+
+        push            rbp
+        mov             rdi,        arg(2) // ref_ptr_base
+
+        LOAD_X4_ADDRESSES rdi, rcx, rdx, rax, rdi
+
+        mov             rsi,        arg(0) //src_ptr
+
+        movsxd          rbx,        dword ptr arg(1) //src_stride
+        movsxd          rbp,        dword ptr arg(3) //ref_stride
+
+        xchg            rbx,        rax
+
+        PROCESS_8X2X4 1
+        PROCESS_8X2X4 0
+        PROCESS_8X2X4 0
+        PROCESS_8X2X4 0
+        PROCESS_8X2X4 0
+        PROCESS_8X2X4 0
+        PROCESS_8X2X4 0
+        PROCESS_8X2X4 0
+
+        pop             rbp
+        mov             rdi,        arg(4) //Results
+
+        movd            [rdi],      mm4
+        movd            [rdi+4],    mm5
+        movd            [rdi+8],    mm6
+        movd            [rdi+12],   mm7
+
+    // begin epilog
+    pop         rbx
+    pop         rdi
+    pop         rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+//void int vp8_sad8x8x4d_sse3(
+//    unsigned char *src_ptr,
+//    int  src_stride,
+//    unsigned char *ref_ptr,
+//    int  ref_stride,
+//    int  *results)
+global sym(vp8_sad8x8x4d_sse3)
+sym(vp8_sad8x8x4d_sse3):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 5
+    push        rsi
+    push        rdi
+    push        rbx
+    // end prolog
+
+        push            rbp
+        mov             rdi,        arg(2) // ref_ptr_base
+
+        LOAD_X4_ADDRESSES rdi, rcx, rdx, rax, rdi
+
+        mov             rsi,        arg(0) //src_ptr
+
+        movsxd          rbx,        dword ptr arg(1) //src_stride
+        movsxd          rbp,        dword ptr arg(3) //ref_stride
+
+        xchg            rbx,        rax
+
+        PROCESS_8X2X4 1
+        PROCESS_8X2X4 0
+        PROCESS_8X2X4 0
+        PROCESS_8X2X4 0
+
+        pop             rbp
+        mov             rdi,        arg(4) //Results
+
+        movd            [rdi],      mm4
+        movd            [rdi+4],    mm5
+        movd            [rdi+8],    mm6
+        movd            [rdi+12],   mm7
+
+    // begin epilog
+    pop         rbx
+    pop         rdi
+    pop         rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+//void int vp8_sad4x4x4d_sse3(
+//    unsigned char *src_ptr,
+//    int  src_stride,
+//    unsigned char *ref_ptr,
+//    int  ref_stride,
+//    int  *results)
+global sym(vp8_sad4x4x4d_sse3)
+sym(vp8_sad4x4x4d_sse3):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 5
+    push        rsi
+    push        rdi
+    push        rbx
+    // end prolog
+
+        push            rbp
+        mov             rdi,        arg(2) // ref_ptr_base
+
+        LOAD_X4_ADDRESSES rdi, rcx, rdx, rax, rdi
+
+        mov             rsi,        arg(0) //src_ptr
+
+        movsxd          rbx,        dword ptr arg(1) //src_stride
+        movsxd          rbp,        dword ptr arg(3) //ref_stride
+
+        xchg            rbx,        rax
+
+        movd            mm0,        DWORD PTR [rsi]
+        movd            mm1,        DWORD PTR [rcx]
+
+        movd            mm2,        DWORD PTR [rsi+rax]
+        movd            mm3,        DWORD PTR [rcx+rbp]
+
+        punpcklbw       mm0,        mm2
+        punpcklbw       mm1,        mm3
+
+        movd            mm4,        DWORD PTR [rdx]
+        movd            mm5,        DWORD PTR [rbx]
+
+        movd            mm6,        DWORD PTR [rdi]
+        movd            mm2,        DWORD PTR [rdx+rbp]
+
+        movd            mm3,        DWORD PTR [rbx+rbp]
+        movd            mm7,        DWORD PTR [rdi+rbp]
+
+        psadbw          mm1,        mm0
+
+        punpcklbw       mm4,        mm2
+        punpcklbw       mm5,        mm3
+
+        punpcklbw       mm6,        mm7
+        psadbw          mm4,        mm0
+
+        psadbw          mm5,        mm0
+        psadbw          mm6,        mm0
+
+
+
+        lea             rsi,        [rsi+rax*2]
+        lea             rcx,        [rcx+rbp*2]
+
+        lea             rdx,        [rdx+rbp*2]
+        lea             rbx,        [rbx+rbp*2]
+
+        lea             rdi,        [rdi+rbp*2]
+
+        movd            mm0,        DWORD PTR [rsi]
+        movd            mm2,        DWORD PTR [rcx]
+
+        movd            mm3,        DWORD PTR [rsi+rax]
+        movd            mm7,        DWORD PTR [rcx+rbp]
+
+        punpcklbw       mm0,        mm3
+        punpcklbw       mm2,        mm7
+
+        movd            mm3,        DWORD PTR [rdx]
+        movd            mm7,        DWORD PTR [rbx]
+
+        psadbw          mm2,        mm0
+        mov             rax,        rbp
+
+        pop             rbp
+        mov             rsi,        arg(4) //Results
+
+        paddw           mm1,        mm2
+        movd            [rsi],      mm1
+
+        movd            mm2,        DWORD PTR [rdx+rax]
+        movd            mm1,        DWORD PTR [rbx+rax]
+
+        punpcklbw       mm3,        mm2
+        punpcklbw       mm7,        mm1
+
+        psadbw          mm3,        mm0
+        psadbw          mm7,        mm0
+
+        movd            mm2,        DWORD PTR [rdi]
+        movd            mm1,        DWORD PTR [rdi+rax]
+
+        paddw           mm3,        mm4
+        paddw           mm7,        mm5
+
+        movd            [rsi+4],    mm3
+        punpcklbw       mm2,        mm1
+
+        movd            [rsi+8],    mm7
+        psadbw          mm2,        mm0
+
+        paddw           mm2,        mm6
+        movd            [rsi+12],   mm2
+
+
+    // begin epilog
+    pop         rbx
+    pop         rdi
+    pop         rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
diff --git a/vp8/encoder/x86/sad_sse3.asm b/vp8/encoder/x86/sad_sse3.asm
deleted file mode 100644
index 38cc029..0000000
--- a/vp8/encoder/x86/sad_sse3.asm
+++ /dev/null
@@ -1,939 +0,0 @@
-;
-;  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
-;
-;  Use of this source code is governed by a BSD-style license and patent
-;  grant that can be found in the LICENSE file in the root of the source
-;  tree. All contributing project authors may be found in the AUTHORS
-;  file in the root of the source tree.
-;
-
-
-%include "vpx_ports/x86_abi_support.asm"
-
-%idefine QWORD
-
-%macro PROCESS_16X2X3 1
-%if %1
-        movdqa          xmm0,       [rsi]
-        lddqu           xmm5,       [rdi]
-        lddqu           xmm6,       [rdi+1]
-        lddqu           xmm7,       [rdi+2]
-
-        psadbw          xmm5,       xmm0
-        psadbw          xmm6,       xmm0
-        psadbw          xmm7,       xmm0
-%else
-        movdqa          xmm0,       [rsi]
-        lddqu           xmm1,       [rdi]
-        lddqu           xmm2,       [rdi+1]
-        lddqu           xmm3,       [rdi+2]
-
-        psadbw          xmm1,       xmm0
-        psadbw          xmm2,       xmm0
-        psadbw          xmm3,       xmm0
-
-        paddw           xmm5,       xmm1
-        paddw           xmm6,       xmm2
-        paddw           xmm7,       xmm3
-%endif
-        movdqa          xmm0,       QWORD PTR [rsi+rax]
-        lddqu           xmm1,       QWORD PTR [rdi+rdx]
-        lddqu           xmm2,       QWORD PTR [rdi+rdx+1]
-        lddqu           xmm3,       QWORD PTR [rdi+rdx+2]
-
-        lea             rsi,        [rsi+rax*2]
-        lea             rdi,        [rdi+rdx*2]
-
-        psadbw          xmm1,       xmm0
-        psadbw          xmm2,       xmm0
-        psadbw          xmm3,       xmm0
-
-        paddw           xmm5,       xmm1
-        paddw           xmm6,       xmm2
-        paddw           xmm7,       xmm3
-%endmacro
-
-%macro PROCESS_8X2X3 1
-%if %1
-        movq            mm0,       [rsi]
-        movq            mm5,       [rdi]
-        movq            mm6,       [rdi+1]
-        movq            mm7,       [rdi+2]
-
-        psadbw          mm5,       mm0
-        psadbw          mm6,       mm0
-        psadbw          mm7,       mm0
-%else
-        movq            mm0,       [rsi]
-        movq            mm1,       [rdi]
-        movq            mm2,       [rdi+1]
-        movq            mm3,       [rdi+2]
-
-        psadbw          mm1,       mm0
-        psadbw          mm2,       mm0
-        psadbw          mm3,       mm0
-
-        paddw           mm5,       mm1
-        paddw           mm6,       mm2
-        paddw           mm7,       mm3
-%endif
-        movq            mm0,       QWORD PTR [rsi+rax]
-        movq            mm1,       QWORD PTR [rdi+rdx]
-        movq            mm2,       QWORD PTR [rdi+rdx+1]
-        movq            mm3,       QWORD PTR [rdi+rdx+2]
-
-        lea             rsi,       [rsi+rax*2]
-        lea             rdi,       [rdi+rdx*2]
-
-        psadbw          mm1,       mm0
-        psadbw          mm2,       mm0
-        psadbw          mm3,       mm0
-
-        paddw           mm5,       mm1
-        paddw           mm6,       mm2
-        paddw           mm7,       mm3
-%endmacro
-
-%macro LOAD_X4_ADDRESSES 5
-        mov             %2,         [%1+REG_SZ_BYTES*0]
-        mov             %3,         [%1+REG_SZ_BYTES*1]
-
-        mov             %4,         [%1+REG_SZ_BYTES*2]
-        mov             %5,         [%1+REG_SZ_BYTES*3]
-%endmacro
-
-%macro PROCESS_16X2X4 1
-%if %1
-        movdqa          xmm0,       [rsi]
-        lddqu           xmm4,       [rcx]
-        lddqu           xmm5,       [rdx]
-        lddqu           xmm6,       [rbx]
-        lddqu           xmm7,       [rdi]
-
-        psadbw          xmm4,       xmm0
-        psadbw          xmm5,       xmm0
-        psadbw          xmm6,       xmm0
-        psadbw          xmm7,       xmm0
-%else
-        movdqa          xmm0,       [rsi]
-        lddqu           xmm1,       [rcx]
-        lddqu           xmm2,       [rdx]
-        lddqu           xmm3,       [rbx]
-
-        psadbw          xmm1,       xmm0
-        psadbw          xmm2,       xmm0
-        psadbw          xmm3,       xmm0
-
-        paddw           xmm4,       xmm1
-        lddqu           xmm1,       [rdi]
-        paddw           xmm5,       xmm2
-        paddw           xmm6,       xmm3
-
-        psadbw          xmm1,       xmm0
-        paddw           xmm7,       xmm1
-%endif
-        movdqa          xmm0,       QWORD PTR [rsi+rax]
-        lddqu           xmm1,       QWORD PTR [rcx+rbp]
-        lddqu           xmm2,       QWORD PTR [rdx+rbp]
-        lddqu           xmm3,       QWORD PTR [rbx+rbp]
-
-        psadbw          xmm1,       xmm0
-        psadbw          xmm2,       xmm0
-        psadbw          xmm3,       xmm0
-
-        paddw           xmm4,       xmm1
-        lddqu           xmm1,       QWORD PTR [rdi+rbp]
-        paddw           xmm5,       xmm2
-        paddw           xmm6,       xmm3
-
-        lea             rsi,        [rsi+rax*2]
-        lea             rcx,        [rcx+rbp*2]
-
-        lea             rdx,        [rdx+rbp*2]
-        lea             rbx,        [rbx+rbp*2]
-
-        lea             rdi,        [rdi+rbp*2]
-
-        psadbw          xmm1,       xmm0
-        paddw           xmm7,       xmm1
-
-%endmacro
-
-%macro PROCESS_8X2X4 1
-%if %1
-        movq            mm0,        [rsi]
-        movq            mm4,        [rcx]
-        movq            mm5,        [rdx]
-        movq            mm6,        [rbx]
-        movq            mm7,        [rdi]
-
-        psadbw          mm4,        mm0
-        psadbw          mm5,        mm0
-        psadbw          mm6,        mm0
-        psadbw          mm7,        mm0
-%else
-        movq            mm0,        [rsi]
-        movq            mm1,        [rcx]
-        movq            mm2,        [rdx]
-        movq            mm3,        [rbx]
-
-        psadbw          mm1,        mm0
-        psadbw          mm2,        mm0
-        psadbw          mm3,        mm0
-
-        paddw           mm4,        mm1
-        movq            mm1,        [rdi]
-        paddw           mm5,        mm2
-        paddw           mm6,        mm3
-
-        psadbw          mm1,        mm0
-        paddw           mm7,        mm1
-%endif
-        movq            mm0,        QWORD PTR [rsi+rax]
-        movq            mm1,        QWORD PTR [rcx+rbp]
-        movq            mm2,        QWORD PTR [rdx+rbp]
-        movq            mm3,        QWORD PTR [rbx+rbp]
-
-        psadbw          mm1,        mm0
-        psadbw          mm2,        mm0
-        psadbw          mm3,        mm0
-
-        paddw           mm4,        mm1
-        movq            mm1,        QWORD PTR [rdi+rbp]
-        paddw           mm5,        mm2
-        paddw           mm6,        mm3
-
-        lea             rsi,        [rsi+rax*2]
-        lea             rcx,        [rcx+rbp*2]
-
-        lea             rdx,        [rdx+rbp*2]
-        lea             rbx,        [rbx+rbp*2]
-
-        lea             rdi,        [rdi+rbp*2]
-
-        psadbw          mm1,        mm0
-        paddw           mm7,        mm1
-
-%endmacro
-
-;void int vp8_sad16x16x3_sse3(
-;    unsigned char *src_ptr,
-;    int  src_stride,
-;    unsigned char *ref_ptr,
-;    int  ref_stride,
-;    int  *results)
-global sym(vp8_sad16x16x3_sse3)
-sym(vp8_sad16x16x3_sse3):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 5
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov             rsi,        arg(0) ;src_ptr
-        mov             rdi,        arg(2) ;ref_ptr
-
-        movsxd          rax,        dword ptr arg(1) ;src_stride
-        movsxd          rdx,        dword ptr arg(3) ;ref_stride
-
-        PROCESS_16X2X3 1
-        PROCESS_16X2X3 0
-        PROCESS_16X2X3 0
-        PROCESS_16X2X3 0
-        PROCESS_16X2X3 0
-        PROCESS_16X2X3 0
-        PROCESS_16X2X3 0
-        PROCESS_16X2X3 0
-
-        mov             rdi,        arg(4) ;Results
-
-        movq            xmm0,       xmm5
-        psrldq          xmm5,       8
-
-        paddw           xmm0,       xmm5
-        movd            [rdi],      xmm0
-;-
-        movq            xmm0,       xmm6
-        psrldq          xmm6,       8
-
-        paddw           xmm0,       xmm6
-        movd            [rdi+4],    xmm0
-;-
-        movq            xmm0,       xmm7
-        psrldq          xmm7,       8
-
-        paddw           xmm0,       xmm7
-        movd            [rdi+8],    xmm0
-
-    ; begin epilog
-    pop         rdi
-    pop         rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-;void int vp8_sad16x8x3_sse3(
-;    unsigned char *src_ptr,
-;    int  src_stride,
-;    unsigned char *ref_ptr,
-;    int  ref_stride,
-;    int  *results)
-global sym(vp8_sad16x8x3_sse3)
-sym(vp8_sad16x8x3_sse3):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 5
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov             rsi,        arg(0) ;src_ptr
-        mov             rdi,        arg(2) ;ref_ptr
-
-        movsxd          rax,        dword ptr arg(1) ;src_stride
-        movsxd          rdx,        dword ptr arg(3) ;ref_stride
-
-        PROCESS_16X2X3 1
-        PROCESS_16X2X3 0
-        PROCESS_16X2X3 0
-        PROCESS_16X2X3 0
-
-        mov             rdi,        arg(4) ;Results
-
-        movq            xmm0,       xmm5
-        psrldq          xmm5,       8
-
-        paddw           xmm0,       xmm5
-        movd            [rdi],      xmm0
-;-
-        movq            xmm0,       xmm6
-        psrldq          xmm6,       8
-
-        paddw           xmm0,       xmm6
-        movd            [rdi+4],    xmm0
-;-
-        movq            xmm0,       xmm7
-        psrldq          xmm7,       8
-
-        paddw           xmm0,       xmm7
-        movd            [rdi+8],    xmm0
-
-    ; begin epilog
-    pop         rdi
-    pop         rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-;void int vp8_sad8x16x3_sse3(
-;    unsigned char *src_ptr,
-;    int  src_stride,
-;    unsigned char *ref_ptr,
-;    int  ref_stride,
-;    int  *results)
-global sym(vp8_sad8x16x3_sse3)
-sym(vp8_sad8x16x3_sse3):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 5
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov             rsi,        arg(0) ;src_ptr
-        mov             rdi,        arg(2) ;ref_ptr
-
-        movsxd          rax,        dword ptr arg(1) ;src_stride
-        movsxd          rdx,        dword ptr arg(3) ;ref_stride
-
-        PROCESS_8X2X3 1
-        PROCESS_8X2X3 0
-        PROCESS_8X2X3 0
-        PROCESS_8X2X3 0
-        PROCESS_8X2X3 0
-        PROCESS_8X2X3 0
-        PROCESS_8X2X3 0
-        PROCESS_8X2X3 0
-
-        mov             rdi,        arg(4) ;Results
-
-        movd            [rdi],      mm5
-        movd            [rdi+4],    mm6
-        movd            [rdi+8],    mm7
-
-    ; begin epilog
-    pop         rdi
-    pop         rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-;void int vp8_sad8x8x3_sse3(
-;    unsigned char *src_ptr,
-;    int  src_stride,
-;    unsigned char *ref_ptr,
-;    int  ref_stride,
-;    int  *results)
-global sym(vp8_sad8x8x3_sse3)
-sym(vp8_sad8x8x3_sse3):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 5
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov             rsi,        arg(0) ;src_ptr
-        mov             rdi,        arg(2) ;ref_ptr
-
-        movsxd          rax,        dword ptr arg(1) ;src_stride
-        movsxd          rdx,        dword ptr arg(3) ;ref_stride
-
-        PROCESS_8X2X3 1
-        PROCESS_8X2X3 0
-        PROCESS_8X2X3 0
-        PROCESS_8X2X3 0
-
-        mov             rdi,        arg(4) ;Results
-
-        movd            [rdi],      mm5
-        movd            [rdi+4],    mm6
-        movd            [rdi+8],    mm7
-
-    ; begin epilog
-    pop         rdi
-    pop         rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-;void int vp8_sad4x4x3_sse3(
-;    unsigned char *src_ptr,
-;    int  src_stride,
-;    unsigned char *ref_ptr,
-;    int  ref_stride,
-;    int  *results)
-global sym(vp8_sad4x4x3_sse3)
-sym(vp8_sad4x4x3_sse3):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 5
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov             rsi,        arg(0) ;src_ptr
-        mov             rdi,        arg(2) ;ref_ptr
-
-        movsxd          rax,        dword ptr arg(1) ;src_stride
-        movsxd          rdx,        dword ptr arg(3) ;ref_stride
-
-        movd            mm0,        QWORD PTR [rsi]
-        movd            mm1,        QWORD PTR [rdi]
-
-        movd            mm2,        QWORD PTR [rsi+rax]
-        movd            mm3,        QWORD PTR [rdi+rdx]
-
-        punpcklbw       mm0,        mm2
-        punpcklbw       mm1,        mm3
-
-        movd            mm4,        QWORD PTR [rdi+1]
-        movd            mm5,        QWORD PTR [rdi+2]
-
-        movd            mm2,        QWORD PTR [rdi+rdx+1]
-        movd            mm3,        QWORD PTR [rdi+rdx+2]
-
-        psadbw          mm1,        mm0
-
-        punpcklbw       mm4,        mm2
-        punpcklbw       mm5,        mm3
-
-        psadbw          mm4,        mm0
-        psadbw          mm5,        mm0
-
-
-
-        lea             rsi,        [rsi+rax*2]
-        lea             rdi,        [rdi+rdx*2]
-
-        movd            mm0,        QWORD PTR [rsi]
-        movd            mm2,        QWORD PTR [rdi]
-
-        movd            mm3,        QWORD PTR [rsi+rax]
-        movd            mm6,        QWORD PTR [rdi+rdx]
-
-        punpcklbw       mm0,        mm3
-        punpcklbw       mm2,        mm6
-
-        movd            mm3,        QWORD PTR [rdi+1]
-        movd            mm7,        QWORD PTR [rdi+2]
-
-        psadbw          mm2,        mm0
-
-        paddw           mm1,        mm2
-
-        movd            mm2,        QWORD PTR [rdi+rdx+1]
-        movd            mm6,        QWORD PTR [rdi+rdx+2]
-
-        punpcklbw       mm3,        mm2
-        punpcklbw       mm7,        mm6
-
-        psadbw          mm3,        mm0
-        psadbw          mm7,        mm0
-
-        paddw           mm3,        mm4
-        paddw           mm7,        mm5
-
-        mov             rdi,        arg(4) ;Results
-        movd            [rdi],      mm1
-
-        movd            [rdi+4],    mm3
-        movd            [rdi+8],    mm7
-
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-;unsigned int vp8_sad16x16_sse3(
-;    unsigned char *src_ptr,
-;    int  src_stride,
-;    unsigned char *ref_ptr,
-;    int  ref_stride,
-;    int  max_err)
-;%define lddqu movdqu
-global sym(vp8_sad16x16_sse3)
-sym(vp8_sad16x16_sse3):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 5
-    push        rbx
-    push        rsi
-    push        rdi
-    ; end prolog
-
-        mov             rsi,        arg(0) ;src_ptr
-        mov             rdi,        arg(2) ;ref_ptr
-
-        movsxd          rbx,        dword ptr arg(1) ;src_stride
-        movsxd          rdx,        dword ptr arg(3) ;ref_stride
-
-        lea             rcx,        [rsi+rbx*8]
-
-        lea             rcx,        [rcx+rbx*8]
-        pxor            mm7,        mm7
-
-vp8_sad16x16_sse3_loop:
-
-        movd            rax,        mm7
-        cmp             rax,        arg(4)
-        jg              vp8_sad16x16_early_exit
-
-        movq            mm0,        QWORD PTR [rsi]
-        movq            mm2,        QWORD PTR [rsi+8]
-
-        movq            mm1,        QWORD PTR [rdi]
-        movq            mm3,        QWORD PTR [rdi+8]
-
-        movq            mm4,        QWORD PTR [rsi+rbx]
-        movq            mm5,        QWORD PTR [rdi+rdx]
-
-        psadbw          mm0,        mm1
-        psadbw          mm2,        mm3
-
-        movq            mm1,        QWORD PTR [rsi+rbx+8]
-        movq            mm3,        QWORD PTR [rdi+rdx+8]
-
-        psadbw          mm4,        mm5
-        psadbw          mm1,        mm3
-
-        lea             rsi,        [rsi+rbx*2]
-        lea             rdi,        [rdi+rdx*2]
-
-        paddw           mm0,        mm2
-        paddw           mm4,        mm1
-
-        paddw           mm7,        mm0
-        paddw           mm7,        mm4
-
-        cmp             rsi,        rcx
-        jne             vp8_sad16x16_sse3_loop
-
-        movd            rax,        mm7
-
-vp8_sad16x16_early_exit:
-
-    ; begin epilog
-    pop         rdi
-    pop         rsi
-    pop         rbx
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-;void vp8_sad16x16x4d_sse3(
-;    unsigned char *src_ptr,
-;    int  src_stride,
-;    unsigned char *ref_ptr_base,
-;    int  ref_stride,
-;    int  *results)
-global sym(vp8_sad16x16x4d_sse3)
-sym(vp8_sad16x16x4d_sse3):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 5
-    push        rsi
-    push        rdi
-    push        rbx
-    ; end prolog
-
-        push            rbp
-        mov             rdi,        arg(2) ; ref_ptr_base
-
-        LOAD_X4_ADDRESSES rdi, rcx, rdx, rax, rdi
-
-        mov             rsi,        arg(0) ;src_ptr
-
-        movsxd          rbx,        dword ptr arg(1) ;src_stride
-        movsxd          rbp,        dword ptr arg(3) ;ref_stride
-
-        xchg            rbx,        rax
-
-        PROCESS_16X2X4 1
-        PROCESS_16X2X4 0
-        PROCESS_16X2X4 0
-        PROCESS_16X2X4 0
-        PROCESS_16X2X4 0
-        PROCESS_16X2X4 0
-        PROCESS_16X2X4 0
-        PROCESS_16X2X4 0
-
-        pop             rbp
-        mov             rdi,        arg(4) ;Results
-
-        movq            xmm0,       xmm4
-        psrldq          xmm4,       8
-
-        paddw           xmm0,       xmm4
-        movd            [rdi],      xmm0
-;-
-        movq            xmm0,       xmm5
-        psrldq          xmm5,       8
-
-        paddw           xmm0,       xmm5
-        movd            [rdi+4],    xmm0
-;-
-        movq            xmm0,       xmm6
-        psrldq          xmm6,       8
-
-        paddw           xmm0,       xmm6
-        movd            [rdi+8],    xmm0
-;-
-        movq            xmm0,       xmm7
-        psrldq          xmm7,       8
-
-        paddw           xmm0,       xmm7
-        movd            [rdi+12],   xmm0
-
-    ; begin epilog
-    pop         rbx
-    pop         rdi
-    pop         rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-;void vp8_sad16x8x4d_sse3(
-;    unsigned char *src_ptr,
-;    int  src_stride,
-;    unsigned char *ref_ptr_base,
-;    int  ref_stride,
-;    int  *results)
-global sym(vp8_sad16x8x4d_sse3)
-sym(vp8_sad16x8x4d_sse3):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 5
-    push        rsi
-    push        rdi
-    push        rbx
-    ; end prolog
-
-        push            rbp
-        mov             rdi,        arg(2) ; ref_ptr_base
-
-        LOAD_X4_ADDRESSES rdi, rcx, rdx, rax, rdi
-
-        mov             rsi,        arg(0) ;src_ptr
-
-        movsxd          rbx,        dword ptr arg(1) ;src_stride
-        movsxd          rbp,        dword ptr arg(3) ;ref_stride
-
-        xchg            rbx,        rax
-
-        PROCESS_16X2X4 1
-        PROCESS_16X2X4 0
-        PROCESS_16X2X4 0
-        PROCESS_16X2X4 0
-
-        pop             rbp
-        mov             rdi,        arg(4) ;Results
-
-        movq            xmm0,       xmm4
-        psrldq          xmm4,       8
-
-        paddw           xmm0,       xmm4
-        movd            [rdi],      xmm0
-;-
-        movq            xmm0,       xmm5
-        psrldq          xmm5,       8
-
-        paddw           xmm0,       xmm5
-        movd            [rdi+4],    xmm0
-;-
-        movq            xmm0,       xmm6
-        psrldq          xmm6,       8
-
-        paddw           xmm0,       xmm6
-        movd            [rdi+8],    xmm0
-;-
-        movq            xmm0,       xmm7
-        psrldq          xmm7,       8
-
-        paddw           xmm0,       xmm7
-        movd            [rdi+12],   xmm0
-
-    ; begin epilog
-    pop         rbx
-    pop         rdi
-    pop         rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-;void int vp8_sad8x16x4d_sse3(
-;    unsigned char *src_ptr,
-;    int  src_stride,
-;    unsigned char *ref_ptr,
-;    int  ref_stride,
-;    int  *results)
-global sym(vp8_sad8x16x4d_sse3)
-sym(vp8_sad8x16x4d_sse3):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 5
-    push        rsi
-    push        rdi
-    push        rbx
-    ; end prolog
-
-        push            rbp
-        mov             rdi,        arg(2) ; ref_ptr_base
-
-        LOAD_X4_ADDRESSES rdi, rcx, rdx, rax, rdi
-
-        mov             rsi,        arg(0) ;src_ptr
-
-        movsxd          rbx,        dword ptr arg(1) ;src_stride
-        movsxd          rbp,        dword ptr arg(3) ;ref_stride
-
-        xchg            rbx,        rax
-
-        PROCESS_8X2X4 1
-        PROCESS_8X2X4 0
-        PROCESS_8X2X4 0
-        PROCESS_8X2X4 0
-        PROCESS_8X2X4 0
-        PROCESS_8X2X4 0
-        PROCESS_8X2X4 0
-        PROCESS_8X2X4 0
-
-        pop             rbp
-        mov             rdi,        arg(4) ;Results
-
-        movd            [rdi],      mm4
-        movd            [rdi+4],    mm5
-        movd            [rdi+8],    mm6
-        movd            [rdi+12],   mm7
-
-    ; begin epilog
-    pop         rbx
-    pop         rdi
-    pop         rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-;void int vp8_sad8x8x4d_sse3(
-;    unsigned char *src_ptr,
-;    int  src_stride,
-;    unsigned char *ref_ptr,
-;    int  ref_stride,
-;    int  *results)
-global sym(vp8_sad8x8x4d_sse3)
-sym(vp8_sad8x8x4d_sse3):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 5
-    push        rsi
-    push        rdi
-    push        rbx
-    ; end prolog
-
-        push            rbp
-        mov             rdi,        arg(2) ; ref_ptr_base
-
-        LOAD_X4_ADDRESSES rdi, rcx, rdx, rax, rdi
-
-        mov             rsi,        arg(0) ;src_ptr
-
-        movsxd          rbx,        dword ptr arg(1) ;src_stride
-        movsxd          rbp,        dword ptr arg(3) ;ref_stride
-
-        xchg            rbx,        rax
-
-        PROCESS_8X2X4 1
-        PROCESS_8X2X4 0
-        PROCESS_8X2X4 0
-        PROCESS_8X2X4 0
-
-        pop             rbp
-        mov             rdi,        arg(4) ;Results
-
-        movd            [rdi],      mm4
-        movd            [rdi+4],    mm5
-        movd            [rdi+8],    mm6
-        movd            [rdi+12],   mm7
-
-    ; begin epilog
-    pop         rbx
-    pop         rdi
-    pop         rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-;void int vp8_sad4x4x4d_sse3(
-;    unsigned char *src_ptr,
-;    int  src_stride,
-;    unsigned char *ref_ptr,
-;    int  ref_stride,
-;    int  *results)
-global sym(vp8_sad4x4x4d_sse3)
-sym(vp8_sad4x4x4d_sse3):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 5
-    push        rsi
-    push        rdi
-    push        rbx
-    ; end prolog
-
-        push            rbp
-        mov             rdi,        arg(2) ; ref_ptr_base
-
-        LOAD_X4_ADDRESSES rdi, rcx, rdx, rax, rdi
-
-        mov             rsi,        arg(0) ;src_ptr
-
-        movsxd          rbx,        dword ptr arg(1) ;src_stride
-        movsxd          rbp,        dword ptr arg(3) ;ref_stride
-
-        xchg            rbx,        rax
-
-        movd            mm0,        QWORD PTR [rsi]
-        movd            mm1,        QWORD PTR [rcx]
-
-        movd            mm2,        QWORD PTR [rsi+rax]
-        movd            mm3,        QWORD PTR [rcx+rbp]
-
-        punpcklbw       mm0,        mm2
-        punpcklbw       mm1,        mm3
-
-        movd            mm4,        QWORD PTR [rdx]
-        movd            mm5,        QWORD PTR [rbx]
-
-        movd            mm6,        QWORD PTR [rdi]
-        movd            mm2,        QWORD PTR [rdx+rbp]
-
-        movd            mm3,        QWORD PTR [rbx+rbp]
-        movd            mm7,        QWORD PTR [rdi+rbp]
-
-        psadbw          mm1,        mm0
-
-        punpcklbw       mm4,        mm2
-        punpcklbw       mm5,        mm3
-
-        punpcklbw       mm6,        mm7
-        psadbw          mm4,        mm0
-
-        psadbw          mm5,        mm0
-        psadbw          mm6,        mm0
-
-
-
-        lea             rsi,        [rsi+rax*2]
-        lea             rcx,        [rcx+rbp*2]
-
-        lea             rdx,        [rdx+rbp*2]
-        lea             rbx,        [rbx+rbp*2]
-
-        lea             rdi,        [rdi+rbp*2]
-
-        movd            mm0,        QWORD PTR [rsi]
-        movd            mm2,        QWORD PTR [rcx]
-
-        movd            mm3,        QWORD PTR [rsi+rax]
-        movd            mm7,        QWORD PTR [rcx+rbp]
-
-        punpcklbw       mm0,        mm3
-        punpcklbw       mm2,        mm7
-
-        movd            mm3,        QWORD PTR [rdx]
-        movd            mm7,        QWORD PTR [rbx]
-
-        psadbw          mm2,        mm0
-        mov             rax,        rbp
-
-        pop             rbp
-        mov             rsi,        arg(4) ;Results
-
-        paddw           mm1,        mm2
-        movd            [rsi],      mm1
-
-        movd            mm2,        QWORD PTR [rdx+rax]
-        movd            mm1,        QWORD PTR [rbx+rax]
-
-        punpcklbw       mm3,        mm2
-        punpcklbw       mm7,        mm1
-
-        psadbw          mm3,        mm0
-        psadbw          mm7,        mm0
-
-        movd            mm2,        QWORD PTR [rdi]
-        movd            mm1,        QWORD PTR [rdi+rax]
-
-        paddw           mm3,        mm4
-        paddw           mm7,        mm5
-
-        movd            [rsi+4],    mm3
-        punpcklbw       mm2,        mm1
-
-        movd            [rsi+8],    mm7
-        psadbw          mm2,        mm0
-
-        paddw           mm2,        mm6
-        movd            [rsi+12],   mm2
-
-
-    ; begin epilog
-    pop         rbx
-    pop         rdi
-    pop         rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
diff --git a/vp8/encoder/x86/sad_ssse3.S b/vp8/encoder/x86/sad_ssse3.S
new file mode 100644
index 0000000..746ab05
--- /dev/null
+++ b/vp8/encoder/x86/sad_ssse3.S
@@ -0,0 +1,363 @@
+//
+//  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
+//
+//  Use of this source code is governed by a BSD-style license and patent
+//  grant that can be found in the LICENSE file in the root of the source
+//  tree. All contributing project authors may be found in the AUTHORS
+//  file in the root of the source tree.
+//
+
+
+#include "vpx_ports/x86_abi_support.S"
+
+        .macro PROCESS_16X2X3 first
+.ifne \first
+        movdqa          xmm0,       [rsi]
+        lddqu           xmm5,       [rdi]
+        lddqu           xmm6,       [rdi+1]
+        lddqu           xmm7,       [rdi+2]
+
+        psadbw          xmm5,       xmm0
+        psadbw          xmm6,       xmm0
+        psadbw          xmm7,       xmm0
+.else
+        movdqa          xmm0,       [rsi]
+        lddqu           xmm1,       [rdi]
+        lddqu           xmm2,       [rdi+1]
+        lddqu           xmm3,       [rdi+2]
+
+        psadbw          xmm1,       xmm0
+        psadbw          xmm2,       xmm0
+        psadbw          xmm3,       xmm0
+
+        paddw           xmm5,       xmm1
+        paddw           xmm6,       xmm2
+        paddw           xmm7,       xmm3
+.endif
+        movdqa          xmm0,       xmmword ptr [rsi+rax]
+        lddqu           xmm1,       xmmword ptr [rdi+rdx]
+        lddqu           xmm2,       xmmword ptr [rdi+rdx+1]
+        lddqu           xmm3,       xmmword ptr [rdi+rdx+2]
+
+        lea             rsi,        [rsi+rax*2]
+        lea             rdi,        [rdi+rdx*2]
+
+        psadbw          xmm1,       xmm0
+        psadbw          xmm2,       xmm0
+        psadbw          xmm3,       xmm0
+
+        paddw           xmm5,       xmm1
+        paddw           xmm6,       xmm2
+        paddw           xmm7,       xmm3
+        .endm
+
+        .macro PROCESS_16X2X3_OFFSET first align
+.ifne \first
+        movdqa          xmm0,       [rsi]
+        movdqa          xmm4,       [rdi]
+        movdqa          xmm7,       [rdi+16]
+
+        movdqa          xmm5,       xmm7
+        palignr         xmm5,       xmm4,       \align
+
+        movdqa          xmm6,       xmm7
+        palignr         xmm6,       xmm4,       (\align + 1)
+
+        palignr         xmm7,       xmm4,       (\align + 2)
+
+        psadbw          xmm5,       xmm0
+        psadbw          xmm6,       xmm0
+        psadbw          xmm7,       xmm0
+.else
+        movdqa          xmm0,       [rsi]
+        movdqa          xmm4,       [rdi]
+        movdqa          xmm3,       [rdi+16]
+
+        movdqa          xmm1,       xmm3
+        palignr         xmm1,       xmm4,       \align
+
+        movdqa          xmm2,       xmm3
+        palignr         xmm2,       xmm4,       (\align + 1)
+
+        palignr         xmm3,       xmm4,       (\align + 2)
+
+        psadbw          xmm1,       xmm0
+        psadbw          xmm2,       xmm0
+        psadbw          xmm3,       xmm0
+
+        paddw           xmm5,       xmm1
+        paddw           xmm6,       xmm2
+        paddw           xmm7,       xmm3
+.endif
+        movdqa          xmm0,       xmmword ptr [rsi+rax]
+        movdqa          xmm4,       xmmword ptr [rdi+rdx]
+        movdqa          xmm3,       xmmword ptr [rdi+rdx+16]
+
+        movdqa          xmm1,       xmm3
+        palignr         xmm1,       xmm4,       \align
+
+        movdqa          xmm2,       xmm3
+        palignr         xmm2,       xmm4,       (\align + 1)
+
+        palignr         xmm3,       xmm4,       (\align + 2)
+
+        lea             rsi,        [rsi+rax*2]
+        lea             rdi,        [rdi+rdx*2]
+
+        psadbw          xmm1,       xmm0
+        psadbw          xmm2,       xmm0
+        psadbw          xmm3,       xmm0
+
+        paddw           xmm5,       xmm1
+        paddw           xmm6,       xmm2
+        paddw           xmm7,       xmm3
+        .endm
+
+        .macro PROCESS_16X16X3_OFFSET align name
+\name\()_aligned_by_\align:
+
+        sub             rdi,        \align
+
+        PROCESS_16X2X3_OFFSET 1, \align
+        PROCESS_16X2X3_OFFSET 0, \align
+        PROCESS_16X2X3_OFFSET 0, \align
+        PROCESS_16X2X3_OFFSET 0, \align
+        PROCESS_16X2X3_OFFSET 0, \align
+        PROCESS_16X2X3_OFFSET 0, \align
+        PROCESS_16X2X3_OFFSET 0, \align
+        PROCESS_16X2X3_OFFSET 0, \align
+
+        jmp             \name\()_store_off
+        .endm
+
+        .macro PROCESS_16X8X3_OFFSET align name
+\name\()_aligned_by_\align:
+
+        sub             rdi,        \align
+
+        PROCESS_16X2X3_OFFSET 1, \align
+        PROCESS_16X2X3_OFFSET 0, \align
+        PROCESS_16X2X3_OFFSET 0, \align
+        PROCESS_16X2X3_OFFSET 0, \align
+
+        jmp             \name\()_store_off
+        .endm
+
+//void int vp8_sad16x16x3_ssse3(
+//    unsigned char *src_ptr,
+//    int  src_stride,
+//    unsigned char *ref_ptr,
+//    int  ref_stride,
+//    int  *results)
+global sym(vp8_sad16x16x3_ssse3)
+sym(vp8_sad16x16x3_ssse3):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 5
+    push        rsi
+    push        rdi
+    push        rcx
+    // end prolog
+
+        mov             rsi,        arg(0) //src_ptr
+        mov             rdi,        arg(2) //ref_ptr
+
+        mov             rdx,        0xf
+        and             rdx,        rdi
+
+        jmp vp8_sad16x16x3_ssse3_skiptable
+vp8_sad16x16x3_ssse3_jumptable:
+        .long vp8_sad16x16x3_ssse3_aligned_by_0  - vp8_sad16x16x3_ssse3_do_jump
+        .long vp8_sad16x16x3_ssse3_aligned_by_1  - vp8_sad16x16x3_ssse3_do_jump
+        .long vp8_sad16x16x3_ssse3_aligned_by_2  - vp8_sad16x16x3_ssse3_do_jump
+        .long vp8_sad16x16x3_ssse3_aligned_by_3  - vp8_sad16x16x3_ssse3_do_jump
+        .long vp8_sad16x16x3_ssse3_aligned_by_4  - vp8_sad16x16x3_ssse3_do_jump
+        .long vp8_sad16x16x3_ssse3_aligned_by_5  - vp8_sad16x16x3_ssse3_do_jump
+        .long vp8_sad16x16x3_ssse3_aligned_by_6  - vp8_sad16x16x3_ssse3_do_jump
+        .long vp8_sad16x16x3_ssse3_aligned_by_7  - vp8_sad16x16x3_ssse3_do_jump
+        .long vp8_sad16x16x3_ssse3_aligned_by_8  - vp8_sad16x16x3_ssse3_do_jump
+        .long vp8_sad16x16x3_ssse3_aligned_by_9  - vp8_sad16x16x3_ssse3_do_jump
+        .long vp8_sad16x16x3_ssse3_aligned_by_10 - vp8_sad16x16x3_ssse3_do_jump
+        .long vp8_sad16x16x3_ssse3_aligned_by_11 - vp8_sad16x16x3_ssse3_do_jump
+        .long vp8_sad16x16x3_ssse3_aligned_by_12 - vp8_sad16x16x3_ssse3_do_jump
+        .long vp8_sad16x16x3_ssse3_aligned_by_13 - vp8_sad16x16x3_ssse3_do_jump
+        .long vp8_sad16x16x3_ssse3_aligned_by_14 - vp8_sad16x16x3_ssse3_do_jump
+        .long vp8_sad16x16x3_ssse3_aligned_by_15 - vp8_sad16x16x3_ssse3_do_jump
+vp8_sad16x16x3_ssse3_skiptable:
+
+        call vp8_sad16x16x3_ssse3_do_jump
+vp8_sad16x16x3_ssse3_do_jump:
+        pop             rcx                         // get the address of do_jump
+        mov             rax,  vp8_sad16x16x3_ssse3_jumptable - vp8_sad16x16x3_ssse3_do_jump
+        add             rax,  rcx  // get the absolute address of vp8_sad16x16x3_ssse3_jumptable
+
+        movsxd          rax,  dword ptr [rax + 4*rdx]   // get the 32 bit offset from the jumptable
+        add             rcx,        rax
+
+        movsxd          rax,        dword ptr arg(1) //src_stride
+        movsxd          rdx,        dword ptr arg(3) //ref_stride
+
+        jmp             rcx
+
+        PROCESS_16X16X3_OFFSET 0,  vp8_sad16x16x3_ssse3
+        PROCESS_16X16X3_OFFSET 1,  vp8_sad16x16x3_ssse3
+        PROCESS_16X16X3_OFFSET 2,  vp8_sad16x16x3_ssse3
+        PROCESS_16X16X3_OFFSET 3,  vp8_sad16x16x3_ssse3
+        PROCESS_16X16X3_OFFSET 4,  vp8_sad16x16x3_ssse3
+        PROCESS_16X16X3_OFFSET 5,  vp8_sad16x16x3_ssse3
+        PROCESS_16X16X3_OFFSET 6,  vp8_sad16x16x3_ssse3
+        PROCESS_16X16X3_OFFSET 7,  vp8_sad16x16x3_ssse3
+        PROCESS_16X16X3_OFFSET 8,  vp8_sad16x16x3_ssse3
+        PROCESS_16X16X3_OFFSET 9,  vp8_sad16x16x3_ssse3
+        PROCESS_16X16X3_OFFSET 10, vp8_sad16x16x3_ssse3
+        PROCESS_16X16X3_OFFSET 11, vp8_sad16x16x3_ssse3
+        PROCESS_16X16X3_OFFSET 12, vp8_sad16x16x3_ssse3
+        PROCESS_16X16X3_OFFSET 13, vp8_sad16x16x3_ssse3
+        PROCESS_16X16X3_OFFSET 14, vp8_sad16x16x3_ssse3
+
+vp8_sad16x16x3_ssse3_aligned_by_15:
+        PROCESS_16X2X3 1
+        PROCESS_16X2X3 0
+        PROCESS_16X2X3 0
+        PROCESS_16X2X3 0
+        PROCESS_16X2X3 0
+        PROCESS_16X2X3 0
+        PROCESS_16X2X3 0
+        PROCESS_16X2X3 0
+
+vp8_sad16x16x3_ssse3_store_off:
+        mov             rdi,        arg(4) //Results
+
+        movq            xmm0,       xmm5
+        psrldq          xmm5,       8
+
+        paddw           xmm0,       xmm5
+        movd            [rdi],      xmm0
+//-
+        movq            xmm0,       xmm6
+        psrldq          xmm6,       8
+
+        paddw           xmm0,       xmm6
+        movd            [rdi+4],    xmm0
+//-
+        movq            xmm0,       xmm7
+        psrldq          xmm7,       8
+
+        paddw           xmm0,       xmm7
+        movd            [rdi+8],    xmm0
+
+    // begin epilog
+    pop         rcx
+    pop         rdi
+    pop         rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+//void int vp8_sad16x8x3_ssse3(
+//    unsigned char *src_ptr,
+//    int  src_stride,
+//    unsigned char *ref_ptr,
+//    int  ref_stride,
+//    int  *results)
+global sym(vp8_sad16x8x3_ssse3)
+sym(vp8_sad16x8x3_ssse3):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 5
+    push        rsi
+    push        rdi
+    push        rcx
+    // end prolog
+
+        mov             rsi,        arg(0) //src_ptr
+        mov             rdi,        arg(2) //ref_ptr
+
+        mov             rdx,        0xf
+        and             rdx,        rdi
+
+        jmp vp8_sad16x8x3_ssse3_skiptable
+vp8_sad16x8x3_ssse3_jumptable:
+        .long vp8_sad16x8x3_ssse3_aligned_by_0  - vp8_sad16x8x3_ssse3_do_jump
+        .long vp8_sad16x8x3_ssse3_aligned_by_1  - vp8_sad16x8x3_ssse3_do_jump
+        .long vp8_sad16x8x3_ssse3_aligned_by_2  - vp8_sad16x8x3_ssse3_do_jump
+        .long vp8_sad16x8x3_ssse3_aligned_by_3  - vp8_sad16x8x3_ssse3_do_jump
+        .long vp8_sad16x8x3_ssse3_aligned_by_4  - vp8_sad16x8x3_ssse3_do_jump
+        .long vp8_sad16x8x3_ssse3_aligned_by_5  - vp8_sad16x8x3_ssse3_do_jump
+        .long vp8_sad16x8x3_ssse3_aligned_by_6  - vp8_sad16x8x3_ssse3_do_jump
+        .long vp8_sad16x8x3_ssse3_aligned_by_7  - vp8_sad16x8x3_ssse3_do_jump
+        .long vp8_sad16x8x3_ssse3_aligned_by_8  - vp8_sad16x8x3_ssse3_do_jump
+        .long vp8_sad16x8x3_ssse3_aligned_by_9  - vp8_sad16x8x3_ssse3_do_jump
+        .long vp8_sad16x8x3_ssse3_aligned_by_10 - vp8_sad16x8x3_ssse3_do_jump
+        .long vp8_sad16x8x3_ssse3_aligned_by_11 - vp8_sad16x8x3_ssse3_do_jump
+        .long vp8_sad16x8x3_ssse3_aligned_by_12 - vp8_sad16x8x3_ssse3_do_jump
+        .long vp8_sad16x8x3_ssse3_aligned_by_13 - vp8_sad16x8x3_ssse3_do_jump
+        .long vp8_sad16x8x3_ssse3_aligned_by_14 - vp8_sad16x8x3_ssse3_do_jump
+        .long vp8_sad16x8x3_ssse3_aligned_by_15 - vp8_sad16x8x3_ssse3_do_jump
+vp8_sad16x8x3_ssse3_skiptable:
+
+        call vp8_sad16x8x3_ssse3_do_jump
+vp8_sad16x8x3_ssse3_do_jump:
+        pop             rcx                         // get the address of do_jump
+        mov             rax,  vp8_sad16x8x3_ssse3_jumptable - vp8_sad16x8x3_ssse3_do_jump
+        add             rax,  rcx  // get the absolute address of vp8_sad16x8x3_ssse3_jumptable
+
+        movsxd          rax,  dword ptr [rax + 4*rdx]   // get the 32 bit offset from the jumptable
+        add             rcx,        rax
+
+        movsxd          rax,        dword ptr arg(1) //src_stride
+        movsxd          rdx,        dword ptr arg(3) //ref_stride
+
+        jmp             rcx
+
+        PROCESS_16X8X3_OFFSET 0,  vp8_sad16x8x3_ssse3
+        PROCESS_16X8X3_OFFSET 1,  vp8_sad16x8x3_ssse3
+        PROCESS_16X8X3_OFFSET 2,  vp8_sad16x8x3_ssse3
+        PROCESS_16X8X3_OFFSET 3,  vp8_sad16x8x3_ssse3
+        PROCESS_16X8X3_OFFSET 4,  vp8_sad16x8x3_ssse3
+        PROCESS_16X8X3_OFFSET 5,  vp8_sad16x8x3_ssse3
+        PROCESS_16X8X3_OFFSET 6,  vp8_sad16x8x3_ssse3
+        PROCESS_16X8X3_OFFSET 7,  vp8_sad16x8x3_ssse3
+        PROCESS_16X8X3_OFFSET 8,  vp8_sad16x8x3_ssse3
+        PROCESS_16X8X3_OFFSET 9,  vp8_sad16x8x3_ssse3
+        PROCESS_16X8X3_OFFSET 10, vp8_sad16x8x3_ssse3
+        PROCESS_16X8X3_OFFSET 11, vp8_sad16x8x3_ssse3
+        PROCESS_16X8X3_OFFSET 12, vp8_sad16x8x3_ssse3
+        PROCESS_16X8X3_OFFSET 13, vp8_sad16x8x3_ssse3
+        PROCESS_16X8X3_OFFSET 14, vp8_sad16x8x3_ssse3
+
+vp8_sad16x8x3_ssse3_aligned_by_15:
+
+        PROCESS_16X2X3 1
+        PROCESS_16X2X3 0
+        PROCESS_16X2X3 0
+        PROCESS_16X2X3 0
+
+vp8_sad16x8x3_ssse3_store_off:
+        mov             rdi,        arg(4) //Results
+
+        movq            xmm0,       xmm5
+        psrldq          xmm5,       8
+
+        paddw           xmm0,       xmm5
+        movd            [rdi],      xmm0
+//-
+        movq            xmm0,       xmm6
+        psrldq          xmm6,       8
+
+        paddw           xmm0,       xmm6
+        movd            [rdi+4],    xmm0
+//-
+        movq            xmm0,       xmm7
+        psrldq          xmm7,       8
+
+        paddw           xmm0,       xmm7
+        movd            [rdi+8],    xmm0
+
+    // begin epilog
+    pop         rcx
+    pop         rdi
+    pop         rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
diff --git a/vp8/encoder/x86/sad_ssse3.asm b/vp8/encoder/x86/sad_ssse3.asm
deleted file mode 100644
index 1bb9561..0000000
--- a/vp8/encoder/x86/sad_ssse3.asm
+++ /dev/null
@@ -1,367 +0,0 @@
-;
-;  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
-;
-;  Use of this source code is governed by a BSD-style license and patent
-;  grant that can be found in the LICENSE file in the root of the source
-;  tree. All contributing project authors may be found in the AUTHORS
-;  file in the root of the source tree.
-;
-
-
-%include "vpx_ports/x86_abi_support.asm"
-
-%idefine QWORD
-
-%macro PROCESS_16X2X3 1
-%if %1
-        movdqa          xmm0,       [rsi]
-        lddqu           xmm5,       [rdi]
-        lddqu           xmm6,       [rdi+1]
-        lddqu           xmm7,       [rdi+2]
-
-        psadbw          xmm5,       xmm0
-        psadbw          xmm6,       xmm0
-        psadbw          xmm7,       xmm0
-%else
-        movdqa          xmm0,       [rsi]
-        lddqu           xmm1,       [rdi]
-        lddqu           xmm2,       [rdi+1]
-        lddqu           xmm3,       [rdi+2]
-
-        psadbw          xmm1,       xmm0
-        psadbw          xmm2,       xmm0
-        psadbw          xmm3,       xmm0
-
-        paddw           xmm5,       xmm1
-        paddw           xmm6,       xmm2
-        paddw           xmm7,       xmm3
-%endif
-        movdqa          xmm0,       QWORD PTR [rsi+rax]
-        lddqu           xmm1,       QWORD PTR [rdi+rdx]
-        lddqu           xmm2,       QWORD PTR [rdi+rdx+1]
-        lddqu           xmm3,       QWORD PTR [rdi+rdx+2]
-
-        lea             rsi,        [rsi+rax*2]
-        lea             rdi,        [rdi+rdx*2]
-
-        psadbw          xmm1,       xmm0
-        psadbw          xmm2,       xmm0
-        psadbw          xmm3,       xmm0
-
-        paddw           xmm5,       xmm1
-        paddw           xmm6,       xmm2
-        paddw           xmm7,       xmm3
-%endmacro
-
-%macro PROCESS_16X2X3_OFFSET 2
-%if %1
-        movdqa          xmm0,       [rsi]
-        movdqa          xmm4,       [rdi]
-        movdqa          xmm7,       [rdi+16]
-
-        movdqa          xmm5,       xmm7
-        palignr         xmm5,       xmm4,       %2
-
-        movdqa          xmm6,       xmm7
-        palignr         xmm6,       xmm4,       (%2+1)
-
-        palignr         xmm7,       xmm4,       (%2+2)
-
-        psadbw          xmm5,       xmm0
-        psadbw          xmm6,       xmm0
-        psadbw          xmm7,       xmm0
-%else
-        movdqa          xmm0,       [rsi]
-        movdqa          xmm4,       [rdi]
-        movdqa          xmm3,       [rdi+16]
-
-        movdqa          xmm1,       xmm3
-        palignr         xmm1,       xmm4,       %2
-
-        movdqa          xmm2,       xmm3
-        palignr         xmm2,       xmm4,       (%2+1)
-
-        palignr         xmm3,       xmm4,       (%2+2)
-
-        psadbw          xmm1,       xmm0
-        psadbw          xmm2,       xmm0
-        psadbw          xmm3,       xmm0
-
-        paddw           xmm5,       xmm1
-        paddw           xmm6,       xmm2
-        paddw           xmm7,       xmm3
-%endif
-        movdqa          xmm0,       QWORD PTR [rsi+rax]
-        movdqa          xmm4,       QWORD PTR [rdi+rdx]
-        movdqa          xmm3,       QWORD PTR [rdi+rdx+16]
-
-        movdqa          xmm1,       xmm3
-        palignr         xmm1,       xmm4,       %2
-
-        movdqa          xmm2,       xmm3
-        palignr         xmm2,       xmm4,       (%2+1)
-
-        palignr         xmm3,       xmm4,       (%2+2)
-
-        lea             rsi,        [rsi+rax*2]
-        lea             rdi,        [rdi+rdx*2]
-
-        psadbw          xmm1,       xmm0
-        psadbw          xmm2,       xmm0
-        psadbw          xmm3,       xmm0
-
-        paddw           xmm5,       xmm1
-        paddw           xmm6,       xmm2
-        paddw           xmm7,       xmm3
-%endmacro
-
-%macro PROCESS_16X16X3_OFFSET 2
-%2_aligned_by_%1:
-
-        sub             rdi,        %1
-
-        PROCESS_16X2X3_OFFSET 1, %1
-        PROCESS_16X2X3_OFFSET 0, %1
-        PROCESS_16X2X3_OFFSET 0, %1
-        PROCESS_16X2X3_OFFSET 0, %1
-        PROCESS_16X2X3_OFFSET 0, %1
-        PROCESS_16X2X3_OFFSET 0, %1
-        PROCESS_16X2X3_OFFSET 0, %1
-        PROCESS_16X2X3_OFFSET 0, %1
-
-        jmp             %2_store_off
-
-%endmacro
-
-%macro PROCESS_16X8X3_OFFSET 2
-%2_aligned_by_%1:
-
-        sub             rdi,        %1
-
-        PROCESS_16X2X3_OFFSET 1, %1
-        PROCESS_16X2X3_OFFSET 0, %1
-        PROCESS_16X2X3_OFFSET 0, %1
-        PROCESS_16X2X3_OFFSET 0, %1
-
-        jmp             %2_store_off
-
-%endmacro
-
-;void int vp8_sad16x16x3_ssse3(
-;    unsigned char *src_ptr,
-;    int  src_stride,
-;    unsigned char *ref_ptr,
-;    int  ref_stride,
-;    int  *results)
-global sym(vp8_sad16x16x3_ssse3)
-sym(vp8_sad16x16x3_ssse3):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 5
-    push        rsi
-    push        rdi
-    push        rcx
-    ; end prolog
-
-        mov             rsi,        arg(0) ;src_ptr
-        mov             rdi,        arg(2) ;ref_ptr
-
-        mov             rdx,        0xf
-        and             rdx,        rdi
-
-        jmp vp8_sad16x16x3_ssse3_skiptable
-vp8_sad16x16x3_ssse3_jumptable:
-        dd vp8_sad16x16x3_ssse3_aligned_by_0  - vp8_sad16x16x3_ssse3_do_jump
-        dd vp8_sad16x16x3_ssse3_aligned_by_1  - vp8_sad16x16x3_ssse3_do_jump
-        dd vp8_sad16x16x3_ssse3_aligned_by_2  - vp8_sad16x16x3_ssse3_do_jump
-        dd vp8_sad16x16x3_ssse3_aligned_by_3  - vp8_sad16x16x3_ssse3_do_jump
-        dd vp8_sad16x16x3_ssse3_aligned_by_4  - vp8_sad16x16x3_ssse3_do_jump
-        dd vp8_sad16x16x3_ssse3_aligned_by_5  - vp8_sad16x16x3_ssse3_do_jump
-        dd vp8_sad16x16x3_ssse3_aligned_by_6  - vp8_sad16x16x3_ssse3_do_jump
-        dd vp8_sad16x16x3_ssse3_aligned_by_7  - vp8_sad16x16x3_ssse3_do_jump
-        dd vp8_sad16x16x3_ssse3_aligned_by_8  - vp8_sad16x16x3_ssse3_do_jump
-        dd vp8_sad16x16x3_ssse3_aligned_by_9  - vp8_sad16x16x3_ssse3_do_jump
-        dd vp8_sad16x16x3_ssse3_aligned_by_10 - vp8_sad16x16x3_ssse3_do_jump
-        dd vp8_sad16x16x3_ssse3_aligned_by_11 - vp8_sad16x16x3_ssse3_do_jump
-        dd vp8_sad16x16x3_ssse3_aligned_by_12 - vp8_sad16x16x3_ssse3_do_jump
-        dd vp8_sad16x16x3_ssse3_aligned_by_13 - vp8_sad16x16x3_ssse3_do_jump
-        dd vp8_sad16x16x3_ssse3_aligned_by_14 - vp8_sad16x16x3_ssse3_do_jump
-        dd vp8_sad16x16x3_ssse3_aligned_by_15 - vp8_sad16x16x3_ssse3_do_jump
-vp8_sad16x16x3_ssse3_skiptable:
-
-        call vp8_sad16x16x3_ssse3_do_jump
-vp8_sad16x16x3_ssse3_do_jump:
-        pop             rcx                         ; get the address of do_jump
-        mov             rax,  vp8_sad16x16x3_ssse3_jumptable - vp8_sad16x16x3_ssse3_do_jump
-        add             rax,  rcx  ; get the absolute address of vp8_sad16x16x3_ssse3_jumptable
-
-        movsxd          rax,  dword [rax + 4*rdx]   ; get the 32 bit offset from the jumptable
-        add             rcx,        rax
-
-        movsxd          rax,        dword ptr arg(1) ;src_stride
-        movsxd          rdx,        dword ptr arg(3) ;ref_stride
-
-        jmp             rcx
-
-        PROCESS_16X16X3_OFFSET 0,  vp8_sad16x16x3_ssse3
-        PROCESS_16X16X3_OFFSET 1,  vp8_sad16x16x3_ssse3
-        PROCESS_16X16X3_OFFSET 2,  vp8_sad16x16x3_ssse3
-        PROCESS_16X16X3_OFFSET 3,  vp8_sad16x16x3_ssse3
-        PROCESS_16X16X3_OFFSET 4,  vp8_sad16x16x3_ssse3
-        PROCESS_16X16X3_OFFSET 5,  vp8_sad16x16x3_ssse3
-        PROCESS_16X16X3_OFFSET 6,  vp8_sad16x16x3_ssse3
-        PROCESS_16X16X3_OFFSET 7,  vp8_sad16x16x3_ssse3
-        PROCESS_16X16X3_OFFSET 8,  vp8_sad16x16x3_ssse3
-        PROCESS_16X16X3_OFFSET 9,  vp8_sad16x16x3_ssse3
-        PROCESS_16X16X3_OFFSET 10, vp8_sad16x16x3_ssse3
-        PROCESS_16X16X3_OFFSET 11, vp8_sad16x16x3_ssse3
-        PROCESS_16X16X3_OFFSET 12, vp8_sad16x16x3_ssse3
-        PROCESS_16X16X3_OFFSET 13, vp8_sad16x16x3_ssse3
-        PROCESS_16X16X3_OFFSET 14, vp8_sad16x16x3_ssse3
-
-vp8_sad16x16x3_ssse3_aligned_by_15:
-        PROCESS_16X2X3 1
-        PROCESS_16X2X3 0
-        PROCESS_16X2X3 0
-        PROCESS_16X2X3 0
-        PROCESS_16X2X3 0
-        PROCESS_16X2X3 0
-        PROCESS_16X2X3 0
-        PROCESS_16X2X3 0
-
-vp8_sad16x16x3_ssse3_store_off:
-        mov             rdi,        arg(4) ;Results
-
-        movq            xmm0,       xmm5
-        psrldq          xmm5,       8
-
-        paddw           xmm0,       xmm5
-        movd            [rdi],      xmm0
-;-
-        movq            xmm0,       xmm6
-        psrldq          xmm6,       8
-
-        paddw           xmm0,       xmm6
-        movd            [rdi+4],    xmm0
-;-
-        movq            xmm0,       xmm7
-        psrldq          xmm7,       8
-
-        paddw           xmm0,       xmm7
-        movd            [rdi+8],    xmm0
-
-    ; begin epilog
-    pop         rcx
-    pop         rdi
-    pop         rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-;void int vp8_sad16x8x3_ssse3(
-;    unsigned char *src_ptr,
-;    int  src_stride,
-;    unsigned char *ref_ptr,
-;    int  ref_stride,
-;    int  *results)
-global sym(vp8_sad16x8x3_ssse3)
-sym(vp8_sad16x8x3_ssse3):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 5
-    push        rsi
-    push        rdi
-    push        rcx
-    ; end prolog
-
-        mov             rsi,        arg(0) ;src_ptr
-        mov             rdi,        arg(2) ;ref_ptr
-
-        mov             rdx,        0xf
-        and             rdx,        rdi
-
-        jmp vp8_sad16x8x3_ssse3_skiptable
-vp8_sad16x8x3_ssse3_jumptable:
-        dd vp8_sad16x8x3_ssse3_aligned_by_0  - vp8_sad16x8x3_ssse3_do_jump
-        dd vp8_sad16x8x3_ssse3_aligned_by_1  - vp8_sad16x8x3_ssse3_do_jump
-        dd vp8_sad16x8x3_ssse3_aligned_by_2  - vp8_sad16x8x3_ssse3_do_jump
-        dd vp8_sad16x8x3_ssse3_aligned_by_3  - vp8_sad16x8x3_ssse3_do_jump
-        dd vp8_sad16x8x3_ssse3_aligned_by_4  - vp8_sad16x8x3_ssse3_do_jump
-        dd vp8_sad16x8x3_ssse3_aligned_by_5  - vp8_sad16x8x3_ssse3_do_jump
-        dd vp8_sad16x8x3_ssse3_aligned_by_6  - vp8_sad16x8x3_ssse3_do_jump
-        dd vp8_sad16x8x3_ssse3_aligned_by_7  - vp8_sad16x8x3_ssse3_do_jump
-        dd vp8_sad16x8x3_ssse3_aligned_by_8  - vp8_sad16x8x3_ssse3_do_jump
-        dd vp8_sad16x8x3_ssse3_aligned_by_9  - vp8_sad16x8x3_ssse3_do_jump
-        dd vp8_sad16x8x3_ssse3_aligned_by_10 - vp8_sad16x8x3_ssse3_do_jump
-        dd vp8_sad16x8x3_ssse3_aligned_by_11 - vp8_sad16x8x3_ssse3_do_jump
-        dd vp8_sad16x8x3_ssse3_aligned_by_12 - vp8_sad16x8x3_ssse3_do_jump
-        dd vp8_sad16x8x3_ssse3_aligned_by_13 - vp8_sad16x8x3_ssse3_do_jump
-        dd vp8_sad16x8x3_ssse3_aligned_by_14 - vp8_sad16x8x3_ssse3_do_jump
-        dd vp8_sad16x8x3_ssse3_aligned_by_15 - vp8_sad16x8x3_ssse3_do_jump
-vp8_sad16x8x3_ssse3_skiptable:
-
-        call vp8_sad16x8x3_ssse3_do_jump
-vp8_sad16x8x3_ssse3_do_jump:
-        pop             rcx                         ; get the address of do_jump
-        mov             rax,  vp8_sad16x8x3_ssse3_jumptable - vp8_sad16x8x3_ssse3_do_jump
-        add             rax,  rcx  ; get the absolute address of vp8_sad16x8x3_ssse3_jumptable
-
-        movsxd          rax,  dword [rax + 4*rdx]   ; get the 32 bit offset from the jumptable
-        add             rcx,        rax
-
-        movsxd          rax,        dword ptr arg(1) ;src_stride
-        movsxd          rdx,        dword ptr arg(3) ;ref_stride
-
-        jmp             rcx
-
-        PROCESS_16X8X3_OFFSET 0,  vp8_sad16x8x3_ssse3
-        PROCESS_16X8X3_OFFSET 1,  vp8_sad16x8x3_ssse3
-        PROCESS_16X8X3_OFFSET 2,  vp8_sad16x8x3_ssse3
-        PROCESS_16X8X3_OFFSET 3,  vp8_sad16x8x3_ssse3
-        PROCESS_16X8X3_OFFSET 4,  vp8_sad16x8x3_ssse3
-        PROCESS_16X8X3_OFFSET 5,  vp8_sad16x8x3_ssse3
-        PROCESS_16X8X3_OFFSET 6,  vp8_sad16x8x3_ssse3
-        PROCESS_16X8X3_OFFSET 7,  vp8_sad16x8x3_ssse3
-        PROCESS_16X8X3_OFFSET 8,  vp8_sad16x8x3_ssse3
-        PROCESS_16X8X3_OFFSET 9,  vp8_sad16x8x3_ssse3
-        PROCESS_16X8X3_OFFSET 10, vp8_sad16x8x3_ssse3
-        PROCESS_16X8X3_OFFSET 11, vp8_sad16x8x3_ssse3
-        PROCESS_16X8X3_OFFSET 12, vp8_sad16x8x3_ssse3
-        PROCESS_16X8X3_OFFSET 13, vp8_sad16x8x3_ssse3
-        PROCESS_16X8X3_OFFSET 14, vp8_sad16x8x3_ssse3
-
-vp8_sad16x8x3_ssse3_aligned_by_15:
-
-        PROCESS_16X2X3 1
-        PROCESS_16X2X3 0
-        PROCESS_16X2X3 0
-        PROCESS_16X2X3 0
-
-vp8_sad16x8x3_ssse3_store_off:
-        mov             rdi,        arg(4) ;Results
-
-        movq            xmm0,       xmm5
-        psrldq          xmm5,       8
-
-        paddw           xmm0,       xmm5
-        movd            [rdi],      xmm0
-;-
-        movq            xmm0,       xmm6
-        psrldq          xmm6,       8
-
-        paddw           xmm0,       xmm6
-        movd            [rdi+4],    xmm0
-;-
-        movq            xmm0,       xmm7
-        psrldq          xmm7,       8
-
-        paddw           xmm0,       xmm7
-        movd            [rdi+8],    xmm0
-
-    ; begin epilog
-    pop         rcx
-    pop         rdi
-    pop         rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
diff --git a/vp8/encoder/x86/subtract_mmx.S b/vp8/encoder/x86/subtract_mmx.S
new file mode 100644
index 0000000..8a14733
--- /dev/null
+++ b/vp8/encoder/x86/subtract_mmx.S
@@ -0,0 +1,431 @@
+//
+//  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
+//
+//  Use of this source code is governed by a BSD-style license and patent
+//  grant that can be found in the LICENSE file in the root of the source
+//  tree. All contributing project authors may be found in the AUTHORS
+//  file in the root of the source tree.
+//
+
+
+#include "vpx_ports/x86_abi_support.S"
+
+//void vp8_subtract_b_mmx_impl(unsigned char *z,  int src_stride,
+//                            unsigned short *diff, unsigned char *Predictor,
+//                            int pitch);
+global sym(vp8_subtract_b_mmx_impl)
+sym(vp8_subtract_b_mmx_impl):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 5
+    push rsi
+    push rdi
+    // end prolog
+
+
+        mov     rdi,        arg(2) //diff
+        mov     rax,        arg(3) //Predictor
+        mov     rsi,        arg(0) //z
+        movsxd  rdx,        dword ptr arg(1) //src_stride;
+        movsxd  rcx,        dword ptr arg(4) //pitch
+        pxor    mm7,        mm7
+
+        movd    mm0,        [rsi]
+        movd    mm1,        [rax]
+        punpcklbw   mm0,    mm7
+        punpcklbw   mm1,    mm7
+        psubw   mm0,        mm1
+        movq    [rdi],      mm0
+
+
+        movd    mm0,        [rsi+rdx]
+        movd    mm1,        [rax+rcx]
+        punpcklbw   mm0,    mm7
+        punpcklbw   mm1,    mm7
+        psubw   mm0,        mm1
+        movq    [rdi+rcx*2],mm0
+
+
+        movd    mm0,        [rsi+rdx*2]
+        movd    mm1,        [rax+rcx*2]
+        punpcklbw   mm0,    mm7
+        punpcklbw   mm1,    mm7
+        psubw   mm0,        mm1
+        movq    [rdi+rcx*4],        mm0
+
+        lea     rsi,        [rsi+rdx*2]
+        lea     rcx,        [rcx+rcx*2]
+
+
+
+        movd    mm0,        [rsi+rdx]
+        movd    mm1,        [rax+rcx]
+        punpcklbw   mm0,    mm7
+        punpcklbw   mm1,    mm7
+        psubw   mm0,        mm1
+        movq    [rdi+rcx*2],        mm0
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+//void vp8_subtract_mby_mmx(short *diff, unsigned char *src, unsigned char *pred, int stride)
+global sym(vp8_subtract_mby_mmx)
+sym(vp8_subtract_mby_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 4
+    push rsi
+    push rdi
+    // end prolog
+
+
+            mov         rsi,            arg(1) //src
+            mov         rdi,            arg(0) //diff
+
+            mov         rax,            arg(2) //pred
+            movsxd      rdx,            dword ptr arg(3) //stride
+
+            mov         rcx,            16
+            pxor        mm0,            mm0
+
+submby_loop:
+
+            movq        mm1,            [rsi]
+            movq        mm3,            [rax]
+
+            movq        mm2,            mm1
+            movq        mm4,            mm3
+
+            punpcklbw   mm1,            mm0
+            punpcklbw   mm3,            mm0
+
+            punpckhbw   mm2,            mm0
+            punpckhbw   mm4,            mm0
+
+            psubw       mm1,            mm3
+            psubw       mm2,            mm4
+
+            movq        [rdi],          mm1
+            movq        [rdi+8],        mm2
+
+
+            movq        mm1,            [rsi+8]
+            movq        mm3,            [rax+8]
+
+            movq        mm2,            mm1
+            movq        mm4,            mm3
+
+            punpcklbw   mm1,            mm0
+            punpcklbw   mm3,            mm0
+
+            punpckhbw   mm2,            mm0
+            punpckhbw   mm4,            mm0
+
+            psubw       mm1,            mm3
+            psubw       mm2,            mm4
+
+            movq        [rdi+16],       mm1
+            movq        [rdi+24],       mm2
+
+
+            add         rdi,            32
+            add         rax,            16
+
+            lea         rsi,            [rsi+rdx]
+
+            sub         rcx,            1
+            jnz         submby_loop
+
+    pop rdi
+    pop rsi
+    // begin epilog
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void vp8_subtract_mbuv_mmx(short *diff, unsigned char *usrc, unsigned char *vsrc, unsigned char *pred, int stride)
+global sym(vp8_subtract_mbuv_mmx)
+sym(vp8_subtract_mbuv_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 5
+    push rsi
+    push rdi
+    // end prolog
+
+    //short *udiff = diff + 256;
+    //short *vdiff = diff + 320;
+    //unsigned char *upred = pred + 256;
+    //unsigned char *vpred = pred + 320;
+
+        //unsigned char  *z    = usrc;
+        //unsigned short *diff = udiff;
+        //unsigned char  *Predictor= upred;
+
+            mov     rdi,        arg(0) //diff
+            mov     rax,        arg(3) //pred
+            mov     rsi,        arg(1) //z = usrc
+            add     rdi,        256*2  //diff = diff + 256 (shorts)
+            add     rax,        256    //Predictor = pred + 256
+            movsxd  rdx,        dword ptr arg(4) //stride;
+            pxor    mm7,        mm7
+
+            movq    mm0,        [rsi]
+            movq    mm1,        [rax]
+            movq    mm3,        mm0
+            movq    mm4,        mm1
+            punpcklbw   mm0,    mm7
+            punpcklbw   mm1,    mm7
+            punpckhbw   mm3,    mm7
+            punpckhbw   mm4,    mm7
+            psubw   mm0,        mm1
+            psubw   mm3,        mm4
+            movq    [rdi],      mm0
+            movq    [rdi+8],    mm3
+
+
+            movq    mm0,        [rsi+rdx]
+            movq    mm1,        [rax+8]
+            movq    mm3,        mm0
+            movq    mm4,        mm1
+            punpcklbw   mm0,    mm7
+            punpcklbw   mm1,    mm7
+            punpckhbw   mm3,    mm7
+            punpckhbw   mm4,    mm7
+            psubw   mm0,        mm1
+            psubw   mm3,        mm4
+            movq    [rdi+16],   mm0
+            movq    [rdi+24],   mm3
+
+            movq    mm0,        [rsi+rdx*2]
+            movq    mm1,        [rax+16]
+            movq    mm3,        mm0
+            movq    mm4,        mm1
+            punpcklbw   mm0,    mm7
+            punpcklbw   mm1,    mm7
+            punpckhbw   mm3,    mm7
+            punpckhbw   mm4,    mm7
+            psubw   mm0,        mm1
+            psubw   mm3,        mm4
+            movq    [rdi+32],   mm0
+            movq    [rdi+40],   mm3
+            lea     rsi,        [rsi+rdx*2]
+
+
+            movq    mm0,        [rsi+rdx]
+            movq    mm1,        [rax+24]
+            movq    mm3,        mm0
+            movq    mm4,        mm1
+            punpcklbw   mm0,    mm7
+            punpcklbw   mm1,    mm7
+            punpckhbw   mm3,    mm7
+            punpckhbw   mm4,    mm7
+            psubw   mm0,        mm1
+            psubw   mm3,        mm4
+
+            movq    [rdi+48],   mm0
+            movq    [rdi+56],   mm3
+
+
+            add     rdi,        64
+            add     rax,        32
+            lea     rsi,        [rsi+rdx*2]
+
+
+            movq    mm0,        [rsi]
+            movq    mm1,        [rax]
+            movq    mm3,        mm0
+            movq    mm4,        mm1
+            punpcklbw   mm0,    mm7
+            punpcklbw   mm1,    mm7
+            punpckhbw   mm3,    mm7
+            punpckhbw   mm4,    mm7
+            psubw   mm0,        mm1
+            psubw   mm3,        mm4
+            movq    [rdi],      mm0
+            movq    [rdi+8],    mm3
+
+
+            movq    mm0,        [rsi+rdx]
+            movq    mm1,        [rax+8]
+            movq    mm3,        mm0
+            movq    mm4,        mm1
+            punpcklbw   mm0,    mm7
+            punpcklbw   mm1,    mm7
+            punpckhbw   mm3,    mm7
+            punpckhbw   mm4,    mm7
+            psubw   mm0,        mm1
+            psubw   mm3,        mm4
+            movq    [rdi+16],   mm0
+            movq    [rdi+24],   mm3
+
+            movq    mm0,        [rsi+rdx*2]
+            movq    mm1,        [rax+16]
+            movq    mm3,        mm0
+            movq    mm4,        mm1
+            punpcklbw   mm0,    mm7
+            punpcklbw   mm1,    mm7
+            punpckhbw   mm3,    mm7
+            punpckhbw   mm4,    mm7
+            psubw   mm0,        mm1
+            psubw   mm3,        mm4
+            movq    [rdi+32],   mm0
+            movq    [rdi+40],   mm3
+            lea     rsi,        [rsi+rdx*2]
+
+
+            movq    mm0,        [rsi+rdx]
+            movq    mm1,        [rax+24]
+            movq    mm3,        mm0
+            movq    mm4,        mm1
+            punpcklbw   mm0,    mm7
+            punpcklbw   mm1,    mm7
+            punpckhbw   mm3,    mm7
+            punpckhbw   mm4,    mm7
+            psubw   mm0,        mm1
+            psubw   mm3,        mm4
+
+            movq    [rdi+48],   mm0
+            movq    [rdi+56],   mm3
+
+        //unsigned char  *z    = vsrc;
+        //unsigned short *diff = vdiff;
+        //unsigned char  *Predictor= vpred;
+
+            mov     rdi,        arg(0) //diff
+            mov     rax,        arg(3) //pred
+            mov     rsi,        arg(2) //z = usrc
+            add     rdi,        320*2  //diff = diff + 320 (shorts)
+            add     rax,        320    //Predictor = pred + 320
+            movsxd  rdx,        dword ptr arg(4) //stride;
+            pxor    mm7,        mm7
+
+            movq    mm0,        [rsi]
+            movq    mm1,        [rax]
+            movq    mm3,        mm0
+            movq    mm4,        mm1
+            punpcklbw   mm0,    mm7
+            punpcklbw   mm1,    mm7
+            punpckhbw   mm3,    mm7
+            punpckhbw   mm4,    mm7
+            psubw   mm0,        mm1
+            psubw   mm3,        mm4
+            movq    [rdi],      mm0
+            movq    [rdi+8],    mm3
+
+
+            movq    mm0,        [rsi+rdx]
+            movq    mm1,        [rax+8]
+            movq    mm3,        mm0
+            movq    mm4,        mm1
+            punpcklbw   mm0,    mm7
+            punpcklbw   mm1,    mm7
+            punpckhbw   mm3,    mm7
+            punpckhbw   mm4,    mm7
+            psubw   mm0,        mm1
+            psubw   mm3,        mm4
+            movq    [rdi+16],   mm0
+            movq    [rdi+24],   mm3
+
+            movq    mm0,        [rsi+rdx*2]
+            movq    mm1,        [rax+16]
+            movq    mm3,        mm0
+            movq    mm4,        mm1
+            punpcklbw   mm0,    mm7
+            punpcklbw   mm1,    mm7
+            punpckhbw   mm3,    mm7
+            punpckhbw   mm4,    mm7
+            psubw   mm0,        mm1
+            psubw   mm3,        mm4
+            movq    [rdi+32],   mm0
+            movq    [rdi+40],   mm3
+            lea     rsi,        [rsi+rdx*2]
+
+
+            movq    mm0,        [rsi+rdx]
+            movq    mm1,        [rax+24]
+            movq    mm3,        mm0
+            movq    mm4,        mm1
+            punpcklbw   mm0,    mm7
+            punpcklbw   mm1,    mm7
+            punpckhbw   mm3,    mm7
+            punpckhbw   mm4,    mm7
+            psubw   mm0,        mm1
+            psubw   mm3,        mm4
+
+            movq    [rdi+48],   mm0
+            movq    [rdi+56],   mm3
+
+
+            add     rdi,        64
+            add     rax,        32
+            lea     rsi,        [rsi+rdx*2]
+
+
+            movq    mm0,        [rsi]
+            movq    mm1,        [rax]
+            movq    mm3,        mm0
+            movq    mm4,        mm1
+            punpcklbw   mm0,    mm7
+            punpcklbw   mm1,    mm7
+            punpckhbw   mm3,    mm7
+            punpckhbw   mm4,    mm7
+            psubw   mm0,        mm1
+            psubw   mm3,        mm4
+            movq    [rdi],      mm0
+            movq    [rdi+8],    mm3
+
+
+            movq    mm0,        [rsi+rdx]
+            movq    mm1,        [rax+8]
+            movq    mm3,        mm0
+            movq    mm4,        mm1
+            punpcklbw   mm0,    mm7
+            punpcklbw   mm1,    mm7
+            punpckhbw   mm3,    mm7
+            punpckhbw   mm4,    mm7
+            psubw   mm0,        mm1
+            psubw   mm3,        mm4
+            movq    [rdi+16],   mm0
+            movq    [rdi+24],   mm3
+
+            movq    mm0,        [rsi+rdx*2]
+            movq    mm1,        [rax+16]
+            movq    mm3,        mm0
+            movq    mm4,        mm1
+            punpcklbw   mm0,    mm7
+            punpcklbw   mm1,    mm7
+            punpckhbw   mm3,    mm7
+            punpckhbw   mm4,    mm7
+            psubw   mm0,        mm1
+            psubw   mm3,        mm4
+            movq    [rdi+32],   mm0
+            movq    [rdi+40],   mm3
+            lea     rsi,        [rsi+rdx*2]
+
+
+            movq    mm0,        [rsi+rdx]
+            movq    mm1,        [rax+24]
+            movq    mm3,        mm0
+            movq    mm4,        mm1
+            punpcklbw   mm0,    mm7
+            punpcklbw   mm1,    mm7
+            punpckhbw   mm3,    mm7
+            punpckhbw   mm4,    mm7
+            psubw   mm0,        mm1
+            psubw   mm3,        mm4
+
+            movq    [rdi+48],   mm0
+            movq    [rdi+56],   mm3
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
diff --git a/vp8/encoder/x86/subtract_mmx.asm b/vp8/encoder/x86/subtract_mmx.asm
deleted file mode 100644
index ce3e610..0000000
--- a/vp8/encoder/x86/subtract_mmx.asm
+++ /dev/null
@@ -1,431 +0,0 @@
-;
-;  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
-;
-;  Use of this source code is governed by a BSD-style license and patent
-;  grant that can be found in the LICENSE file in the root of the source
-;  tree. All contributing project authors may be found in the AUTHORS
-;  file in the root of the source tree.
-;
-
-
-%include "vpx_ports/x86_abi_support.asm"
-
-;void vp8_subtract_b_mmx_impl(unsigned char *z,  int src_stride,
-;                            unsigned short *diff, unsigned char *Predictor,
-;                            int pitch);
-global sym(vp8_subtract_b_mmx_impl)
-sym(vp8_subtract_b_mmx_impl)
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 5
-    push rsi
-    push rdi
-    ; end prolog
-
-
-        mov     rdi,        arg(2) ;diff
-        mov     rax,        arg(3) ;Predictor
-        mov     rsi,        arg(0) ;z
-        movsxd  rdx,        dword ptr arg(1);src_stride;
-        movsxd  rcx,        dword ptr arg(4);pitch
-        pxor    mm7,        mm7
-
-        movd    mm0,        [rsi]
-        movd    mm1,        [rax]
-        punpcklbw   mm0,    mm7
-        punpcklbw   mm1,    mm7
-        psubw   mm0,        mm1
-        movq    [rdi],      mm0
-
-
-        movd    mm0,        [rsi+rdx]
-        movd    mm1,        [rax+rcx]
-        punpcklbw   mm0,    mm7
-        punpcklbw   mm1,    mm7
-        psubw   mm0,        mm1
-        movq    [rdi+rcx*2],mm0
-
-
-        movd    mm0,        [rsi+rdx*2]
-        movd    mm1,        [rax+rcx*2]
-        punpcklbw   mm0,    mm7
-        punpcklbw   mm1,    mm7
-        psubw   mm0,        mm1
-        movq    [rdi+rcx*4],        mm0
-
-        lea     rsi,        [rsi+rdx*2]
-        lea     rcx,        [rcx+rcx*2]
-
-
-
-        movd    mm0,        [rsi+rdx]
-        movd    mm1,        [rax+rcx]
-        punpcklbw   mm0,    mm7
-        punpcklbw   mm1,    mm7
-        psubw   mm0,        mm1
-        movq    [rdi+rcx*2],        mm0
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-;void vp8_subtract_mby_mmx(short *diff, unsigned char *src, unsigned char *pred, int stride)
-global sym(vp8_subtract_mby_mmx)
-sym(vp8_subtract_mby_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 4
-    push rsi
-    push rdi
-    ; end prolog
-
-
-            mov         rsi,            arg(1) ;src
-            mov         rdi,            arg(0) ;diff
-
-            mov         rax,            arg(2) ;pred
-            movsxd      rdx,            dword ptr arg(3) ;stride
-
-            mov         rcx,            16
-            pxor        mm0,            mm0
-
-submby_loop:
-
-            movq        mm1,            [rsi]
-            movq        mm3,            [rax]
-
-            movq        mm2,            mm1
-            movq        mm4,            mm3
-
-            punpcklbw   mm1,            mm0
-            punpcklbw   mm3,            mm0
-
-            punpckhbw   mm2,            mm0
-            punpckhbw   mm4,            mm0
-
-            psubw       mm1,            mm3
-            psubw       mm2,            mm4
-
-            movq        [rdi],          mm1
-            movq        [rdi+8],        mm2
-
-
-            movq        mm1,            [rsi+8]
-            movq        mm3,            [rax+8]
-
-            movq        mm2,            mm1
-            movq        mm4,            mm3
-
-            punpcklbw   mm1,            mm0
-            punpcklbw   mm3,            mm0
-
-            punpckhbw   mm2,            mm0
-            punpckhbw   mm4,            mm0
-
-            psubw       mm1,            mm3
-            psubw       mm2,            mm4
-
-            movq        [rdi+16],       mm1
-            movq        [rdi+24],       mm2
-
-
-            add         rdi,            32
-            add         rax,            16
-
-            lea         rsi,            [rsi+rdx]
-
-            sub         rcx,            1
-            jnz         submby_loop
-
-    pop rdi
-    pop rsi
-    ; begin epilog
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void vp8_subtract_mbuv_mmx(short *diff, unsigned char *usrc, unsigned char *vsrc, unsigned char *pred, int stride)
-global sym(vp8_subtract_mbuv_mmx)
-sym(vp8_subtract_mbuv_mmx)
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 5
-    push rsi
-    push rdi
-    ; end prolog
-
-    ;short *udiff = diff + 256;
-    ;short *vdiff = diff + 320;
-    ;unsigned char *upred = pred + 256;
-    ;unsigned char *vpred = pred + 320;
-
-        ;unsigned char  *z    = usrc;
-        ;unsigned short *diff = udiff;
-        ;unsigned char  *Predictor= upred;
-
-            mov     rdi,        arg(0) ;diff
-            mov     rax,        arg(3) ;pred
-            mov     rsi,        arg(1) ;z = usrc
-            add     rdi,        256*2  ;diff = diff + 256 (shorts)
-            add     rax,        256    ;Predictor = pred + 256
-            movsxd  rdx,        dword ptr arg(4) ;stride;
-            pxor    mm7,        mm7
-
-            movq    mm0,        [rsi]
-            movq    mm1,        [rax]
-            movq    mm3,        mm0
-            movq    mm4,        mm1
-            punpcklbw   mm0,    mm7
-            punpcklbw   mm1,    mm7
-            punpckhbw   mm3,    mm7
-            punpckhbw   mm4,    mm7
-            psubw   mm0,        mm1
-            psubw   mm3,        mm4
-            movq    [rdi],      mm0
-            movq    [rdi+8],    mm3
-
-
-            movq    mm0,        [rsi+rdx]
-            movq    mm1,        [rax+8]
-            movq    mm3,        mm0
-            movq    mm4,        mm1
-            punpcklbw   mm0,    mm7
-            punpcklbw   mm1,    mm7
-            punpckhbw   mm3,    mm7
-            punpckhbw   mm4,    mm7
-            psubw   mm0,        mm1
-            psubw   mm3,        mm4
-            movq    [rdi+16],   mm0
-            movq    [rdi+24],   mm3
-
-            movq    mm0,        [rsi+rdx*2]
-            movq    mm1,        [rax+16]
-            movq    mm3,        mm0
-            movq    mm4,        mm1
-            punpcklbw   mm0,    mm7
-            punpcklbw   mm1,    mm7
-            punpckhbw   mm3,    mm7
-            punpckhbw   mm4,    mm7
-            psubw   mm0,        mm1
-            psubw   mm3,        mm4
-            movq    [rdi+32],   mm0
-            movq    [rdi+40],   mm3
-            lea     rsi,        [rsi+rdx*2]
-
-
-            movq    mm0,        [rsi+rdx]
-            movq    mm1,        [rax+24]
-            movq    mm3,        mm0
-            movq    mm4,        mm1
-            punpcklbw   mm0,    mm7
-            punpcklbw   mm1,    mm7
-            punpckhbw   mm3,    mm7
-            punpckhbw   mm4,    mm7
-            psubw   mm0,        mm1
-            psubw   mm3,        mm4
-
-            movq    [rdi+48],   mm0
-            movq    [rdi+56],   mm3
-
-
-            add     rdi,        64
-            add     rax,        32
-            lea     rsi,        [rsi+rdx*2]
-
-
-            movq    mm0,        [rsi]
-            movq    mm1,        [rax]
-            movq    mm3,        mm0
-            movq    mm4,        mm1
-            punpcklbw   mm0,    mm7
-            punpcklbw   mm1,    mm7
-            punpckhbw   mm3,    mm7
-            punpckhbw   mm4,    mm7
-            psubw   mm0,        mm1
-            psubw   mm3,        mm4
-            movq    [rdi],      mm0
-            movq    [rdi+8],    mm3
-
-
-            movq    mm0,        [rsi+rdx]
-            movq    mm1,        [rax+8]
-            movq    mm3,        mm0
-            movq    mm4,        mm1
-            punpcklbw   mm0,    mm7
-            punpcklbw   mm1,    mm7
-            punpckhbw   mm3,    mm7
-            punpckhbw   mm4,    mm7
-            psubw   mm0,        mm1
-            psubw   mm3,        mm4
-            movq    [rdi+16],   mm0
-            movq    [rdi+24],   mm3
-
-            movq    mm0,        [rsi+rdx*2]
-            movq    mm1,        [rax+16]
-            movq    mm3,        mm0
-            movq    mm4,        mm1
-            punpcklbw   mm0,    mm7
-            punpcklbw   mm1,    mm7
-            punpckhbw   mm3,    mm7
-            punpckhbw   mm4,    mm7
-            psubw   mm0,        mm1
-            psubw   mm3,        mm4
-            movq    [rdi+32],   mm0
-            movq    [rdi+40],   mm3
-            lea     rsi,        [rsi+rdx*2]
-
-
-            movq    mm0,        [rsi+rdx]
-            movq    mm1,        [rax+24]
-            movq    mm3,        mm0
-            movq    mm4,        mm1
-            punpcklbw   mm0,    mm7
-            punpcklbw   mm1,    mm7
-            punpckhbw   mm3,    mm7
-            punpckhbw   mm4,    mm7
-            psubw   mm0,        mm1
-            psubw   mm3,        mm4
-
-            movq    [rdi+48],   mm0
-            movq    [rdi+56],   mm3
-
-        ;unsigned char  *z    = vsrc;
-        ;unsigned short *diff = vdiff;
-        ;unsigned char  *Predictor= vpred;
-
-            mov     rdi,        arg(0) ;diff
-            mov     rax,        arg(3) ;pred
-            mov     rsi,        arg(2) ;z = usrc
-            add     rdi,        320*2  ;diff = diff + 320 (shorts)
-            add     rax,        320    ;Predictor = pred + 320
-            movsxd  rdx,        dword ptr arg(4) ;stride;
-            pxor    mm7,        mm7
-
-            movq    mm0,        [rsi]
-            movq    mm1,        [rax]
-            movq    mm3,        mm0
-            movq    mm4,        mm1
-            punpcklbw   mm0,    mm7
-            punpcklbw   mm1,    mm7
-            punpckhbw   mm3,    mm7
-            punpckhbw   mm4,    mm7
-            psubw   mm0,        mm1
-            psubw   mm3,        mm4
-            movq    [rdi],      mm0
-            movq    [rdi+8],    mm3
-
-
-            movq    mm0,        [rsi+rdx]
-            movq    mm1,        [rax+8]
-            movq    mm3,        mm0
-            movq    mm4,        mm1
-            punpcklbw   mm0,    mm7
-            punpcklbw   mm1,    mm7
-            punpckhbw   mm3,    mm7
-            punpckhbw   mm4,    mm7
-            psubw   mm0,        mm1
-            psubw   mm3,        mm4
-            movq    [rdi+16],   mm0
-            movq    [rdi+24],   mm3
-
-            movq    mm0,        [rsi+rdx*2]
-            movq    mm1,        [rax+16]
-            movq    mm3,        mm0
-            movq    mm4,        mm1
-            punpcklbw   mm0,    mm7
-            punpcklbw   mm1,    mm7
-            punpckhbw   mm3,    mm7
-            punpckhbw   mm4,    mm7
-            psubw   mm0,        mm1
-            psubw   mm3,        mm4
-            movq    [rdi+32],   mm0
-            movq    [rdi+40],   mm3
-            lea     rsi,        [rsi+rdx*2]
-
-
-            movq    mm0,        [rsi+rdx]
-            movq    mm1,        [rax+24]
-            movq    mm3,        mm0
-            movq    mm4,        mm1
-            punpcklbw   mm0,    mm7
-            punpcklbw   mm1,    mm7
-            punpckhbw   mm3,    mm7
-            punpckhbw   mm4,    mm7
-            psubw   mm0,        mm1
-            psubw   mm3,        mm4
-
-            movq    [rdi+48],   mm0
-            movq    [rdi+56],   mm3
-
-
-            add     rdi,        64
-            add     rax,        32
-            lea     rsi,        [rsi+rdx*2]
-
-
-            movq    mm0,        [rsi]
-            movq    mm1,        [rax]
-            movq    mm3,        mm0
-            movq    mm4,        mm1
-            punpcklbw   mm0,    mm7
-            punpcklbw   mm1,    mm7
-            punpckhbw   mm3,    mm7
-            punpckhbw   mm4,    mm7
-            psubw   mm0,        mm1
-            psubw   mm3,        mm4
-            movq    [rdi],      mm0
-            movq    [rdi+8],    mm3
-
-
-            movq    mm0,        [rsi+rdx]
-            movq    mm1,        [rax+8]
-            movq    mm3,        mm0
-            movq    mm4,        mm1
-            punpcklbw   mm0,    mm7
-            punpcklbw   mm1,    mm7
-            punpckhbw   mm3,    mm7
-            punpckhbw   mm4,    mm7
-            psubw   mm0,        mm1
-            psubw   mm3,        mm4
-            movq    [rdi+16],   mm0
-            movq    [rdi+24],   mm3
-
-            movq    mm0,        [rsi+rdx*2]
-            movq    mm1,        [rax+16]
-            movq    mm3,        mm0
-            movq    mm4,        mm1
-            punpcklbw   mm0,    mm7
-            punpcklbw   mm1,    mm7
-            punpckhbw   mm3,    mm7
-            punpckhbw   mm4,    mm7
-            psubw   mm0,        mm1
-            psubw   mm3,        mm4
-            movq    [rdi+32],   mm0
-            movq    [rdi+40],   mm3
-            lea     rsi,        [rsi+rdx*2]
-
-
-            movq    mm0,        [rsi+rdx]
-            movq    mm1,        [rax+24]
-            movq    mm3,        mm0
-            movq    mm4,        mm1
-            punpcklbw   mm0,    mm7
-            punpcklbw   mm1,    mm7
-            punpckhbw   mm3,    mm7
-            punpckhbw   mm4,    mm7
-            psubw   mm0,        mm1
-            psubw   mm3,        mm4
-
-            movq    [rdi+48],   mm0
-            movq    [rdi+56],   mm3
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
diff --git a/vp8/encoder/x86/variance_impl_mmx.S b/vp8/encoder/x86/variance_impl_mmx.S
new file mode 100644
index 0000000..1b9c935
--- /dev/null
+++ b/vp8/encoder/x86/variance_impl_mmx.S
@@ -0,0 +1,980 @@
+//
+//  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
+//
+//  Use of this source code is governed by a BSD-style license and patent
+//  grant that can be found in the LICENSE file in the root of the source
+//  tree. All contributing project authors may be found in the AUTHORS
+//  file in the root of the source tree.
+//
+
+
+#include "vpx_ports/x86_abi_support.S"
+
+//unsigned int vp8_get_mb_ss_mmx( short *src_ptr )
+global sym(vp8_get_mb_ss_mmx)
+sym(vp8_get_mb_ss_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 7
+    GET_GOT     rbx
+    push rsi
+    push rdi
+    sub         rsp, 8
+    // end prolog
+
+        mov         rax, arg(0) //src_ptr
+        mov         rcx, 16
+        pxor        mm4, mm4
+
+NEXTROW:
+        movq        mm0, [rax]
+        movq        mm1, [rax+8]
+        movq        mm2, [rax+16]
+        movq        mm3, [rax+24]
+        pmaddwd     mm0, mm0
+        pmaddwd     mm1, mm1
+        pmaddwd     mm2, mm2
+        pmaddwd     mm3, mm3
+
+        paddd       mm4, mm0
+        paddd       mm4, mm1
+        paddd       mm4, mm2
+        paddd       mm4, mm3
+
+        add         rax, 32
+        dec         rcx
+        ja          NEXTROW
+        movq        QWORD PTR [rsp], mm4
+
+        //return sum[0]+sum[1];
+        movsxd      rax, dword ptr [rsp]
+        movsxd      rcx, dword ptr [rsp+4]
+        add         rax, rcx
+
+
+    // begin epilog
+    add rsp, 8
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//unsigned int vp8_get8x8var_mmx
+//(
+//    unsigned char *src_ptr,
+//    int  source_stride,
+//    unsigned char *ref_ptr,
+//    int  recon_stride,
+//    unsigned int *SSE,
+//    int *Sum
+//)
+global sym(vp8_get8x8var_mmx)
+sym(vp8_get8x8var_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 6
+    push rsi
+    push rdi
+    push rbx
+    sub         rsp, 16
+    // end prolog
+
+
+        pxor        mm5, mm5                    // Blank mmx6
+        pxor        mm6, mm6                    // Blank mmx7
+        pxor        mm7, mm7                    // Blank mmx7
+
+        mov         rax, arg(0) //[src_ptr]  ; Load base addresses
+        mov         rbx, arg(2) //[ref_ptr]
+        movsxd      rcx, dword ptr arg(1) //[source_stride]
+        movsxd      rdx, dword ptr arg(3) //[recon_stride]
+
+        // Row 1
+        movq        mm0, [rax]                  // Copy eight bytes to mm0
+        movq        mm1, [rbx]                  // Copy eight bytes to mm1
+        movq        mm2, mm0                    // Take copies
+        movq        mm3, mm1                    // Take copies
+
+        punpcklbw   mm0, mm6                    // unpack to higher prrcision
+        punpcklbw   mm1, mm6
+        punpckhbw   mm2, mm6                    // unpack to higher prrcision
+        punpckhbw   mm3, mm6
+        psubsw      mm0, mm1                    // A-B (low order) to MM0
+        psubsw      mm2, mm3                    // A-B (high order) to MM2
+
+        paddw       mm5, mm0                    // accumulate differences in mm5
+        paddw       mm5, mm2                    // accumulate differences in mm5
+
+        pmaddwd     mm0, mm0                    // square and accumulate
+        pmaddwd     mm2, mm2                    // square and accumulate
+        add         rbx,rdx                     // Inc pointer into ref data
+        add         rax,rcx                     // Inc pointer into the new data
+        movq        mm1, [rbx]                  // Copy eight bytes to mm1
+        paddd       mm7, mm0                    // accumulate in mm7
+        paddd       mm7, mm2                    // accumulate in mm7
+
+
+        // Row 2
+        movq        mm0, [rax]                  // Copy eight bytes to mm0
+        movq        mm2, mm0                    // Take copies
+        movq        mm3, mm1                    // Take copies
+
+        punpcklbw   mm0, mm6                    // unpack to higher prrcision
+        punpcklbw   mm1, mm6
+        punpckhbw   mm2, mm6                    // unpack to higher prrcision
+        punpckhbw   mm3, mm6
+        psubsw      mm0, mm1                    // A-B (low order) to MM0
+        psubsw      mm2, mm3                    // A-B (high order) to MM2
+
+        paddw       mm5, mm0                    // accumulate differences in mm5
+        paddw       mm5, mm2                    // accumulate differences in mm5
+
+        pmaddwd     mm0, mm0                    // square and accumulate
+        pmaddwd     mm2, mm2                    // square and accumulate
+        add         rbx,rdx                     // Inc pointer into ref data
+        add         rax,rcx                     // Inc pointer into the new data
+        movq        mm1, [rbx]                  // Copy eight bytes to mm1
+        paddd       mm7, mm0                    // accumulate in mm7
+        paddd       mm7, mm2                    // accumulate in mm7
+
+        // Row 3
+        movq        mm0, [rax]                  // Copy eight bytes to mm0
+        movq        mm2, mm0                    // Take copies
+        movq        mm3, mm1                    // Take copies
+
+        punpcklbw   mm0, mm6                    // unpack to higher prrcision
+        punpcklbw   mm1, mm6
+        punpckhbw   mm2, mm6                    // unpack to higher prrcision
+        punpckhbw   mm3, mm6
+        psubsw      mm0, mm1                    // A-B (low order) to MM0
+        psubsw      mm2, mm3                    // A-B (high order) to MM2
+
+        paddw       mm5, mm0                    // accumulate differences in mm5
+        paddw       mm5, mm2                    // accumulate differences in mm5
+
+        pmaddwd     mm0, mm0                    // square and accumulate
+        pmaddwd     mm2, mm2                    // square and accumulate
+        add         rbx,rdx                     // Inc pointer into ref data
+        add         rax,rcx                     // Inc pointer into the new data
+        movq        mm1, [rbx]                  // Copy eight bytes to mm1
+        paddd       mm7, mm0                    // accumulate in mm7
+        paddd       mm7, mm2                    // accumulate in mm7
+
+        // Row 4
+        movq        mm0, [rax]                  // Copy eight bytes to mm0
+        movq        mm2, mm0                    // Take copies
+        movq        mm3, mm1                    // Take copies
+
+        punpcklbw   mm0, mm6                    // unpack to higher prrcision
+        punpcklbw   mm1, mm6
+        punpckhbw   mm2, mm6                    // unpack to higher prrcision
+        punpckhbw   mm3, mm6
+        psubsw      mm0, mm1                    // A-B (low order) to MM0
+        psubsw      mm2, mm3                    // A-B (high order) to MM2
+
+        paddw       mm5, mm0                    // accumulate differences in mm5
+        paddw       mm5, mm2                    // accumulate differences in mm5
+
+        pmaddwd     mm0, mm0                    // square and accumulate
+        pmaddwd     mm2, mm2                    // square and accumulate
+        add         rbx,rdx                     // Inc pointer into ref data
+        add         rax,rcx                     // Inc pointer into the new data
+        movq        mm1, [rbx]                  // Copy eight bytes to mm1
+        paddd       mm7, mm0                    // accumulate in mm7
+        paddd       mm7, mm2                    // accumulate in mm7
+
+        // Row 5
+        movq        mm0, [rax]                  // Copy eight bytes to mm0
+        movq        mm2, mm0                    // Take copies
+        movq        mm3, mm1                    // Take copies
+
+        punpcklbw   mm0, mm6                    // unpack to higher prrcision
+        punpcklbw   mm1, mm6
+        punpckhbw   mm2, mm6                    // unpack to higher prrcision
+        punpckhbw   mm3, mm6
+        psubsw      mm0, mm1                    // A-B (low order) to MM0
+        psubsw      mm2, mm3                    // A-B (high order) to MM2
+
+        paddw       mm5, mm0                    // accumulate differences in mm5
+        paddw       mm5, mm2                    // accumulate differences in mm5
+
+        pmaddwd     mm0, mm0                    // square and accumulate
+        pmaddwd     mm2, mm2                    // square and accumulate
+        add         rbx,rdx                     // Inc pointer into ref data
+        add         rax,rcx                     // Inc pointer into the new data
+        movq        mm1, [rbx]                  // Copy eight bytes to mm1
+        //              movq        mm4, [rbx + rdx]
+        paddd       mm7, mm0                    // accumulate in mm7
+        paddd       mm7, mm2                    // accumulate in mm7
+
+        // Row 6
+        movq        mm0, [rax]                  // Copy eight bytes to mm0
+        movq        mm2, mm0                    // Take copies
+        movq        mm3, mm1                    // Take copies
+
+        punpcklbw   mm0, mm6                    // unpack to higher prrcision
+        punpcklbw   mm1, mm6
+        punpckhbw   mm2, mm6                    // unpack to higher prrcision
+        punpckhbw   mm3, mm6
+        psubsw      mm0, mm1                    // A-B (low order) to MM0
+        psubsw      mm2, mm3                    // A-B (high order) to MM2
+
+        paddw       mm5, mm0                    // accumulate differences in mm5
+        paddw       mm5, mm2                    // accumulate differences in mm5
+
+        pmaddwd     mm0, mm0                    // square and accumulate
+        pmaddwd     mm2, mm2                    // square and accumulate
+        add         rbx,rdx                     // Inc pointer into ref data
+        add         rax,rcx                     // Inc pointer into the new data
+        movq        mm1, [rbx]                  // Copy eight bytes to mm1
+        paddd       mm7, mm0                    // accumulate in mm7
+        paddd       mm7, mm2                    // accumulate in mm7
+
+        // Row 7
+        movq        mm0, [rax]                  // Copy eight bytes to mm0
+        movq        mm2, mm0                    // Take copies
+        movq        mm3, mm1                    // Take copies
+
+        punpcklbw   mm0, mm6                    // unpack to higher prrcision
+        punpcklbw   mm1, mm6
+        punpckhbw   mm2, mm6                    // unpack to higher prrcision
+        punpckhbw   mm3, mm6
+        psubsw      mm0, mm1                    // A-B (low order) to MM0
+        psubsw      mm2, mm3                    // A-B (high order) to MM2
+
+        paddw       mm5, mm0                    // accumulate differences in mm5
+        paddw       mm5, mm2                    // accumulate differences in mm5
+
+        pmaddwd     mm0, mm0                    // square and accumulate
+        pmaddwd     mm2, mm2                    // square and accumulate
+        add         rbx,rdx                     // Inc pointer into ref data
+        add         rax,rcx                     // Inc pointer into the new data
+        movq        mm1, [rbx]                  // Copy eight bytes to mm1
+        paddd       mm7, mm0                    // accumulate in mm7
+        paddd       mm7, mm2                    // accumulate in mm7
+
+        // Row 8
+        movq        mm0, [rax]                  // Copy eight bytes to mm0
+        movq        mm2, mm0                    // Take copies
+        movq        mm3, mm1                    // Take copies
+
+        punpcklbw   mm0, mm6                    // unpack to higher prrcision
+        punpcklbw   mm1, mm6
+        punpckhbw   mm2, mm6                    // unpack to higher prrcision
+        punpckhbw   mm3, mm6
+        psubsw      mm0, mm1                    // A-B (low order) to MM0
+        psubsw      mm2, mm3                    // A-B (high order) to MM2
+
+        paddw       mm5, mm0                    // accumulate differences in mm5
+        paddw       mm5, mm2                    // accumulate differences in mm5
+
+        pmaddwd     mm0, mm0                    // square and accumulate
+        pmaddwd     mm2, mm2                    // square and accumulate
+        add         rbx,rdx                     // Inc pointer into ref data
+        add         rax,rcx                     // Inc pointer into the new data
+        paddd       mm7, mm0                    // accumulate in mm7
+        paddd       mm7, mm2                    // accumulate in mm7
+
+        // Now accumulate the final results.
+        movq        QWORD PTR [rsp+8], mm5      // copy back accumulated results into normal memory
+        movq        QWORD PTR [rsp], mm7        // copy back accumulated results into normal memory
+        movsx       rdx, WORD PTR [rsp+8]
+        movsx       rcx, WORD PTR [rsp+10]
+        movsx       rbx, WORD PTR [rsp+12]
+        movsx       rax, WORD PTR [rsp+14]
+        add         rdx, rcx
+        add         rbx, rax
+        add         rdx, rbx    //XSum
+        movsxd      rax, DWORD PTR [rsp]
+        movsxd      rcx, DWORD PTR [rsp+4]
+        add         rax, rcx    //XXSum
+        mov         rsi, arg(4) //SSE
+        mov         rdi, arg(5) //Sum
+        mov         dword ptr [rsi], eax
+        mov         dword ptr [rdi], edx
+        xor         rax, rax    // return 0
+
+
+    // begin epilog
+    add rsp, 16
+    pop rbx
+    pop rdi
+    pop rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+
+//unsigned int
+//vp8_get4x4var_mmx
+//(
+//    unsigned char *src_ptr,
+//    int  source_stride,
+//    unsigned char *ref_ptr,
+//    int  recon_stride,
+//    unsigned int *SSE,
+//    int *Sum
+//)
+global sym(vp8_get4x4var_mmx)
+sym(vp8_get4x4var_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 6
+    push rsi
+    push rdi
+    push rbx
+    sub         rsp, 16
+    // end prolog
+
+
+        pxor        mm5, mm5                    // Blank mmx6
+        pxor        mm6, mm6                    // Blank mmx7
+        pxor        mm7, mm7                    // Blank mmx7
+
+        mov         rax, arg(0) //[src_ptr]  ; Load base addresses
+        mov         rbx, arg(2) //[ref_ptr]
+        movsxd      rcx, dword ptr arg(1) //[source_stride]
+        movsxd      rdx, dword ptr arg(3) //[recon_stride]
+
+        // Row 1
+        movq        mm0, [rax]                  // Copy eight bytes to mm0
+        movq        mm1, [rbx]                  // Copy eight bytes to mm1
+        punpcklbw   mm0, mm6                    // unpack to higher prrcision
+        punpcklbw   mm1, mm6
+        psubsw      mm0, mm1                    // A-B (low order) to MM0
+        paddw       mm5, mm0                    // accumulate differences in mm5
+        pmaddwd     mm0, mm0                    // square and accumulate
+        add         rbx,rdx                     // Inc pointer into ref data
+        add         rax,rcx                     // Inc pointer into the new data
+        movq        mm1, [rbx]                  // Copy eight bytes to mm1
+        paddd       mm7, mm0                    // accumulate in mm7
+
+
+        // Row 2
+        movq        mm0, [rax]                  // Copy eight bytes to mm0
+        punpcklbw   mm0, mm6                    // unpack to higher prrcision
+        punpcklbw   mm1, mm6
+        psubsw      mm0, mm1                    // A-B (low order) to MM0
+        paddw       mm5, mm0                    // accumulate differences in mm5
+
+        pmaddwd     mm0, mm0                    // square and accumulate
+        add         rbx,rdx                     // Inc pointer into ref data
+        add         rax,rcx                     // Inc pointer into the new data
+        movq        mm1, [rbx]                  // Copy eight bytes to mm1
+        paddd       mm7, mm0                    // accumulate in mm7
+
+        // Row 3
+        movq        mm0, [rax]                  // Copy eight bytes to mm0
+        punpcklbw   mm0, mm6                    // unpack to higher prrcision
+        punpcklbw   mm1, mm6
+        psubsw      mm0, mm1                    // A-B (low order) to MM0
+        paddw       mm5, mm0                    // accumulate differences in mm5
+
+        pmaddwd     mm0, mm0                    // square and accumulate
+        add         rbx,rdx                     // Inc pointer into ref data
+        add         rax,rcx                     // Inc pointer into the new data
+        movq        mm1, [rbx]                  // Copy eight bytes to mm1
+        paddd       mm7, mm0                    // accumulate in mm7
+
+        // Row 4
+        movq        mm0, [rax]                  // Copy eight bytes to mm0
+
+        punpcklbw   mm0, mm6                    // unpack to higher prrcision
+        punpcklbw   mm1, mm6
+        psubsw      mm0, mm1                    // A-B (low order) to MM0
+
+        paddw       mm5, mm0                    // accumulate differences in mm5
+
+        pmaddwd     mm0, mm0                    // square and accumulate
+        paddd       mm7, mm0                    // accumulate in mm7
+
+
+        // Now accumulate the final results.
+        movq        QWORD PTR [rsp+8], mm5      // copy back accumulated results into normal memory
+        movq        QWORD PTR [rsp], mm7        // copy back accumulated results into normal memory
+        movsx       rdx, WORD PTR [rsp+8]
+        movsx       rcx, WORD PTR [rsp+10]
+        movsx       rbx, WORD PTR [rsp+12]
+        movsx       rax, WORD PTR [rsp+14]
+        add         rdx, rcx
+        add         rbx, rax
+        add         rdx, rbx    //XSum
+        movsxd      rax, DWORD PTR [rsp]
+        movsxd      rcx, DWORD PTR [rsp+4]
+        add         rax, rcx    //XXSum
+        mov         rsi, arg(4) //SSE
+        mov         rdi, arg(5) //Sum
+        mov         dword ptr [rsi], eax
+        mov         dword ptr [rdi], edx
+        xor         rax, rax    // return 0
+
+
+    // begin epilog
+    add rsp, 16
+    pop rbx
+    pop rdi
+    pop rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+
+//unsigned int
+//vp8_get4x4sse_cs_mmx
+//(
+//    unsigned char *src_ptr,
+//    int  source_stride,
+//    unsigned char *ref_ptr,
+//    int  recon_stride
+//)
+global sym(vp8_get4x4sse_cs_mmx)
+sym(vp8_get4x4sse_cs_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 4
+    push rsi
+    push rdi
+    push rbx
+    // end prolog
+
+
+        pxor        mm6, mm6                    // Blank mmx7
+        pxor        mm7, mm7                    // Blank mmx7
+
+        mov         rax, arg(0) //[src_ptr]  ; Load base addresses
+        mov         rbx, arg(2) //[ref_ptr]
+        movsxd      rcx, dword ptr arg(1) //[source_stride]
+        movsxd      rdx, dword ptr arg(3) //[recon_stride]
+        // Row 1
+        movd        mm0, [rax]                  // Copy eight bytes to mm0
+        movd        mm1, [rbx]                  // Copy eight bytes to mm1
+        punpcklbw   mm0, mm6                    // unpack to higher prrcision
+        punpcklbw   mm1, mm6
+        psubsw      mm0, mm1                    // A-B (low order) to MM0
+        pmaddwd     mm0, mm0                    // square and accumulate
+        add         rbx,rdx                     // Inc pointer into ref data
+        add         rax,rcx                     // Inc pointer into the new data
+        movd        mm1, [rbx]                  // Copy eight bytes to mm1
+        paddd       mm7, mm0                    // accumulate in mm7
+
+        // Row 2
+        movd        mm0, [rax]                  // Copy eight bytes to mm0
+        punpcklbw   mm0, mm6                    // unpack to higher prrcision
+        punpcklbw   mm1, mm6
+        psubsw      mm0, mm1                    // A-B (low order) to MM0
+        pmaddwd     mm0, mm0                    // square and accumulate
+        add         rbx,rdx                     // Inc pointer into ref data
+        add         rax,rcx                     // Inc pointer into the new data
+        movd        mm1, [rbx]                  // Copy eight bytes to mm1
+        paddd       mm7, mm0                    // accumulate in mm7
+
+        // Row 3
+        movd        mm0, [rax]                  // Copy eight bytes to mm0
+        punpcklbw   mm1, mm6
+        punpcklbw   mm0, mm6                    // unpack to higher prrcision
+        psubsw      mm0, mm1                    // A-B (low order) to MM0
+
+        pmaddwd     mm0, mm0                    // square and accumulate
+        add         rbx,rdx                     // Inc pointer into ref data
+        add         rax,rcx                     // Inc pointer into the new data
+        movd        mm1, [rbx]                  // Copy eight bytes to mm1
+        paddd       mm7, mm0                    // accumulate in mm7
+
+        // Row 4
+        movd        mm0, [rax]                  // Copy eight bytes to mm0
+        punpcklbw   mm0, mm6                    // unpack to higher prrcision
+        punpcklbw   mm1, mm6
+        psubsw      mm0, mm1                    // A-B (low order) to MM0
+        pmaddwd     mm0, mm0                    // square and accumulate
+        paddd       mm7, mm0                    // accumulate in mm7
+
+        movq        mm0,    mm7                 //
+        psrlq       mm7,    32
+
+        paddd       mm0,    mm7
+        movd        rax,    mm0
+
+
+    // begin epilog
+    pop rbx
+    pop rdi
+    pop rsi
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+#define mmx_filter_shift            7
+
+//void vp8_filter_block2d_bil4x4_var_mmx
+//(
+//    unsigned char *ref_ptr,
+//    int ref_pixels_per_line,
+//    unsigned char *src_ptr,
+//    int src_pixels_per_line,
+//    unsigned short *HFilter,
+//    unsigned short *VFilter,
+//    int *sum,
+//    unsigned int *sumsquared
+//)
+global sym(vp8_filter_block2d_bil4x4_var_mmx)
+sym(vp8_filter_block2d_bil4x4_var_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 8
+    GET_GOT     rbx
+    push rsi
+    push rdi
+    sub         rsp, 16
+    // end prolog
+
+
+        pxor            mm6,            mm6                 //
+        pxor            mm7,            mm7                 //
+
+        mov             rax,            arg(4) //HFilter             ;
+        mov             rdx,            arg(5) //VFilter             ;
+
+        mov             rsi,            arg(0) //ref_ptr              ;
+        mov             rdi,            arg(2) //src_ptr              ;
+
+        mov             rcx,            4                   //
+        pxor            mm0,            mm0                 //
+
+        movd            mm1,            [rsi]               //
+        movd            mm3,            [rsi+1]             //
+
+        punpcklbw       mm1,            mm0                 //
+        pmullw          mm1,            [rax]               //
+
+        punpcklbw       mm3,            mm0                 //
+        pmullw          mm3,            [rax+8]             //
+
+        paddw           mm1,            mm3                 //
+        paddw           mm1,            [GLOBAL (mmx_bi_rd)]  //
+
+        psraw           mm1,            mmx_filter_shift    //
+        movq            mm5,            mm1
+
+#if ABI_IS_32BIT
+        add             rsi, dword ptr  arg(1) //ref_pixels_per_line    ;
+#else
+        movsxd          r8, dword ptr  arg(1) //ref_pixels_per_line    ;
+        add             rsi, r8
+#endif
+
+filter_block2d_bil4x4_var_mmx_loop:
+
+        movd            mm1,            [rsi]               //
+        movd            mm3,            [rsi+1]             //
+
+        punpcklbw       mm1,            mm0                 //
+        pmullw          mm1,            [rax]               //
+
+        punpcklbw       mm3,            mm0                 //
+        pmullw          mm3,            [rax+8]             //
+
+        paddw           mm1,            mm3                 //
+        paddw           mm1,            [GLOBAL (mmx_bi_rd)]  //
+
+        psraw           mm1,            mmx_filter_shift    //
+        movq            mm3,            mm5                 //
+
+        movq            mm5,            mm1                 //
+        pmullw          mm3,            [rdx]               //
+
+        pmullw          mm1,            [rdx+8]             //
+        paddw           mm1,            mm3                 //
+
+
+        paddw           mm1,            [GLOBAL (mmx_bi_rd)]  //
+        psraw           mm1,            mmx_filter_shift    //
+
+        movd            mm3,            [rdi]               //
+        punpcklbw       mm3,            mm0                 //
+
+        psubw           mm1,            mm3                 //
+        paddw           mm6,            mm1                 //
+
+        pmaddwd         mm1,            mm1                 //
+        paddd           mm7,            mm1                 //
+
+#if ABI_IS_32BIT
+        add             rsi,            dword ptr arg(1) //ref_pixels_per_line    ;
+        add             rdi,            dword ptr arg(3) //src_pixels_per_line    ;
+#else
+        movsxd          r8,             dword ptr arg(1) //ref_pixels_per_line
+        movsxd          r9,             dword ptr arg(3) //src_pixels_per_line
+        add             rsi,            r8
+        add             rdi,            r9
+#endif
+        sub             rcx,            1                   //
+        jnz             filter_block2d_bil4x4_var_mmx_loop       //
+
+
+        pxor            mm3,            mm3                 //
+        pxor            mm2,            mm2                 //
+
+        punpcklwd       mm2,            mm6                 //
+        punpckhwd       mm3,            mm6                 //
+
+        paddd           mm2,            mm3                 //
+        movq            mm6,            mm2                 //
+
+        psrlq           mm6,            32                  //
+        paddd           mm2,            mm6                 //
+
+        psrad           mm2,            16                  //
+        movq            mm4,            mm7                 //
+
+        psrlq           mm4,            32                  //
+        paddd           mm4,            mm7                 //
+
+        mov             rdi,            arg(6) //sum
+        mov             rsi,            arg(7) //sumsquared
+
+        movd            dword ptr [rdi],          mm2                 //
+        movd            dword ptr [rsi],          mm4                 //
+
+
+
+    // begin epilog
+    add rsp, 16
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+
+
+//void vp8_filter_block2d_bil_var_mmx
+//(
+//    unsigned char *ref_ptr,
+//    int ref_pixels_per_line,
+//    unsigned char *src_ptr,
+//    int src_pixels_per_line,
+//    unsigned int Height,
+//    unsigned short *HFilter,
+//    unsigned short *VFilter,
+//    int *sum,
+//    unsigned int *sumsquared
+//)
+global sym(vp8_filter_block2d_bil_var_mmx)
+sym(vp8_filter_block2d_bil_var_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 9
+    GET_GOT     rbx
+    push rsi
+    push rdi
+    sub         rsp, 16
+    // end prolog
+
+        pxor            mm6,            mm6                 //
+        pxor            mm7,            mm7                 //
+        mov             rax,            arg(5) //HFilter             ;
+
+        mov             rdx,            arg(6) //VFilter             ;
+        mov             rsi,            arg(0) //ref_ptr              ;
+
+        mov             rdi,            arg(2) //src_ptr              ;
+        movsxd          rcx,            dword ptr arg(4) //Height              ;
+
+        pxor            mm0,            mm0                 //
+        movq            mm1,            [rsi]               //
+
+        movq            mm3,            [rsi+1]             //
+        movq            mm2,            mm1                 //
+
+        movq            mm4,            mm3                 //
+        punpcklbw       mm1,            mm0                 //
+
+        punpckhbw       mm2,            mm0                 //
+        pmullw          mm1,            [rax]               //
+
+        pmullw          mm2,            [rax]               //
+        punpcklbw       mm3,            mm0                 //
+
+        punpckhbw       mm4,            mm0                 //
+        pmullw          mm3,            [rax+8]             //
+
+        pmullw          mm4,            [rax+8]             //
+        paddw           mm1,            mm3                 //
+
+        paddw           mm2,            mm4                 //
+        paddw           mm1,            [GLOBAL (mmx_bi_rd)]  //
+
+        psraw           mm1,            mmx_filter_shift    //
+        paddw           mm2,            [GLOBAL (mmx_bi_rd)]  //
+
+        psraw           mm2,            mmx_filter_shift    //
+        movq            mm5,            mm1
+
+        packuswb        mm5,            mm2                 //
+#if ABI_IS_32BIT
+        add             rsi,            dword ptr arg(1) //ref_pixels_per_line
+#else
+        movsxd          r8,             dword ptr arg(1) //ref_pixels_per_line
+        add             rsi,            r8
+#endif
+
+filter_block2d_bil_var_mmx_loop:
+
+        movq            mm1,            [rsi]               //
+        movq            mm3,            [rsi+1]             //
+
+        movq            mm2,            mm1                 //
+        movq            mm4,            mm3                 //
+
+        punpcklbw       mm1,            mm0                 //
+        punpckhbw       mm2,            mm0                 //
+
+        pmullw          mm1,            [rax]               //
+        pmullw          mm2,            [rax]               //
+
+        punpcklbw       mm3,            mm0                 //
+        punpckhbw       mm4,            mm0                 //
+
+        pmullw          mm3,            [rax+8]             //
+        pmullw          mm4,            [rax+8]             //
+
+        paddw           mm1,            mm3                 //
+        paddw           mm2,            mm4                 //
+
+        paddw           mm1,            [GLOBAL (mmx_bi_rd)]  //
+        psraw           mm1,            mmx_filter_shift    //
+
+        paddw           mm2,            [GLOBAL (mmx_bi_rd)]  //
+        psraw           mm2,            mmx_filter_shift    //
+
+        movq            mm3,            mm5                 //
+        movq            mm4,            mm5                 //
+
+        punpcklbw       mm3,            mm0                 //
+        punpckhbw       mm4,            mm0                 //
+
+        movq            mm5,            mm1                 //
+        packuswb        mm5,            mm2                 //
+
+        pmullw          mm3,            [rdx]               //
+        pmullw          mm4,            [rdx]               //
+
+        pmullw          mm1,            [rdx+8]             //
+        pmullw          mm2,            [rdx+8]             //
+
+        paddw           mm1,            mm3                 //
+        paddw           mm2,            mm4                 //
+
+        paddw           mm1,            [GLOBAL (mmx_bi_rd)]  //
+        paddw           mm2,            [GLOBAL (mmx_bi_rd)]  //
+
+        psraw           mm1,            mmx_filter_shift    //
+        psraw           mm2,            mmx_filter_shift    //
+
+        movq            mm3,            [rdi]               //
+        movq            mm4,            mm3                 //
+
+        punpcklbw       mm3,            mm0                 //
+        punpckhbw       mm4,            mm0                 //
+
+        psubw           mm1,            mm3                 //
+        psubw           mm2,            mm4                 //
+
+        paddw           mm6,            mm1                 //
+        pmaddwd         mm1,            mm1                 //
+
+        paddw           mm6,            mm2                 //
+        pmaddwd         mm2,            mm2                 //
+
+        paddd           mm7,            mm1                 //
+        paddd           mm7,            mm2                 //
+
+#if ABI_IS_32BIT
+        add             rsi,            dword ptr arg(1) //ref_pixels_per_line    ;
+        add             rdi,            dword ptr arg(3) //src_pixels_per_line    ;
+#else
+        movsxd          r8,             dword ptr arg(1) //ref_pixels_per_line    ;
+        movsxd          r9,             dword ptr arg(3) //src_pixels_per_line    ;
+        add             rsi,            r8
+        add             rdi,            r9
+#endif
+        sub             rcx,            1                   //
+        jnz             filter_block2d_bil_var_mmx_loop       //
+
+
+        pxor            mm3,            mm3                 //
+        pxor            mm2,            mm2                 //
+
+        punpcklwd       mm2,            mm6                 //
+        punpckhwd       mm3,            mm6                 //
+
+        paddd           mm2,            mm3                 //
+        movq            mm6,            mm2                 //
+
+        psrlq           mm6,            32                  //
+        paddd           mm2,            mm6                 //
+
+        psrad           mm2,            16                  //
+        movq            mm4,            mm7                 //
+
+        psrlq           mm4,            32                  //
+        paddd           mm4,            mm7                 //
+
+        mov             rdi,            arg(7) //sum
+        mov             rsi,            arg(8) //sumsquared
+
+        movd            dword ptr [rdi],          mm2                 //
+        movd            dword ptr [rsi],          mm4                 //
+
+    // begin epilog
+    add rsp, 16
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+//unsigned int vp8_get16x16pred_error_mmx
+//(
+//    unsigned char *src_ptr,
+//    int src_stride,
+//    unsigned char *ref_ptr,
+//    int ref_stride
+//)
+global sym(vp8_get16x16pred_error_mmx)
+sym(vp8_get16x16pred_error_mmx):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 4
+    GET_GOT     rbx
+    push rsi
+    push rdi
+    sub         rsp, 16
+    // end prolog
+
+        mov         rsi,            arg(0) //DWORD PTR [src_ptr]
+        mov         rdi,            arg(2) //DWORD PTR [ref_ptr]
+
+        movsxd      rax,            DWORD PTR arg(1) //[src_stride]
+        movsxd      rdx,            DWORD PTR arg(3) //[ref_stride]
+
+        pxor        mm0,            mm0                     // clear xmm0 for unpack
+        pxor        mm7,            mm7                     // clear xmm7 for accumulating diffs
+
+        pxor        mm6,            mm6                     // clear xmm6 for accumulating sse
+        mov         rcx,            16
+
+var16loop:
+
+        movq        mm1,            [rsi]
+        movq        mm2,            [rdi]
+
+        movq        mm3,            mm1
+        movq        mm4,            mm2
+
+        punpcklbw   mm1,            mm0
+        punpckhbw   mm3,            mm0
+
+        punpcklbw   mm2,            mm0
+        punpckhbw   mm4,            mm0
+
+        psubw       mm1,            mm2
+        psubw       mm3,            mm4
+
+        paddw       mm7,            mm1
+        pmaddwd     mm1,            mm1
+
+        paddw       mm7,            mm3
+        pmaddwd     mm3,            mm3
+
+        paddd       mm6,            mm1
+        paddd       mm6,            mm3
+
+
+        movq        mm1,            [rsi+8]
+        movq        mm2,            [rdi+8]
+
+        movq        mm3,            mm1
+        movq        mm4,            mm2
+
+        punpcklbw   mm1,            mm0
+        punpckhbw   mm3,            mm0
+
+        punpcklbw   mm2,            mm0
+        punpckhbw   mm4,            mm0
+
+        psubw       mm1,            mm2
+        psubw       mm3,            mm4
+
+        paddw       mm7,            mm1
+        pmaddwd     mm1,            mm1
+
+        paddw       mm7,            mm3
+        pmaddwd     mm3,            mm3
+
+        paddd       mm6,            mm1
+        paddd       mm6,            mm3
+
+        add         rsi,            rax
+        add         rdi,            rdx
+
+        sub         rcx,            1
+        jnz         var16loop
+
+
+        movq        mm1,            mm6
+        pxor        mm6,            mm6
+
+        pxor        mm5,            mm5
+        punpcklwd   mm6,            mm7
+
+        punpckhwd   mm5,            mm7
+        psrad       mm5,            16
+
+        psrad       mm6,            16
+        paddd       mm6,            mm5
+
+        movq        mm2,            mm1
+        psrlq       mm1,            32
+
+        paddd       mm2,            mm1
+        movq        mm7,            mm6
+
+        psrlq       mm6,            32
+        paddd       mm6,            mm7
+
+        movd DWORD PTR [rsp],       mm6  //Sum
+        movd DWORD PTR [rsp+4],     mm2  //SSE
+
+        // return (SSE-((Sum*Sum)>>8));
+        movsxd      rdx, dword ptr [rsp]
+        imul        rdx, rdx
+        sar         rdx, 8
+        movsxd      rax, dword ptr [rsp + 4]
+        sub         rax, rdx
+
+
+    // begin epilog
+    add rsp, 16
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+
+SECTION_RODATA
+//short mmx_bi_rd[4] = { 64, 64, 64, 64};
+align 16
+mmx_bi_rd:
+    .fill 4, 2, 64
diff --git a/vp8/encoder/x86/variance_impl_mmx.asm b/vp8/encoder/x86/variance_impl_mmx.asm
deleted file mode 100644
index d0da82a..0000000
--- a/vp8/encoder/x86/variance_impl_mmx.asm
+++ /dev/null
@@ -1,980 +0,0 @@
-;
-;  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
-;
-;  Use of this source code is governed by a BSD-style license and patent
-;  grant that can be found in the LICENSE file in the root of the source
-;  tree. All contributing project authors may be found in the AUTHORS
-;  file in the root of the source tree.
-;
-
-
-%include "vpx_ports/x86_abi_support.asm"
-
-;unsigned int vp8_get_mb_ss_mmx( short *src_ptr )
-global sym(vp8_get_mb_ss_mmx)
-sym(vp8_get_mb_ss_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 7
-    GET_GOT     rbx
-    push rsi
-    push rdi
-    sub         rsp, 8
-    ; end prolog
-
-        mov         rax, arg(0) ;src_ptr
-        mov         rcx, 16
-        pxor        mm4, mm4
-
-NEXTROW:
-        movq        mm0, [rax]
-        movq        mm1, [rax+8]
-        movq        mm2, [rax+16]
-        movq        mm3, [rax+24]
-        pmaddwd     mm0, mm0
-        pmaddwd     mm1, mm1
-        pmaddwd     mm2, mm2
-        pmaddwd     mm3, mm3
-
-        paddd       mm4, mm0
-        paddd       mm4, mm1
-        paddd       mm4, mm2
-        paddd       mm4, mm3
-
-        add         rax, 32
-        dec         rcx
-        ja          NEXTROW
-        movq        QWORD PTR [rsp], mm4
-
-        ;return sum[0]+sum[1];
-        movsxd      rax, dword ptr [rsp]
-        movsxd      rcx, dword ptr [rsp+4]
-        add         rax, rcx
-
-
-    ; begin epilog
-    add rsp, 8
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;unsigned int vp8_get8x8var_mmx
-;(
-;    unsigned char *src_ptr,
-;    int  source_stride,
-;    unsigned char *ref_ptr,
-;    int  recon_stride,
-;    unsigned int *SSE,
-;    int *Sum
-;)
-global sym(vp8_get8x8var_mmx)
-sym(vp8_get8x8var_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 6
-    push rsi
-    push rdi
-    push rbx
-    sub         rsp, 16
-    ; end prolog
-
-
-        pxor        mm5, mm5                    ; Blank mmx6
-        pxor        mm6, mm6                    ; Blank mmx7
-        pxor        mm7, mm7                    ; Blank mmx7
-
-        mov         rax, arg(0) ;[src_ptr]  ; Load base addresses
-        mov         rbx, arg(2) ;[ref_ptr]
-        movsxd      rcx, dword ptr arg(1) ;[source_stride]
-        movsxd      rdx, dword ptr arg(3) ;[recon_stride]
-
-        ; Row 1
-        movq        mm0, [rax]                  ; Copy eight bytes to mm0
-        movq        mm1, [rbx]                  ; Copy eight bytes to mm1
-        movq        mm2, mm0                    ; Take copies
-        movq        mm3, mm1                    ; Take copies
-
-        punpcklbw   mm0, mm6                    ; unpack to higher prrcision
-        punpcklbw   mm1, mm6
-        punpckhbw   mm2, mm6                    ; unpack to higher prrcision
-        punpckhbw   mm3, mm6
-        psubsw      mm0, mm1                    ; A-B (low order) to MM0
-        psubsw      mm2, mm3                    ; A-B (high order) to MM2
-
-        paddw       mm5, mm0                    ; accumulate differences in mm5
-        paddw       mm5, mm2                    ; accumulate differences in mm5
-
-        pmaddwd     mm0, mm0                    ; square and accumulate
-        pmaddwd     mm2, mm2                    ; square and accumulate
-        add         rbx,rdx                     ; Inc pointer into ref data
-        add         rax,rcx                     ; Inc pointer into the new data
-        movq        mm1, [rbx]                  ; Copy eight bytes to mm1
-        paddd       mm7, mm0                    ; accumulate in mm7
-        paddd       mm7, mm2                    ; accumulate in mm7
-
-
-        ; Row 2
-        movq        mm0, [rax]                  ; Copy eight bytes to mm0
-        movq        mm2, mm0                    ; Take copies
-        movq        mm3, mm1                    ; Take copies
-
-        punpcklbw   mm0, mm6                    ; unpack to higher prrcision
-        punpcklbw   mm1, mm6
-        punpckhbw   mm2, mm6                    ; unpack to higher prrcision
-        punpckhbw   mm3, mm6
-        psubsw      mm0, mm1                    ; A-B (low order) to MM0
-        psubsw      mm2, mm3                    ; A-B (high order) to MM2
-
-        paddw       mm5, mm0                    ; accumulate differences in mm5
-        paddw       mm5, mm2                    ; accumulate differences in mm5
-
-        pmaddwd     mm0, mm0                    ; square and accumulate
-        pmaddwd     mm2, mm2                    ; square and accumulate
-        add         rbx,rdx                     ; Inc pointer into ref data
-        add         rax,rcx                     ; Inc pointer into the new data
-        movq        mm1, [rbx]                  ; Copy eight bytes to mm1
-        paddd       mm7, mm0                    ; accumulate in mm7
-        paddd       mm7, mm2                    ; accumulate in mm7
-
-        ; Row 3
-        movq        mm0, [rax]                  ; Copy eight bytes to mm0
-        movq        mm2, mm0                    ; Take copies
-        movq        mm3, mm1                    ; Take copies
-
-        punpcklbw   mm0, mm6                    ; unpack to higher prrcision
-        punpcklbw   mm1, mm6
-        punpckhbw   mm2, mm6                    ; unpack to higher prrcision
-        punpckhbw   mm3, mm6
-        psubsw      mm0, mm1                    ; A-B (low order) to MM0
-        psubsw      mm2, mm3                    ; A-B (high order) to MM2
-
-        paddw       mm5, mm0                    ; accumulate differences in mm5
-        paddw       mm5, mm2                    ; accumulate differences in mm5
-
-        pmaddwd     mm0, mm0                    ; square and accumulate
-        pmaddwd     mm2, mm2                    ; square and accumulate
-        add         rbx,rdx                     ; Inc pointer into ref data
-        add         rax,rcx                     ; Inc pointer into the new data
-        movq        mm1, [rbx]                  ; Copy eight bytes to mm1
-        paddd       mm7, mm0                    ; accumulate in mm7
-        paddd       mm7, mm2                    ; accumulate in mm7
-
-        ; Row 4
-        movq        mm0, [rax]                  ; Copy eight bytes to mm0
-        movq        mm2, mm0                    ; Take copies
-        movq        mm3, mm1                    ; Take copies
-
-        punpcklbw   mm0, mm6                    ; unpack to higher prrcision
-        punpcklbw   mm1, mm6
-        punpckhbw   mm2, mm6                    ; unpack to higher prrcision
-        punpckhbw   mm3, mm6
-        psubsw      mm0, mm1                    ; A-B (low order) to MM0
-        psubsw      mm2, mm3                    ; A-B (high order) to MM2
-
-        paddw       mm5, mm0                    ; accumulate differences in mm5
-        paddw       mm5, mm2                    ; accumulate differences in mm5
-
-        pmaddwd     mm0, mm0                    ; square and accumulate
-        pmaddwd     mm2, mm2                    ; square and accumulate
-        add         rbx,rdx                     ; Inc pointer into ref data
-        add         rax,rcx                     ; Inc pointer into the new data
-        movq        mm1, [rbx]                  ; Copy eight bytes to mm1
-        paddd       mm7, mm0                    ; accumulate in mm7
-        paddd       mm7, mm2                    ; accumulate in mm7
-
-        ; Row 5
-        movq        mm0, [rax]                  ; Copy eight bytes to mm0
-        movq        mm2, mm0                    ; Take copies
-        movq        mm3, mm1                    ; Take copies
-
-        punpcklbw   mm0, mm6                    ; unpack to higher prrcision
-        punpcklbw   mm1, mm6
-        punpckhbw   mm2, mm6                    ; unpack to higher prrcision
-        punpckhbw   mm3, mm6
-        psubsw      mm0, mm1                    ; A-B (low order) to MM0
-        psubsw      mm2, mm3                    ; A-B (high order) to MM2
-
-        paddw       mm5, mm0                    ; accumulate differences in mm5
-        paddw       mm5, mm2                    ; accumulate differences in mm5
-
-        pmaddwd     mm0, mm0                    ; square and accumulate
-        pmaddwd     mm2, mm2                    ; square and accumulate
-        add         rbx,rdx                     ; Inc pointer into ref data
-        add         rax,rcx                     ; Inc pointer into the new data
-        movq        mm1, [rbx]                  ; Copy eight bytes to mm1
-        ;              movq        mm4, [rbx + rdx]
-        paddd       mm7, mm0                    ; accumulate in mm7
-        paddd       mm7, mm2                    ; accumulate in mm7
-
-        ; Row 6
-        movq        mm0, [rax]                  ; Copy eight bytes to mm0
-        movq        mm2, mm0                    ; Take copies
-        movq        mm3, mm1                    ; Take copies
-
-        punpcklbw   mm0, mm6                    ; unpack to higher prrcision
-        punpcklbw   mm1, mm6
-        punpckhbw   mm2, mm6                    ; unpack to higher prrcision
-        punpckhbw   mm3, mm6
-        psubsw      mm0, mm1                    ; A-B (low order) to MM0
-        psubsw      mm2, mm3                    ; A-B (high order) to MM2
-
-        paddw       mm5, mm0                    ; accumulate differences in mm5
-        paddw       mm5, mm2                    ; accumulate differences in mm5
-
-        pmaddwd     mm0, mm0                    ; square and accumulate
-        pmaddwd     mm2, mm2                    ; square and accumulate
-        add         rbx,rdx                     ; Inc pointer into ref data
-        add         rax,rcx                     ; Inc pointer into the new data
-        movq        mm1, [rbx]                  ; Copy eight bytes to mm1
-        paddd       mm7, mm0                    ; accumulate in mm7
-        paddd       mm7, mm2                    ; accumulate in mm7
-
-        ; Row 7
-        movq        mm0, [rax]                  ; Copy eight bytes to mm0
-        movq        mm2, mm0                    ; Take copies
-        movq        mm3, mm1                    ; Take copies
-
-        punpcklbw   mm0, mm6                    ; unpack to higher prrcision
-        punpcklbw   mm1, mm6
-        punpckhbw   mm2, mm6                    ; unpack to higher prrcision
-        punpckhbw   mm3, mm6
-        psubsw      mm0, mm1                    ; A-B (low order) to MM0
-        psubsw      mm2, mm3                    ; A-B (high order) to MM2
-
-        paddw       mm5, mm0                    ; accumulate differences in mm5
-        paddw       mm5, mm2                    ; accumulate differences in mm5
-
-        pmaddwd     mm0, mm0                    ; square and accumulate
-        pmaddwd     mm2, mm2                    ; square and accumulate
-        add         rbx,rdx                     ; Inc pointer into ref data
-        add         rax,rcx                     ; Inc pointer into the new data
-        movq        mm1, [rbx]                  ; Copy eight bytes to mm1
-        paddd       mm7, mm0                    ; accumulate in mm7
-        paddd       mm7, mm2                    ; accumulate in mm7
-
-        ; Row 8
-        movq        mm0, [rax]                  ; Copy eight bytes to mm0
-        movq        mm2, mm0                    ; Take copies
-        movq        mm3, mm1                    ; Take copies
-
-        punpcklbw   mm0, mm6                    ; unpack to higher prrcision
-        punpcklbw   mm1, mm6
-        punpckhbw   mm2, mm6                    ; unpack to higher prrcision
-        punpckhbw   mm3, mm6
-        psubsw      mm0, mm1                    ; A-B (low order) to MM0
-        psubsw      mm2, mm3                    ; A-B (high order) to MM2
-
-        paddw       mm5, mm0                    ; accumulate differences in mm5
-        paddw       mm5, mm2                    ; accumulate differences in mm5
-
-        pmaddwd     mm0, mm0                    ; square and accumulate
-        pmaddwd     mm2, mm2                    ; square and accumulate
-        add         rbx,rdx                     ; Inc pointer into ref data
-        add         rax,rcx                     ; Inc pointer into the new data
-        paddd       mm7, mm0                    ; accumulate in mm7
-        paddd       mm7, mm2                    ; accumulate in mm7
-
-        ; Now accumulate the final results.
-        movq        QWORD PTR [rsp+8], mm5      ; copy back accumulated results into normal memory
-        movq        QWORD PTR [rsp], mm7        ; copy back accumulated results into normal memory
-        movsx       rdx, WORD PTR [rsp+8]
-        movsx       rcx, WORD PTR [rsp+10]
-        movsx       rbx, WORD PTR [rsp+12]
-        movsx       rax, WORD PTR [rsp+14]
-        add         rdx, rcx
-        add         rbx, rax
-        add         rdx, rbx    ;XSum
-        movsxd      rax, DWORD PTR [rsp]
-        movsxd      rcx, DWORD PTR [rsp+4]
-        add         rax, rcx    ;XXSum
-        mov         rsi, arg(4) ;SSE
-        mov         rdi, arg(5) ;Sum
-        mov         dword ptr [rsi], eax
-        mov         dword ptr [rdi], edx
-        xor         rax, rax    ; return 0
-
-
-    ; begin epilog
-    add rsp, 16
-    pop rbx
-    pop rdi
-    pop rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-
-;unsigned int
-;vp8_get4x4var_mmx
-;(
-;    unsigned char *src_ptr,
-;    int  source_stride,
-;    unsigned char *ref_ptr,
-;    int  recon_stride,
-;    unsigned int *SSE,
-;    int *Sum
-;)
-global sym(vp8_get4x4var_mmx)
-sym(vp8_get4x4var_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 6
-    push rsi
-    push rdi
-    push rbx
-    sub         rsp, 16
-    ; end prolog
-
-
-        pxor        mm5, mm5                    ; Blank mmx6
-        pxor        mm6, mm6                    ; Blank mmx7
-        pxor        mm7, mm7                    ; Blank mmx7
-
-        mov         rax, arg(0) ;[src_ptr]  ; Load base addresses
-        mov         rbx, arg(2) ;[ref_ptr]
-        movsxd      rcx, dword ptr arg(1) ;[source_stride]
-        movsxd      rdx, dword ptr arg(3) ;[recon_stride]
-
-        ; Row 1
-        movq        mm0, [rax]                  ; Copy eight bytes to mm0
-        movq        mm1, [rbx]                  ; Copy eight bytes to mm1
-        punpcklbw   mm0, mm6                    ; unpack to higher prrcision
-        punpcklbw   mm1, mm6
-        psubsw      mm0, mm1                    ; A-B (low order) to MM0
-        paddw       mm5, mm0                    ; accumulate differences in mm5
-        pmaddwd     mm0, mm0                    ; square and accumulate
-        add         rbx,rdx                     ; Inc pointer into ref data
-        add         rax,rcx                     ; Inc pointer into the new data
-        movq        mm1, [rbx]                  ; Copy eight bytes to mm1
-        paddd       mm7, mm0                    ; accumulate in mm7
-
-
-        ; Row 2
-        movq        mm0, [rax]                  ; Copy eight bytes to mm0
-        punpcklbw   mm0, mm6                    ; unpack to higher prrcision
-        punpcklbw   mm1, mm6
-        psubsw      mm0, mm1                    ; A-B (low order) to MM0
-        paddw       mm5, mm0                    ; accumulate differences in mm5
-
-        pmaddwd     mm0, mm0                    ; square and accumulate
-        add         rbx,rdx                     ; Inc pointer into ref data
-        add         rax,rcx                     ; Inc pointer into the new data
-        movq        mm1, [rbx]                  ; Copy eight bytes to mm1
-        paddd       mm7, mm0                    ; accumulate in mm7
-
-        ; Row 3
-        movq        mm0, [rax]                  ; Copy eight bytes to mm0
-        punpcklbw   mm0, mm6                    ; unpack to higher prrcision
-        punpcklbw   mm1, mm6
-        psubsw      mm0, mm1                    ; A-B (low order) to MM0
-        paddw       mm5, mm0                    ; accumulate differences in mm5
-
-        pmaddwd     mm0, mm0                    ; square and accumulate
-        add         rbx,rdx                     ; Inc pointer into ref data
-        add         rax,rcx                     ; Inc pointer into the new data
-        movq        mm1, [rbx]                  ; Copy eight bytes to mm1
-        paddd       mm7, mm0                    ; accumulate in mm7
-
-        ; Row 4
-        movq        mm0, [rax]                  ; Copy eight bytes to mm0
-
-        punpcklbw   mm0, mm6                    ; unpack to higher prrcision
-        punpcklbw   mm1, mm6
-        psubsw      mm0, mm1                    ; A-B (low order) to MM0
-
-        paddw       mm5, mm0                    ; accumulate differences in mm5
-
-        pmaddwd     mm0, mm0                    ; square and accumulate
-        paddd       mm7, mm0                    ; accumulate in mm7
-
-
-        ; Now accumulate the final results.
-        movq        QWORD PTR [rsp+8], mm5      ; copy back accumulated results into normal memory
-        movq        QWORD PTR [rsp], mm7        ; copy back accumulated results into normal memory
-        movsx       rdx, WORD PTR [rsp+8]
-        movsx       rcx, WORD PTR [rsp+10]
-        movsx       rbx, WORD PTR [rsp+12]
-        movsx       rax, WORD PTR [rsp+14]
-        add         rdx, rcx
-        add         rbx, rax
-        add         rdx, rbx    ;XSum
-        movsxd      rax, DWORD PTR [rsp]
-        movsxd      rcx, DWORD PTR [rsp+4]
-        add         rax, rcx    ;XXSum
-        mov         rsi, arg(4) ;SSE
-        mov         rdi, arg(5) ;Sum
-        mov         dword ptr [rsi], eax
-        mov         dword ptr [rdi], edx
-        xor         rax, rax    ; return 0
-
-
-    ; begin epilog
-    add rsp, 16
-    pop rbx
-    pop rdi
-    pop rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-
-;unsigned int
-;vp8_get4x4sse_cs_mmx
-;(
-;    unsigned char *src_ptr,
-;    int  source_stride,
-;    unsigned char *ref_ptr,
-;    int  recon_stride
-;)
-global sym(vp8_get4x4sse_cs_mmx)
-sym(vp8_get4x4sse_cs_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 4
-    push rsi
-    push rdi
-    push rbx
-    ; end prolog
-
-
-        pxor        mm6, mm6                    ; Blank mmx7
-        pxor        mm7, mm7                    ; Blank mmx7
-
-        mov         rax, arg(0) ;[src_ptr]  ; Load base addresses
-        mov         rbx, arg(2) ;[ref_ptr]
-        movsxd      rcx, dword ptr arg(1) ;[source_stride]
-        movsxd      rdx, dword ptr arg(3) ;[recon_stride]
-        ; Row 1
-        movd        mm0, [rax]                  ; Copy eight bytes to mm0
-        movd        mm1, [rbx]                  ; Copy eight bytes to mm1
-        punpcklbw   mm0, mm6                    ; unpack to higher prrcision
-        punpcklbw   mm1, mm6
-        psubsw      mm0, mm1                    ; A-B (low order) to MM0
-        pmaddwd     mm0, mm0                    ; square and accumulate
-        add         rbx,rdx                     ; Inc pointer into ref data
-        add         rax,rcx                     ; Inc pointer into the new data
-        movd        mm1, [rbx]                  ; Copy eight bytes to mm1
-        paddd       mm7, mm0                    ; accumulate in mm7
-
-        ; Row 2
-        movd        mm0, [rax]                  ; Copy eight bytes to mm0
-        punpcklbw   mm0, mm6                    ; unpack to higher prrcision
-        punpcklbw   mm1, mm6
-        psubsw      mm0, mm1                    ; A-B (low order) to MM0
-        pmaddwd     mm0, mm0                    ; square and accumulate
-        add         rbx,rdx                     ; Inc pointer into ref data
-        add         rax,rcx                     ; Inc pointer into the new data
-        movd        mm1, [rbx]                  ; Copy eight bytes to mm1
-        paddd       mm7, mm0                    ; accumulate in mm7
-
-        ; Row 3
-        movd        mm0, [rax]                  ; Copy eight bytes to mm0
-        punpcklbw   mm1, mm6
-        punpcklbw   mm0, mm6                    ; unpack to higher prrcision
-        psubsw      mm0, mm1                    ; A-B (low order) to MM0
-
-        pmaddwd     mm0, mm0                    ; square and accumulate
-        add         rbx,rdx                     ; Inc pointer into ref data
-        add         rax,rcx                     ; Inc pointer into the new data
-        movd        mm1, [rbx]                  ; Copy eight bytes to mm1
-        paddd       mm7, mm0                    ; accumulate in mm7
-
-        ; Row 4
-        movd        mm0, [rax]                  ; Copy eight bytes to mm0
-        punpcklbw   mm0, mm6                    ; unpack to higher prrcision
-        punpcklbw   mm1, mm6
-        psubsw      mm0, mm1                    ; A-B (low order) to MM0
-        pmaddwd     mm0, mm0                    ; square and accumulate
-        paddd       mm7, mm0                    ; accumulate in mm7
-
-        movq        mm0,    mm7                 ;
-        psrlq       mm7,    32
-
-        paddd       mm0,    mm7
-        movd        rax,    mm0
-
-
-    ; begin epilog
-    pop rbx
-    pop rdi
-    pop rsi
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-%define mmx_filter_shift            7
-
-;void vp8_filter_block2d_bil4x4_var_mmx
-;(
-;    unsigned char *ref_ptr,
-;    int ref_pixels_per_line,
-;    unsigned char *src_ptr,
-;    int src_pixels_per_line,
-;    unsigned short *HFilter,
-;    unsigned short *VFilter,
-;    int *sum,
-;    unsigned int *sumsquared
-;)
-global sym(vp8_filter_block2d_bil4x4_var_mmx)
-sym(vp8_filter_block2d_bil4x4_var_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 8
-    GET_GOT     rbx
-    push rsi
-    push rdi
-    sub         rsp, 16
-    ; end prolog
-
-
-        pxor            mm6,            mm6                 ;
-        pxor            mm7,            mm7                 ;
-
-        mov             rax,            arg(4) ;HFilter             ;
-        mov             rdx,            arg(5) ;VFilter             ;
-
-        mov             rsi,            arg(0) ;ref_ptr              ;
-        mov             rdi,            arg(2) ;src_ptr              ;
-
-        mov             rcx,            4                   ;
-        pxor            mm0,            mm0                 ;
-
-        movd            mm1,            [rsi]               ;
-        movd            mm3,            [rsi+1]             ;
-
-        punpcklbw       mm1,            mm0                 ;
-        pmullw          mm1,            [rax]               ;
-
-        punpcklbw       mm3,            mm0                 ;
-        pmullw          mm3,            [rax+8]             ;
-
-        paddw           mm1,            mm3                 ;
-        paddw           mm1,            [mmx_bi_rd GLOBAL]  ;
-
-        psraw           mm1,            mmx_filter_shift    ;
-        movq            mm5,            mm1
-
-%if ABI_IS_32BIT
-        add             rsi, dword ptr  arg(1) ;ref_pixels_per_line    ;
-%else
-        movsxd          r8, dword ptr  arg(1) ;ref_pixels_per_line    ;
-        add             rsi, r8
-%endif
-
-filter_block2d_bil4x4_var_mmx_loop:
-
-        movd            mm1,            [rsi]               ;
-        movd            mm3,            [rsi+1]             ;
-
-        punpcklbw       mm1,            mm0                 ;
-        pmullw          mm1,            [rax]               ;
-
-        punpcklbw       mm3,            mm0                 ;
-        pmullw          mm3,            [rax+8]             ;
-
-        paddw           mm1,            mm3                 ;
-        paddw           mm1,            [mmx_bi_rd GLOBAL]  ;
-
-        psraw           mm1,            mmx_filter_shift    ;
-        movq            mm3,            mm5                 ;
-
-        movq            mm5,            mm1                 ;
-        pmullw          mm3,            [rdx]               ;
-
-        pmullw          mm1,            [rdx+8]             ;
-        paddw           mm1,            mm3                 ;
-
-
-        paddw           mm1,            [mmx_bi_rd GLOBAL]  ;
-        psraw           mm1,            mmx_filter_shift    ;
-
-        movd            mm3,            [rdi]               ;
-        punpcklbw       mm3,            mm0                 ;
-
-        psubw           mm1,            mm3                 ;
-        paddw           mm6,            mm1                 ;
-
-        pmaddwd         mm1,            mm1                 ;
-        paddd           mm7,            mm1                 ;
-
-%if ABI_IS_32BIT
-        add             rsi,            dword ptr arg(1) ;ref_pixels_per_line    ;
-        add             rdi,            dword ptr arg(3) ;src_pixels_per_line    ;
-%else
-        movsxd          r8,             dword ptr arg(1) ;ref_pixels_per_line
-        movsxd          r9,             dword ptr arg(3) ;src_pixels_per_line
-        add             rsi,            r8
-        add             rdi,            r9
-%endif
-        sub             rcx,            1                   ;
-        jnz             filter_block2d_bil4x4_var_mmx_loop       ;
-
-
-        pxor            mm3,            mm3                 ;
-        pxor            mm2,            mm2                 ;
-
-        punpcklwd       mm2,            mm6                 ;
-        punpckhwd       mm3,            mm6                 ;
-
-        paddd           mm2,            mm3                 ;
-        movq            mm6,            mm2                 ;
-
-        psrlq           mm6,            32                  ;
-        paddd           mm2,            mm6                 ;
-
-        psrad           mm2,            16                  ;
-        movq            mm4,            mm7                 ;
-
-        psrlq           mm4,            32                  ;
-        paddd           mm4,            mm7                 ;
-
-        mov             rdi,            arg(6) ;sum
-        mov             rsi,            arg(7) ;sumsquared
-
-        movd            dword ptr [rdi],          mm2                 ;
-        movd            dword ptr [rsi],          mm4                 ;
-
-
-
-    ; begin epilog
-    add rsp, 16
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-
-
-;void vp8_filter_block2d_bil_var_mmx
-;(
-;    unsigned char *ref_ptr,
-;    int ref_pixels_per_line,
-;    unsigned char *src_ptr,
-;    int src_pixels_per_line,
-;    unsigned int Height,
-;    unsigned short *HFilter,
-;    unsigned short *VFilter,
-;    int *sum,
-;    unsigned int *sumsquared
-;)
-global sym(vp8_filter_block2d_bil_var_mmx)
-sym(vp8_filter_block2d_bil_var_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 9
-    GET_GOT     rbx
-    push rsi
-    push rdi
-    sub         rsp, 16
-    ; end prolog
-
-        pxor            mm6,            mm6                 ;
-        pxor            mm7,            mm7                 ;
-        mov             rax,            arg(5) ;HFilter             ;
-
-        mov             rdx,            arg(6) ;VFilter             ;
-        mov             rsi,            arg(0) ;ref_ptr              ;
-
-        mov             rdi,            arg(2) ;src_ptr              ;
-        movsxd          rcx,            dword ptr arg(4) ;Height              ;
-
-        pxor            mm0,            mm0                 ;
-        movq            mm1,            [rsi]               ;
-
-        movq            mm3,            [rsi+1]             ;
-        movq            mm2,            mm1                 ;
-
-        movq            mm4,            mm3                 ;
-        punpcklbw       mm1,            mm0                 ;
-
-        punpckhbw       mm2,            mm0                 ;
-        pmullw          mm1,            [rax]               ;
-
-        pmullw          mm2,            [rax]               ;
-        punpcklbw       mm3,            mm0                 ;
-
-        punpckhbw       mm4,            mm0                 ;
-        pmullw          mm3,            [rax+8]             ;
-
-        pmullw          mm4,            [rax+8]             ;
-        paddw           mm1,            mm3                 ;
-
-        paddw           mm2,            mm4                 ;
-        paddw           mm1,            [mmx_bi_rd GLOBAL]  ;
-
-        psraw           mm1,            mmx_filter_shift    ;
-        paddw           mm2,            [mmx_bi_rd GLOBAL]  ;
-
-        psraw           mm2,            mmx_filter_shift    ;
-        movq            mm5,            mm1
-
-        packuswb        mm5,            mm2                 ;
-%if ABI_IS_32BIT
-        add             rsi,            dword ptr arg(1) ;ref_pixels_per_line
-%else
-        movsxd          r8,             dword ptr arg(1) ;ref_pixels_per_line
-        add             rsi,            r8
-%endif
-
-filter_block2d_bil_var_mmx_loop:
-
-        movq            mm1,            [rsi]               ;
-        movq            mm3,            [rsi+1]             ;
-
-        movq            mm2,            mm1                 ;
-        movq            mm4,            mm3                 ;
-
-        punpcklbw       mm1,            mm0                 ;
-        punpckhbw       mm2,            mm0                 ;
-
-        pmullw          mm1,            [rax]               ;
-        pmullw          mm2,            [rax]               ;
-
-        punpcklbw       mm3,            mm0                 ;
-        punpckhbw       mm4,            mm0                 ;
-
-        pmullw          mm3,            [rax+8]             ;
-        pmullw          mm4,            [rax+8]             ;
-
-        paddw           mm1,            mm3                 ;
-        paddw           mm2,            mm4                 ;
-
-        paddw           mm1,            [mmx_bi_rd GLOBAL]  ;
-        psraw           mm1,            mmx_filter_shift    ;
-
-        paddw           mm2,            [mmx_bi_rd GLOBAL]  ;
-        psraw           mm2,            mmx_filter_shift    ;
-
-        movq            mm3,            mm5                 ;
-        movq            mm4,            mm5                 ;
-
-        punpcklbw       mm3,            mm0                 ;
-        punpckhbw       mm4,            mm0                 ;
-
-        movq            mm5,            mm1                 ;
-        packuswb        mm5,            mm2                 ;
-
-        pmullw          mm3,            [rdx]               ;
-        pmullw          mm4,            [rdx]               ;
-
-        pmullw          mm1,            [rdx+8]             ;
-        pmullw          mm2,            [rdx+8]             ;
-
-        paddw           mm1,            mm3                 ;
-        paddw           mm2,            mm4                 ;
-
-        paddw           mm1,            [mmx_bi_rd GLOBAL]  ;
-        paddw           mm2,            [mmx_bi_rd GLOBAL]  ;
-
-        psraw           mm1,            mmx_filter_shift    ;
-        psraw           mm2,            mmx_filter_shift    ;
-
-        movq            mm3,            [rdi]               ;
-        movq            mm4,            mm3                 ;
-
-        punpcklbw       mm3,            mm0                 ;
-        punpckhbw       mm4,            mm0                 ;
-
-        psubw           mm1,            mm3                 ;
-        psubw           mm2,            mm4                 ;
-
-        paddw           mm6,            mm1                 ;
-        pmaddwd         mm1,            mm1                 ;
-
-        paddw           mm6,            mm2                 ;
-        pmaddwd         mm2,            mm2                 ;
-
-        paddd           mm7,            mm1                 ;
-        paddd           mm7,            mm2                 ;
-
-%if ABI_IS_32BIT
-        add             rsi,            dword ptr arg(1) ;ref_pixels_per_line    ;
-        add             rdi,            dword ptr arg(3) ;src_pixels_per_line    ;
-%else
-        movsxd          r8,             dword ptr arg(1) ;ref_pixels_per_line    ;
-        movsxd          r9,             dword ptr arg(3) ;src_pixels_per_line    ;
-        add             rsi,            r8
-        add             rdi,            r9
-%endif
-        sub             rcx,            1                   ;
-        jnz             filter_block2d_bil_var_mmx_loop       ;
-
-
-        pxor            mm3,            mm3                 ;
-        pxor            mm2,            mm2                 ;
-
-        punpcklwd       mm2,            mm6                 ;
-        punpckhwd       mm3,            mm6                 ;
-
-        paddd           mm2,            mm3                 ;
-        movq            mm6,            mm2                 ;
-
-        psrlq           mm6,            32                  ;
-        paddd           mm2,            mm6                 ;
-
-        psrad           mm2,            16                  ;
-        movq            mm4,            mm7                 ;
-
-        psrlq           mm4,            32                  ;
-        paddd           mm4,            mm7                 ;
-
-        mov             rdi,            arg(7) ;sum
-        mov             rsi,            arg(8) ;sumsquared
-
-        movd            dword ptr [rdi],          mm2                 ;
-        movd            dword ptr [rsi],          mm4                 ;
-
-    ; begin epilog
-    add rsp, 16
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-;unsigned int vp8_get16x16pred_error_mmx
-;(
-;    unsigned char *src_ptr,
-;    int src_stride,
-;    unsigned char *ref_ptr,
-;    int ref_stride
-;)
-global sym(vp8_get16x16pred_error_mmx)
-sym(vp8_get16x16pred_error_mmx):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 4
-    GET_GOT     rbx
-    push rsi
-    push rdi
-    sub         rsp, 16
-    ; end prolog
-
-        mov         rsi,            arg(0) ;DWORD PTR [src_ptr]
-        mov         rdi,            arg(2) ;DWORD PTR [ref_ptr]
-
-        movsxd      rax,            DWORD PTR arg(1) ;[src_stride]
-        movsxd      rdx,            DWORD PTR arg(3) ;[ref_stride]
-
-        pxor        mm0,            mm0                     ; clear xmm0 for unpack
-        pxor        mm7,            mm7                     ; clear xmm7 for accumulating diffs
-
-        pxor        mm6,            mm6                     ; clear xmm6 for accumulating sse
-        mov         rcx,            16
-
-var16loop:
-
-        movq        mm1,            [rsi]
-        movq        mm2,            [rdi]
-
-        movq        mm3,            mm1
-        movq        mm4,            mm2
-
-        punpcklbw   mm1,            mm0
-        punpckhbw   mm3,            mm0
-
-        punpcklbw   mm2,            mm0
-        punpckhbw   mm4,            mm0
-
-        psubw       mm1,            mm2
-        psubw       mm3,            mm4
-
-        paddw       mm7,            mm1
-        pmaddwd     mm1,            mm1
-
-        paddw       mm7,            mm3
-        pmaddwd     mm3,            mm3
-
-        paddd       mm6,            mm1
-        paddd       mm6,            mm3
-
-
-        movq        mm1,            [rsi+8]
-        movq        mm2,            [rdi+8]
-
-        movq        mm3,            mm1
-        movq        mm4,            mm2
-
-        punpcklbw   mm1,            mm0
-        punpckhbw   mm3,            mm0
-
-        punpcklbw   mm2,            mm0
-        punpckhbw   mm4,            mm0
-
-        psubw       mm1,            mm2
-        psubw       mm3,            mm4
-
-        paddw       mm7,            mm1
-        pmaddwd     mm1,            mm1
-
-        paddw       mm7,            mm3
-        pmaddwd     mm3,            mm3
-
-        paddd       mm6,            mm1
-        paddd       mm6,            mm3
-
-        add         rsi,            rax
-        add         rdi,            rdx
-
-        sub         rcx,            1
-        jnz         var16loop
-
-
-        movq        mm1,            mm6
-        pxor        mm6,            mm6
-
-        pxor        mm5,            mm5
-        punpcklwd   mm6,            mm7
-
-        punpckhwd   mm5,            mm7
-        psrad       mm5,            16
-
-        psrad       mm6,            16
-        paddd       mm6,            mm5
-
-        movq        mm2,            mm1
-        psrlq       mm1,            32
-
-        paddd       mm2,            mm1
-        movq        mm7,            mm6
-
-        psrlq       mm6,            32
-        paddd       mm6,            mm7
-
-        movd DWORD PTR [rsp],       mm6  ;Sum
-        movd DWORD PTR [rsp+4],     mm2  ;SSE
-
-        ; return (SSE-((Sum*Sum)>>8));
-        movsxd      rdx, dword ptr [rsp]
-        imul        rdx, rdx
-        sar         rdx, 8
-        movsxd      rax, dword ptr [rsp + 4]
-        sub         rax, rdx
-
-
-    ; begin epilog
-    add rsp, 16
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-
-SECTION_RODATA
-;short mmx_bi_rd[4] = { 64, 64, 64, 64};
-align 16
-mmx_bi_rd:
-    times 4 dw 64
diff --git a/vp8/encoder/x86/variance_impl_sse2.S b/vp8/encoder/x86/variance_impl_sse2.S
new file mode 100644
index 0000000..897f52d
--- /dev/null
+++ b/vp8/encoder/x86/variance_impl_sse2.S
@@ -0,0 +1,975 @@
+//
+//  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
+//
+//  Use of this source code is governed by a BSD-style license and patent
+//  grant that can be found in the LICENSE file in the root of the source
+//  tree. All contributing project authors may be found in the AUTHORS
+//  file in the root of the source tree.
+//
+
+
+#include "vpx_ports/x86_abi_support.S"
+
+#define xmm_filter_shift            7
+
+//unsigned int vp8_get_mb_ss_sse2
+//(
+//    short *src_ptr
+//)
+global sym(vp8_get_mb_ss_sse2)
+sym(vp8_get_mb_ss_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 1
+    GET_GOT     rbx
+    push rsi
+    push rdi
+    sub         rsp, 16
+    // end prolog
+
+
+        mov         rax, arg(0) //[src_ptr]
+        mov         rcx, 8
+        pxor        xmm4, xmm4
+
+NEXTROW:
+        movdqa      xmm0, [rax]
+        movdqa      xmm1, [rax+16]
+        movdqa      xmm2, [rax+32]
+        movdqa      xmm3, [rax+48]
+        pmaddwd     xmm0, xmm0
+        pmaddwd     xmm1, xmm1
+        pmaddwd     xmm2, xmm2
+        pmaddwd     xmm3, xmm3
+
+        paddd       xmm0, xmm1
+        paddd       xmm2, xmm3
+        paddd       xmm4, xmm0
+        paddd       xmm4, xmm2
+
+        add         rax, 0x40
+        dec         rcx
+        ja          NEXTROW
+
+        movdqa      xmm3,xmm4
+        psrldq      xmm4,8
+        paddd       xmm4,xmm3
+        movdqa      xmm3,xmm4
+        psrldq      xmm4,4
+        paddd       xmm4,xmm3
+        movd        rax,xmm4
+
+
+    // begin epilog
+    add rsp, 16
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//unsigned int vp8_get16x16var_sse2
+//(
+//    unsigned char   *  src_ptr,
+//    int             source_stride,
+//    unsigned char   *  ref_ptr,
+//    int             recon_stride,
+//    unsigned int    *  SSE,
+//    int             *  Sum
+//)
+global sym(vp8_get16x16var_sse2)
+sym(vp8_get16x16var_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 6
+    GET_GOT     rbx
+    push rsi
+    push rdi
+    sub         rsp, 16
+    // end prolog
+
+        mov         rsi,            arg(0) //[src_ptr]
+        mov         rdi,            arg(2) //[ref_ptr]
+
+        movsxd      rax,            DWORD PTR arg(1) //[source_stride]
+        movsxd      rdx,            DWORD PTR arg(3) //[recon_stride]
+
+        pxor        xmm0,           xmm0                        // clear xmm0 for unpack
+        pxor        xmm7,           xmm7                        // clear xmm7 for accumulating diffs
+
+        pxor        xmm6,           xmm6                        // clear xmm6 for accumulating sse
+        mov         rcx,            16
+
+var16loop:
+        movdqu      xmm1,           XMMWORD PTR [rsi]
+        movdqu      xmm2,           XMMWORD PTR [rdi]
+
+        movdqa      xmm3,           xmm1
+        movdqa      xmm4,           xmm2
+
+
+        punpcklbw   xmm1,           xmm0
+        punpckhbw   xmm3,           xmm0
+
+        punpcklbw   xmm2,           xmm0
+        punpckhbw   xmm4,           xmm0
+
+
+        psubw       xmm1,           xmm2
+        psubw       xmm3,           xmm4
+
+        paddw       xmm7,           xmm1
+        pmaddwd     xmm1,           xmm1
+
+        paddw       xmm7,           xmm3
+        pmaddwd     xmm3,           xmm3
+
+        paddd       xmm6,           xmm1
+        paddd       xmm6,           xmm3
+
+        add         rsi,            rax
+        add         rdi,            rdx
+
+        sub         rcx,            1
+        jnz         var16loop
+
+
+        movdqa      xmm1,           xmm6
+        pxor        xmm6,           xmm6
+
+        pxor        xmm5,           xmm5
+        punpcklwd   xmm6,           xmm7
+
+        punpckhwd   xmm5,           xmm7
+        psrad       xmm5,           16
+
+        psrad       xmm6,           16
+        paddd       xmm6,           xmm5
+
+        movdqa      xmm2,           xmm1
+        punpckldq   xmm1,           xmm0
+
+        punpckhdq   xmm2,           xmm0
+        movdqa      xmm7,           xmm6
+
+        paddd       xmm1,           xmm2
+        punpckldq   xmm6,           xmm0
+
+        punpckhdq   xmm7,           xmm0
+        paddd       xmm6,           xmm7
+
+        movdqa      xmm2,           xmm1
+        movdqa      xmm7,           xmm6
+
+        psrldq      xmm1,           8
+        psrldq      xmm6,           8
+
+        paddd       xmm7,           xmm6
+        paddd       xmm1,           xmm2
+
+        mov         rax,            arg(5) //[Sum]
+        mov         rdi,            arg(4) //[SSE]
+
+        movd DWORD PTR [rax],       xmm7
+        movd DWORD PTR [rdi],       xmm1
+
+
+    // begin epilog
+    add rsp, 16
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//unsigned int vp8_get16x16pred_error_sse2
+//(
+//   unsigned char *src_ptr,
+//    int src_stride,
+//    unsigned char *ref_ptr,
+//    int ref_stride
+//)
+global sym(vp8_get16x16pred_error_sse2)
+sym(vp8_get16x16pred_error_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 4
+    GET_GOT     rbx
+    push rsi
+    push rdi
+    sub         rsp, 16
+    // end prolog
+
+        mov         rsi,            arg(0) //[src_ptr]
+        mov         rdi,            arg(2) //[ref_ptr]
+
+        movsxd      rax,            DWORD PTR arg(1) //[src_stride]
+        movsxd      rdx,            DWORD PTR arg(3) //[ref_stride]
+
+        pxor        xmm0,           xmm0                        // clear xmm0 for unpack
+        pxor        xmm7,           xmm7                        // clear xmm7 for accumulating diffs
+
+        pxor        xmm6,           xmm6                        // clear xmm6 for accumulating sse
+        mov         rcx,            16
+
+var16peloop:
+        movdqu      xmm1,           XMMWORD PTR [rsi]
+        movdqu      xmm2,           XMMWORD PTR [rdi]
+
+        movdqa      xmm3,           xmm1
+        movdqa      xmm4,           xmm2
+
+        punpcklbw   xmm1,           xmm0
+        punpckhbw   xmm3,           xmm0
+
+        punpcklbw   xmm2,           xmm0
+        punpckhbw   xmm4,           xmm0
+
+        psubw       xmm1,           xmm2
+        psubw       xmm3,           xmm4
+
+        paddw       xmm7,           xmm1
+        pmaddwd     xmm1,           xmm1
+
+        paddw       xmm7,           xmm3
+        pmaddwd     xmm3,           xmm3
+
+        paddd       xmm6,           xmm1
+        paddd       xmm6,           xmm3
+
+        add         rsi,            rax
+        add         rdi,            rdx
+
+        sub         rcx,            1
+        jnz         var16peloop
+
+
+        movdqa      xmm1,           xmm6
+        pxor        xmm6,           xmm6
+
+        pxor        xmm5,           xmm5
+        punpcklwd   xmm6,           xmm7
+
+        punpckhwd   xmm5,           xmm7
+        psrad       xmm5,           16
+
+        psrad       xmm6,           16
+        paddd       xmm6,           xmm5
+
+        movdqa      xmm2,           xmm1
+        punpckldq   xmm1,           xmm0
+
+        punpckhdq   xmm2,           xmm0
+        movdqa      xmm7,           xmm6
+
+        paddd       xmm1,           xmm2
+        punpckldq   xmm6,           xmm0
+
+        punpckhdq   xmm7,           xmm0
+        paddd       xmm6,           xmm7
+
+        movdqa      xmm2,           xmm1
+        movdqa      xmm7,           xmm6
+
+        psrldq      xmm1,           8
+        psrldq      xmm6,           8
+
+        paddd       xmm7,           xmm6
+        paddd       xmm1,           xmm2
+
+        movd DWORD PTR [rsp],       xmm7  //Sum
+        movd DWORD PTR [rsp+4],     xmm1  //SSE
+
+        // return (SSE-((Sum*Sum)>>8));
+        movsxd      rdx, dword ptr [rsp]
+        imul        rdx, rdx
+        sar         rdx, 8
+        movsxd      rax, dword ptr [rsp + 4]
+        sub         rax, rdx
+
+    // begin epilog
+    add rsp, 16
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+
+//unsigned int vp8_get8x8var_sse2
+//(
+//    unsigned char   *  src_ptr,
+//    int             source_stride,
+//    unsigned char   *  ref_ptr,
+//    int             recon_stride,
+//    unsigned int    *  SSE,
+//    int             *  Sum
+//)
+global sym(vp8_get8x8var_sse2)
+sym(vp8_get8x8var_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 6
+    GET_GOT     rbx
+    push rsi
+    push rdi
+    sub         rsp, 16
+    // end prolog
+
+        mov         rsi,            arg(0) //[src_ptr]
+        mov         rdi,            arg(2) //[ref_ptr]
+
+        movsxd      rax,            DWORD PTR arg(1) //[source_stride]
+        movsxd      rdx,            DWORD PTR arg(3) //[recon_stride]
+
+        pxor        xmm0,           xmm0                        // clear xmm0 for unpack
+        pxor        xmm7,           xmm7                        // clear xmm7 for accumulating diffs
+
+        movq        xmm1,           QWORD PTR [rsi]
+        movq        xmm2,           QWORD PTR [rdi]
+
+        punpcklbw   xmm1,           xmm0
+        punpcklbw   xmm2,           xmm0
+
+        psubsw      xmm1,           xmm2
+        paddw       xmm7,           xmm1
+
+        pmaddwd     xmm1,           xmm1
+
+        movq        xmm2,           QWORD PTR[rsi + rax]
+        movq        xmm3,           QWORD PTR[rdi + rdx]
+
+        punpcklbw   xmm2,           xmm0
+        punpcklbw   xmm3,           xmm0
+
+        psubsw      xmm2,           xmm3
+        paddw       xmm7,           xmm2
+
+        pmaddwd     xmm2,           xmm2
+        paddd       xmm1,           xmm2
+
+
+        movq        xmm2,           QWORD PTR[rsi + rax * 2]
+        movq        xmm3,           QWORD PTR[rdi + rdx * 2]
+
+        punpcklbw   xmm2,           xmm0
+        punpcklbw   xmm3,           xmm0
+
+        psubsw      xmm2,           xmm3
+        paddw       xmm7,           xmm2
+
+        pmaddwd     xmm2,           xmm2
+        paddd       xmm1,           xmm2
+
+
+        lea         rsi,            [rsi + rax * 2]
+        lea         rdi,            [rdi + rdx * 2]
+        movq        xmm2,           QWORD PTR[rsi + rax]
+        movq        xmm3,           QWORD PTR[rdi + rdx]
+
+        punpcklbw   xmm2,           xmm0
+        punpcklbw   xmm3,           xmm0
+
+        psubsw      xmm2,           xmm3
+        paddw       xmm7,           xmm2
+
+        pmaddwd     xmm2,           xmm2
+        paddd       xmm1,           xmm2
+
+        movq        xmm2,           QWORD PTR[rsi + rax *2]
+        movq        xmm3,           QWORD PTR[rdi + rdx *2]
+
+        punpcklbw   xmm2,           xmm0
+        punpcklbw   xmm3,           xmm0
+
+        psubsw      xmm2,           xmm3
+        paddw       xmm7,           xmm2
+
+        pmaddwd     xmm2,           xmm2
+        paddd       xmm1,           xmm2
+
+
+        lea         rsi,            [rsi + rax * 2]
+        lea         rdi,            [rdi + rdx * 2]
+
+
+        movq        xmm2,           QWORD PTR[rsi + rax]
+        movq        xmm3,           QWORD PTR[rdi + rdx]
+
+        punpcklbw   xmm2,           xmm0
+        punpcklbw   xmm3,           xmm0
+
+        psubsw      xmm2,           xmm3
+        paddw       xmm7,           xmm2
+
+        pmaddwd     xmm2,           xmm2
+        paddd       xmm1,           xmm2
+
+        movq        xmm2,           QWORD PTR[rsi + rax *2]
+        movq        xmm3,           QWORD PTR[rdi + rdx *2]
+
+        punpcklbw   xmm2,           xmm0
+        punpcklbw   xmm3,           xmm0
+
+        psubsw      xmm2,           xmm3
+        paddw       xmm7,           xmm2
+
+        pmaddwd     xmm2,           xmm2
+        paddd       xmm1,           xmm2
+
+
+        lea         rsi,            [rsi + rax * 2]
+        lea         rdi,            [rdi + rdx * 2]
+
+        movq        xmm2,           QWORD PTR[rsi + rax]
+        movq        xmm3,           QWORD PTR[rdi + rdx]
+
+        punpcklbw   xmm2,           xmm0
+        punpcklbw   xmm3,           xmm0
+
+        psubsw      xmm2,           xmm3
+        paddw       xmm7,           xmm2
+
+        pmaddwd     xmm2,           xmm2
+        paddd       xmm1,           xmm2
+
+
+        movdqa      xmm6,           xmm7
+        punpcklwd   xmm6,           xmm0
+
+        punpckhwd   xmm7,           xmm0
+        movdqa      xmm2,           xmm1
+
+        paddw       xmm6,           xmm7
+        punpckldq   xmm1,           xmm0
+
+        punpckhdq   xmm2,           xmm0
+        movdqa      xmm7,           xmm6
+
+        paddd       xmm1,           xmm2
+        punpckldq   xmm6,           xmm0
+
+        punpckhdq   xmm7,           xmm0
+        paddw       xmm6,           xmm7
+
+        movdqa      xmm2,           xmm1
+        movdqa      xmm7,           xmm6
+
+        psrldq      xmm1,           8
+        psrldq      xmm6,           8
+
+        paddw       xmm7,           xmm6
+        paddd       xmm1,           xmm2
+
+        mov         rax,            arg(5) //[Sum]
+        mov         rdi,            arg(4) //[SSE]
+
+        movd        rdx,            xmm7
+        movsx       rcx,            dx
+
+        mov  dword ptr [rax],       ecx
+        movd DWORD PTR [rdi],       xmm1
+
+    // begin epilog
+    add rsp, 16
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+//void vp8_filter_block2d_bil_var_sse2
+//(
+//    unsigned char *ref_ptr,
+//    int ref_pixels_per_line,
+//    unsigned char *src_ptr,
+//    int src_pixels_per_line,
+//    unsigned int Height,
+//    unsigned short *HFilter,
+//    unsigned short *VFilter,
+//    int *sum,
+//    unsigned int *sumsquared;;
+//
+//)
+global sym(vp8_filter_block2d_bil_var_sse2)
+sym(vp8_filter_block2d_bil_var_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 9
+    GET_GOT     rbx
+    push rsi
+    push rdi
+    sub         rsp, 16
+    // end prolog
+
+        pxor            xmm6,           xmm6                 //
+        pxor            xmm7,           xmm7                 //
+        mov             rax,            arg(5) //HFilter             ;
+
+        mov             rdx,            arg(6) //VFilter             ;
+        mov             rsi,            arg(0) //ref_ptr              ;
+
+        mov             rdi,            arg(2) //src_ptr              ;
+        movsxd          rcx,            dword ptr arg(4) //Height              ;
+
+        pxor            xmm0,           xmm0                 //
+        movq            xmm1,           QWORD PTR [rsi]               //
+
+        movq            xmm3,           QWORD PTR [rsi+1]        //
+        punpcklbw       xmm1,           xmm0                 //
+
+        pmullw          xmm1,           [rax]               //
+        punpcklbw       xmm3,           xmm0
+            //
+        pmullw          xmm3,           [rax+16]             //
+        paddw           xmm1,           xmm3                 //
+
+        paddw           xmm1,           [GLOBAL (xmm_bi_rd)]   //
+        psraw           xmm1,           xmm_filter_shift    //
+
+        movdqa          xmm5,           xmm1
+#if ABI_IS_32BIT
+        add             rsi,            dword ptr arg(1) //ref_pixels_per_line    ;
+#else
+        movsxd          r8,             dword ptr arg(1) //ref_pixels_per_line    ;
+        add             rsi,            r8
+#endif
+filter_block2d_bil_var_sse2_loop:
+
+        movq            xmm1,           QWORD PTR [rsi]               //
+        movq            xmm3,           QWORD PTR [rsi+1]             //
+
+        punpcklbw       xmm1,           xmm0                 //
+        pmullw          xmm1,           [rax]               //
+
+        punpcklbw       xmm3,           xmm0                 //
+        pmullw          xmm3,           [rax+16]             //
+
+        paddw           xmm1,           xmm3                 //
+        paddw           xmm1,           [GLOBAL (xmm_bi_rd)]   //
+
+        psraw           xmm1,           xmm_filter_shift    //
+        movdqa          xmm3,           xmm5                 //
+
+        movdqa          xmm5,           xmm1                 //
+        pmullw          xmm3,           [rdx]               //
+
+        pmullw          xmm1,           [rdx+16]             //
+        paddw           xmm1,           xmm3                 //
+
+        paddw           xmm1,           [GLOBAL (xmm_bi_rd)]   //
+        psraw           xmm1,           xmm_filter_shift    //
+
+        movq            xmm3,           QWORD PTR [rdi]               //
+        punpcklbw       xmm3,           xmm0                 //
+
+        psubw           xmm1,           xmm3                 //
+        paddw           xmm6,           xmm1                 //
+
+        pmaddwd         xmm1,           xmm1                 //
+        paddd           xmm7,           xmm1                 //
+
+#if ABI_IS_32BIT
+        add             rsi,            dword ptr arg(1) //ref_pixels_per_line    ;
+        add             rdi,            dword ptr arg(3) //src_pixels_per_line    ;
+#else
+        movsxd          r8,             dword ptr arg(1) //ref_pixels_per_line    ;
+        movsxd          r9,             dword ptr arg(3) //src_pixels_per_line    ;
+        add             rsi,            r8
+        add             rdi,            r9
+#endif
+
+        sub             rcx,            1                   //
+        jnz             filter_block2d_bil_var_sse2_loop       //
+
+
+        movdq2q         mm6,            xmm6                //
+        movdq2q         mm7,            xmm7                //
+
+        psrldq          xmm6,           8
+        psrldq          xmm7,           8
+
+        movdq2q         mm2,            xmm6
+        movdq2q         mm3,            xmm7
+
+        paddw           mm6,            mm2
+        paddd           mm7,            mm3
+
+        pxor            mm3,            mm3                 //
+        pxor            mm2,            mm2                 //
+
+        punpcklwd       mm2,            mm6                 //
+        punpckhwd       mm3,            mm6                 //
+
+        paddd           mm2,            mm3                 //
+        movq            mm6,            mm2                 //
+
+        psrlq           mm6,            32                  //
+        paddd           mm2,            mm6                 //
+
+        psrad           mm2,            16                  //
+        movq            mm4,            mm7                 //
+
+        psrlq           mm4,            32                  //
+        paddd           mm4,            mm7                 //
+
+        mov             rsi,            arg(7) // sum
+        mov             rdi,            arg(8) // sumsquared
+
+        movd            [rsi],          mm2    // xsum
+        movd            [rdi],          mm4    // xxsum
+
+
+    // begin epilog
+    add rsp, 16
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void vp8_half_horiz_vert_variance16x_h_sse2
+//(
+//    unsigned char *ref_ptr,
+//    int ref_pixels_per_line,
+//    unsigned char *src_ptr,
+//    int src_pixels_per_line,
+//    unsigned int Height,
+//    int *sum,
+//    unsigned int *sumsquared
+//)
+global sym(vp8_half_horiz_vert_variance16x_h_sse2)
+sym(vp8_half_horiz_vert_variance16x_h_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 7
+    GET_GOT     rbx
+    push rsi
+    push rdi
+    // end prolog
+
+#if ! ABI_IS_32BIT
+    movsxd          r8, dword ptr arg(1) //ref_pixels_per_line
+    movsxd          r9, dword ptr arg(3) //src_pixels_per_line
+#endif
+
+        pxor            xmm6,           xmm6                //  error accumulator
+        pxor            xmm7,           xmm7                //  sse eaccumulator
+        mov             rsi,            arg(0) //ref_ptr              ;
+
+        mov             rdi,            arg(2) //src_ptr              ;
+        movsxd          rcx,            dword ptr arg(4) //Height              ;
+        movsxd          rax,            dword ptr arg(1) //ref_pixels_per_line
+
+        pxor            xmm0,           xmm0                //
+
+        movq            xmm5,           QWORD PTR [rsi]     //  xmm5 = s0,s1,s2..s8
+        movq            xmm3,           QWORD PTR [rsi+1]   //  xmm3 = s1,s2,s3..s9
+        pavgb           xmm5,           xmm3                //  xmm5 = avg(xmm1,xmm3) horizontal line 1
+
+#if ABI_IS_32BIT
+        add             rsi,            dword ptr arg(1) //ref_pixels_per_line    ;  next source
+#else
+        add             rsi, r8
+#endif
+
+vp8_half_horiz_vert_variance16x_h_1:
+
+        movq            xmm1,           QWORD PTR [rsi]     //
+        movq            xmm2,           QWORD PTR [rsi+1]   //
+        pavgb           xmm1,           xmm2                //  xmm1 = avg(xmm1,xmm3) horizontal line i+1
+
+        pavgb           xmm5,           xmm1                //  xmm = vertical average of the above
+        punpcklbw       xmm5,           xmm0                //  xmm5 = words of above
+
+        movq            xmm3,           QWORD PTR [rdi]     //  xmm3 = d0,d1,d2..d8
+        punpcklbw       xmm3,           xmm0                //  xmm3 = words of above
+
+        psubw           xmm5,           xmm3                //  xmm5 -= xmm3
+        paddw           xmm6,           xmm5                //  xmm6 += accumulated column differences
+        pmaddwd         xmm5,           xmm5                //  xmm5 *= xmm5
+        paddd           xmm7,           xmm5                //  xmm7 += accumulated square column differences
+
+        movdqa          xmm5,           xmm1                //  save xmm1 for use on the next row
+
+#if ABI_IS_32BIT
+        add             esi,            dword ptr arg(1) //ref_pixels_per_line    ;  next source
+        add             edi,            dword ptr arg(3) //src_pixels_per_line    ;  next destination
+#else
+        add             rsi, r8
+        add             rdi, r9
+#endif
+
+        sub             rcx,            1                   //
+        jnz             vp8_half_horiz_vert_variance16x_h_1     //
+
+        movdq2q         mm6,            xmm6                //
+        movdq2q         mm7,            xmm7                //
+
+        psrldq          xmm6,           8
+        psrldq          xmm7,           8
+
+        movdq2q         mm2,            xmm6
+        movdq2q         mm3,            xmm7
+
+        paddw           mm6,            mm2
+        paddd           mm7,            mm3
+
+        pxor            mm3,            mm3                 //
+        pxor            mm2,            mm2                 //
+
+        punpcklwd       mm2,            mm6                 //
+        punpckhwd       mm3,            mm6                 //
+
+        paddd           mm2,            mm3                 //
+        movq            mm6,            mm2                 //
+
+        psrlq           mm6,            32                  //
+        paddd           mm2,            mm6                 //
+
+        psrad           mm2,            16                  //
+        movq            mm4,            mm7                 //
+
+        psrlq           mm4,            32                  //
+        paddd           mm4,            mm7                 //
+
+        mov             rsi,            arg(5) // sum
+        mov             rdi,            arg(6) // sumsquared
+
+        movd            [rsi],          mm2                 //
+        movd            [rdi],          mm4                 //
+
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void vp8_half_vert_variance16x_h_sse2
+//(
+//    unsigned char *ref_ptr,
+//    int ref_pixels_per_line,
+//    unsigned char *src_ptr,
+//    int src_pixels_per_line,
+//    unsigned int Height,
+//    int *sum,
+//    unsigned int *sumsquared
+//)
+global sym(vp8_half_vert_variance16x_h_sse2)
+sym(vp8_half_vert_variance16x_h_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 7
+    GET_GOT     rbx
+    push rsi
+    push rdi
+    // end prolog
+
+#if ! ABI_IS_32BIT
+    movsxd          r8, dword ptr arg(1) //ref_pixels_per_line
+    movsxd          r9, dword ptr arg(3) //src_pixels_per_line
+#endif
+
+        pxor            xmm6,           xmm6                //  error accumulator
+        pxor            xmm7,           xmm7                //  sse eaccumulator
+        mov             rsi,            arg(0) //ref_ptr              ;
+
+        mov             rdi,            arg(2) //src_ptr              ;
+        movsxd          rcx,            dword ptr arg(4) //Height              ;
+        movsxd          rax,            dword ptr arg(1) //ref_pixels_per_line
+
+        pxor            xmm0,           xmm0                //
+vp8_half_vert_variance16x_h_1:
+        movq            xmm5,           QWORD PTR [rsi]     //  xmm5 = s0,s1,s2..s8
+        movq            xmm3,           QWORD PTR [rsi+rax] //  xmm3 = s1,s2,s3..s9
+
+        pavgb           xmm5,           xmm3                //  xmm5 = avg(xmm1,xmm3)
+        punpcklbw       xmm5,           xmm0                //  xmm5 = words of above
+
+        movq            xmm3,           QWORD PTR [rdi]     //  xmm3 = d0,d1,d2..d8
+        punpcklbw       xmm3,           xmm0                //  xmm3 = words of above
+
+        psubw           xmm5,           xmm3                //  xmm5 -= xmm3
+        paddw           xmm6,           xmm5                //  xmm6 += accumulated column differences
+        pmaddwd         xmm5,           xmm5                //  xmm5 *= xmm5
+        paddd           xmm7,           xmm5                //  xmm7 += accumulated square column differences
+
+#if ABI_IS_32BIT
+        add             esi,            dword ptr arg(1) //ref_pixels_per_line    ;  next source
+        add             edi,            dword ptr arg(3) //src_pixels_per_line    ;  next destination
+#else
+        add             rsi, r8
+        add             rdi, r9
+#endif
+
+        sub             rcx,            1                   //
+        jnz             vp8_half_vert_variance16x_h_1          //
+
+        movdq2q         mm6,            xmm6                //
+        movdq2q         mm7,            xmm7                //
+
+        psrldq          xmm6,           8
+        psrldq          xmm7,           8
+
+        movdq2q         mm2,            xmm6
+        movdq2q         mm3,            xmm7
+
+        paddw           mm6,            mm2
+        paddd           mm7,            mm3
+
+        pxor            mm3,            mm3                 //
+        pxor            mm2,            mm2                 //
+
+        punpcklwd       mm2,            mm6                 //
+        punpckhwd       mm3,            mm6                 //
+
+        paddd           mm2,            mm3                 //
+        movq            mm6,            mm2                 //
+
+        psrlq           mm6,            32                  //
+        paddd           mm2,            mm6                 //
+
+        psrad           mm2,            16                  //
+        movq            mm4,            mm7                 //
+
+        psrlq           mm4,            32                  //
+        paddd           mm4,            mm7                 //
+
+        mov             rsi,            arg(5) // sum
+        mov             rdi,            arg(6) // sumsquared
+
+        movd            [rsi],          mm2                 //
+        movd            [rdi],          mm4                 //
+
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+//void vp8_half_horiz_variance16x_h_sse2
+//(
+//    unsigned char *ref_ptr,
+//    int ref_pixels_per_line,
+//    unsigned char *src_ptr,
+//    int src_pixels_per_line,
+//    unsigned int Height,
+//    int *sum,
+//    unsigned int *sumsquared
+//)
+global sym(vp8_half_horiz_variance16x_h_sse2)
+sym(vp8_half_horiz_variance16x_h_sse2):
+    push        rbp
+    mov         rbp, rsp
+    SHADOW_ARGS_TO_STACK 7
+    GET_GOT     rbx
+    push rsi
+    push rdi
+    // end prolog
+
+#if ! ABI_IS_32BIT
+    movsxd          r8, dword ptr arg(1) //ref_pixels_per_line
+    movsxd          r9, dword ptr arg(3) //src_pixels_per_line
+#endif
+
+        pxor            xmm6,           xmm6                //  error accumulator
+        pxor            xmm7,           xmm7                //  sse eaccumulator
+        mov             rsi,            arg(0) //ref_ptr              ;
+
+        mov             rdi,            arg(2) //src_ptr              ;
+        movsxd          rcx,            dword ptr arg(4) //Height              ;
+
+        pxor            xmm0,           xmm0                //
+vp8_half_horiz_variance16x16_1:
+        movq            xmm5,           QWORD PTR [rsi]     //  xmm5 = s0,s1,s2..s8
+        movq            xmm3,           QWORD PTR [rsi+1]   //  xmm3 = s1,s2,s3..s9
+
+        pavgb           xmm5,           xmm3                //  xmm5 = avg(xmm1,xmm3)
+        punpcklbw       xmm5,           xmm0                //  xmm5 = words of above
+
+        movq            xmm3,           QWORD PTR [rdi]     //  xmm3 = d0,d1,d2..d8
+        punpcklbw       xmm3,           xmm0                //  xmm3 = words of above
+
+        psubw           xmm5,           xmm3                //  xmm5 -= xmm3
+        paddw           xmm6,           xmm5                //  xmm6 += accumulated column differences
+        pmaddwd         xmm5,           xmm5                //  xmm5 *= xmm5
+        paddd           xmm7,           xmm5                //  xmm7 += accumulated square column differences
+
+#if ABI_IS_32BIT
+        add             esi,            dword ptr arg(1) //ref_pixels_per_line    ;  next source
+        add             edi,            dword ptr arg(3) //src_pixels_per_line    ;  next destination
+#else
+        add             rsi, r8
+        add             rdi, r9
+#endif
+        sub             rcx,            1                   //
+        jnz             vp8_half_horiz_variance16x16_1        //
+
+        movdq2q         mm6,            xmm6                //
+        movdq2q         mm7,            xmm7                //
+
+        psrldq          xmm6,           8
+        psrldq          xmm7,           8
+
+        movdq2q         mm2,            xmm6
+        movdq2q         mm3,            xmm7
+
+        paddw           mm6,            mm2
+        paddd           mm7,            mm3
+
+        pxor            mm3,            mm3                 //
+        pxor            mm2,            mm2                 //
+
+        punpcklwd       mm2,            mm6                 //
+        punpckhwd       mm3,            mm6                 //
+
+        paddd           mm2,            mm3                 //
+        movq            mm6,            mm2                 //
+
+        psrlq           mm6,            32                  //
+        paddd           mm2,            mm6                 //
+
+        psrad           mm2,            16                  //
+        movq            mm4,            mm7                 //
+
+        psrlq           mm4,            32                  //
+        paddd           mm4,            mm7                 //
+
+        mov             rsi,            arg(5) // sum
+        mov             rdi,            arg(6) // sumsquared
+
+        movd            [rsi],          mm2                 //
+        movd            [rdi],          mm4                 //
+
+
+    // begin epilog
+    pop rdi
+    pop rsi
+    RESTORE_GOT
+    UNSHADOW_ARGS
+    pop         rbp
+    ret
+
+
+SECTION_RODATA
+//    short xmm_bi_rd[8] = { 64, 64, 64, 64,64, 64, 64, 64};
+align 16
+xmm_bi_rd:
+    .fill 8, 2, 64
diff --git a/vp8/encoder/x86/variance_impl_sse2.asm b/vp8/encoder/x86/variance_impl_sse2.asm
deleted file mode 100644
index 7e5ee28..0000000
--- a/vp8/encoder/x86/variance_impl_sse2.asm
+++ /dev/null
@@ -1,975 +0,0 @@
-;
-;  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
-;
-;  Use of this source code is governed by a BSD-style license and patent
-;  grant that can be found in the LICENSE file in the root of the source
-;  tree. All contributing project authors may be found in the AUTHORS
-;  file in the root of the source tree.
-;
-
-
-%include "vpx_ports/x86_abi_support.asm"
-
-%define xmm_filter_shift            7
-
-;unsigned int vp8_get_mb_ss_sse2
-;(
-;    short *src_ptr
-;)
-global sym(vp8_get_mb_ss_sse2)
-sym(vp8_get_mb_ss_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 1
-    GET_GOT     rbx
-    push rsi
-    push rdi
-    sub         rsp, 16
-    ; end prolog
-
-
-        mov         rax, arg(0) ;[src_ptr]
-        mov         rcx, 8
-        pxor        xmm4, xmm4
-
-NEXTROW:
-        movdqa      xmm0, [rax]
-        movdqa      xmm1, [rax+16]
-        movdqa      xmm2, [rax+32]
-        movdqa      xmm3, [rax+48]
-        pmaddwd     xmm0, xmm0
-        pmaddwd     xmm1, xmm1
-        pmaddwd     xmm2, xmm2
-        pmaddwd     xmm3, xmm3
-
-        paddd       xmm0, xmm1
-        paddd       xmm2, xmm3
-        paddd       xmm4, xmm0
-        paddd       xmm4, xmm2
-
-        add         rax, 0x40
-        dec         rcx
-        ja          NEXTROW
-
-        movdqa      xmm3,xmm4
-        psrldq      xmm4,8
-        paddd       xmm4,xmm3
-        movdqa      xmm3,xmm4
-        psrldq      xmm4,4
-        paddd       xmm4,xmm3
-        movd        rax,xmm4
-
-
-    ; begin epilog
-    add rsp, 16
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;unsigned int vp8_get16x16var_sse2
-;(
-;    unsigned char   *  src_ptr,
-;    int             source_stride,
-;    unsigned char   *  ref_ptr,
-;    int             recon_stride,
-;    unsigned int    *  SSE,
-;    int             *  Sum
-;)
-global sym(vp8_get16x16var_sse2)
-sym(vp8_get16x16var_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 6
-    GET_GOT     rbx
-    push rsi
-    push rdi
-    sub         rsp, 16
-    ; end prolog
-
-        mov         rsi,            arg(0) ;[src_ptr]
-        mov         rdi,            arg(2) ;[ref_ptr]
-
-        movsxd      rax,            DWORD PTR arg(1) ;[source_stride]
-        movsxd      rdx,            DWORD PTR arg(3) ;[recon_stride]
-
-        pxor        xmm0,           xmm0                        ; clear xmm0 for unpack
-        pxor        xmm7,           xmm7                        ; clear xmm7 for accumulating diffs
-
-        pxor        xmm6,           xmm6                        ; clear xmm6 for accumulating sse
-        mov         rcx,            16
-
-var16loop:
-        movdqu      xmm1,           XMMWORD PTR [rsi]
-        movdqu      xmm2,           XMMWORD PTR [rdi]
-
-        movdqa      xmm3,           xmm1
-        movdqa      xmm4,           xmm2
-
-
-        punpcklbw   xmm1,           xmm0
-        punpckhbw   xmm3,           xmm0
-
-        punpcklbw   xmm2,           xmm0
-        punpckhbw   xmm4,           xmm0
-
-
-        psubw       xmm1,           xmm2
-        psubw       xmm3,           xmm4
-
-        paddw       xmm7,           xmm1
-        pmaddwd     xmm1,           xmm1
-
-        paddw       xmm7,           xmm3
-        pmaddwd     xmm3,           xmm3
-
-        paddd       xmm6,           xmm1
-        paddd       xmm6,           xmm3
-
-        add         rsi,            rax
-        add         rdi,            rdx
-
-        sub         rcx,            1
-        jnz         var16loop
-
-
-        movdqa      xmm1,           xmm6
-        pxor        xmm6,           xmm6
-
-        pxor        xmm5,           xmm5
-        punpcklwd   xmm6,           xmm7
-
-        punpckhwd   xmm5,           xmm7
-        psrad       xmm5,           16
-
-        psrad       xmm6,           16
-        paddd       xmm6,           xmm5
-
-        movdqa      xmm2,           xmm1
-        punpckldq   xmm1,           xmm0
-
-        punpckhdq   xmm2,           xmm0
-        movdqa      xmm7,           xmm6
-
-        paddd       xmm1,           xmm2
-        punpckldq   xmm6,           xmm0
-
-        punpckhdq   xmm7,           xmm0
-        paddd       xmm6,           xmm7
-
-        movdqa      xmm2,           xmm1
-        movdqa      xmm7,           xmm6
-
-        psrldq      xmm1,           8
-        psrldq      xmm6,           8
-
-        paddd       xmm7,           xmm6
-        paddd       xmm1,           xmm2
-
-        mov         rax,            arg(5) ;[Sum]
-        mov         rdi,            arg(4) ;[SSE]
-
-        movd DWORD PTR [rax],       xmm7
-        movd DWORD PTR [rdi],       xmm1
-
-
-    ; begin epilog
-    add rsp, 16
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;unsigned int vp8_get16x16pred_error_sse2
-;(
-;   unsigned char *src_ptr,
-;    int src_stride,
-;    unsigned char *ref_ptr,
-;    int ref_stride
-;)
-global sym(vp8_get16x16pred_error_sse2)
-sym(vp8_get16x16pred_error_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 4
-    GET_GOT     rbx
-    push rsi
-    push rdi
-    sub         rsp, 16
-    ; end prolog
-
-        mov         rsi,            arg(0) ;[src_ptr]
-        mov         rdi,            arg(2) ;[ref_ptr]
-
-        movsxd      rax,            DWORD PTR arg(1) ;[src_stride]
-        movsxd      rdx,            DWORD PTR arg(3) ;[ref_stride]
-
-        pxor        xmm0,           xmm0                        ; clear xmm0 for unpack
-        pxor        xmm7,           xmm7                        ; clear xmm7 for accumulating diffs
-
-        pxor        xmm6,           xmm6                        ; clear xmm6 for accumulating sse
-        mov         rcx,            16
-
-var16peloop:
-        movdqu      xmm1,           XMMWORD PTR [rsi]
-        movdqu      xmm2,           XMMWORD PTR [rdi]
-
-        movdqa      xmm3,           xmm1
-        movdqa      xmm4,           xmm2
-
-        punpcklbw   xmm1,           xmm0
-        punpckhbw   xmm3,           xmm0
-
-        punpcklbw   xmm2,           xmm0
-        punpckhbw   xmm4,           xmm0
-
-        psubw       xmm1,           xmm2
-        psubw       xmm3,           xmm4
-
-        paddw       xmm7,           xmm1
-        pmaddwd     xmm1,           xmm1
-
-        paddw       xmm7,           xmm3
-        pmaddwd     xmm3,           xmm3
-
-        paddd       xmm6,           xmm1
-        paddd       xmm6,           xmm3
-
-        add         rsi,            rax
-        add         rdi,            rdx
-
-        sub         rcx,            1
-        jnz         var16peloop
-
-
-        movdqa      xmm1,           xmm6
-        pxor        xmm6,           xmm6
-
-        pxor        xmm5,           xmm5
-        punpcklwd   xmm6,           xmm7
-
-        punpckhwd   xmm5,           xmm7
-        psrad       xmm5,           16
-
-        psrad       xmm6,           16
-        paddd       xmm6,           xmm5
-
-        movdqa      xmm2,           xmm1
-        punpckldq   xmm1,           xmm0
-
-        punpckhdq   xmm2,           xmm0
-        movdqa      xmm7,           xmm6
-
-        paddd       xmm1,           xmm2
-        punpckldq   xmm6,           xmm0
-
-        punpckhdq   xmm7,           xmm0
-        paddd       xmm6,           xmm7
-
-        movdqa      xmm2,           xmm1
-        movdqa      xmm7,           xmm6
-
-        psrldq      xmm1,           8
-        psrldq      xmm6,           8
-
-        paddd       xmm7,           xmm6
-        paddd       xmm1,           xmm2
-
-        movd DWORD PTR [rsp],       xmm7  ;Sum
-        movd DWORD PTR [rsp+4],     xmm1  ;SSE
-
-        ; return (SSE-((Sum*Sum)>>8));
-        movsxd      rdx, dword ptr [rsp]
-        imul        rdx, rdx
-        sar         rdx, 8
-        movsxd      rax, dword ptr [rsp + 4]
-        sub         rax, rdx
-
-    ; begin epilog
-    add rsp, 16
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-
-;unsigned int vp8_get8x8var_sse2
-;(
-;    unsigned char   *  src_ptr,
-;    int             source_stride,
-;    unsigned char   *  ref_ptr,
-;    int             recon_stride,
-;    unsigned int    *  SSE,
-;    int             *  Sum
-;)
-global sym(vp8_get8x8var_sse2)
-sym(vp8_get8x8var_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 6
-    GET_GOT     rbx
-    push rsi
-    push rdi
-    sub         rsp, 16
-    ; end prolog
-
-        mov         rsi,            arg(0) ;[src_ptr]
-        mov         rdi,            arg(2) ;[ref_ptr]
-
-        movsxd      rax,            DWORD PTR arg(1) ;[source_stride]
-        movsxd      rdx,            DWORD PTR arg(3) ;[recon_stride]
-
-        pxor        xmm0,           xmm0                        ; clear xmm0 for unpack
-        pxor        xmm7,           xmm7                        ; clear xmm7 for accumulating diffs
-
-        movq        xmm1,           QWORD PTR [rsi]
-        movq        xmm2,           QWORD PTR [rdi]
-
-        punpcklbw   xmm1,           xmm0
-        punpcklbw   xmm2,           xmm0
-
-        psubsw      xmm1,           xmm2
-        paddw       xmm7,           xmm1
-
-        pmaddwd     xmm1,           xmm1
-
-        movq        xmm2,           QWORD PTR[rsi + rax]
-        movq        xmm3,           QWORD PTR[rdi + rdx]
-
-        punpcklbw   xmm2,           xmm0
-        punpcklbw   xmm3,           xmm0
-
-        psubsw      xmm2,           xmm3
-        paddw       xmm7,           xmm2
-
-        pmaddwd     xmm2,           xmm2
-        paddd       xmm1,           xmm2
-
-
-        movq        xmm2,           QWORD PTR[rsi + rax * 2]
-        movq        xmm3,           QWORD PTR[rdi + rdx * 2]
-
-        punpcklbw   xmm2,           xmm0
-        punpcklbw   xmm3,           xmm0
-
-        psubsw      xmm2,           xmm3
-        paddw       xmm7,           xmm2
-
-        pmaddwd     xmm2,           xmm2
-        paddd       xmm1,           xmm2
-
-
-        lea         rsi,            [rsi + rax * 2]
-        lea         rdi,            [rdi + rdx * 2]
-        movq        xmm2,           QWORD PTR[rsi + rax]
-        movq        xmm3,           QWORD PTR[rdi + rdx]
-
-        punpcklbw   xmm2,           xmm0
-        punpcklbw   xmm3,           xmm0
-
-        psubsw      xmm2,           xmm3
-        paddw       xmm7,           xmm2
-
-        pmaddwd     xmm2,           xmm2
-        paddd       xmm1,           xmm2
-
-        movq        xmm2,           QWORD PTR[rsi + rax *2]
-        movq        xmm3,           QWORD PTR[rdi + rdx *2]
-
-        punpcklbw   xmm2,           xmm0
-        punpcklbw   xmm3,           xmm0
-
-        psubsw      xmm2,           xmm3
-        paddw       xmm7,           xmm2
-
-        pmaddwd     xmm2,           xmm2
-        paddd       xmm1,           xmm2
-
-
-        lea         rsi,            [rsi + rax * 2]
-        lea         rdi,            [rdi + rdx * 2]
-
-
-        movq        xmm2,           QWORD PTR[rsi + rax]
-        movq        xmm3,           QWORD PTR[rdi + rdx]
-
-        punpcklbw   xmm2,           xmm0
-        punpcklbw   xmm3,           xmm0
-
-        psubsw      xmm2,           xmm3
-        paddw       xmm7,           xmm2
-
-        pmaddwd     xmm2,           xmm2
-        paddd       xmm1,           xmm2
-
-        movq        xmm2,           QWORD PTR[rsi + rax *2]
-        movq        xmm3,           QWORD PTR[rdi + rdx *2]
-
-        punpcklbw   xmm2,           xmm0
-        punpcklbw   xmm3,           xmm0
-
-        psubsw      xmm2,           xmm3
-        paddw       xmm7,           xmm2
-
-        pmaddwd     xmm2,           xmm2
-        paddd       xmm1,           xmm2
-
-
-        lea         rsi,            [rsi + rax * 2]
-        lea         rdi,            [rdi + rdx * 2]
-
-        movq        xmm2,           QWORD PTR[rsi + rax]
-        movq        xmm3,           QWORD PTR[rdi + rdx]
-
-        punpcklbw   xmm2,           xmm0
-        punpcklbw   xmm3,           xmm0
-
-        psubsw      xmm2,           xmm3
-        paddw       xmm7,           xmm2
-
-        pmaddwd     xmm2,           xmm2
-        paddd       xmm1,           xmm2
-
-
-        movdqa      xmm6,           xmm7
-        punpcklwd   xmm6,           xmm0
-
-        punpckhwd   xmm7,           xmm0
-        movdqa      xmm2,           xmm1
-
-        paddw       xmm6,           xmm7
-        punpckldq   xmm1,           xmm0
-
-        punpckhdq   xmm2,           xmm0
-        movdqa      xmm7,           xmm6
-
-        paddd       xmm1,           xmm2
-        punpckldq   xmm6,           xmm0
-
-        punpckhdq   xmm7,           xmm0
-        paddw       xmm6,           xmm7
-
-        movdqa      xmm2,           xmm1
-        movdqa      xmm7,           xmm6
-
-        psrldq      xmm1,           8
-        psrldq      xmm6,           8
-
-        paddw       xmm7,           xmm6
-        paddd       xmm1,           xmm2
-
-        mov         rax,            arg(5) ;[Sum]
-        mov         rdi,            arg(4) ;[SSE]
-
-        movd        rdx,            xmm7
-        movsx       rcx,            dx
-
-        mov  dword ptr [rax],       ecx
-        movd DWORD PTR [rdi],       xmm1
-
-    ; begin epilog
-    add rsp, 16
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-;void vp8_filter_block2d_bil_var_sse2
-;(
-;    unsigned char *ref_ptr,
-;    int ref_pixels_per_line,
-;    unsigned char *src_ptr,
-;    int src_pixels_per_line,
-;    unsigned int Height,
-;    unsigned short *HFilter,
-;    unsigned short *VFilter,
-;    int *sum,
-;    unsigned int *sumsquared;;
-;
-;)
-global sym(vp8_filter_block2d_bil_var_sse2)
-sym(vp8_filter_block2d_bil_var_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 9
-    GET_GOT     rbx
-    push rsi
-    push rdi
-    sub         rsp, 16
-    ; end prolog
-
-        pxor            xmm6,           xmm6                 ;
-        pxor            xmm7,           xmm7                 ;
-        mov             rax,            arg(5) ;HFilter             ;
-
-        mov             rdx,            arg(6) ;VFilter             ;
-        mov             rsi,            arg(0) ;ref_ptr              ;
-
-        mov             rdi,            arg(2) ;src_ptr              ;
-        movsxd          rcx,            dword ptr arg(4) ;Height              ;
-
-        pxor            xmm0,           xmm0                 ;
-        movq            xmm1,           QWORD PTR [rsi]               ;
-
-        movq            xmm3,           QWORD PTR [rsi+1]        ;
-        punpcklbw       xmm1,           xmm0                 ;
-
-        pmullw          xmm1,           [rax]               ;
-        punpcklbw       xmm3,           xmm0
-            ;
-        pmullw          xmm3,           [rax+16]             ;
-        paddw           xmm1,           xmm3                 ;
-
-        paddw           xmm1,           [xmm_bi_rd GLOBAL]   ;
-        psraw           xmm1,           xmm_filter_shift    ;
-
-        movdqa          xmm5,           xmm1
-%if ABI_IS_32BIT
-        add             rsi,            dword ptr arg(1) ;ref_pixels_per_line    ;
-%else
-        movsxd          r8,             dword ptr arg(1) ;ref_pixels_per_line    ;
-        add             rsi,            r8
-%endif
-filter_block2d_bil_var_sse2_loop:
-
-        movq            xmm1,           QWORD PTR [rsi]               ;
-        movq            xmm3,           QWORD PTR [rsi+1]             ;
-
-        punpcklbw       xmm1,           xmm0                 ;
-        pmullw          xmm1,           [rax]               ;
-
-        punpcklbw       xmm3,           xmm0                 ;
-        pmullw          xmm3,           [rax+16]             ;
-
-        paddw           xmm1,           xmm3                 ;
-        paddw           xmm1,           [xmm_bi_rd GLOBAL]   ;
-
-        psraw           xmm1,           xmm_filter_shift    ;
-        movdqa          xmm3,           xmm5                 ;
-
-        movdqa          xmm5,           xmm1                 ;
-        pmullw          xmm3,           [rdx]               ;
-
-        pmullw          xmm1,           [rdx+16]             ;
-        paddw           xmm1,           xmm3                 ;
-
-        paddw           xmm1,           [xmm_bi_rd GLOBAL]   ;
-        psraw           xmm1,           xmm_filter_shift    ;
-
-        movq            xmm3,           QWORD PTR [rdi]               ;
-        punpcklbw       xmm3,           xmm0                 ;
-
-        psubw           xmm1,           xmm3                 ;
-        paddw           xmm6,           xmm1                 ;
-
-        pmaddwd         xmm1,           xmm1                 ;
-        paddd           xmm7,           xmm1                 ;
-
-%if ABI_IS_32BIT
-        add             rsi,            dword ptr arg(1) ;ref_pixels_per_line    ;
-        add             rdi,            dword ptr arg(3) ;src_pixels_per_line    ;
-%else
-        movsxd          r8,             dword ptr arg(1) ;ref_pixels_per_line    ;
-        movsxd          r9,             dword ptr arg(3) ;src_pixels_per_line    ;
-        add             rsi,            r8
-        add             rdi,            r9
-%endif
-
-        sub             rcx,            1                   ;
-        jnz             filter_block2d_bil_var_sse2_loop       ;
-
-
-        movdq2q         mm6,            xmm6                ;
-        movdq2q         mm7,            xmm7                ;
-
-        psrldq          xmm6,           8
-        psrldq          xmm7,           8
-
-        movdq2q         mm2,            xmm6
-        movdq2q         mm3,            xmm7
-
-        paddw           mm6,            mm2
-        paddd           mm7,            mm3
-
-        pxor            mm3,            mm3                 ;
-        pxor            mm2,            mm2                 ;
-
-        punpcklwd       mm2,            mm6                 ;
-        punpckhwd       mm3,            mm6                 ;
-
-        paddd           mm2,            mm3                 ;
-        movq            mm6,            mm2                 ;
-
-        psrlq           mm6,            32                  ;
-        paddd           mm2,            mm6                 ;
-
-        psrad           mm2,            16                  ;
-        movq            mm4,            mm7                 ;
-
-        psrlq           mm4,            32                  ;
-        paddd           mm4,            mm7                 ;
-
-        mov             rsi,            arg(7) ; sum
-        mov             rdi,            arg(8) ; sumsquared
-
-        movd            [rsi],          mm2    ; xsum
-        movd            [rdi],          mm4    ; xxsum
-
-
-    ; begin epilog
-    add rsp, 16
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void vp8_half_horiz_vert_variance16x_h_sse2
-;(
-;    unsigned char *ref_ptr,
-;    int ref_pixels_per_line,
-;    unsigned char *src_ptr,
-;    int src_pixels_per_line,
-;    unsigned int Height,
-;    int *sum,
-;    unsigned int *sumsquared
-;)
-global sym(vp8_half_horiz_vert_variance16x_h_sse2)
-sym(vp8_half_horiz_vert_variance16x_h_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 7
-    GET_GOT     rbx
-    push rsi
-    push rdi
-    ; end prolog
-
-%if ABI_IS_32BIT=0
-    movsxd          r8, dword ptr arg(1) ;ref_pixels_per_line
-    movsxd          r9, dword ptr arg(3) ;src_pixels_per_line
-%endif
-
-        pxor            xmm6,           xmm6                ;  error accumulator
-        pxor            xmm7,           xmm7                ;  sse eaccumulator
-        mov             rsi,            arg(0) ;ref_ptr              ;
-
-        mov             rdi,            arg(2) ;src_ptr              ;
-        movsxd          rcx,            dword ptr arg(4) ;Height              ;
-        movsxd          rax,            dword ptr arg(1) ;ref_pixels_per_line
-
-        pxor            xmm0,           xmm0                ;
-
-        movq            xmm5,           QWORD PTR [rsi]     ;  xmm5 = s0,s1,s2..s8
-        movq            xmm3,           QWORD PTR [rsi+1]   ;  xmm3 = s1,s2,s3..s9
-        pavgb           xmm5,           xmm3                ;  xmm5 = avg(xmm1,xmm3) horizontal line 1
-
-%if ABI_IS_32BIT
-        add             rsi,            dword ptr arg(1) ;ref_pixels_per_line    ;  next source
-%else
-        add             rsi, r8
-%endif
-
-vp8_half_horiz_vert_variance16x_h_1:
-
-        movq            xmm1,           QWORD PTR [rsi]     ;
-        movq            xmm2,           QWORD PTR [rsi+1]   ;
-        pavgb           xmm1,           xmm2                ;  xmm1 = avg(xmm1,xmm3) horizontal line i+1
-
-        pavgb           xmm5,           xmm1                ;  xmm = vertical average of the above
-        punpcklbw       xmm5,           xmm0                ;  xmm5 = words of above
-
-        movq            xmm3,           QWORD PTR [rdi]     ;  xmm3 = d0,d1,d2..d8
-        punpcklbw       xmm3,           xmm0                ;  xmm3 = words of above
-
-        psubw           xmm5,           xmm3                ;  xmm5 -= xmm3
-        paddw           xmm6,           xmm5                ;  xmm6 += accumulated column differences
-        pmaddwd         xmm5,           xmm5                ;  xmm5 *= xmm5
-        paddd           xmm7,           xmm5                ;  xmm7 += accumulated square column differences
-
-        movdqa          xmm5,           xmm1                ;  save xmm1 for use on the next row
-
-%if ABI_IS_32BIT
-        add             esi,            dword ptr arg(1) ;ref_pixels_per_line    ;  next source
-        add             edi,            dword ptr arg(3) ;src_pixels_per_line    ;  next destination
-%else
-        add             rsi, r8
-        add             rdi, r9
-%endif
-
-        sub             rcx,            1                   ;
-        jnz             vp8_half_horiz_vert_variance16x_h_1     ;
-
-        movdq2q         mm6,            xmm6                ;
-        movdq2q         mm7,            xmm7                ;
-
-        psrldq          xmm6,           8
-        psrldq          xmm7,           8
-
-        movdq2q         mm2,            xmm6
-        movdq2q         mm3,            xmm7
-
-        paddw           mm6,            mm2
-        paddd           mm7,            mm3
-
-        pxor            mm3,            mm3                 ;
-        pxor            mm2,            mm2                 ;
-
-        punpcklwd       mm2,            mm6                 ;
-        punpckhwd       mm3,            mm6                 ;
-
-        paddd           mm2,            mm3                 ;
-        movq            mm6,            mm2                 ;
-
-        psrlq           mm6,            32                  ;
-        paddd           mm2,            mm6                 ;
-
-        psrad           mm2,            16                  ;
-        movq            mm4,            mm7                 ;
-
-        psrlq           mm4,            32                  ;
-        paddd           mm4,            mm7                 ;
-
-        mov             rsi,            arg(5) ; sum
-        mov             rdi,            arg(6) ; sumsquared
-
-        movd            [rsi],          mm2                 ;
-        movd            [rdi],          mm4                 ;
-
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void vp8_half_vert_variance16x_h_sse2
-;(
-;    unsigned char *ref_ptr,
-;    int ref_pixels_per_line,
-;    unsigned char *src_ptr,
-;    int src_pixels_per_line,
-;    unsigned int Height,
-;    int *sum,
-;    unsigned int *sumsquared
-;)
-global sym(vp8_half_vert_variance16x_h_sse2)
-sym(vp8_half_vert_variance16x_h_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 7
-    GET_GOT     rbx
-    push rsi
-    push rdi
-    ; end prolog
-
-%if ABI_IS_32BIT=0
-    movsxd          r8, dword ptr arg(1) ;ref_pixels_per_line
-    movsxd          r9, dword ptr arg(3) ;src_pixels_per_line
-%endif
-
-        pxor            xmm6,           xmm6                ;  error accumulator
-        pxor            xmm7,           xmm7                ;  sse eaccumulator
-        mov             rsi,            arg(0) ;ref_ptr              ;
-
-        mov             rdi,            arg(2) ;src_ptr              ;
-        movsxd          rcx,            dword ptr arg(4) ;Height              ;
-        movsxd          rax,            dword ptr arg(1) ;ref_pixels_per_line
-
-        pxor            xmm0,           xmm0                ;
-vp8_half_vert_variance16x_h_1:
-        movq            xmm5,           QWORD PTR [rsi]     ;  xmm5 = s0,s1,s2..s8
-        movq            xmm3,           QWORD PTR [rsi+rax] ;  xmm3 = s1,s2,s3..s9
-
-        pavgb           xmm5,           xmm3                ;  xmm5 = avg(xmm1,xmm3)
-        punpcklbw       xmm5,           xmm0                ;  xmm5 = words of above
-
-        movq            xmm3,           QWORD PTR [rdi]     ;  xmm3 = d0,d1,d2..d8
-        punpcklbw       xmm3,           xmm0                ;  xmm3 = words of above
-
-        psubw           xmm5,           xmm3                ;  xmm5 -= xmm3
-        paddw           xmm6,           xmm5                ;  xmm6 += accumulated column differences
-        pmaddwd         xmm5,           xmm5                ;  xmm5 *= xmm5
-        paddd           xmm7,           xmm5                ;  xmm7 += accumulated square column differences
-
-%if ABI_IS_32BIT
-        add             esi,            dword ptr arg(1) ;ref_pixels_per_line    ;  next source
-        add             edi,            dword ptr arg(3) ;src_pixels_per_line    ;  next destination
-%else
-        add             rsi, r8
-        add             rdi, r9
-%endif
-
-        sub             rcx,            1                   ;
-        jnz             vp8_half_vert_variance16x_h_1          ;
-
-        movdq2q         mm6,            xmm6                ;
-        movdq2q         mm7,            xmm7                ;
-
-        psrldq          xmm6,           8
-        psrldq          xmm7,           8
-
-        movdq2q         mm2,            xmm6
-        movdq2q         mm3,            xmm7
-
-        paddw           mm6,            mm2
-        paddd           mm7,            mm3
-
-        pxor            mm3,            mm3                 ;
-        pxor            mm2,            mm2                 ;
-
-        punpcklwd       mm2,            mm6                 ;
-        punpckhwd       mm3,            mm6                 ;
-
-        paddd           mm2,            mm3                 ;
-        movq            mm6,            mm2                 ;
-
-        psrlq           mm6,            32                  ;
-        paddd           mm2,            mm6                 ;
-
-        psrad           mm2,            16                  ;
-        movq            mm4,            mm7                 ;
-
-        psrlq           mm4,            32                  ;
-        paddd           mm4,            mm7                 ;
-
-        mov             rsi,            arg(5) ; sum
-        mov             rdi,            arg(6) ; sumsquared
-
-        movd            [rsi],          mm2                 ;
-        movd            [rdi],          mm4                 ;
-
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-;void vp8_half_horiz_variance16x_h_sse2
-;(
-;    unsigned char *ref_ptr,
-;    int ref_pixels_per_line,
-;    unsigned char *src_ptr,
-;    int src_pixels_per_line,
-;    unsigned int Height,
-;    int *sum,
-;    unsigned int *sumsquared
-;)
-global sym(vp8_half_horiz_variance16x_h_sse2)
-sym(vp8_half_horiz_variance16x_h_sse2):
-    push        rbp
-    mov         rbp, rsp
-    SHADOW_ARGS_TO_STACK 7
-    GET_GOT     rbx
-    push rsi
-    push rdi
-    ; end prolog
-
-%if ABI_IS_32BIT=0
-    movsxd          r8, dword ptr arg(1) ;ref_pixels_per_line
-    movsxd          r9, dword ptr arg(3) ;src_pixels_per_line
-%endif
-
-        pxor            xmm6,           xmm6                ;  error accumulator
-        pxor            xmm7,           xmm7                ;  sse eaccumulator
-        mov             rsi,            arg(0) ;ref_ptr              ;
-
-        mov             rdi,            arg(2) ;src_ptr              ;
-        movsxd          rcx,            dword ptr arg(4) ;Height              ;
-
-        pxor            xmm0,           xmm0                ;
-vp8_half_horiz_variance16x16_1:
-        movq            xmm5,           QWORD PTR [rsi]     ;  xmm5 = s0,s1,s2..s8
-        movq            xmm3,           QWORD PTR [rsi+1]   ;  xmm3 = s1,s2,s3..s9
-
-        pavgb           xmm5,           xmm3                ;  xmm5 = avg(xmm1,xmm3)
-        punpcklbw       xmm5,           xmm0                ;  xmm5 = words of above
-
-        movq            xmm3,           QWORD PTR [rdi]     ;  xmm3 = d0,d1,d2..d8
-        punpcklbw       xmm3,           xmm0                ;  xmm3 = words of above
-
-        psubw           xmm5,           xmm3                ;  xmm5 -= xmm3
-        paddw           xmm6,           xmm5                ;  xmm6 += accumulated column differences
-        pmaddwd         xmm5,           xmm5                ;  xmm5 *= xmm5
-        paddd           xmm7,           xmm5                ;  xmm7 += accumulated square column differences
-
-%if ABI_IS_32BIT
-        add             esi,            dword ptr arg(1) ;ref_pixels_per_line    ;  next source
-        add             edi,            dword ptr arg(3) ;src_pixels_per_line    ;  next destination
-%else
-        add             rsi, r8
-        add             rdi, r9
-%endif
-        sub             rcx,            1                   ;
-        jnz             vp8_half_horiz_variance16x16_1        ;
-
-        movdq2q         mm6,            xmm6                ;
-        movdq2q         mm7,            xmm7                ;
-
-        psrldq          xmm6,           8
-        psrldq          xmm7,           8
-
-        movdq2q         mm2,            xmm6
-        movdq2q         mm3,            xmm7
-
-        paddw           mm6,            mm2
-        paddd           mm7,            mm3
-
-        pxor            mm3,            mm3                 ;
-        pxor            mm2,            mm2                 ;
-
-        punpcklwd       mm2,            mm6                 ;
-        punpckhwd       mm3,            mm6                 ;
-
-        paddd           mm2,            mm3                 ;
-        movq            mm6,            mm2                 ;
-
-        psrlq           mm6,            32                  ;
-        paddd           mm2,            mm6                 ;
-
-        psrad           mm2,            16                  ;
-        movq            mm4,            mm7                 ;
-
-        psrlq           mm4,            32                  ;
-        paddd           mm4,            mm7                 ;
-
-        mov             rsi,            arg(5) ; sum
-        mov             rdi,            arg(6) ; sumsquared
-
-        movd            [rsi],          mm2                 ;
-        movd            [rdi],          mm4                 ;
-
-
-    ; begin epilog
-    pop rdi
-    pop rsi
-    RESTORE_GOT
-    UNSHADOW_ARGS
-    pop         rbp
-    ret
-
-
-SECTION_RODATA
-;    short xmm_bi_rd[8] = { 64, 64, 64, 64,64, 64, 64, 64};
-align 16
-xmm_bi_rd:
-    times 8 dw 64
diff --git a/vp8/vp8_common.mk b/vp8/vp8_common.mk
index ec467c5..6d13e7c 100644
--- a/vp8/vp8_common.mk
+++ b/vp8/vp8_common.mk
@@ -102,18 +102,18 @@ VP8_COMMON_SRCS-$(CONFIG_POSTPROC) += common/postproc.h
 VP8_COMMON_SRCS-$(CONFIG_POSTPROC) += common/postproc.c
 VP8_COMMON_SRCS-$(CONFIG_VP8_ENCODER) += common/postproc.h
 VP8_COMMON_SRCS-$(CONFIG_VP8_ENCODER) += common/postproc.c
-VP8_COMMON_SRCS-$(HAVE_MMX) += common/x86/idctllm_mmx.asm
-VP8_COMMON_SRCS-$(HAVE_MMX) += common/x86/iwalsh_mmx.asm
-VP8_COMMON_SRCS-$(HAVE_MMX) += common/x86/recon_mmx.asm
-VP8_COMMON_SRCS-$(HAVE_MMX) += common/x86/subpixel_mmx.asm
-VP8_COMMON_SRCS-$(HAVE_MMX) += common/x86/loopfilter_mmx.asm
-VP8_COMMON_SRCS-$(HAVE_SSE2) += common/x86/recon_sse2.asm
-VP8_COMMON_SRCS-$(HAVE_SSE2) += common/x86/subpixel_sse2.asm
-VP8_COMMON_SRCS-$(HAVE_SSE2) += common/x86/loopfilter_sse2.asm
-VP8_COMMON_SRCS-$(HAVE_SSE2) += common/x86/iwalsh_sse2.asm
+VP8_COMMON_SRCS-$(HAVE_MMX) += common/x86/idctllm_mmx.S
+VP8_COMMON_SRCS-$(HAVE_MMX) += common/x86/iwalsh_mmx.S
+VP8_COMMON_SRCS-$(HAVE_MMX) += common/x86/recon_mmx.S
+VP8_COMMON_SRCS-$(HAVE_MMX) += common/x86/subpixel_mmx.S
+VP8_COMMON_SRCS-$(HAVE_MMX) += common/x86/loopfilter_mmx.S
+VP8_COMMON_SRCS-$(HAVE_SSE2) += common/x86/recon_sse2.S
+VP8_COMMON_SRCS-$(HAVE_SSE2) += common/x86/subpixel_sse2.S
+VP8_COMMON_SRCS-$(HAVE_SSE2) += common/x86/loopfilter_sse2.S
+VP8_COMMON_SRCS-$(HAVE_SSE2) += common/x86/iwalsh_sse2.S
 ifeq ($(CONFIG_POSTPROC),yes)
-VP8_COMMON_SRCS-$(HAVE_MMX) += common/x86/postproc_mmx.asm
-VP8_COMMON_SRCS-$(HAVE_SSE2) += common/x86/postproc_sse2.asm
+VP8_COMMON_SRCS-$(HAVE_MMX) += common/x86/postproc_mmx.S
+VP8_COMMON_SRCS-$(HAVE_SSE2) += common/x86/postproc_sse2.S
 endif
 
 # common (c)
diff --git a/vp8/vp8cx.mk b/vp8/vp8cx.mk
index e7e7663..ec78c78 100644
--- a/vp8/vp8cx.mk
+++ b/vp8/vp8cx.mk
@@ -85,19 +85,19 @@ VP8_CX_SRCS-$(ARCH_X86)$(ARCH_X86_64) += encoder/x86/mcomp_x86.h
 VP8_CX_SRCS-$(ARCH_X86)$(ARCH_X86_64) += encoder/x86/variance_x86.h
 VP8_CX_SRCS-$(ARCH_X86)$(ARCH_X86_64) += encoder/x86/x86_csystemdependent.c
 VP8_CX_SRCS-$(HAVE_MMX) += encoder/x86/variance_mmx.c
-VP8_CX_SRCS-$(HAVE_MMX) += encoder/x86/variance_impl_mmx.asm
-VP8_CX_SRCS-$(HAVE_MMX) += encoder/x86/sad_mmx.asm
-VP8_CX_SRCS-$(HAVE_MMX) += encoder/x86/dct_mmx.asm
-VP8_CX_SRCS-$(HAVE_MMX) += encoder/x86/subtract_mmx.asm
+VP8_CX_SRCS-$(HAVE_MMX) += encoder/x86/variance_impl_mmx.S
+VP8_CX_SRCS-$(HAVE_MMX) += encoder/x86/sad_mmx.S
+VP8_CX_SRCS-$(HAVE_MMX) += encoder/x86/dct_mmx.S
+VP8_CX_SRCS-$(HAVE_MMX) += encoder/x86/subtract_mmx.S
 VP8_CX_SRCS-$(HAVE_SSE2) += encoder/x86/variance_sse2.c
-VP8_CX_SRCS-$(HAVE_SSE2) += encoder/x86/variance_impl_sse2.asm
-VP8_CX_SRCS-$(HAVE_SSE2) += encoder/x86/sad_sse2.asm
-VP8_CX_SRCS-$(HAVE_SSE2) += encoder/x86/dct_sse2.asm
-VP8_CX_SRCS-$(HAVE_SSE2) += encoder/x86/fwalsh_sse2.asm
-VP8_CX_SRCS-$(HAVE_SSE3) += encoder/x86/sad_sse3.asm
-VP8_CX_SRCS-$(HAVE_SSSE3) += encoder/x86/sad_ssse3.asm
-VP8_CX_SRCS-$(ARCH_X86)$(ARCH_X86_64) += encoder/x86/quantize_mmx.asm
-VP8_CX_SRCS-$(ARCH_X86)$(ARCH_X86_64) += encoder/x86/encodeopt.asm
+VP8_CX_SRCS-$(HAVE_SSE2) += encoder/x86/variance_impl_sse2.S
+VP8_CX_SRCS-$(HAVE_SSE2) += encoder/x86/sad_sse2.S
+VP8_CX_SRCS-$(HAVE_SSE2) += encoder/x86/dct_sse2.S
+VP8_CX_SRCS-$(HAVE_SSE2) += encoder/x86/fwalsh_sse2.S
+VP8_CX_SRCS-$(HAVE_SSE3) += encoder/x86/sad_sse3.S
+VP8_CX_SRCS-$(HAVE_SSSE3) += encoder/x86/sad_ssse3.S
+VP8_CX_SRCS-$(ARCH_X86)$(ARCH_X86_64) += encoder/x86/quantize_mmx.S
+VP8_CX_SRCS-$(ARCH_X86)$(ARCH_X86_64) += encoder/x86/encodeopt.S
 
 VP8_CX_SRCS-yes := $(filter-out $(VP8_CX_SRCS_REMOVE-yes),$(VP8_CX_SRCS-yes))
 
diff --git a/vp8/vp8dx.mk b/vp8/vp8dx.mk
index e6af543..76fd95c 100644
--- a/vp8/vp8dx.mk
+++ b/vp8/vp8dx.mk
@@ -73,4 +73,4 @@ INSTALL-LIBS-yes += include/vp8.h include/vp8dx.h
 
 VP8_DX_SRCS-$(ARCH_X86)$(ARCH_X86_64) += decoder/x86/dequantize_x86.h
 VP8_DX_SRCS-$(ARCH_X86)$(ARCH_X86_64) += decoder/x86/x86_dsystemdependent.c
-VP8_DX_SRCS-$(HAVE_MMX) += decoder/x86/dequantize_mmx.asm
+VP8_DX_SRCS-$(HAVE_MMX) += decoder/x86/dequantize_mmx.S
diff --git a/vpx_ports/emms.S b/vpx_ports/emms.S
new file mode 100644
index 0000000..600ff74
--- /dev/null
+++ b/vpx_ports/emms.S
@@ -0,0 +1,39 @@
+//
+//  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
+//
+//  Use of this source code is governed by a BSD-style license and patent
+//  grant that can be found in the LICENSE file in the root of the source
+//  tree. All contributing project authors may be found in the AUTHORS
+//  file in the root of the source tree.
+//
+
+
+#include "x86_abi_support.S"
+
+.text
+    global sym(vpx_reset_mmx_state)
+sym(vpx_reset_mmx_state):
+    emms
+    ret
+
+
+#ifdef _M_X64
+
+global sym(vpx_winx64_fldcw)
+sym(vpx_winx64_fldcw):
+    sub   rsp, 8
+    mov   [rsp], rcx // win x64 specific
+    fldcw [rsp]
+    add   rsp, 8
+    ret
+
+
+global sym(vpx_winx64_fstcw)
+sym(vpx_winx64_fstcw):
+    sub   rsp, 8
+    fstcw [rsp]
+    mov   rax, [rsp]
+    add   rsp, 8
+    ret
+
+#endif
diff --git a/vpx_ports/emms.asm b/vpx_ports/emms.asm
deleted file mode 100644
index 03e3499..0000000
--- a/vpx_ports/emms.asm
+++ /dev/null
@@ -1,37 +0,0 @@
-;
-;  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
-;
-;  Use of this source code is governed by a BSD-style license and patent
-;  grant that can be found in the LICENSE file in the root of the source
-;  tree. All contributing project authors may be found in the AUTHORS
-;  file in the root of the source tree.
-;
-
-
-%include "x86_abi_support.asm"
-
-section .text
-    global sym(vpx_reset_mmx_state)
-sym(vpx_reset_mmx_state):
-    emms
-    ret
-
-
-%ifidn __OUTPUT_FORMAT__,x64
-global sym(vpx_winx64_fldcw)
-sym(vpx_winx64_fldcw):
-    sub   rsp, 8
-    mov   [rsp], rcx ; win x64 specific
-    fldcw [rsp]
-    add   rsp, 8
-    ret
-
-
-global sym(vpx_winx64_fstcw)
-sym(vpx_winx64_fstcw):
-    sub   rsp, 8
-    fstcw [rsp]
-    mov   rax, [rsp]
-    add   rsp, 8
-    ret
-%endif
diff --git a/vpx_ports/x86_abi_support.S b/vpx_ports/x86_abi_support.S
new file mode 100644
index 0000000..a390ae9
--- /dev/null
+++ b/vpx_ports/x86_abi_support.S
@@ -0,0 +1,231 @@
+//
+//  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
+//
+//  Use of this source code is governed by a BSD-style license and patent
+//  grant that can be found in the LICENSE file in the root of the source
+//  tree. All contributing project authors may be found in the AUTHORS
+//  file in the root of the source tree.
+//
+
+
+#include "vpx_config.S"
+
+// 32/64 bit compatibility macros
+//
+// In general, we make the source use 64 bit syntax, then twiddle with it using
+// the preprocessor to get the 32 bit syntax on 32 bit platforms.
+//
+#if defined __x86_64__
+# define ABI_IS_32BIT 0
+#elif defined __i386__
+# define ABI_IS_32BIT 1
+#else
+# error "arch neither x86_64 nor i?86"
+#endif
+
+#if ABI_IS_32BIT
+# define rax eax
+# define rbx ebx
+# define rcx ecx
+# define rdx edx
+# define rsi esi
+# define rdi edi
+# define rsp esp
+# define rbp ebp
+# define movsxd mov
+#endif
+
+#define global .global
+#define extern .extern
+#define align .align
+#define MMWORD qword
+
+
+// sym()
+// Return the proper symbol name for the target ABI.
+//
+// Certain ABIs, notably MS COFF and Darwin MACH-O, require that symbols
+// with C linkage be prefixed with an underscore.
+//
+#ifdef __gnu_linux__
+# define sym(x) x
+#else
+# define sym(x) _ ## x
+#endif
+
+// arg()
+// Return the address specification of the given argument
+//
+#if ABI_IS_32BIT
+# define arg(x) [rbp+8+4*x]
+ // 64 bit MS-Windows ABI passes arguments in registers. This is a workaround
+ // to get up and running quickly. Relies on SHADOW_ARGS_TO_STACK
+#elif defined _M_X64
+# define arg(x) [rbp+16+8*x]
+#else
+# define arg(x) [rbp-8-8*x]
+#endif
+
+// REG_SZ_BYTES, REG_SZ_BITS
+// Size of a register
+#if ABI_IS_32BIT
+# define REG_SZ_BYTES 4
+# define REG_SZ_BITS  32
+#else
+# define REG_SZ_BYTES 8
+# define REG_SZ_BITS  64
+#endif
+
+
+// ALIGN_STACK <alignment> <register>
+// This macro aligns the stack to the given alignment (in bytes). The stack
+// is left such that the previous value of the stack pointer is the first
+// argument on the stack (ie, the inverse of this macro is 'pop rsp.')
+// This macro uses one temporary register, which is not preserved, and thus
+// must be specified as an argument.
+    .macro      ALIGN_STACK alignment, register
+    mov         \register, rsp
+    and         rsp, -\alignment
+    sub         rsp, \alignment - REG_SZ_BYTES
+    push        \register
+    .endm
+
+
+// PIC macros
+//
+#if CONFIG_PIC
+# if ABI_IS_32BIT
+#  if defined __gnu_linux__
+
+#define GET_GOT_REG rbx
+    .macro GET_GOT reg
+    .ifnc \reg, GET_GOT_REG
+    .error "Unsupported GET_GOT parameter"
+    .endif
+    push \reg
+    call 1f
+1:  pop \reg
+    add \reg, _GLOBAL_OFFSET_TABLE_ - 1b
+    .endm
+#   define GET_GOT GET_GOT
+#   define GLOBAL(symname) symname@GOTOFF + GET_GOT_REG
+    .macro RESTORE_GOT
+    pop GET_GOT_REG
+    .endm
+#   define RESTORE_GOT RESTORE_GOT
+
+#  elif defined __MACH__ /* && CONFIG_PIC && ABI_IS_32BIT */
+
+#   error "FIXME"
+
+#  endif /* __MACH__; && CONFIG_PIC && ABI_IS_32BIT */
+# else /* ! ABI_IS_32BIT; && CONFIG_PIC */
+#   if defined __gnu_linux__ /* && CONFIG_PIC && ! ABI_IS_32BIT */
+
+#    define GLOBAL(symname) symname + rip
+
+#  endif /* __gnu_linux__; && CONFIG_PIC && ! ABI_IS_32BIT */
+# endif /* ! ABI_IS_32BIT; && CONFIG_PIC */
+#endif /* CONFIG_PIC */
+
+#if defined __gnu_linux__ && CONFIG_PIC
+# define WRT_PLT_internal(x) x ## @PLT
+# define WRT_PLT(x) WRT_PLT_internal (x)
+#endif
+
+#ifndef GET_GOT
+ .macro GET_GOT reg
+ .endm
+#endif
+
+#ifndef GLOBAL
+# define GLOBAL(symname) symname
+#endif
+
+#ifndef RESTORE_GOT
+# define RESTORE_GOT
+#endif
+
+#ifndef WRT_PLT
+# define WRT_PLT(x) x
+#endif
+
+#if ABI_IS_32BIT
+
+    .macro SHADOW_ARGS_TO_STACK argc
+    .endm
+# define UNSHADOW_ARGS
+
+#else /* ! ABI_IS_32BIT */
+# if defined _M_X64
+
+    .macro SHADOW_ARGS_TO_STACK argc
+    .ifgt \argc - 0
+     mov arg(0),rcx
+    .endif
+    .ifgt \argc - 1
+     mov arg(1),rdx
+    .endif
+    .ifgt \argc - 2
+     mov arg(2),r8
+    .endif
+    .ifgt \argc - 3
+     mov arg(3),r9
+    .endif
+    .endm
+
+# else /* ! _M_X64 */
+
+    .macro SHADOW_ARGS_TO_STACK argc
+    .ifgt \argc - 0
+     push rdi
+    .endif
+    .ifgt \argc - 1
+     push rsi
+    .endif
+    .ifgt \argc - 2
+     push rdx
+    .endif
+    .ifgt \argc - 3
+     push rcx
+    .endif
+    .ifgt \argc - 4
+     push r8
+    .endif
+    .ifgt \argc - 5
+     push r9
+    .endif
+    .ifgt \argc - 6
+     mov rax,[rbp+16]
+     push rax
+    .endif
+    .ifgt \argc - 7
+     mov rax,[rbp+24]
+     push rax
+    .endif
+    .ifgt \argc - 8
+     mov rax,[rbp+32]
+     push rax
+    .endif
+    .endm
+
+# endif /* ! _M_X64 */
+
+# define UNSHADOW_ARGS mov rsp, rbp
+
+#endif
+
+
+// Name of the rodata section
+//
+// .rodata seems to be an elf-ism, as it doesn't work on OSX.
+//
+#ifdef __MACH__
+
+# define SECTION_RODATA .text
+
+#else
+
+# define SECTION_RODATA .section .rodata
+
+#endif
diff --git a/vpx_ports/x86_abi_support.asm b/vpx_ports/x86_abi_support.asm
deleted file mode 100644
index db8208f..0000000
--- a/vpx_ports/x86_abi_support.asm
+++ /dev/null
@@ -1,231 +0,0 @@
-;
-;  Copyright (c) 2010 The VP8 project authors. All Rights Reserved.
-;
-;  Use of this source code is governed by a BSD-style license and patent
-;  grant that can be found in the LICENSE file in the root of the source
-;  tree. All contributing project authors may be found in the AUTHORS
-;  file in the root of the source tree.
-;
-
-
-%include "vpx_config.asm"
-
-; 32/64 bit compatibility macros
-;
-; In general, we make the source use 64 bit syntax, then twiddle with it using
-; the preprocessor to get the 32 bit syntax on 32 bit platforms.
-;
-%ifidn __OUTPUT_FORMAT__,elf32
-%define ABI_IS_32BIT 1
-%elifidn __OUTPUT_FORMAT__,macho32
-%define ABI_IS_32BIT 1
-%elifidn __OUTPUT_FORMAT__,win32
-%define ABI_IS_32BIT 1
-%else
-%define ABI_IS_32BIT 0
-%endif
-
-%if ABI_IS_32BIT
-%define rax eax
-%define rbx ebx
-%define rcx ecx
-%define rdx edx
-%define rsi esi
-%define rdi edi
-%define rsp esp
-%define rbp ebp
-%define movsxd mov
-%endif
-
-
-; sym()
-; Return the proper symbol name for the target ABI.
-;
-; Certain ABIs, notably MS COFF and Darwin MACH-O, require that symbols
-; with C linkage be prefixed with an underscore.
-;
-%ifidn   __OUTPUT_FORMAT__,elf32
-%define sym(x) x
-%elifidn __OUTPUT_FORMAT__,elf64
-%define sym(x) x
-%elifidn __OUTPUT_FORMAT__,x64
-%define sym(x) x
-%else
-%define sym(x) _ %+ x
-%endif
-
-; arg()
-; Return the address specification of the given argument
-;
-%if ABI_IS_32BIT
-  %define arg(x) [ebp+8+4*x]
-%else
-  ; 64 bit ABI passes arguments in registers. This is a workaround to get up
-  ; and running quickly. Relies on SHADOW_ARGS_TO_STACK
-  %ifidn __OUTPUT_FORMAT__,x64
-    %define arg(x) [rbp+16+8*x]
-  %else
-    %define arg(x) [rbp-8-8*x]
-  %endif
-%endif
-
-; REG_SZ_BYTES, REG_SZ_BITS
-; Size of a register
-%if ABI_IS_32BIT
-%define REG_SZ_BYTES 4
-%define REG_SZ_BITS  32
-%else
-%define REG_SZ_BYTES 8
-%define REG_SZ_BITS  64
-%endif
-
-
-; ALIGN_STACK <alignment> <register>
-; This macro aligns the stack to the given alignment (in bytes). The stack
-; is left such that the previous value of the stack pointer is the first
-; argument on the stack (ie, the inverse of this macro is 'pop rsp.')
-; This macro uses one temporary register, which is not preserved, and thus
-; must be specified as an argument.
-%macro ALIGN_STACK 2
-    mov         %2, rsp
-    and         rsp, -%1
-    sub         rsp, %1 - REG_SZ_BYTES
-    push        %2
-%endmacro
-
-
-;
-; The Microsoft assembler tries to impose a certain amount of type safety in
-; its register usage. YASM doesn't recognize these directives, so we just
-; %define them away to maintain as much compatibility as possible with the
-; original inline assembler we're porting from.
-;
-%idefine PTR
-%idefine XMMWORD
-%idefine MMWORD
-
-
-; PIC macros
-;
-%if ABI_IS_32BIT
-  %if CONFIG_PIC=1
-  %ifidn __OUTPUT_FORMAT__,elf32
-    %define WRT_PLT wrt ..plt
-    %macro GET_GOT 1
-      extern _GLOBAL_OFFSET_TABLE_
-      push %1
-      call %%get_got
-      %%get_got:
-      pop %1
-      add %1, _GLOBAL_OFFSET_TABLE_ + $$ - %%get_got wrt ..gotpc
-      %undef GLOBAL
-      %define GLOBAL + %1 wrt ..gotoff
-      %undef RESTORE_GOT
-      %define RESTORE_GOT pop %1
-    %endmacro
-  %elifidn __OUTPUT_FORMAT__,macho32
-    %macro GET_GOT 1
-      push %1
-      call %%get_got
-      %%get_got:
-      pop %1
-      add %1, fake_got - %%get_got
-      %undef GLOBAL
-      %define GLOBAL + %1 - fake_got
-      %undef RESTORE_GOT
-      %define RESTORE_GOT pop %1
-    %endmacro
-  %endif
-  %endif
-%else
-  %macro GET_GOT 1
-  %endmacro
-  %define GLOBAL wrt rip
-  %ifidn __OUTPUT_FORMAT__,elf64
-    %define WRT_PLT wrt ..plt
-  %endif
-%endif
-%ifnmacro GET_GOT
-    %macro GET_GOT 1
-    %endmacro
-    %define GLOBAL
-%endif
-%ifndef RESTORE_GOT
-%define RESTORE_GOT
-%endif
-%ifndef WRT_PLT
-%define WRT_PLT
-%endif
-
-%if ABI_IS_32BIT
-  %macro SHADOW_ARGS_TO_STACK 1
-  %endm
-  %define UNSHADOW_ARGS
-%else
-%ifidn __OUTPUT_FORMAT__,x64
-  %macro SHADOW_ARGS_TO_STACK 1 ; argc
-    %if %1 > 0
-        mov arg(0),rcx
-    %endif
-    %if %1 > 1
-        mov arg(1),rdx
-    %endif
-    %if %1 > 2
-        mov arg(2),r8
-    %endif
-    %if %1 > 3
-        mov arg(3),r9
-    %endif
-  %endm
-%else
-  %macro SHADOW_ARGS_TO_STACK 1 ; argc
-    %if %1 > 0
-        push rdi
-    %endif
-    %if %1 > 1
-        push rsi
-    %endif
-    %if %1 > 2
-        push rdx
-    %endif
-    %if %1 > 3
-        push rcx
-    %endif
-    %if %1 > 4
-        push r8
-    %endif
-    %if %1 > 5
-        push r9
-    %endif
-    %if %1 > 6
-        mov rax,[rbp+16]
-        push rax
-    %endif
-    %if %1 > 7
-        mov rax,[rbp+24]
-        push rax
-    %endif
-    %if %1 > 8
-        mov rax,[rbp+32]
-        push rax
-    %endif
-  %endm
-%endif
-  %define UNSHADOW_ARGS mov rsp, rbp
-%endif
-
-
-; Name of the rodata section
-;
-; .rodata seems to be an elf-ism, as it doesn't work on OSX.
-;
-%ifidn __OUTPUT_FORMAT__,macho64
-%define SECTION_RODATA section .text
-%elifidn __OUTPUT_FORMAT__,macho32
-%macro SECTION_RODATA 0
-section .text
-fake_got:
-%endmacro
-%else
-%define SECTION_RODATA section .rodata
-%endif
